<!DOCTYPE html>
<html xmlns="https://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
  <html>
  <title>API Evangelist </title>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
  <!--[if lte IE 8]><script src="/assets/js/ie/html5shiv.js"></script><![endif]-->
  <link rel="stylesheet" href="/assets/css/main.css" />
  <link rel="stylesheet" href="/assets/css/bootstrap.min.css" />
  <!--[if lte IE 9]><link rel="stylesheet" href="/assets/css/ie9.css" /><![endif]-->
  <!--[if lte IE 8]><link rel="stylesheet" href="/assets/css/ie8.css" /><![endif]-->

  <!-- Icons -->
  <link rel="shortcut icon" type="image/x-icon" href="https://apievangelist.com/favicon.ico">
	<link rel="icon" type="image/x-icon" href="https://apievangelist.com/favicon.ico">

  <link rel="alternate" type="application/rss+xml" title="API Evangelist Blog - RSS 2.0" href="https://apievangelist.com/blog.xml" />
  <link rel="alternate" type="application/atom+xml" title="API Evangelist Blog - Atom" href="https://apievangelist.com/atom.xml">

  <!-- JQuery -->
  <script src="/js/jquery-latest.min.js" type="text/javascript" charset="utf-8"></script>
  <script src="/js/bootstrap.min.js" type="text/javascript" charset="utf-8"></script>
  <script src="/js/utility.js" type="text/javascript" charset="utf-8"></script>

  <!-- Github.js - http://github.com/michael/github -->
  <script src="/js/github.js" type="text/javascript" charset="utf-8"></script>

  <!-- Cookies.js - http://github.com/ScottHamper/Cookies -->
  <script src="/js/cookies.js"></script>

  <!-- D3.js http://github.com/d3/d3 -->
  <script src="/js/d3.v3.min.js"></script>

  <!-- js-yaml - http://github.com/nodeca/js-yaml -->
  <script src="/js/js-yaml.min.js"></script>

  <script src="/js/subway-map-1.js" type="text/javascript"></script>

  <style type="text/css">

    .gist {width:100% !important;}
    .gist-file
    .gist-data {max-height: 500px;}

    /* The main DIV for the map */
    .subway-map
    {
        margin: 0;
        width: 110px;
        height: 5000px;
        background-color: white;
    }

    /* Text labels */
    .text
    {
        text-decoration: none;
        color: black;
    }

    #legend
    {
    	border: 1px solid #000;
        float: left;
        width: 250px;
        height:400px;
    }

    #legend div
    {
        height: 25px;
    }

    #legend span
    {
        margin: 5px 5px 5px 0;
    }
    .subway-map span
    {
        margin: 5px 5px 5px 0;
    }
    
    .container {
        position: relative;
        width: 100%;
        height: 0;
        padding-bottom: 56.25%;
    }
    .video {
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
    }    

    </style>

    <meta property="og:url" content="">
    <meta property="og:type" content="website">
    <meta property="og:title" content="API Evangelist">
    <meta property="og:site_name" content="API Evangelist">
    <meta property="og:description" content="A network of research sites dedicated to the technology, business, and politics of APIs.">
    <meta property="og:image" content="http://s3.amazonaws.com/kinlane-productions/api-evangelist/t-shirts/KL_InApiWeTrust-1000.png">

    <meta name="twitter:url" content="">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="API Evangelist">
    <meta name="twitter:site" content="API Evangelist">
    <meta name="twitter:description" content="A network of research sites dedicated to the technology, business, and politics of APIs.">
    
      <meta name="twitter:creator" content="@apievangelist">
    
    <meta property="twitter:image" content="http://s3.amazonaws.com/kinlane-productions/api-evangelist/t-shirts/KL_InApiWeTrust-1000.png">


</head>

  <body>

			<div id="wrapper">
					<div id="main">
						<div class="inner">

              <header id="header">
	<a href="http://apievangelist.com" class="logo"><img src="https://kinlane-productions2.s3.amazonaws.com/api-evangelist/api-evangelist-logo-400.png" width="75%" /></a>
	<ul class="icons">
		<li><a href="https://twitter.com/apievangelist" class="icon fa-twitter"><span class="label">Twitter</span></a></li>
		<li><a href="https://github.com/api-evangelist" class="icon fa-github"><span class="label">Github</span></a></li>
		<li><a href="https://www.linkedin.com/company/api-evangelist/" class="icon fa-linkedin"><span class="label">LinkedIn</span></a></li>
		<li><a href="http://apievangelist.com/atom.xml" class="icon fa-rss"><span class="label">RSS</span></a></li>
	</ul>
</header>

    	        <section>
	<div class="content">

		<h3>The API Evangelist Blog</h3>

	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/02/05/automated-mapping-of-the-api-universe-with-charles-proxy-dropbox-openapi-spec-and-some-custom-apis/"><img src="https://s3.amazonaws.com/kinlane-productions2/charles-proxy/reclaim-charles-proxy.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/02/05/automated-mapping-of-the-api-universe-with-charles-proxy-dropbox-openapi-spec-and-some-custom-apis/">Automated Mapping Of The API Universe With Charles Proxy, Dropbox, OpenAPI Spec, And Some Custom APIs</a></h3>
			<p><em>05 Feb 2016</em></p>
			<p>I have been working hard for about a year now trying to craft machine readable API definitions for the leading APIs out there. I've written before about my use of Charles Proxy to generate OpenAPI Spec files, something I'm evolving over the last couple days, making it more automated, and hopefully making my mapping of the API universe much more efficient. Hand crafting even the base API definition for any API is time consuming, which is something that swells quickly to being hours when you consider the finish work that required, so I was desperately looking how I could automate this aspect of my operations more. I have two modes when looking at an API, review mode where I'm documenting the API and its surrounding operations, with the second being about actually using the API. While I will still be reviewing APIs, my goal is to immediately begin actually using an API, where I feel most of the value is at, while also kicking off the documentation process in the same motion. Logging All Of My Traffic Using Charles Proxy On MachineUsing Charles Proxy, I route all of my network traffic on my Macbook Pro through a single proxy which I am in control of, allowing me to log every Internet location my computer visits throughout the day. It is something I cannot leave running 100% of the time, as it breaks certificates, sets of security warnings from a number of destinations, but is something I can run about 75% of my world through--establishing a pretty interesting map of the resources I consume, and produce on each day.&nbsp; Auto Saving Charles Proxy Session Files Every 30 MinutesWhile running running Charles Proxy, I have it setup to auto save a session XML every 30 minutes, giving me bite size snapshots of transaction throughout my day. I turn Charles Proxy on or off, depending on what I am doing. I selected to save as a session XML...[<a href="/2016/02/05/automated-mapping-of-the-api-universe-with-charles-proxy-dropbox-openapi-spec-and-some-custom-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/02/04/offering-a-monthly-to-annual-toggle-for-your-api-pricing-page/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/auth0-pricing-switch.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/02/04/offering-a-monthly-to-annual-toggle-for-your-api-pricing-page/">Offering A Monthly To Annual Toggle For Your API Pricing Page</a></h3>
			<p><em>04 Feb 2016</em></p>
			<p>I am continuing to work through notes from a recent push forward of my API monetization, and API plan research. Something that yielded a number of valuable nuggets &nbsp;that I think API providers should be considering when crafting their own strategy. One of the pricing pages I was looking at as part of my research, was from authentication provider Auth0, which provided a nice way for allowing their customers to toggle between monthly or annual pricing.

I organize small elements like this, into my lists of common API building blocks, which help API providers, and API service providers, with a list of things they can consider applying in their own strategies. I like the approach from Auth0 especially, because the toggle actually changes the plan pricing on the page, reflecting the shorter, or longer term costs associated with their authentication services.
Whether your intent is to offer price breaks for longer term relationships, or helping your customers better understand and manage their costs, a simple thing like a time-frame toggle, that adjusts pricing, could make a positive impact. Anyhoo, I just wanted to share this nugget with you, as I was adding it as a building block to my API plan research.
[<a href="/2016/02/04/offering-a-monthly-to-annual-toggle-for-your-api-pricing-page/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/01/30/if-you-are-proud-of-your-api-patents-publish-your-portfolio-and-showcase-them/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-showcase-something.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/01/30/if-you-are-proud-of-your-api-patents-publish-your-portfolio-and-showcase-them/">If You Are Proud Of Your API Patents Publish Your Portfolio And Showcase Them</a></h3>
			<p><em>30 Jan 2016</em></p>
			<p>I'm going to keep beating the patent API drumbeat, until I bring more awareness to the topic, and shine a light on what is going on. While I will still be my usual self and call out the worst behavior in the space, I am also going to try and be a little more friendlier around my views, and try and help bring more options to the table. This is a serious problem, nobody is talking about, and one that has many dimensions and nuances--if you want my raw stance on API patents, you can read it here.&nbsp; One area I wanted to try and cover, in response to my friends trying to convince me their aren't bad people, in having patents. I know you aren't, and it isn't my goal to make you look bad in this, it is only to shine light on the entire process, how broken it is, and call out the worst offenders. If you truly believe in patents, protecting the work you've done, and that your intentions are good, share your patent portfolio with the world, and showcase it like you do the other aspects of the work you do. You will craft a press release about everything else you do, do the same for your patents.&nbsp; I do not think patents are bad. I think ill-conceived patent ideas, that haven't been properly vetted by the under resourced USPTO, that are used in back door dealings as leverage, and litigated in a court of law are bad. I'll take your word that your patents are good, and you aren't operating in any of these areas, if you are public, transparent, and openly proud of them, as you state in private conversations. Part of the purpose of my research is to encourage good behavior in the sector, by highlight the common building blocks of the space. I think I will add a patent portfolio building to my research. While I...[<a href="/2016/01/30/if-you-are-proud-of-your-api-patents-publish-your-portfolio-and-showcase-them/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/01/29/parse-shutting-down-maybe-we-should-lower-our-expectations-of-tech-just-a-little-bit/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/parse-moving-on.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/01/29/parse-shutting-down-maybe-we-should-lower-our-expectations-of-tech-just-a-little-bit/">Parse Shutting Down: Maybe We Should Lower Our Expectations Of Tech Just A Little Bit</a></h3>
			<p><em>29 Jan 2016</em></p>
			<p>The mobile backend as a service (MBaaS) platform Parse is shutting down. I started tracking on Parse as part of my BaaS research a couple years back, something that resulted in having all of the BaaS providers, including Ilya Sukhar (@) of Parse, on stage at @APIStrat NYC in early 2013--this conversation was just a couple months before Parse was acquired by Facebook.&nbsp; Parse was widely consider to be the top BaaS platform, which resulted in wide adoption, something that I'm sure grew expoentitally after the purchase by Facebook. Parse is giving everyone a year to migrate, providing a database migration tool, as well as open sourcing a version of the platform. Which I think is a pretty fair deprecation strategy for customers, even with the unexpected news. Despite the tec highway is littered with these types of acquisitions, and deprecations, the tech blogosphere, and social bookmarkosphere (is that a word?), loves to sqawk when these happen. Competitors like AWS, Google, and others love to invite you to come use their platform, and the technorati love to point out how you cannot depend on any platform--which is the truth.&nbsp; Personally, I enjoy taking these moments to explore why the space think technology is such an asbsolute, where these ways of thought rarely exist in other sectors.&nbsp;I think there are a couple distinct things at play: Promises Of Tech Providers - In an effort to get new users, tech solution providers make some pretty wild promises of how they'll make your life easier, do all the hard work for you, all you have to do is just believe in them. Never mentioning you aren't really their true target customer, an acquisition by big tech company is their true customer. Religious Belief In Technology - Like the marketing of providers, developers, and other folks who drink the Silicon Valley Kool-Aid, really, really, really belive that technology is the answer, it will save us, and all of this...[<a href="/2016/01/29/parse-shutting-down-maybe-we-should-lower-our-expectations-of-tech-just-a-little-bit/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/01/29/my-vision-for-one-possible-future-of-the-api-life-cycle-present-in-a-realtime-subway-map-for-helsinki/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/helsinki-subway-map.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/01/29/my-vision-for-one-possible-future-of-the-api-life-cycle-present-in-a-realtime-subway-map-for-helsinki/">My Vision For One Possible Future Of The API Life Cycle Present In A Real-Time Subway Map For Helsinki</a></h3>
			<p><em>29 Jan 2016</em></p>
			<p>If you caught my keynotes at @Defrag and @APIStrat last year, you know I'm working on using the subway map as a method for visualizing, understand, and eventually exploration of the API life cycle. I feel like the subway map concept, has helped us find a globally universal way of understanding the transport of humans, via some very complex transportation systems, in cities around the globe--something I feel can be applied to world of APIs. I was giving a version of my API life cycle talk to a group in Finland the other evening (their morning), and someone in the audience sent me a link to the real-time subway map for Helsinki. If you watch it closely, it updates based upon where the trains are, sharing times and locations.&nbsp; Click To See Real Interactive Map This is what I'm working for across the API space. I see the subway map analogy being key to understanding our API life cycle, across the 40+ areas I track on in my research, as well as a potential real-time window to understanding how each API is being used by employing modern API management infrastructure like 3Scale. API providers (which ALL companies will be shortly) should have real-time windows into where each of their vital API resources are in the life cycle, whether they are being designed, developed, managed or deprecated. We should also be able to experience real-time views of how are APIs are being consumed, which apps are currently making calls, and potentially even security threats against our API infrastructure. The subway map is also providing me a way to educate new, and existing API folks in the space, providing them with an interactive journey within the design, definition, deployment, management, monitoring, and 40+ other areas of the API life cycle I keep an eye on. I'm optimistic for what is possible, when it comes to applying the subway map concept to the world of APIs, but like...[<a href="/2016/01/29/my-vision-for-one-possible-future-of-the-api-life-cycle-present-in-a-realtime-subway-map-for-helsinki/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/01/29/breaking-out-api-support-into-a-separate-research-area/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-support.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/01/29/breaking-out-api-support-into-a-separate-research-area/">Breaking Out API Support Into A Separate Research Area</a></h3>
			<p><em>29 Jan 2016</em></p>
			<p>
Supporting your community is not unique to the API space, but supporting API operations does have some unique needs, and approaches that are proven by leading platforms. Like other areas of my research, I'm pulling out API support into its own area, so I can start shining a light on successful patterns I find in the area of API support.
Two things pushed me to spin out this research area. One, I was tagging more blog posts, and other resources as support, and without a dedicated research area, this information would rarely float to the surface for me. Two, my partners over at Cloud Elements have an API hub dedicated to "Help Desk". While their aggregate API solution is targeting beyond the API community, it is API driven, and can also be applied to providing an aggregate support solution for API communities.
As with most of the areas of the API space, there are several dimensions to how APIs are being applied to support customers, and online communities. With my research, I will focus on tracking on approaches to community support for API providers, and API service providers. There will also be that layer of tracking on help desk and support platforms who employ APIs, as well as API aggregate and API interoperability solutions from leaders (and my partners) in the space like Cloud Elements.
You can visit my API support research via its Github repository, and I will try to make sure and continue linking to it from my API management research, where it was born out of.
[<a href="/2016/01/29/breaking-out-api-support-into-a-separate-research-area/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/01/27/my-stance-on-apis-and-patents/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-certificate.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/01/27/my-stance-on-apis-and-patents/">My Stance On APIs And Patents</a></h3>
			<p><em>27 Jan 2016</em></p>
			<p>My post the other day on the hypermedia API focused patents from ElasticPath, has resulted in some very interesting conversations, with folks trying to understand this world, to those who are patent believers, and those who are just doing what they have to--in a world they do not control. This is why I write these stories, and frankly, it is why I am looking to push the patent conversation to new levels, to bring all y'all out of the woodwork. In a collective response to these conversations, I wanted to share my stance on patents, when it comes to the world of APIs. Let's start closer to the median, and talk about patents, and the world that "exists today", and explore the common responses when you look to discuss API patents in the current climate. I Do Not Want To Do Patents, I Only Do Them As a Defensive Response!C'mon Kin! You do not understand why we have to do patents. We only do them to protect our space, against the worst, of the worst in the tech space--you know SAP, Sun, Oracle, Microsoft, IBM, and the other evil that lurk (the ones with most patents). I get it. It is the same reason all my redneck, and now hippie friends own guns--those over there have guns, and I need to defend myself. You never know when one of those situations will happen, and I will need to defend what I've invested so much to build. I Need To Generate Intellectual Property (IP), Because It Is How We Define Value!If I could spend my time as I wish, I wouldn't be writing up patents, and spending money on the patent process. My investors, CEO, and my wider stakeholder's expect that, as a startup, I patent the most valuable of the exhaust from our operations. Ok. So you do this because the people who give you money tell you to? Or do you do this because...[<a href="/2016/01/27/my-stance-on-apis-and-patents/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/01/27/embedding-your-language-sdks-in-your-apiary-documentation-using-apimatic/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/company/logos/apimatic-logo.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/01/27/embedding-your-language-sdks-in-your-apiary-documentation-using-apimatic/">Embedding Your Language SDK(s) In Your Apiary Documentation Using APIMATIC</a></h3>
			<p><em>27 Jan 2016</em></p>
			<p>I'm seeing a resurgence in my embeddable API research lately, based upon signals I'm seeing across the space, and conversations I'm having with folks. The interesting part for me is that this wave isn't about API providers like Twitter and Faceobok using JavaScript to create buttons, badges, and widgets. This latest round is about API service providers making their services more accessible to both API providers, and API consumers, using embeddable tooling, and most importantly, API definitions. API driven embeddable tools comes in many shapes and sizes, but is something I work hard to understand, and track on in the space. I have several new embeddable stories to talk about this week, but today's is from my friends over at APIMATIC, as well as Apiary. The two service providers now offer the ability to embed your APIMATIC driven SDKs, into your Apiary driven API documentation. All you do, is plug in the URL of your Apiary portal page for your API, into your APIMATC account, and you are returned embeddable markdown you can paste into your Apiary API documentation--Apiary addresses your API design, documentation, testing and virtualization needs, and APIMATIC comes is with the API SDK assist.&nbsp; I like API service providers working together like this, it is something that makes API provider's and API consumer's lives easier. This approach to API service interoperability is what it will take to weave together the patchwork of API services that will be needed across the API life cycle. As more API service providers emerge to fill gaps in the life cycle, the ability to stitch these stops will grow more critical, something embeddability will contribute to. Depending on a single provider in 2016, is just not a reality, and I need the services that I depend on to work together. As I will work to showcase in future stories, embedability comes in many shapes and sizes. I'm hoping we are on the cusp of a new wave...[<a href="/2016/01/27/embedding-your-language-sdks-in-your-apiary-documentation-using-apimatic/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/01/27/api-definitions-are-the-contract-for-doing-business-with-apis/"><img src="https://www.youtube.com/embed/OrGPHBQ4dGo" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/01/27/api-definitions-are-the-contract-for-doing-business-with-apis/">API Definitions Are The Contract For Doing Business With APIs</a></h3>
			<p><em>27 Jan 2016</em></p>
			<p>I held a hangout with API Evangelist this morning, with Steve Willmot (@njyx) of @3scale, &amp; Jakub Nesetril (@jakubnesetril) of @apiaryio&nbsp;today, where we discussed API definitions. Both Steve and Jakub are CEOs of leading tech companies, who are taking frontline positions when it comes to the whole API definition conversation. My role in this hangout, was just bringing together these two API leaders, to discuss the most important topic facing us in the world of APIs. API definitions are touching on every aspect of the API life cycle, and as Steve and Jakub discuss, playing a central role in their businesses, and their customer's businesses. We published the hour and half conversation on Youtube, so you can join in, even if you couldn't make the hangout. &nbsp; &nbsp; The focus on API definitions being the contract, was the most important part of today's hangout for me. This wasn't a conversation about just Swagger, or API Blueprint, it was a discussion about the role API definitions play in the API life cycle, from the latest wave of API description formats like Swagger and Blueprint, to API discovery formats like APIs.json, and even media types, and schemas. These are the contracts we are using to communicate our ideas, generate code, setup tests, drive documentation, and make the API economy go roudn. This hangout was scheduled to be an hour, but there was so much to cover, we took it an extra 30 minutes. The conversation left me feeling like I need to do this more often, expanding on the API definition discussion, but also push into other important areas like API deployment, virtualization, discovery, monitoring, and the other almost 40 areas of the API lifecycle I track on. We'll see how much time i have to do these, but more importantly my ability to bring smart people like Steve and Jakub together--something I hope I can make it work. Thanks to Jakub and Steve for participating today!...[<a href="/2016/01/27/api-definitions-are-the-contract-for-doing-business-with-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/01/25/reverse-engineering-apis-from-the-common-apis-models-we-know/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-reverse-engineer.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/01/25/reverse-engineering-apis-from-the-common-apis-models-we-know/">Reverse Engineering APIs From The Common APIs Models We Know</a></h3>
			<p><em>25 Jan 2016</em></p>
			<p>As I work to complete more API definitions, with all API endpoints defined as an OpenAPI Spec, API Blueprint, and Postman Collection, with everything wrapped in a complete APIs.json index--I can't help but consider the importance of these definitions in helping others reverse engineer these APIs, to help apply in their own API design, development, and management processes. Whether or not you are learning about an API for consumption purposes, or learning about it from a providers perspective, there is a lot to learn from APIs that are defined using&nbsp;OpenAPI Spec, API Blueprint, and Postman Collection, and is something I'm working to push APIs.json to deliver on more. Right now I'm struggling to just get the basics of each API, its individual methods, parameters, and underlying schemas. I am also working to index their overall operations using APIs.json. Soon though, I will reach the point where I will have a nice collection of existing APIs defined, I will be able to do much, much more--this is what I'm planning for now. Now that I am closing in on having a couple hundred, complete (enough) API definitions for leading platforms, I think I will take another look through the stack, and evaluate how I can position them better to help potential API consumers, as well as API providers. API consumers are going to care about learning only what they need to get at the valuable resources made available via the API, while providers are going to want to better understand the API design, schemas, business models, and other aspects of the operations. I'm thinking more deeply the API provider and API consumer sides of the same coin, so when you land on the home page of any API service provider, there is personalized, easy to use, visual elements that draw you in to learn more about an existing API you already know about. Want to learn how to connect to APIs using Postman, here is a...[<a href="/2016/01/25/reverse-engineering-apis-from-the-common-apis-models-we-know/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/01/25/moving-towards-a-meaningful-set-of-icons-for-the-api-community/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/api-image.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/01/25/moving-towards-a-meaningful-set-of-icons-for-the-api-community/">Moving Towards A Meaningful Set Of Icons For The API Community</a></h3>
			<p><em>25 Jan 2016</em></p>
			<p>There are many inconsistencies I struggle with in the API space, and the lack of meaningful icons to express myself is one of them. I was meeting with my friend Jerome Louvel of Restlet this last week, and he also articulated (again), the lack of imagery that represents APIs. To understand what we are talking about simple icons, like what RSS has, but to represent an API, instead of an XML feed. When I need an image to represent an API, I always borrow the simple icon from the API Commons. Like my API Evangelist logo, it is a pretty simple, black and white, minimum viable representation of "API". The folks over at Restlet also have their own, image, that they use across the platform, and suggested it as one potential design that could be used. This is a concept that I would like to push forward. I think branding, and iconography is very important, and is something long overdue for the API space. I would like to see a single universal, community driven icon to represent the concept of a web API. I would also like to see similar icons for formats used across the space, as well as vendor specific icons. If you look at my personal API stack, as well as my overall stack, you see me using a mix of format, and vendor icons to document a pretty complex assortment of API driven resources, and information. I'd like to step this up a bit, be able to standardize across not just my network of sites, but the overall API community.&nbsp; I am guessing this is something I will have to slowly push forward, like the numerous other areas of my API industry research, but would love to hear your input, and see what else we could do to establish a common set of API industry icons. I'm already working with a handful of API vendors to define their API driven embeddable...[<a href="/2016/01/25/moving-towards-a-meaningful-set-of-icons-for-the-api-community/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/01/25/join-3scale-apiary-and-i-for-a-hangout-on-api-definitions-this-wednesday/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/serviceproviders/3scale-logo.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/01/25/join-3scale-apiary-and-i-for-a-hangout-on-api-definitions-this-wednesday/">Join @3Scale, @Apiary, And I For A Hangout On API Definitions This Wednesday</a></h3>
			<p><em>25 Jan 2016</em></p>
			<p>
Join me, Steve Willmott(@njyx) of 3Scale, and Jakub Nesetril(@jakubnesetril) of Apiary, for a hangout on API definitions this week. I wanted to explore&nbsp; doing more hangouts under the APIStrat, as well as API Evangelist brand(s)--for this one I wanted to bring together some experts to talk about the fast moving world of API definitions, as a Hangout with API Evangelist.
This Wednesday, January 27th, at 11:00 AM PST, the three of us will jump on a Google Hangout, and you are welcome to join in the conversation. We will be doing the gathering as a Hangout on Air, so that you can ask questions if you want, joining in the live conversation, or you can wait until after we are done, I will make sure and publish the video to Youtube.

Its a pretty important time for API definitions with the Swagger specification reborn as the OpenAPISpec, and Apiary, the creator of API Blueprint and MSON, also adopting OpenAPI Spec this last week, allowing you to design and mock your API in both formats. 3Scale was an earlier adopter of Swagger, and has taken a leadership position in shepherding it to into the Linux Foundation, and is a member of the governance working group.
I figured that it is a pretty good time to check-in with Steve and Jakub, on the current state of API definitions, and how they see them impacting their own platforms, as well as the overall API space. If you have any specific questions you'd like me to ask, or have any specific topics you'd like to see discussed, feel free to tweet at me. I'll tweet out the link for the event, but all you need to do is visit hangoutwith.apievangelist.com, this Wednesday at 11:00 PST, and join in the conversation.
[<a href="/2016/01/25/join-3scale-apiary-and-i-for-a-hangout-on-api-definitions-this-wednesday/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/01/25/a-new-open-source-interactive-api-documentation-from-folks-over-at-lucybot/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/lucyboty-api-console.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/01/25/a-new-open-source-interactive-api-documentation-from-folks-over-at-lucybot/">A New Open Source Interactive API Documentation From Folks Over At Lucybot</a></h3>
			<p><em>25 Jan 2016</em></p>
			<p>
I am happy to be showcasing a new open source, OpenAPI Spec driven, interactive API documentation, from the LucyBot team. The API definition driven documentation solution is one of the best implementations I've seen to date, and reflects the future of where API documentation should be going in my opinion. While the Swagger UI has significantly moved the API documentation conversation forward, it has never been the most attractive solution, pushing some API providers to use a more attractive, less interactive, open source solution from Slate.
The LucyBot API Console is both! It is API definition driven, using the OpenAPI Spec as its engine, but also provides a conversion tool for RAML, WADL, or API Blueprint. The LucyBot API Console is also very attractive, responsive, and flows much like Slate does, but goes much further by being an actual interactive API console, not just good looking, static docs. You can see Lucy Console in action over at AnyAPI, or as a small set that demonstrates different CSS variations.&nbsp;
I have forked, and started playing with the LucyBot API Console more--I encourage you to do the same. There are a number of features I'd like to see in there, like more embeddability, and templability of the UI, as well as some APIs.json support, and D3.js visualization integration--so I wil be getting more knowledgeable of the code base, and in tune with the road map. I know the LucyBot team is open sourcing the code to encourage contributions, and are looking for investment in dev and business resources to move the project forward--so get involved!
It is good to see the API definition driven API documentation conversation moving forward in 2016!
[<a href="/2016/01/25/a-new-open-source-interactive-api-documentation-from-folks-over-at-lucybot/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/01/23/the-new-api-definition-abstraction-layer-over-at-apiary/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-abstraction-2.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/01/23/the-new-api-definition-abstraction-layer-over-at-apiary/">The New API Definition Abstraction Layer Over At Apiary</a></h3>
			<p><em>23 Jan 2016</em></p>
			<p>I was on the road last week, so I didn't maintain my usual barrage of API analysis. As I go through my monitoring for the week, I'd say the biggest news of the week was Apiary's support of the OpenAPI Spec. I got a test drive of the support for the API definition format over the holidays, and was impressed with how smoothly Apiary integrated the OpenAPI Spec into their API design, virtualization, and management platform.&nbsp; Another very interesting dimension of the Apiary release for me, was how they seamlessly integrated the new API definition into their road map. This wasn't a switch to the OpenAPI Spec from API Blueprint, it was about opening up, embracing, and abstracting away of multiple API definition formats across their platform operations. As an API service provider, it is just smart business to support as many possible API definition formats as you possibly can. The 2016 road map for Apiary acknowledges the value of using the OpenAPI Spec, but still reflects the strengths that API Blueprint + MSON bring to the table.&nbsp; Last September, I walked around San Francisco with Jakub Nesetril (@jakubnesetril), the CEO of Apiary, talking about the need for an open abstraction layer to help us better define our API, across all stops of the API life cycle. This wee's OpenAPI Spec support at Apiary is Jakub's vision playing out, making sure the process of defining your APIs across the design, virtualization, and management areas of your API life cycle is as robust, and agile as it possibly can be. For me, this makes this weeks news much more than about Apiary abstracting away the complexity of switching between leading API definitions, than it is about their support for the OpenAPI Spec. I had beers with Emmanuel Paraskakis(@manp) and Jakub at the Toronado on Haight Street in San Francisco this week, and had another conversation with them about their abstraction layer, which helps them efficiently switch...[<a href="/2016/01/23/the-new-api-definition-abstraction-layer-over-at-apiary/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/01/18/taking-a-snapshot-of-just-the-essential-api-building-blocks-across-my-research/"><img src="http://essential.apievangelist.com/images/essential-api-building-blocks-covershot.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/01/18/taking-a-snapshot-of-just-the-essential-api-building-blocks-across-my-research/">Taking A Snapshot Of Just The Essential API Building Blocks Across My Research</a></h3>
			<p><em>18 Jan 2016</em></p>
			<p>My API industry research is constantly moving forward, shifting, and being added to--much like the space itself. As I work to update each of my research areas each week, my process involves adding any news I've curated, and changes to the companies who are doing things in the space, as well as add or remove any common building blocks I've identified. These building blocks are the common patterns I've identified by studying how API providers are operating, and what features API service providers are bringing to the table, for API providers to put to work. This last fall, in preparation for my keynotes at Defrag and APIStrat, I pushed forward much of my research, flushing out more of the building blocks across 20+ of my research areas. As I was preparing for another big push forward with my research, I wanted to stop and take a snapshot of just what I'd consider to be the essential building blocks across the most mature areas of my API monitoring research. I track almost 1000 stops along the modern API life cycle, but this snapshot represents what I'd consider to be a master list that API providers, and service providers should be considering as they design, develop, manage, and execute on almost 20 other areas of a modern API lifecycle. This snapshot is meant to be a guide to what I'm seeing in the space, which can be used as a checklist, in your own API strategy. I do not recommend every company do every thing listed in this document, but they are elements that you should be considering, and hopefully have a better understanding of. Like my other guides, this one is in beta. I'm adding a couple new areas to my research in January that will impact this work, and I will also be exposing links to other companies, services, and resources that support each building block. You can download via a PDF version, or access...[<a href="/2016/01/18/taking-a-snapshot-of-just-the-essential-api-building-blocks-across-my-research/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/01/13/the-four-categories-of-dwolla-api-consumers/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/dwolla-developer-home.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/01/13/the-four-categories-of-dwolla-api-consumers/">The Four Categories Of Dwolla API Consumers</a></h3>
			<p><em>13 Jan 2016</em></p>
			<p>
I just finished spending an hour talking with&nbsp;Brent Baker (@norcaljhawk), head of product for Dwolla, and Jordan Lampe (@JsLampe), about the vision behind the developer experience for their new developer portal. I will be able to craft many stories from the notes I generated during our conversation, but there was one aspect of how they view consumers of their ACH transfer API, I wanted to quickly share.
This portion part of our conversation came up when they mentioned how they broke up their API users, as they were rethinking the overall developer experience. They put API consumers into four distinct categories:

seeker - individual looking for a solution
implementer - individual implementing solution
maintainer - individual maintaining solution
hacker - individual playing with their solution

I think this is a great way to look at your API consumers. I've heard many different approaches to labeling your API consumer buckets, but I'd say this is the first time that I've heard it put so elegantly. A moment I couldn't help but ruin, by selfishly adding:

analyst - individual looking to understand role solution plays in big picture

You can't forget about us analyst types who will just talk about your APIs, and rarely actually do any "real work". ;-) Anyways, I just wanted to share this small part of our conversation. The Dwolla developer portal experience is rich with API management examples, that other API providers should be looking to emulate. I will keep processing the notes from our conversation, and share any other nuggets I collected during my walk through the API journey the Dwolla team has crafted within their new&nbsp;API portal.
[<a href="/2016/01/13/the-four-categories-of-dwolla-api-consumers/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/01/13/the-api-feedback-loop-your-feedback-powers-everything-we-do/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/company/logos/practice-fusion-logo.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/01/13/the-api-feedback-loop-your-feedback-powers-everything-we-do/">The API Feedback Loop: Your Feedback Powers Everything We Do</a></h3>
			<p><em>13 Jan 2016</em></p>
			<p>One of the benefits of doing an API, is so that you can take advantage of the potential for a community feedback loop, driven by internal groups, external partners, and even in some cases the pubic. Under my API management research, you can find a number of building blocks I recommend for helping power your feedback loop, but sometimes I like to just showcase examples of this in the wild, to show how it all can work. I was reading the&nbsp;Letter from our co-founder: 2016 Product vision, from Electronic Health Record (EHR) provider Practice Fusion, and I thought the heart of the blog post, represented a well functioning feedback loop. As Practice Fusion looked back over 2015, they noted the following activity: 798&nbsp;product ideas submitted&nbsp;with over 3,000 comments. 64&nbsp;community ideas already delivered&nbsp;as product features. 45&nbsp;new ideas currently being worked on. Acknowledging that this feedback "powers everything we do". They continue listing some of the major customer requests that were fulfilled in 2015, and close the letter with an "eye towards the future". It is a simple, but nice example of how a platform's community can drive the platform road map. Sure a lot of this comes from the SaaS side of the Practice Fusion operations, but it works in sync with the Practice Fusion developer community as well.&nbsp; The lesson from this one, to include in my overall research, is to always have a way to collect feedback from the community, tag ideas for discussion as potential additions to the road map, and carefully track on which ideas get delivered, and which ones end up being included in the road map. This is something that is pretty easy to do with Github Issue Management, which I use for my own personal projects, to drive both my road maps, and resulting change logs. This post also pushed me to begin tagging these types of stories, organizing them into a simple API playbook, full of API platform...[<a href="/2016/01/13/the-api-feedback-loop-your-feedback-powers-everything-we-do/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/01/13/just-the-best-parts-of-the-api-documentation-please/"><img src="https://s3.amazonaws.com/kinlane-productions2/api-evangelist/slate/slate-tripit.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/01/13/just-the-best-parts-of-the-api-documentation-please/">Just The Best Parts Of The API Documentation Please</a></h3>
			<p><em>13 Jan 2016</em></p>
			<p>I was just talking API documentation with&nbsp;Brent Baker (@norcaljhawk), and Jordan Lampe (@JsLampe) from&nbsp;Dwolla. As we were going through their API documentation, they mentioned how they were using Slate for the version 1.0 of their API documentation, but for this round they took what they felt were just the best parts of Slate, and were looking to craft a new experience.&nbsp; Interestingly I had written about their use of Slate for API docs back in 2014, so it makes sense for me to keep tracking on, but more importantly I think the move reflects the wider evolution of API documentation. If you aren't familiar with Slate, it is a very attractive way to document your APIs, that many API providers and consumers have latched on to. Slate, in contrast to the very utilitarian style of Swagger UI, has certain elements developer prefer--something I can see why, after looking at a lot of API docs. Dwolla's evolution from their old static API docs to Slate, and then to their current version&nbsp;highlighted two important aspects of the modern API documentation evolution for me. First, the feedback to the Dwolla team revealed that the three column format which Slate used for documentation, made the documentation seem like it was not part of the overall Dwolla experience--it was separate. Which is one unique thing Swagger UI did, is that allowed it to be embedded within any API portal, even though the look was not as attractive as Slate is. As they evolve overall their portal experience, Dwolla was sure they wanted to keep the code sample viewer, which allows for inline viewing of raw, PHP, Ruby, Python, and JavaScript samples for each API. In rethinking their API docs, the Dwolla team wanted to decouple the three-pane experience, but keep the attractiveness, flowing navigation, and inline language sample experience that Slate delivered--keeping just the best parts of the increasingly ubiquitous API documentation format. For me this highlights some of the...[<a href="/2016/01/13/just-the-best-parts-of-the-api-documentation-please/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/01/12/i-just-cannot-get-behind-api-patents-especially-when-they-apply-to-http-and-hypermedia/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-sad-face.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/01/12/i-just-cannot-get-behind-api-patents-especially-when-they-apply-to-http-and-hypermedia/">I Just Cannot Get Behind API Patents, Especially When They Apply To HTTP And Hypermedia</a></h3>
			<p><em>12 Jan 2016</em></p>
			<p>I got an email in my inbox, about a new API modeling language from Elastic Path earlier today. The product is called Helix, and is sold as being "the first enterprise-class API modeling language designed specifically for REST Level 3". &nbsp; The Elastic Path team is where I first learned about the concept of hypermedia, I believe back in 2011--honestly, I had heard the concept before, but never fully grasped what it was, and the potential until 2011 (I know I am slow). However it has been an awareness that has grown rapidly, the more I learn about hypermedia, study how people are practicing hypermedia, and even dabble in it myself with my curation, and building block APIs. Elastic Path is an expert in the area of hypermedia, so it makes sense they would step up with some hypermedia focused API tooling, and even a modeling language. No surprises here, but where I was a little surprised, was when I read the "Why Helix": Elastic Path built Helix because existing API modeling languages, such as RAML, Swagger, and API Blueprint, while good for describing standard APIs, are not well suited to designing hypermedia APIs. Elastic Path Cortex, our patented API technology, utilizes Helix definitions and a Helix-compatible implementation, allowing our partners and customers to extend existing APIs and quickly create new ones. After reading, I wanted to explore the portion of their description that states, "Elastic Path Cortex, our patented API technology, utilizes Helix definitions and a Helix-compatible implementation, allowing our partners and customers to extend existing APIs and quickly create new ones.", but specifically the "patented API technology". Something a quick Google Patent search discovers as defined five separate patents held by Elastic Path.&nbsp; Linking functionality for encoding application state in linked resources in a stateless microkernel web server architecturePublication # US9143385 B2 A method of serving a resource to a client via a computer network is provided. The method may include at an...[<a href="/2016/01/12/i-just-cannot-get-behind-api-patents-especially-when-they-apply-to-http-and-hypermedia/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/01/12/how-do-i-provide-a-list-of-certified-applications-to-my-api-ecosystem-partners/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-trusted-apps-and-users.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/01/12/how-do-i-provide-a-list-of-certified-applications-to-my-api-ecosystem-partners/">How Do I Provide A List Of Certified Applications To My API Ecosystem Partners</a></h3>
			<p><em>12 Jan 2016</em></p>
			<p>I was emailed by someone working in government, asking some pretty interesting questions around using an application showcase, to make trusted applications available to an ecosystem of partners. I'm not going to talk specifically about the agency, as I have not gotten approval to talk publicly, but I think the question is an interesting mix of several areas I am researching, that I wanted to explore a little further, in an anonymous fashion. &nbsp; This is a a heavily edited, summarized version of what was asked, but it essentially went like this: There are 400 apps that want to get data from an organization but only some portion of them meet or exceed the governance criteria to be deemed &ldquo;trustworthy&rdquo;. &nbsp;This usually involves certain legal commitments are followed and other privacy requirements are satisfied--these 400 apps that will be evaluated, and if they qualify, they will be put into the an application registry. Another aspect of it is that rather than each of the 400 apps having to go to each of the partners to get authorized and access the partners API that it would be more efficient to rely on the application registry to determine if they can expose their APIs to that apps request(s) as well. Application showcases, that share approved applications with an ecosystem is common, but what I found interesting about this agencies question is that they want to also use the application approval process, as a sign of trust for other partners, when it comes to accessing their own API resources. As I said, this conversation spans three key areas of what I'm seeing occur modern API ecosystems: 3rd Party Applications (ie. approval, showcase, case studies, etc.) Partner Programs (i.e. certification, access tiers, etc.) Service Composition (ie. plans, monetization, rate limiting, etc.) Modern approaches to API planning, and well thought-out API driven partner programs, provide the approaches you need to approve partners (ie. companies), and the applications they build. Then...[<a href="/2016/01/12/how-do-i-provide-a-list-of-certified-applications-to-my-api-ecosystem-partners/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/01/12/helping-the-average-business-user-with-more-information-on-how-to-put-apis-to-work/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-users-business.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/01/12/helping-the-average-business-user-with-more-information-on-how-to-put-apis-to-work/">Helping The Average Business User With More Information On How To Put APIs To Work</a></h3>
			<p><em>12 Jan 2016</em></p>
			<p>API Evangelist has long been dedicated to helping the average business user understand all that is API. I saw early on in 2010, the potential of APIs, when used to empower the IT, or even shadow IT of the average business user. I think I've done well in this mission, except for one thing, the API Evangelist network is heavily focused on providing APIs, and much more lighter on topics and information around consuming APIs--something I will be working hard to shift over the next five years. To help me tackle this, is my new partner Cloud Elements. I do not partner with organizations, unless they help fuel my research, and Cloud Elements is helping me pushing forward several areas including API aggregation, API reciprocity, as well as pushing me to profile 50 of the top business sectors. While these areas of my research will have lots of information for API providers, many of the companies, services, and tooling I profile in these areas will be about empowering API consumers, and even more importantly--all types of API consumers, not just developers. Services like IFTTT and Zapier, make APIs accessible to the average business user because they allow them to move things around in the cloud using APIs. API service providers like Cloud Elements are allowing the average user to not just move things around in a way that protects their interest, and the interest of platforms (aka reciprocity), but they also all for aggregation, automation, and orchestration, of critical business "life bits" like documents, contacts, and images. This is why I seek out partners like them, to work in concert to better understand the space, but also tell stories that help average business user solve their actual problems. #winwin You will hear me talk a lot about what Cloud Elements is doing in 2016. Partly because they give me money, yes, but also because they are giving me money to operate, and spend my time...[<a href="/2016/01/12/helping-the-average-business-user-with-more-information-on-how-to-put-apis-to-work/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/01/12/api-aggregation-reciprocity-and-orchestration/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-conductor.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/01/12/api-aggregation-reciprocity-and-orchestration/">API Aggregation, Reciprocity, and Orchestration</a></h3>
			<p><em>12 Jan 2016</em></p>
			<p>I struggle a lot with how I separate out my research areas--there are a lot of reasons why I will break off, or group information in a certain way. Really it all comes down to some layer of separation in my head, or possibly what I perceive will be in my readers head. For example, I broke off hypermedia into its own research project, but now I'm considering just weaving it into my API design research.&nbsp; This is one of the reasons I conduct my research the way I do, is that it lets me spin out research, if I feel necessary, but I can easily combine projects, when I want as well. As I move API aggregation and reciprocity out of my "trends" category, and into my primary bucket of research, I'm consideration an addition of a 3rd area dedicated to just orchestration. Right now I'm considering aggregation staying focused on providing APIs that bring together multiple APIs into a single interface, and reciprocity is about moving things between two API driven services--I'm thinking orchestration will be more about the bigger picture that will involve automation, scheduling, events, jobs, logging, and much more.&nbsp; I enjoy my research being like my APIs, and keeping them the smallest possible units as possible. When they start getting too big, I can carve off a piece into its own area. I can also easily daisy chain them together, like API design, definitions, and hypermedia are. Some companies I track on will only enable API reciprocity at the consumer level, like IFTTT, where others like Cloud Elements will live in aggregation, reciprocity, and orchestration. I also think orchestration will always deal with business or industrial grade API usage, where my individual users can look to some of the lighter weight, more focused solutions, available in reciprocity. Who knows? I might change my tune in the future, but for now I have enough curated stories, and companies who are focused...[<a href="/2016/01/12/api-aggregation-reciprocity-and-orchestration/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/01/09/api-stack-apis-io-and-apis-guru-need-you-to-create-and-share-your-api-definitions/"><img src="https://s3.amazonaws.com/kinlane-productions2/api-commons/api-commons-icon.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/01/09/api-stack-apis-io-and-apis-guru-need-you-to-create-and-share-your-api-definitions/">API Stack, APIs.io, And APIs.Guru Need You To Create And Share Your API Definitions</a></h3>
			<p><em>09 Jan 2016</em></p>
			<p>I feel pretty strongly that for the next wave of growth in the API sector, we need the majority of public APIs in use today, to have well crafted, as complete as possible, API definitions in either OpenAPI Spec or API Blueprint. Yes I know, we actually need all of these APIs to be crafted using hypermedia approaches, but until then we need them all to possess machine readable API definitions, making them discoverable, learnable, and consumable. It is easy to get hung up on this being about API discovery, but API definitions are enabling almost every step along the 35 areas of the API life cycle I am mapping out. Historically API definitions have bee used for interactive API documentation, but more recently are additionally being used to light up other aspects of API integration, such as setting up your API monitoring, loading into the API client of your choosing, or lighting up a mock server for use in development.&nbsp; In addition enabling services and tooling throughout the life cycle, well crafted, complete API definitions is driving API design literacy. Many API developers and architects learn by reverse engineering the APIs they know, and a well crafted OpenAPI Spec or API Blueprint provides a detail blueprint for enabling this experience. API definitions make it easier to learn about good, and bad API design, in terms of the APIs you actually care about--equaling a much more open mind. I've been working to define API definitions as part of my API Stack work, for over a year now. You can access all the APIs.json + OpenAPI Specs + API Blueprint + Postman collections under the /data folder for the project repository. Additionally, this repo is one of the sources of APIs.io which is an APIs.json driven open source API search engine, which provides an API for you to register and search for API definitions. In 2015, I saw another strong player emerge, that I'm big on...[<a href="/2016/01/09/api-stack-apis-io-and-apis-guru-need-you-to-create-and-share-your-api-definitions/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/01/08/public-gets-in-concert-with-private-post-put-and-delete-for-your-apis/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-open.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/01/08/public-gets-in-concert-with-private-post-put-and-delete-for-your-apis/">Public GETs, In Concert With Private POST, PUT, And DELETE For Your APIs</a></h3>
			<p><em>08 Jan 2016</em></p>
			<p>Another story I wanted to tell from my work to expose an API yesterday, so I could get help with it, was focused around the service composition that I used. I feel like this is a powerful story, that should be told, and retold among API evangelists, across conversations with folks who are new to the API space, and the concept of putting APIs to work in their daily business worlds. The largest concern I hear from people who don't fully understand API, is the perceived loss of control, from putting things up on the open Internet. When you don't understand modern API management infrastructure, and the nuance of API service composition, what an API does can seem pretty scary. The first lesson around me exposing of an API, from the @APIStrat speaker database, was about soliciting help from Nicolas Greni&eacute; (@picsoung), and the second lesson is centered around how I used a combination of public / private endpoints to make this work. The first two endpoints or methods I published from my speaker databases, were simple GETs: http://api.apistrat.com/speakers/ http://api.apistrat.com/speakers/aO6zItrUhKEUexi7zNiUjOzzJ1230Rfno9P123DJRHNEuh4117/ All 351 speakers in our database are already public, on the schedules for each of the six @APIStrat events, so there really is no reason why I would lock up the APIs to get this information--I am just returning JSON representations, in addition to the HTML I already do on the websites. However, for the collaboration part with @picsoung the POST, PUT, DELETE (aka Add, Update, Delete), I'm going to need to secure things a little more. Using my already in place, 3Scale API management infrastructure, I have an access tier specifically for my partners like 3Scale, WSO2, and @picsoung already has a set of API keys at this API plan level. I simply put the three endpoints / methods for POST, PUT, and DELETE for the URLs above, into my "partner" level, and they require an appID and appKey for each API call--secured. This...[<a href="/2016/01/08/public-gets-in-concert-with-private-post-put-and-delete-for-your-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/01/08/are-we-stepping-back-and-considering-the-potential-for-abuse-with-our-apis/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-api-evil.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/01/08/are-we-stepping-back-and-considering-the-potential-for-abuse-with-our-apis/">Are We Stepping Back And Considering The Potential For Abuse With Our APIs?</a></h3>
			<p><em>08 Jan 2016</em></p>
			<p>I see a lot of APIs, and honestly I'm not excited about all of them. Some are public. Some are private. I am feeling that I could put the APIs I see into 3 different buckets: valuable, some value, and no value. Obviously there is going to be much more nuance to it that that, but this post is about the APIs that generate no value. First, let me clarify--I am speaking value to everyone involved. This is my own personal measurement. Examples of APIs that offer no value, are usually about the exploitation of developers and/or end-users, while giving the lion share of value to the platform. I put a lot of Internet of Things APIs into this bucket, and other leading APIs from companies like Snapchat or LinkedIn. I'd also put APIs like facial recognition technology, some machine learning APIs, and APIs that may seemingly offer a lot of value to everyone involved, because of the opportunities for abuse, any value that has generated is cancelled out. I' not going to point fingers at the specific API that triggered this post. I will just say that after reviewing an API, the opportunity for abuse is pretty huge, by the platform, as well as with 3rd party developers. It reminded me that I need to work to provide more ethical best practices as part of my API design research, reminding API architects to step back early on in the process, and consider the big picture--asking themselves should we be doing building this API in the first place. We have what it takes to do almost anything we want, but I don't think we ask ourselves: "should we be doing this" enough. We aren't look at the big picture, and considering privacy, security, surveillance, and what the overall potential for abuse might be. When I am considering the potential for API abuse, I ask myself "what would Keith Casey (@CaseySoftware) be able to do?" Keith...[<a href="/2016/01/08/are-we-stepping-back-and-considering-the-potential-for-abuse-with-our-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/01/07/using-apis-to-address-regulatory-uncertainty-involved-in-crossborder-data-flows/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-government-regulation-uncertainty.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/01/07/using-apis-to-address-regulatory-uncertainty-involved-in-crossborder-data-flows/">Using APIs To Address Regulatory Uncertainty Involved In Cross-Border Data Flows</a></h3>
			<p><em>07 Jan 2016</em></p>
			<p>I pulled the title for this post directly from understanding the impact of cross-border routing of data during an era of emerging geographic restrictions, from Dyn. I'm writing about this to add it to my list of numerous concerns for API providers, when it comes to internationalizing their APIs, for the global API economy--such as establishing&nbsp;successful patterns for multi-lingual APIs and documentation, or providing API access that is replicated into multiple regions around the globe. Dyn's perspective comes from a more regulatory level, which I think coming from a DNS provider is something that makes the story even more compelling. At any rate, I feel with the big data / surveillance culture that is thriving right now, regulatory concerns, when it comes to data and privacy will continue to be a natural response, and will increase, and continue to be more heavy handed.&nbsp; I am not a fan of regulation, I understand its purpose, but historically I have not been an advocate for. However there has to be a counterbalance to the bad big data behavior from tech companies, surveillance by tech companies and the government, and the increasing cyberbullshittery that is going on. I'd prefer this counter-balance be a human and people driven response, but I'm guessing it will end up being a wave of very emotional government regulatory responses, like we seen with Safe Harbor, and beyond. Its my opinion that extensive logging, software defined networking, and APIs coupled with OAuth controls is how we are going to orchestrate our operations in this new, extremely volatile, land-mine ridden regulatory environment that is unfolding. This is why I keep an eye on global DNS infrastructure providers like Dyn, as part of my DNS research, so that I can map out all of their API operations, and include alongside logging, SDN, and other relevant APIs--the automation of cross-border data flows using APIs, so that you can mitigate regulatory uncertainty. I see the concept of "data...[<a href="/2016/01/07/using-apis-to-address-regulatory-uncertainty-involved-in-crossborder-data-flows/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/01/07/i-loaded-that-csv-into-a-database-now-let-me-expose-an-api-so-i-can-get-some-help/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-api-help.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/01/07/i-loaded-that-csv-into-a-database-now-let-me-expose-an-api-so-i-can-get-some-help/">I Loaded That CSV Into A Database, Now Let Me Expose An API So I Can Get Some Help</a></h3>
			<p><em>07 Jan 2016</em></p>
			<p>I have been working to clean up the the web presence for the API Strategy &amp; Practice conference. We concluded the 6th edition of @APIStrat in Austin this last november (check out the videos), and in addition to this events website, I have five other sites to maintain, and make sure remain accessible. The first three sites have a custom database back-end, the next two had a WordPress + MySQL back-end, and the last edition uses Jekyll + YAML as its back-end(?).&nbsp; As part of this round of housecleaning I aggregated the schedule of speakers from all six events into a single spreadsheet, which ended up on my desktop as a CSV file. As I was talking this morning with the rest of the @APIStrat team about the 2016 schedule, I shared the CSV in Slack, as I also uploaded to a MySQL database (yeah I'm new / old school like that). I was talking with my partner in crime Nicolas Greni&eacute; (@picsoung) shortly after, and he wanted to help me push forward the list of speakers, expand the speaker and company info, as well as connect it up with sponsor info. I then responded, as Steve Willmott (@njyx) points out on Twitter (is nothing private these days!!!): APIer's at work @kinlane "I may take you up on that sir. loaded into DB. Let me expose an API on it I&rsquo;ll ping you for some help" @picsoung &mdash; Steven Willmott (@njyx) January 7, 2016 I went ahead and exposed an API of all of the 351 speakers who have participated in @APIStrat since the first edition in New York in February 2013--you can access the endpoints, publicly at: http://api.apistrat.com/speakers/ I also added the ability to pull a single speaker as well: http://api.apistrat.com/speakers/aO6zItrUhKEUexi7zNiUjOzzJ1230Rfno9P123DJRHNEuh4117/ All you have to do is put in the speaker_id for each of the speakers. Now, anyone can pull the information on 351 of the speakers who have helped make @APIStrat a thing....[<a href="/2016/01/07/i-loaded-that-csv-into-a-database-now-let-me-expose-an-api-so-i-can-get-some-help/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/01/06/we-need-an-api-for-the-chronology-of-data-breaches-database/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/privacy-rights-clearinghouse-logo.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/01/06/we-need-an-api-for-the-chronology-of-data-breaches-database/">We Need An API For The Chronology of Data Breaches Database</a></h3>
			<p><em>06 Jan 2016</em></p>
			<p>
I came across the Privacy Rights Clearinghouse, while conducting a search that turned up the chronology of data breaches, which provides details on&nbsp;4,725 data breaches that have been made public since 2005. The website allows you to search for data breaches by type of breach, type of organization, and the year in which it occurred--some very valuable information.
In 2016, as breaches continue to be common place across almost all industries, we are going to need to take the chronology of data breaches up a notch. I would like to see an API be made available for the valuable database. As I do, I write stories about what I'd like to see in the space, and forward the link to key actors, and tell the story to the public at large, in hopes of inciting something to happen.
Making the data breach information available via API, would encourage more storytelling around the events, which could include much more meaningful visualizations using solutions like D3.js. Information about companies, could be included into other business search and discovery tooling, and more push notification networks could be setup that could keep industry experts more informed about what is happening across the sector.
Now that I am on the subject, it would make sense if all the privacy topics, and other resources available via the Privacy Rights Clearinghouse accessible through a simple API interface. If you work with the&nbsp;Privacy Rights Clearinghouse, and would like to talk about making this happen, feel free to reach out. If you are someone who would like to help work on this project, or possibly fund this work, also please let me know.
The type of information the&nbsp;Privacy Rights Clearinghouse is aggregating is only going to become more important in the insecure cyber world we have created, and making it accessible for reading and writing via a simple API, would significantly help the organization make a bigger impact, and educate a larger audiences.
[<a href="/2016/01/06/we-need-an-api-for-the-chronology-of-data-breaches-database/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/01/05/your-api-access-replicated-into-multiple-regions-around-the-globe-for-additional-charge/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/algolia-world-wide-replication-slider.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/01/05/your-api-access-replicated-into-multiple-regions-around-the-globe-for-additional-charge/">Your API Access Replicated Into Multiple Regions Around The Globe For Additional Charge</a></h3>
			<p><em>05 Jan 2016</em></p>
			<p>I am finding all sorts of interesting examples as I push forward my API plans research, where I study the API planning approaches employed by over 50 of the leading APIs. One of the items, on my API plan story list, comes from Algolia, the search API, who I think has one of the more sophisticated API plans of all of the APIs I looked at this round.&nbsp; One of the cool aspects I found was a "world-wide replicator" option on the pricing page for Algolia. The feature is interesting to me because of the UX / UI approach employed, as well as the concept of offering API replication to different regions as a dimension of API plans. You have to admit the separate section, as part of API pricing, is pretty forward leaning, and not something you see often. What is even cooler, is that when you move the slider, increasing the number of regions the API is available in, your price per package is adjusted to include the replication. I believe they apply just a flat rate increase for each plan level, but I could see this be something that has unique cost per region (ie. US being more expensive than EU). As the debate about in-country data storage and compute evolves, I think this will become pretty significant. The goal for the Algolia world-wide replication, is to decrease latency for end-users, when searches are made. Providing up to five separate regions around the globe, where your API can be deployed, as part of your Algolia API plan. While not something that could be accomplished by every API, the approach is in alignment with wholesale API movements I've talked about before. Using API infrastructure like 3Scale offers, you could establish this type of variability in plan levels, that are tailored for containerized-enabled, world-wide replication similar to what Algolia offers. I have added world-wide or regional replication as one of the API plan building...[<a href="/2016/01/05/your-api-access-replicated-into-multiple-regions-around-the-globe-for-additional-charge/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/01/05/security-will-increasingly-be-used-as-component-of-tiered-api-planning/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/box-plans-screenshot-1.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/01/05/security-will-increasingly-be-used-as-component-of-tiered-api-planning/">Security Will Increasingly Be Used AS Component Of Tiered API Planning</a></h3>
			<p><em>05 Jan 2016</em></p>
			<p>As I look through the business models of leading API providers I am profiling, I'm increasingly seeing security as a selling point. When API providers break down their pricing into tiers, they are usually very good at breakdown down the elements of what goes into each plan--this is what I have been studying for last couple weeks.&nbsp; When I come across security leveraged as part of API plans, it is rarely a part of the free or entry levels, and is something you usually see in the higher level paid plans, and enterprise tiers. Here is an example of this, in a screen shot from the Box pricing page. These plans are part of the SaaS side of the Box operations, but Box are pretty unique in that they have separate pricing tiers for the SaaS side of their operations, and a related, but addition set of pricing for the API side of their platforms. However, Box's approach provide the best example of this in action, with add-ons beyond the plan based pricing, that were also very security focused. Box is a document platform that services the enterprise, which includes numerous, very heavily regulated industries. It makes sense that they are emphasizing security. My focus is that security is leveraged as specific feature of individual plans, with an emphasis on it being present in the upper tiers, and with add-ons. This really isn't news. It makes sense that an emotionally charged element like security is used as a component of planning and pricing. I'm just looking to document security as a component of API planning for my research, educate other platforms about the potential for this type of use, but I am also looking to better understand how different companies, in different industries are wielding it (or not). I predict that security will increasingly be used as a component like this in SaaS and API planning. In the current, very insecure online environment we all...[<a href="/2016/01/05/security-will-increasingly-be-used-as-component-of-tiered-api-planning/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/01/05/providing-a-dedicated-test-user-api-as-part-of-your-api-virtualization-strategy/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-test-user.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/01/05/providing-a-dedicated-test-user-api-as-part-of-your-api-virtualization-strategy/">Providing A Dedicated Test User API As Part Of Your API Virtualization Strategy</a></h3>
			<p><em>05 Jan 2016</em></p>
			<p>
I was profiling the Facebook API as part of my API Stack work. While I only use a handful of the endpoints available to me via the Facebook API, as the API Evangelist, I feel like I should have an awareness of the popular social API. Additionally, the number of great stories I find dramatically increase with the number of API profiles that I complete.
One story I extracted from my Facebook API research is about providing a dedicated test user API. Using the test user API you can add, manage and delete test users, which you can use throughout the developing and testing of your API integration. Facebook is user- centric, but it seems like the concept applies equally to any other valuable resource made available via APIs today.
I'd file this under virtualization, when it comes to organizing as part of my overall research. Providing virtualization options for API consumers is something that is only going to grow with the Internet of Things, and privacy concerns. API providers should be looking at how they virtualize entire APIs using modern approaches to containerization, so they can be used in dev, qa, and production environments, but they should also be looking at providing data and content virtualization solutions like Facebook does with a test user API.
[<a href="/2016/01/05/providing-a-dedicated-test-user-api-as-part-of-your-api-virtualization-strategy/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/01/05/aws-has-a-blog-that-is-dedicated-to-the-command-line/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-command-line.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/01/05/aws-has-a-blog-that-is-dedicated-to-the-command-line/">AWS Has A Blog That Is Dedicated To The Command Line</a></h3>
			<p><em>05 Jan 2016</em></p>
			<p>
Amazon has a new blog dedicated to just their Command Line Interface (CLI). I use AWS as anchor for many of my API stories, but I also acknowledge that many API providers will never be at the scale of AWS, but nonetheless I am drawn to the regular streams of lessons available via the cloud platform, if you look in the cracks.
The new AWS CLI blog is one of these. I do not think all API providers should run out and start a separate blog for their CLI, but the existence of a dedicated CLI blog at AWS shows the significance of CLI to the API world. If you are looking to court the enterprise, and many other developer groups, a CLI should be a very relevant tool in your toolbox. If a platform interface is not also available via a CLI, you might be missing an entire segment of the developer community.
Like with my IDE, and SDK research, I may be firing up a separate area for CLI. I regularly curated CLI focused conversation, services, and tooling during my monitoring, making it a good candidate for isolation into its own research project. Part of the reason in isolating into its own research, is that the topic will get regular attention from me, and a single repo for storing my research, which means the chances my understanding around the topic will increase greatly.
[<a href="/2016/01/05/aws-has-a-blog-that-is-dedicated-to-the-command-line/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/01/05/all-companies-who-have-an-online-product-catalog-should-look-at-what-octopart-does-with-their-api/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/octopart-api-screenshot.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/01/05/all-companies-who-have-an-online-product-catalog-should-look-at-what-octopart-does-with-their-api/">All Companies Who Have An Online Product Catalog Should Look At What Octopart Does With Their API</a></h3>
			<p><em>05 Jan 2016</em></p>
			<p>
Octopart is a search engine for electronic parts. They have been on my API monitoring radar for some time now, because they have a very well done API. Octopart was one of the first API providers I wrote about, who were making their data available via their API, available in spreadsheets for business users, via a plugin.&nbsp;
The reasons I am writing about Octopart this time, is much more mundane. They are just doing it right, and I wish all product websites, had an API presence like Octopart does. As soon as you land on the home page of the site, where you can search for electronics products, all you have to do is scroll down, and you immediately see a link for the API. There is also a prominent set of links in the footer, labeled products, that focus on the API, as well as the Excel and Google spreadsheet connectors built on top of it.
Octopart has a well designed API, that clearly plays a significant role in their overall existence as an online electronic parts company. Every time I read one of their blog post, or end up in their developer area looking at something, I can't help but think about how ALL product companies should be following Octopart's lead. It all takes me back to the year 2000, where I was working hard to convince companies of the importance of having a website, as I now work to convince companies of the importance of having an API. #dejavu
[<a href="/2016/01/05/all-companies-who-have-an-online-product-catalog-should-look-at-what-octopart-does-with-their-api/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/01/04/the-openapi-specification-fka-the-swagger-specification/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/open-api-logo.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/01/04/the-openapi-specification-fka-the-swagger-specification/">The OpenAPI Specification (fka The Swagger Specification)</a></h3>
			<p><em>04 Jan 2016</em></p>
			<p>
It is a new year, and we have a lot of work to do when it comes to defining APIs in the new year. One of the results of 2015, was that the specification known as Swagger was spun off into the Linux Foundation, where for the remaining of the year we were simply calling it the Open API Definition Format (OADF)--quite a mouthful.
In 2016, a name as been given to the specification--OpenAPI Spec. If you know me, you know how I feel on all of this, but in 2016, I am focusing on whats next, not what just happened, so I am just happy there is a name, not some intermediary WTF. Soooo, head over to the new Github repo home for OpenAPI Spec, and get involved.
If you are planning on doing anything cool with the OpenAPI Spec, please reach out and let me know. Now that we have forward motion with the specification, and a name we can ALL use, I will be assembling a new toolbox dedicated to the spec, and all the cool things y'all are doing with it. As I look forward across the 2016 API horizon, I have no doubt that the OpenAPI Spec will be essential to the next wave of growth in the API sector.
[<a href="/2016/01/04/the-openapi-specification-fka-the-swagger-specification/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/01/04/microsoft-increases-the-visibility-of-their-api-driven-platform-with-a-new-road-map/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/microsoft-cloud-platform-roadmap.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/01/04/microsoft-increases-the-visibility-of-their-api-driven-platform-with-a-new-road-map/">Microsoft Increases The Visibility Of Their API Driven Platform With A New Road Map</a></h3>
			<p><em>04 Jan 2016</em></p>
			<p>
A road map for your API, is one of those essential building blocks that can go a long way in building trust with your API consumers. Sharing your plans, helps developers prepare for the future, and better plan for their own road maps, keeping everything potentially in sync.&nbsp;
From my vantage point, a simple, up to date, easily found road map is a building block that benefits both API provider and consumer. Road maps help provider organize their plans, and figure out how they are going to communicate it with the ecosystem, then setting the overall tone for how API consumers will engaging with a platform--both good and bad.
During my regular monitoring of the space, I saw that Microsoft released a pretty slick "Cloud Platform Roadmap", which is yet another sign for me on how Microsoft is stepping up their cloud (API) game. Their interactive road map allows you browse the roadmap by areas like cloud infrastructure or Internet of Things (IoT), and see features that are&nbsp;recently available, public preview, in development, cancelled, or have been archived.
Beyond the core functionality of the road map, I'm impressed that they published a blog post telling why they did it, acknowledging that it will bring visibility into platform operations. Additionally there is a prominent button, providing an email address where you can send your suggestions for the road map, providing evidence of how a roadmap can contribute to the overall feedback loop for an API platform.
Overall, I like the simplicity of the Microsoft cloud platform road map, and it is definitely a healthy building block I'd encourage other API providers to consider offering as well. I'm going to make sure Microsoft's roadmap is one of the examples I cite along the API management line, as part of my overall API life cycle map.&nbsp;
[<a href="/2016/01/04/microsoft-increases-the-visibility-of-their-api-driven-platform-with-a-new-road-map/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/01/04/look-across-my-api-monitoring-api-methods-by-grouping-them-using-tag/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/api-monitoring-tag-cloud.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/01/04/look-across-my-api-monitoring-api-methods-by-grouping-them-using-tag/">Look Across My API Monitoring API Methods By Grouping Them Using Tag</a></h3>
			<p><em>04 Jan 2016</em></p>
			<p>Last week I was playing with&nbsp;defining API monitoring APIs so I can map to each stop along the API life cycle. I took three of the API monitoring services I use (APIMetrics, API Science, and Runscope), and like I do for other areas along the API life cycle, and for common API stacks, I profiled their APIs using the OpenAPI Spec. This is standard operating procedure for any of my research areas, in that part of profiling each company's operations, I profile the API surface area in detail. For each of my research projects, I will include this listing of each API endpoint available as part of the work. As I was adding one for my API monitoring research, I had a thought--I wanted to reorganize the endpoints, across the three API monitoring service providers, and group them by tag. So I started playing with a new way to look at the APIs available in any given APIs.json driven collection. This is a listing of API resources available in&nbsp;this projects APIs.json, organized by tag. Account Account Resource - (GET) -&nbsp;/account Team integrations list - (GET) -&nbsp;/teams/{teamId}/integrations Teams Resource - (GET) -&nbsp;/teams/{teamId}/people Auth Delete an Authentication Setting - (DELETE) -&nbsp;/auth/{id}/ Get an existing Authentication Setting - (GET) -&nbsp;/auth/{id}/ List Authentication Settings - (GET) -&nbsp;/auth/ Update an existing Authentication Setting - (PUT) -&nbsp;/auth/{id}/ Buckets Create a new bucket - (POST) -&nbsp;/buckets Delete a single bucket resource. - (DELETE) -&nbsp;/buckets/{bucketKey} Returns a list of buckets. - (GET) -&nbsp;/buckets Returns a single bucket resource. - (GET) -&nbsp;/buckets/{bucketKey} Calls Create new API Call - (POST) -&nbsp;/calls/ Delete an API Call - (DELETE) -&nbsp;/calls/{id}/ Get an existing API Call - (GET) -&nbsp;/calls/{id}/ List API Calls - (GET) -&nbsp;/calls/ List API Calls by Authentication - (GET) -&nbsp;/calls/auth/{auth_id}/ List Stats from before a date for an API Call - (GET) -&nbsp;/calls/{id}/stats/before List Stats since a date for an API Call - (GET) -&nbsp;/calls/{id}/stats/since Trigger an API Call to run - (POST) -&nbsp;/calls/{id}/run Update...[<a href="/2016/01/04/look-across-my-api-monitoring-api-methods-by-grouping-them-using-tag/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/01/04/diff-and-merging-of-api-definition-formats/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-diff.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/01/04/diff-and-merging-of-api-definition-formats/">Diff And Merging Of API Definition Formats</a></h3>
			<p><em>04 Jan 2016</em></p>
			<p>
As the number of API definitions increases out there, I'm coming across many duplicates of APIs I already have in my collection(s). In 2016, I will increasingly need to be able to execute a diff on two OpenAPI Spec or API Blueprint files, and get back a programmatic, as well as a visual reference, which allows me to quickly understand the differences between each spec in detail.
In support of this API definition diff tooling, I can also see the potential for some sort of merging tooling, that would allow me to easily say yes or no, and merge various elements of either API definitions. I recently got sucked into using Ancestry.com, and they provide a nice way to merge discovered documents into your family tree, accepting or rejecting what you want--I would like to see this exist for API definitions.
As with every other other of the almost 1000 building blocks available across my API research, each element of the API life cycle should be available as an API, as well as lightweight, open source, micro tool. An API definition diff and merge would make to very viable API services, and if someone doesn't get around to building, I will probably get to work on a version of it for my own needs. I have a growing queue of API definitions I need to merge with my master stack, and not all of it is as straightforward as "accept all".&nbsp;
In addition to adding attribution to my API definition research, I'm adding diff and merge as building blocks. They'll provide a reminder for me (and anyone else), that attribution, diff, and merging at the API definition level is an important aspect of the API life cycle.
[<a href="/2016/01/04/diff-and-merging-of-api-definition-formats/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/01/04/api-definition-origin-validation-and-attribution/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-attribution.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/01/04/api-definition-origin-validation-and-attribution/">API Definition Origin, Validation, And Attribution</a></h3>
			<p><em>04 Jan 2016</em></p>
			<p>I have done a lot of work hand crafting, and often scrape crafting, machine readable OpenAPI Spec, as part of the work on the API Stack. Creating a usable API definition is a lot of work, making it is a pretty valuable commodity, in contrast to my strong opinion that they should be readily available for EVERY API today. While there is still a HUGE AMOUNT of work to be done, I feel like the ball is beginning to move forward, when it comes to the number of publicly available API definitions.&nbsp; For the API economy to work at the scale we all have pictured in our head, the surface area of ALL APIs, and its supporting operations needs to be defined, and available to consumers and service providers. Every API should have an OpenAPI Spec, API Blueprint, and Postman Collection available for consumers to put to work. As we close 2015, I'm happy to say that I am optimistic about the amount of work others across the space are putting into API definitions, like the folks over at API Guru--who are discovering, improving upon, and validating API definitions in a variety of formats, all available on Github. A lot of work goes into crafting these definitions, and it is good to see them investing in this area. Their valuable index of almost 200 API definitions is being used to power Any API, and is complete with&nbsp;a JSON index for the API collection. Keep an eye on it, as it is growing every day--I know that I will be closely watching every commit to the open API definition repository. As I look through their collection, there are many APIs I already have, but there are many others I would love to build upon the work done by API Guru--just as I encourage others to do with my API Stack work.&nbsp; All of this forces me to consider, as this new API definition layer of the...[<a href="/2016/01/04/api-definition-origin-validation-and-attribution/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/01/04/api-blueprint-has-been-evolving-in-two-critical-areas-where-openapi-spec-aka-swagger-falls-significantly-short/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-api-definitions-gears.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/01/04/api-blueprint-has-been-evolving-in-two-critical-areas-where-openapi-spec-aka-swagger-falls-significantly-short/">API Blueprint Has Been Evolving In Two Critical Areas Where OpenAPI Spec (aka Swagger) Falls Significantly Short</a></h3>
			<p><em>04 Jan 2016</em></p>
			<p>Z (@zdne) over at Apiary published a pretty interesting blog post before christmas&nbsp;which highlights two important elements of profiling APIs using popular API definition formats. Z is key to the vision behind API Blueprint, one of the top 3 API definition formats, that are fueling API design in 2016.&nbsp; Giving The Body Some LoveOne common complaint I've seen on forums, issue threads, and other places API developers hang out, is that OpenAPI Spec does not allow for properly describing the request body payload. I definitely agree with this, but is something that doesn't often impact me, as the type of APIs I am currently deploying, rarely employ a very complex body payload. However I do know some APIs that I've documented, where if you can't properly define the body, the API appears to have no value whatsoever, when described using an&nbsp;OpenAPI Spec. It was good to hear Z state that, "In 2015, we have spent most of the year building only one feature--the description of body parameters. This feature is also know as the MSON syntax." Acknowledging Media TypesThe next significant area Apiary is addressing with API Blueprint and MSON, is when it comes to supporting multiple media types, and making sure they are properly described in the API definition--MSON FTW!&nbsp; Z talks about how, "MSON isn't another syntax for JSON. MSON is agnostic to serialization media types. With MSON, I can describe the data and defer the decision whether they will be send as JSON, XML or HAL over the wire." I will be learning more&nbsp;MSON&nbsp;in January, and reacquainting myself with API Blueprint, as I document my APIs stack(s), but also specifically two of my APIs that provide JSON, HTML, and Siren media types. Hopefully this will allow me to also document the growing number of hypermedia APIs available across the space. Media types, and body are two areas that OpenAPI Spec (aka Swagger) is deficient. Something that gives Apiary a pretty interesting head...[<a href="/2016/01/04/api-blueprint-has-been-evolving-in-two-critical-areas-where-openapi-spec-aka-swagger-falls-significantly-short/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2016/01/03/thinking-about-the-monetization-layer-for-public-data/"><img src="https://kinlane-productions2.s3.amazonaws.com/google/google-public-data-explorer.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2016/01/03/thinking-about-the-monetization-layer-for-public-data/">Thinking About The Monetization Layer For Public Data</a></h3>
			<p><em>03 Jan 2016</em></p>
			<p>This is my walk-through of the concepts involved with the monetization of public data using APIs. In this work I am not advocating that companies should be mindlessly profiting from publicly available data, my intent is to provide a framework for organizations to think through the process of generating revenue from commercial access to public data, acknowledging that it costs money to aggregate, serve up, and keep data up to date and usable for the greater public good--if public data is not accessible, accurate, and up to date it is of no use to anyone. I have long argued that companies and even government agencies should be able to charge for commercial access to public&nbsp;data and be able to generate revenue to cover operational costs, and even produce much-needed funds that can be applied to the road map. My work in this has been referenced in existing projects,&nbsp;such as the Department of Interior and Forest Service looking to generate revenue from commercial access and usage of public data generated&nbsp;by&nbsp;the national parks systems. In my opinion, this conversation around generating revenue from publicly available digital assets should be occurring right alongside the existing conversations that already are going on around publicly available physical assets. Building Upon The Monetization Strategies Of Leading Cloud ProvidersMy thoughts around generating revenue from public open data is built upon monitoring the strategies of leading online platforms like Amazon Web Services, Google, and others. In 2001 a new approach to providing access to digital resources began to emerge from Internet companies like Amazon and Salesforce, and by 2016, it has become a common way for companies to do business online, providing metered, secure access to valuable corporate and end-users data, content, and other algorithmic resources. This research looks to combine these practices into a single guide that public data stewards can consider as they look to fund their important work. Do not get me wrong, there are many practices of leading tech...[<a href="/2016/01/03/thinking-about-the-monetization-layer-for-public-data/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/12/30/here-are-the-top-api-stacks-i-will-be-working-to-define-in-2016/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-stack-people.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/12/30/here-are-the-top-api-stacks-i-will-be-working-to-define-in-2016/">Here Are The Top API Stacks I Will Be Working To Define in 2016</a></h3>
			<p><em>30 Dec 2015</em></p>
			<p>My new partner in API crime Cloud Elements is helping motivate me to spend more cycles in 2016 on defining specific stacks of APIs, as part of my ongoing API industry research. I am taking the approach I've honed over the last five years in my core research, and continuing to push forward on specific areas of the API industry. Cloud Elements calls their aggregated APIs -- Hubs, because they are working to aggregate them into actual usable APIs. My approach is meant to organize common API definitions, into specific groups. I do not go as far as aggregating APIs into a single API, and providing a platform, and tooling for you to actually work with the APIs.&nbsp; Cloud Elements currently has 11 business API hubs defined, where I'm looking to push the space forward by defining 50 stacks: social messaging users storage compute documents commerce payments photos videos music audio voice search content language news travel geo mapping places businesses links events weather movies advertising accounting shipping government (city) government (state) government (fed) home auto transportation wearables energy space healthcare environment education libraries university (faculty) university (student) sharing economy banking 3d printing internet of things drones machine learning I am not in the business of pushing the overall number of APIs forward in the API space--this number means nothing to me in 2016. I am looking to better define what the most valuable APIs are, in some of the most meaningful areas of the Internet. Some of the areas I chose because they are core to web and mobile application development, others because they are important areas to the overall economy and society, with others just because they are frick'n cool! You can see my earlier work in this area, present under the verticals section on the home page of API Evangelist, with my early look at the payment API space, and more recent email, SMS, and MMS research projects. I will step up...[<a href="/2015/12/30/here-are-the-top-api-stacks-i-will-be-working-to-define-in-2016/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/12/30/do-you-have-what-it-takes-to-be-on-the-api-academy-team/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/company/logos/api-academy-logo.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/12/30/do-you-have-what-it-takes-to-be-on-the-api-academy-team/">Do You Have What It Takes To Be On The API Academy Team?</a></h3>
			<p><em>30 Dec 2015</em></p>
			<p>When it comes to keeping an eye on what others are doing across the API space, and occasionally pushing forward a few crazy ideas, API Evangelist is your source. However if you really want to learn about API design and architecture, that you can put to work at your company, organization, institution, and government agency--the API Academy is where you go. There is not another team API team that so focused on API literacy, with as much expertise, as the API Academy team. If you have been to any of the leading API events like APIStrat, APIDays, API Craft, and RESTFEst, you've seen their team in action, and known what they are bringing to the table. Mike Amundsen (@mamund) is making sure we are all on the correct path. Ronnie Mitra (@mitraman) is pushing the concept of API design forward. Matt McLarty (@MattMcLartyBC) with the big enterprise API architecture picture. Irakli Nadareishvili (@inadarei) is paying attention to the overall API vision. I have learned a great deal of what I know about API design and architecture from these individuals, during my tenure as the API Evangelist. When it comes to the business or politics of APIs I'm on solid ground, but when it comes to API design, and API architectural considerations at scale--I will always defer to the API Academy. The team informed me, that they are looking for someone to join their team. Someone worthy. Which is no small task. I can barely count on two hands, the number of people who I would recommend for the position, sadly many are already happily working on existing projects. Good thing there are many folks I do not know as well across the space, who are API leaders--if you are one of these people, and thrive on teaching others about API design and architecture, I suggest you ping Matt McLarty over at the API Academy...they need your help! The #API Academy is hiring! Please contact me...[<a href="/2015/12/30/do-you-have-what-it-takes-to-be-on-the-api-academy-team/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/12/29/the-hard-work-when-it-comes-to-defining-apis/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-work-in-progress.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/12/29/the-hard-work-when-it-comes-to-defining-apis/">The Hard Work When It Comes To Defining APIs</a></h3>
			<p><em>29 Dec 2015</em></p>
			<p>I am stopping and collecting some of my thoughts, as I work through my API stack. I'm thinking about the more difficult aspects of defining APIs, this time it is for the APIs I depend on to operate my own company. I am working to define the APIs I depend on from over 30 companies, partly to help me better understand the APIs I use, but also partly as theater here for API Evangelist. To profile APIs, I use OADF and APIs.json as my machine readable definition formats. Not all APIs are created equal, so it takes different approaches to crafting their OADF, from doing it by hand for the easier ones, to scrape scripts that take consistent (static) documentation, and generate an OADF version. As I do this work, here is where the hard work is (will be) in all of this. Surface - Finding and documenting the surface area (endpoints + headers + parameters + security). There is just no way to automate this, you only know what you know. Response - Documenting the response, and schema using Charles Proxy. The first version of my API definitions rarely have the response modeled, as I depend on Charles Proxy plus a custom API I developed for generating JSON schema from HAR files. APIs.json - Bring together with an APIs.json index, which is fairly automated for me from my central API monitoring system, publishing a single, machine readable index of all the APIs available, as well as the wider API operations. Menus - As I complete around 30 of these, I realize that I will need some sort of machine readable, APIs.json driven menu, which puts a list of APIs in a certain order, and maps responses, to following request parameters, so I can daisy chain APis together for more automated tasks. Updates - Like knowing the surface area of an API, we only know what we know, and as Rumsfeld says, there are also...[<a href="/2015/12/29/the-hard-work-when-it-comes-to-defining-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/12/28/thinking-about-my-api-usage-at-scale-across-almost-35-external-apis/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-scale-api.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/12/28/thinking-about-my-api-usage-at-scale-across-almost-35-external-apis/">Thinking About My API Usage At Scale Across Almost 35 External APIs</a></h3>
			<p><em>28 Dec 2015</em></p>
			<p>As I conclude the first phase of profiling the APIs that I depend on, I am thinking about my API usage at scale, and some new questions are arising, that I wasn't thinking about before. I find my API consumption, and API integration thinking historically has been on an individual API basis, which something that I hope to evolve upon in 2016. Here are a handful of questions that have arose in my notebook, as I worked to profile these APIs: Where do I login / register for a service? What are the security definitions? Where do I get support? Where do I get updates? How do I manage my keys / tokens? What are the details of applications I have created? What are my rate limits? Plan levels available to me?&nbsp; Where am I at with my rate limits? Overall consumption? What am I spending across my API usage? Do I have plan B for any of these? Even possible? What SDKs do I depend on for integration? What are my code, content, and data licensing concerns? Am I adhering to branding requirements appropriately? Can I increase my API usage? Are there new fetaures I am not using? These are just a few of the questions that I wrote down, as I profiled the surface area of each of my APIs. I'm just creating OADF, API Blueprint, and Postman Collections, that allow me understand each endpoint, and the parameters across this almost 35 APIs I use. The next phase of my work involves profiling the security and data definitions for these APIs--a process which I'm sure will surface even more questions. I am not confident I will be able to answer all of these questions in the near future. Many API providers just do not make it easy for me, resulting in the addition of another manual process, which in a world of limited resources means it probably won't get done. Even with the...[<a href="/2015/12/28/thinking-about-my-api-usage-at-scale-across-almost-35-external-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/12/28/my-api-evangelist-strategy-for-2016/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-strategy.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/12/28/my-api-evangelist-strategy-for-2016/">My API Evangelist Strategy for 2016</a></h3>
			<p><em>28 Dec 2015</em></p>
			<p>As I approach 2016, I'm stepping back, and looking at the big picture of what it is that do, and using what I learn to help guide what I will accomplish in 2016. I tend to not subscribe to the concept of predictions, and instead focus on what change I personally would like make within the API space, and this strategy is key to me achieving this vision. First, let's start with what do I do? I track on the world of APIs, with eye towards how we can better execute on the tech, business, and politics of APIs, based upon a better understanding of approaches established by existing API providers, and the features being offered by service providers who target the space. In 2010, I started tracking on API management, and in 2015 this has expanded to almost 35 areas: Aggregation Branding Client Containers Definitions Deployment Design Discovery DNS Embeddable Evangelism Hypermedia&nbsp; IDE Licensing Management Monetization Monitoring Partners Patents Performance Plans Privacy Ratings Real Time Reciprocity Regulation SDK Security Spreadsheets Terms of Service Virtualization Voice Webhooks Originally I saw these research projects as just various lines along the API life cycle or journey, but increasingly I'm also seeing these as just the "first" stack of API resources that I study. Meaning, in 2016 these aspects of the API journey are themselves increasingly API driven--API deployment, management, monitoring, and many other areas are being automated via APIs. Over the last five years, I've conducted my research by studying the approach of successful API providers like Amazon, SalesForce, Google, Twitter, and the longer tale of lesser known government, university, and utility APIs available today. Along the way, these APIs have started organizing themselves into logical groups for me, some based upon the industry they operate in, while others are more about specific business or developmental goals.&nbsp; I call these groupings "stacks"--they also go by other names like hubs, industries, categories, but one important aspect of stacks...[<a href="/2015/12/28/my-api-evangelist-strategy-for-2016/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/12/28/a-roundup-of-api-meetup-groups-in-north-america/"><img src="http://kinlane-productions2.s3.amazonaws.com/oscon-drinkup-2.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/12/28/a-roundup-of-api-meetup-groups-in-north-america/">A Roundup Of API Meetup Groups In North America</a></h3>
			<p><em>28 Dec 2015</em></p>
			<p>The existence, membership, and activity around local API Meetup groups is one of the overall health indicators in the API space. I've long been a proponent of local API meetups, helping jumpstart the early API Craft gatherings, as well as helping new Meetup groups get off the ground.
As we move into 2016, it is a good time to take another look at what API Meetup groups exist, and here is what I found:


San Francisco, CA with 884 members
San Francisco (API Craft) with 662 members
Washington, DC with 1306 members
Austin, TX with 717 members
Seattle, WA with 463 members
Chicago, IL with 394 members
New York, NY (API Craft) with 343 members
Los Angeles, CA with 191 members
Houston, TX with 141 members
Detroit, MI (API Craft)&nbsp;with 246 members
Boston (API Craft) with 426 members
Dallas, TX with 107 members
Denver, CO with 895 members
Nashville, TN with 185 members
Baltimore, MD with 76 members
Montreal, Quebec with 229 members&nbsp;
Toronto, Ontario with 201 members&nbsp;
Minnesota with 169 members&nbsp;
Raleigh, NC with 196 members

At @APIStrat, we use these numbers to help us decide where to put API conferences on, as on the ground support is crucial to making the event a success. I also consider the activity around these local Meetups a sign of how well the space is doing when it comes to outreach and evangelism across the entire industry.&nbsp;
If I missed an API Meetup in your community, please let me know. If you'd like to start an API Meetup in your community, also please reach out, as I may be able to help you jumpstart your efforts with speakers, sponsors, and attendeess. However, ultimately you will have to do all the hard work of finding venues, and getting the word out locally, which if you do right, can be a very rewarding journey in my opinion.
[<a href="/2015/12/28/a-roundup-of-api-meetup-groups-in-north-america/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/12/23/a-little-hack-to-help-me-better-define-method-based-apis-using-oadf/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-technology-of-apis.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/12/23/a-little-hack-to-help-me-better-define-method-based-apis-using-oadf/">A Little Hack To Help Me Better Define Method Based APIs Using OADF</a></h3>
			<p><em>23 Dec 2015</em></p>
			<p>A handful of the most iconic APIs out there, which I also happen to depend on for my own operations, are some of the more frustratingly designed APIs I know. There are many API design offenses we all commit, but one of the most frustrating for me is when you use a single URL, and depend on a single parameter, for accessing everything an API has to offer. A couple of my favorite APIs, Flickr and Amazon EC2 both employ this approach. A single URL, and a single parameter for working with a wealth of API driven resources. This is a classic mistake of the technologist, delivering what you need, but making it difficult to actually learn about an API. This approach to API design delivers upon the functionality desired, but makes very difficult to document using common approaches available to us like OADF, and API Blueprint. When it comes to Amazon EC2, and Flickr, there is so much more value to be articulated in the API design by itself. Flickr organizes their API methods by grouping them on the main page for the API, and Amazon just groups each method for Amazon EC2 on their documentation page--something you can get in a single list if you like, if you prefer. It doesn't' take much work to expose the richness available within these APIs, but when documenting using OADF, it can be hard to articulate the value brought to the table by each resource. Amazon and Flickr both rely on all API calls utilizing GET, but rely on a query parameter to define each unique API call. When you document using OADF, this ends up being a single API endpoint, with a parameter, and any number of parameters to pull out the value an API offers. I needed to define each endpoint as /?method=XXXX, while still allowing each underlying parameter to be defined as a collection for each endpoint.&nbsp; The problem is that each parameter...[<a href="/2015/12/23/a-little-hack-to-help-me-better-define-method-based-apis-using-oadf/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/12/21/variable-rates-on-your-api-get-requests-depending-on-how-many-post-or-put-requests-you-make/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-scatter-plot.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/12/21/variable-rates-on-your-api-get-requests-depending-on-how-many-post-or-put-requests-you-make/">Variable Rates On Your API GET Requests Depending On How Many POST or PUT Requests You Make</a></h3>
			<p><em>21 Dec 2015</em></p>
			<p>I'm down in the detail of how we craft our API plans, looking at the approaches of almost 100 different providers, and working to establish a common schema for cataloging the plans of these popular APIs. I have already talked about dialing in your API pricing down to the endpoint and level, but was something I wanted to take a little bit further. In my previous story, I talked about how mature API providers charge different rates for POST, and PUT requests, than they did for GET requests. Using this scenario, what if we wanted to incentivize and reward behavior through variable rate pricing at the HTTP verb level, to give developers more ownership over an API, including better access and pricing structures the more they contribute. Lets use a standard business directory like say Crunchbase as a model. Everyone wants this data, and you only get so many GET requests, based upon the rate limits limits they've set. What if I was given access to more GET requests, based upon the number of POST and PUT requests I made? Meaning the more data I had added, and updated, the more access I was given when pulling data. Something I think could incentivize developers to be more involved, and improve on the overall quality of content or data via an API. Of course, there would be ways people could game this, but I'm pretty sure you could identify the bad actors using modern API management approaches. You would also need other checks and balances, and quality control elements to make this a reality, but I wanted to focus on the service composition aspect. Could you incentivize internal, partner, or even public API developers to take more ownership of a resource, and help make it better, by applying variable rate controls at the GET level, that are influenced by controls at the POST, and PUT levels? Something to think about. It is also something I will...[<a href="/2015/12/21/variable-rates-on-your-api-get-requests-depending-on-how-many-post-or-put-requests-you-make/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/12/19/button-to-run-this-api-in-the-http-api-client-of-my-choice/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/run-api-in-postman.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/12/19/button-to-run-this-api-in-the-http-api-client-of-my-choice/">Button To Run This API In The HTTP API Client of My Choice</a></h3>
			<p><em>19 Dec 2015</em></p>
			<p>There are more HTTP client tools out there than I can shake a stick at (I've reached that point, I'm shaking sticks at things), and in 2016 I predict there will be even more entrants into the space. I'd say Postman was a pioneering force in the evolution of the HTTP client when it comes for web API space, but is something that it is beginning to collide with API design tooling from Apiary, as well as being morphed by new players like Stoplight.io. Maybe I am playing with more of these environments than the average API consumer is, because of what I do for a living, but I have to say, I am getting tired of "importing" my API definitions. Don't me wrong. I am stoked that all tools support the importing of machine readable API definitions like OADF, and API Blueprint, but I cannot help&nbsp;always looking to what should be next, and I want to be able to just run each API, in my HTTP client of my choice. For all of my own APIs, I provide a Postman icon, and link to a Postman Collection. It just gives you quick access to the machine readable currency that all services I depend on speak, OADF, API Blueprint, and Postman Collection. However, I still have to import it into Postman, or other HTTP API client, or service I will be using. While this is a good start, and is something I recommend other API providers do, I think we can still do better. If you are operating one of the HTTP API clients, or planning one of the next generation&nbsp;API cleints, tools, garage, hub, playground, studio, workbench, or builder, can you please provide a "run in XXXX" embeddable button please? I would like to see pretty little icons throughout API portals, and the service providers we depend on across the API space, that empower me run any API via the client I depend on...[<a href="/2015/12/19/button-to-run-this-api-in-the-http-api-client-of-my-choice/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/12/18/adding-journeys-to-each-of-my-api-research-areas/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/api-plans-journey.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/12/18/adding-journeys-to-each-of-my-api-research-areas/">Adding Journeys To Each Of My API Research Areas</a></h3>
			<p><em>18 Dec 2015</em></p>
			<p>I am continuing to build on the subway map exploration work, that I talked about at @Defrag and @APIStrat last month, and have a more static version of my API life cycle explorer ready, which I'm simply calling the API journey. I have only rolled this out for my API plans research, but so far I'm happy with the results, something that shouldn't be too difficult to light up for the other 30+ areas I'm researching. There is quite of bit of research that goes into the work that I publish, and the subway analogy is allowing me to share more it, making more parts of it more accessible, in ways I was never able to before. Currently you can take the journey through each of the stops along the API plans portion of my research, and learn about in details about some of the common patterns I'm seeing across the space. For each stop I provide a title, and description for the stop, but if I have related organizations, tools, links, and even specific APIs or questions to ask at this stop in the life cycle for any API. My goal is to take the building blocks from leading API platforms, and the features offered by companies offering services to the space, and make accessible to anyone who wants to learn for their own operations. The narrative for my API plans journey isn't 100% there, and some of the stops are lacking in description, as well as related organizations, tools, and other links. However it gives me an excellent framework to further flush out my research, while also sharing it with my readers, in a potentially interactive way. Eventually I'd like for you to be able to actually select the pieces that are important to you, and save it as a customized list at the end--soon! For now, it is helping me flush out the narrative around my research, and connect the dots a...[<a href="/2015/12/18/adding-journeys-to-each-of-my-api-research-areas/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/12/16/defining-api-monitoring-apis-so-i-can-map-to-each-stop-along-the-api-life-cycle/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-heart-monitor.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/12/16/defining-api-monitoring-apis-so-i-can-map-to-each-stop-along-the-api-life-cycle/">Defining API Monitoring APIs So I Can Map To Each Stop Along The API Life Cycle</a></h3>
			<p><em>16 Dec 2015</em></p>
			<p>I am going through each of the 35+ areas of the APi space that I monitor, working to bring alive the over 900 stops along the API life cycle, that I have&nbsp;identified through my research. I'm still working through prototypes for my life cycle explorer, but the current version has organizations, tools, links, and questions, along with the title and description of each stop of the life cycle journey I am trying to bring into focus. Part of my approach in identifying the different lines, areas, and stops along this life cycle involves taking a look at the approach of leading API providers, as well as service being offered by companies selling their solutions to these API providers--giving me two sides of the API life cycle coin. In the last couple months I have also found another way to identify potential building blocks, and round off the ones I have, through the API definitions of leading API providers. All I do, is craft an OADF file for each of the API service providers I track on, within each area of my research. I'm spending time tonight working on my API monitoring research, so I look at three of the service providers I track on, who have APIs. The OADF specs are not complete, but provide me a baseline definition for the surface area of each API, something I'll round out with more use. Here are the endpoints I have from each provider so far. API Science Monitors API&nbsp;(oadf) Get All Contacts&nbsp;- (GET) - /contacts.json Create a Contact&nbsp;- (POST) - /contacts.json Delete a Contact&nbsp;- (DELETE) - /contacts/{id}.json Get a Specific Contact&nbsp;- (GET) - /contacts/{id}.json Update a Contact&nbsp;- (PATCH) - /contacts/{id}.json Get All Monitors&nbsp;- (GET) - /monitors Create a Monitor&nbsp;- (POST) - /monitors Apply Actions to Multiple Monitors&nbsp;- (PUT) - /monitors Get a Specific Monitor&nbsp;- (GET) - /monitors/{id} Get Checks For A Monitor&nbsp;- (GET) - /monitors/{id}/checks.json Performance Report&nbsp;- (GET) - /monitors/{id}/performance Show a Monitors Templates&nbsp;- (GET) -...[<a href="/2015/12/16/defining-api-monitoring-apis-so-i-can-map-to-each-stop-along-the-api-life-cycle/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/12/15/why-i-labeled-my-research-api-plans-instead-of-api-pricing/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-plan.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/12/15/why-i-labeled-my-research-api-plans-instead-of-api-pricing/">Why I Labeled My Research API Plans Instead Of API Pricing</a></h3>
			<p><em>15 Dec 2015</em></p>
			<p>How to monetize APIs is on of the top questions I get from companies, right after concerns around security and control. I have separated my research into two main buckets, the first is focused on the questions I should be asking around API monetization as I'm planning my strategy, with the second focused on the actual plans for the operations of leading API providers. There is a lot of overlap between the two, but I guess API monetization is more strategy, and API plans is more about operations. When I started my API monetization research, it was very focused on how do you make money from your APIs, resulting in the poorly crafted title. I'm not making the same mistake with my API plans research, which is meant to help define a wide range of motivations for providing APIs. I think every API should have an API monetization plan, to cover the costs of acquisition, deployment, and management in a sensible way, and all APIs should have a plan--not all APIs need to have pricing. This is why I labeled my research into API plans the way I did, instead of just focusing on API pricing. Not all APIs have a straightforward API monetization strategy that can be translated into "pricing", from the dark side of platforms that are just content farms, to the brighter side where platforms are focused on the social good. There are many motivations behind API operations, this is why I'm trying to come up with some common ways to reference these motivations in a machine readable way. Keep an eye on my API plan research, as I'm rapidly evolving the building blocks that go into planning your API operations. I am also publishing some common, machine readable definitions from leading API players like AWS, Twilio, and more. All of this is very alpha work, so it might seem cluttered at first, but I am working to slice it up into...[<a href="/2015/12/15/why-i-labeled-my-research-api-plans-instead-of-api-pricing/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/12/15/solution-discovery-instead-of-api-discovery-via-api-aggregation-and-reciprocity-providers/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-api-solution-discovery.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/12/15/solution-discovery-instead-of-api-discovery-via-api-aggregation-and-reciprocity-providers/">Solution Discovery Instead of API Discovery Via API Aggregation and Reciprocity Providers</a></h3>
			<p><em>15 Dec 2015</em></p>
			<p>During my API discovery session talk at @APIStrat Austin this last November, I talked about what I see as an added dimension to the concept of API discovery, one that will become increasingly important when it comes to actually moving things forward --- discovering solutions that are API driven vs. API discovery, where a developer is looking for an API.&nbsp; It might not seem that significant to developers, but SaaS services like Zapier, DataFire, and API hubs like Cloud Elements, bring this critical new dimension to how people actually will find your APIs. As nice as ProgrammableWeb has been for the last 10 years, we have to get more sophisticated about how we get our APIs in front of would-be consumers. We just can't depend on everyone who will put our API to work, immediately thinking that they need an API--most likely they are just going to need a solution to their problem, and secondarily need to understand there is an API driving things behind the scenes. Of of many examples of this in the wild, could be in the area of tech support for your operations. Maybe you use Jira currently, because this is what your development team uses, but with a latest release you need something a little more public facing. When you are exploring what is possible with API reciprocity services like Zapier, and API hubs like Cloud Elements, you get introduced to other API driven solutions like Zendesk, or Desk.com from SalesForce. This is just one example of how APIs can make an impact on the average business user, and will be the way API discovery happens in the future. In this scenario, I didn't set out looking for an API, but because I use API enabled service providers, I am introduced to other alternative solutions that might also help me tackle the problem I need. I may never have even known SalesForce had a help desk solution, if I wasn't...[<a href="/2015/12/15/solution-discovery-instead-of-api-discovery-via-api-aggregation-and-reciprocity-providers/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/12/15/how-tight-is-the-coupling-between-the-saas-business-model-and-the-api/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-link.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/12/15/how-tight-is-the-coupling-between-the-saas-business-model-and-the-api/">How Tight Is The Coupling Between The SaaS Business Model And The API?</a></h3>
			<p><em>15 Dec 2015</em></p>
			<p>As part of evaluating 50+ companies, and their business approach to delivering APIs, I came across the Box platform. As I am looking through this diverse slice of API companies, I am looking to better understand the motivations behind providing APIs, and how sophisticated the monetization or overall planning are for their operations.&nbsp; For most APIs, there is either no evident monetization strategy, the strategy is directly coupled with API access, or indirectly part of larger monetization strategy around existing devices, products, advertising, software as a service, or any other type of service. When it came to Box, they have a clear SaaS pricing model, as well as one specifically for their API ecosystem--of course they are both intertwined, but the fact there are separate dimensions I felt made it worth highlighting. Box has obviously put a lot of thought into their business model. In addition to having a separate set of plans for their SaaS, and developer areas, they have the developer page broken down into packages by Box platform, content, and view--which I don't fully grasp yet, and will continue to evaluate. Out of the 50+ companies I looked at, Box was the only to have such a significant separation between the SaaS and developer layers, whie also being very tightly coupled, leading to me putting aside for further consideration. This latest sprint in my API plan research was limited. I am guessing that the more companies I find that operate like Box, the more this will all come into focus. I'm guessing at Box central there is a command and control center with a master plan on the wall of how the SaaS side of things works with the API side, as well as a breakdown of the tiers that is based upon their operational experience over the years. The best I can do from the outside is try document the patterns across SaaS and API pioneers like Box, and understand the...[<a href="/2015/12/15/how-tight-is-the-coupling-between-the-saas-business-model-and-the-api/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/12/15/easier-to-offer-ops-apis-to-your-devs-if-your-api-service-provider-has-apis/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-inception.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/12/15/easier-to-offer-ops-apis-to-your-devs-if-your-api-service-provider-has-apis/">Easier To Offer Ops APIs To Your Devs If Your API Service Provider Has APIs</a></h3>
			<p><em>15 Dec 2015</em></p>
			<p>I'm looking at the pricing APIs offered by some of the API providers that are further along in their API journey. This is just one example of how API providers are offering more operational level APIs to their developers, giving them control over their own integration, allowing programmatic control over account settings, billing, rate limits, and pricing. I've talked about the need to allow for more automation of the modern API life cycle, allowing API consumers to better manage their consumption across the many APIs they are depending on. This is why I'm spending a greater amount of time focusing on API service providers in the space practicing what they preach, and making simple, easy to use APIs available for the services they offer. When API service providers do this, it make it easier for API providers to extend API driven operations to their consumers. The fact that my 3Scale API management infrastructure has an API, allows me to proxy and deliver a pricing, plans, and rate limit API to my API consumers. All of these elements are present in the service composition 3Scale provides me, and the fact that they have an API allows me to extend it as part of my own API stack to my consumers. This does not stop with just the API management line of my API life cycle. I can provide programmatic access to my API monitoring, because API Science and Runscope has APIs, and to my SDKs via APIMATIC, and multi-format versions of my API definitions using the API Transformer API. Every stop along my API life cycle involves my API consumers, and in addition to me being able to automate my API operations using APIs, my developers should be able to automate their API consumption as well. The moral of this story I guess, is that if you are providing services to API providers--have all of your services available via an API. Once you have done this,...[<a href="/2015/12/15/easier-to-offer-ops-apis-to-your-devs-if-your-api-service-provider-has-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/12/15/dialing-in-your-api-pricing-down-to-the-endpoint-and-verb-level/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-getpostputdelete.pn" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/12/15/dialing-in-your-api-pricing-down-to-the-endpoint-and-verb-level/">Dialing In Your API Pricing Down To The Endpoint And Verb Level</a></h3>
			<p><em>15 Dec 2015</em></p>
			<p>
I am spending a significant amount of time looking through the pricing pages for leading API providers, working to get a sense for some of the common approaches to API monetization in use across the space. Along the way I am also finding some simple and unique approaches from API providers that I wanted to share as bit-size API planning stories here on the blog.
As the API service composition of leading providers evolve in the space you see platforms getting more granular in not just how they control access to their API resources, but also how they incentivize consumption. When I say granular, I am talking about API pricing for APIs available down to the endpoint, or even HTTP verb level. Here is a description, straight from Amazon S3:
PUT, COPY, POST, or LIST Requests = $0.005 per 1,000 requests ,GET and all other Requests = $0.004 per 10,000 requests, with delete requests being free
This approach represents a sophisticated view of API planning and monetization. Companies who are earlier on in their API journey often only use their GET verb, afraid of the repercussions of opening up PUT, POST, or DELETE. This is where API service composition comes into play, and gives you greater control over your resources, while also opening up access, and incentivizing the type of behavior that is beneficial to both API provider and consumer.
I've come across a number of providers who are taking this approach, and will link to them more within my API plan research. I have a whole list of bit-size API monetization, pricing, and planning stories queued up. I will try to space them out, alongside other stories, but you will just have to suffer a little as I spend time expanding on my&nbsp;API monetization, and&nbsp;API plans&nbsp;research areas.&nbsp;
[<a href="/2015/12/15/dialing-in-your-api-pricing-down-to-the-endpoint-and-verb-level/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/12/15/customizable-terms-of-service-as-part-of-your-api-plans/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-terms-conditions.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/12/15/customizable-terms-of-service-as-part-of-your-api-plans/">Customizable Terms of Service As Part Of Your API Plans</a></h3>
			<p><em>15 Dec 2015</em></p>
			<p>
I am spending a significant amount of time looking through the pricing pages for leading API providers, working to get a sense for some of the common approaches to API monetization in use across the space. Along the way I am also finding some simple and unique approaches from API providers that I wanted to share as bit-size API planning stories here on the blog.
As I was working to understand the coupling between the Box SaaS business model, and the one applied to their API, I noticed an interesting element, that was part of their enterprise API plan--custom terms of service. At first glance it doesn't seem like much, but making elements of your TOS dynamic, allowing them up to be used as a metric within your API plans, opens up a whole world of possibilities.&nbsp;
I have to note, this option is only available in the enterprise plan, which means only those with the most resources get this opportunity, but I still think its presence is meaningful. Right now, most terms of service and privacy policies are immovable shadows that guide how we do business and conduct our personal lives online, so the ability to think of them more dynamically, and one that could be tied to specific API access plans has huge potential. Unfortunately in the true Silicon Valley spirit, only some of this potential will be good, much of it will be in the name of exploitation, and the shifting of how power flows.
I have terms of service listed as a potential metric in my API plans research--we'll see where this goes, as my work evolves. I have a whole list of bit-size API monetization, pricing, and planning stories queued up. I will try to space them out, alongside other stories, but you will just have to suffer a little as I spend time expanding on my&nbsp;API monetization, and&nbsp;API plans&nbsp;research areas.&nbsp;
[<a href="/2015/12/15/customizable-terms-of-service-as-part-of-your-api-plans/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/12/14/where-is-the-api-reciprocity-platform-designed-just-for-managing-api-operations/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-api-operations.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/12/14/where-is-the-api-reciprocity-platform-designed-just-for-managing-api-operations/">Where Is The API Reciprocity Platform Designed Just For Managing API Operations</a></h3>
			<p><em>14 Dec 2015</em></p>
			<p>
I am seeing more operations focused API tooling emerge lately, like Stoplight.io, and as I'm adding API reciprocity platform DataFire to my list of integration, automation, and interoperability providers, I'm asking myself -- where is the API reciprocity platform designed specifically for managing API operations?
I am talking about the Zapier, but just for API providers and consumers. With Datafire, I see things have a little more business and operations edge, than I've seen from more consumer offerings like Zapier. What I am hoping for, is someone to build a platform that lets you automate, integrate, and orchestrate all of your API focused operational needs across the cloud.
This new platform will automatically setup monitoring using API Science or Runscope, when a new containerized microservice fires up. I could have recipes for automatically registering public APIs.json indexes, with APIs.io, the open source API search engine. Whenever a new developer registers via my 3Scale API infrastructure, I could profile them on FullContact, and queue up their Twitter, LinkedIn, and Github profiles for me to engage with as part of my evangelism efforts.
I could go on and on, regarding tasks that I need automated across my API operations, and about how the services that I employ are providing me with APIs to manage things. All of this is making the potential for integration, interoperability, automation, transformation, and most importantly reciprocity within my API operations increase pretty dramatically. Hopefully someone will follow the lead of Zapier, and newer offerings like DataFire, and bring a solution to the table that will help alleviate some of the challenges we face daily, in the operations of our APIs.
[<a href="/2015/12/14/where-is-the-api-reciprocity-platform-designed-just-for-managing-api-operations/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/12/14/making-sure-the-latest-api-pricing-update-is-available-in-a-developer-portal-messaging-area/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/auth0-pricing-fma.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/12/14/making-sure-the-latest-api-pricing-update-is-available-in-a-developer-portal-messaging-area/">Making Sure The Latest API Pricing Update Is Available In A Developer Portal Messaging Area</a></h3>
			<p><em>14 Dec 2015</em></p>
			<p>I am spending a significant amount of time looking through the pricing pages for leading API providers, working to get a sense for some of the common approaches to API monetization in use across the space. Along the way I am finding some simple approaches from API providers that I wanted to share as bit-size API planning stories here on the blog. After recently landing on the pricing page for identity service provider Auth0, I saw that they included a simple message and link to the latest blog post about API pricing changes. It is a simple, subtle, yet very prominent approach to making sure your API consumers are aware of pricing changes that may impact their integration. I recently wrote about providing a messaging area to reach developers upon platform login, but this approach from Auth0 is about providing relevant messaging no matter where you are at in the developer portal--not just at login. Couple of lessons for me, extracted from this approach: Prominent FMA - Providing a prominently placed, flexible messaging area, can help make sure your API consumers stay up to speed on the latest, when it comes to platform operations.&nbsp; Pricing Storytelling - Telling the story around each change in pricing is a critical aspect of operation. Publishing a story on your blog, syndicating out through your social channels, and prominent placement via a FMA is key. This help rekenforce the fact that we should make sure to regularly communicating out our decisions around API monetization. Also making sure there is a saturation factor to our messaging, and that it is available via our blogs, Twitter, LinkedIn, and any other relevant page or channel used to reach API consumers. I have a whole list of bit-size API monetization, pricing, and planning stories queued up. I will try to space them out, alongside other stories, but you will just have to suffer a little as I spend time expanding on my API...[<a href="/2015/12/14/making-sure-the-latest-api-pricing-update-is-available-in-a-developer-portal-messaging-area/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/12/12/apis-in-the-most-mature-sectors-have-pricing-apis/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-machine-readable-pricing.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/12/12/apis-in-the-most-mature-sectors-have-pricing-apis/">APIs In The Most Mature Sectors Have Pricing APIs</a></h3>
			<p><em>12 Dec 2015</em></p>
			<p>A lot can be learned from the pioneers of the API space. Companies like Amazon and Twilio have been used as a model by many providers, and are something I reference often across my research and storytelling. These providers have been playing the API game for a while, so they have a wealth of experience to bring to the table, but they also are working with well defined, and highly valuable API driven resources which we can learn from. I'm neck deep in evaluating the pricing of modern APIs, and Amazon and Twilio both provide a wealth of things to consider when it comes to API monetization. One of the common patterns that has emerged for me, is the presence of pricing APIs: AWS Price List API - In order to meet the needs of these customers and to foster the development of even more tools that focus on cost management, budgeting, and the like, we are launching the AWS Price List API. Twilio Pricing API - The Pricing REST resource provides a simple API to pull real time, account-specific pricing for Twilio's messaging, voice and phone number products. As Amazon says on their page, "Many AWS customers and partners have been asking for a programmatic way to access prices for AWS services. Current customers and partners would like to make sure that their budgeting, forecasting, and analytics tools are able to analyze AWS prices without having to resort to scraping our web site." These types of API resources provide the rest of us with a glimpse at what the future possibly holds for our own APIs. The world of cloud computing, voice, and messaging APIs are significantly more mature than other areas being served by APIs, but how the leading API providers are monetizing their APIs, and develop tooling for their consumers, gives us elements we should all be considering for our own road maps. I hope you are ready for a time, where...[<a href="/2015/12/12/apis-in-the-most-mature-sectors-have-pricing-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/12/10/a-process-to-aggregate-rss-feeds-as-apis-for-nondevelopers/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-rss-icon.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/12/10/a-process-to-aggregate-rss-feeds-as-apis-for-nondevelopers/">A Process To Aggregate RSS Feeds As APIs For Non-Developers</a></h3>
			<p><em>10 Dec 2015</em></p>
			<p>A blog RSS feed is still my number one way to monitor what is happening across the API space. I also use RSS from Google Alerts and TalkWalker to monitor a variety of leading API industry keywords. RSS is an important information gathering format, and I wanted to help some of my non-developer followers, understand how they can aggregate RSS feeds across a variety of topics, clean up, and publish a centralized API for all feeds. To take advantage of this advice, you will need to have three separate accounts: Zapier - API reciprocity provider, helping you move your bits and bytes around online. Google - Online spreadsheet solution, which can be used to deploy APIs. Restlet - API deployment and management as a service provider. Once you have accounts with these three services, you can take advantage of the features each brings to the table: Pull RSS From Providers - Using Zapier, you can setup Zaps, which will allow you to connect RSS feeds, and route them to your Google Sheets. Setup a recipe for each RSS feed you will want to pull, store, and make available later. Google Sheet Content Store - Google Sheets provides you a data store, which your Zapier recipe will route all new RSS posts to. Depending on how many feeds you pull, and aggregate, you can setup one or many documents, and worksheets. Publish Central API - Using Restlet, you can setup what is called an entity store, which pulls the content of your spreadsheet(s), and stores them locally for publishing as an API. Once deployed, you can then setup a web API, which provides all content pulled via RSS, as a single API. Ok, many developers are going to ask me, "why the hell would you do this"? First, this isn't for you--it is for folks without programming experience. This post is meant to be the outline, for an actual API integration how-to series I am working...[<a href="/2015/12/10/a-process-to-aggregate-rss-feeds-as-apis-for-nondevelopers/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/12/07/minimum-viable-api-service-provider-blueprint/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-minimum-viable.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/12/07/minimum-viable-api-service-provider-blueprint/">Minimum Viable API Service Provider Blueprint</a></h3>
			<p><em>07 Dec 2015</em></p>
			<p>There are some pretty good examples (in my opinion), of well defined API service providers across the API landscape right now-- companies, who are selling services specifically to API providers. You know how you can tell a good provider? They do one thing, or just a handful of things well, it is well presented, and they also have an API -- who woulda thought that? Companies selling services to API providers should also do so via an API! I am most definitely biased in showcase these companies, but a couple examples of this in action can be found with APIMATIC, Runscope, 3Scale, SecureDB, and API Scrience. These are all companies that I support, but I support them because they offer valuable services to companies who are operating APIs, and they do it in a simple, well thought out way, complete with an API. When you are crafting the strategy for the API service provider you would like to launch, here are my recommendations of what you should be including: Website - Simple, modern, and informative website for your customers to discover, and on-board with the services you offer. Twitter - Have a genuine, active Twitter account that actually engages in conversations with community. Github - Establish an active, and meaningful Github presence via user account or organization, and make it your open work bench. Blog - Provide a thoughtful, active, and informative blog to comunicate with the community, your customers, and the public. API - If you are selling APIs to API providers, you need to make sure and be drinking the kool-aid with an API of your own. SaaS - Follow the principles of software as a service. I do not want to deal with old ways of purchasing and licensing software. Pricing - Offer tiered pricing, so that we can kick the tires, and small companies (or groups) like myself can actually afford what you are offering. Support - Make sure you are...[<a href="/2015/12/07/minimum-viable-api-service-provider-blueprint/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/12/07/going-beyond-just-json-data-and-considering-the-relationships-that-exist-and-the-actions-that-can-be-taken/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-relational-data.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/12/07/going-beyond-just-json-data-and-considering-the-relationships-that-exist-and-the-actions-that-can-be-taken/">Going Beyond Just  JSON Data And Considering The Relationships That Exist, And The Actions That Can Be Taken</a></h3>
			<p><em>07 Dec 2015</em></p>
			<p>I spent the weekend adding a Siren media type to my API building blocks API, in support of my API life cycle map&nbsp;work. Every time I dive into using Siren, and begin applying hypermedia constraints to my API design, I'm pleasantly surprised by what I learn. I am not a hypermedia evangelist, I am just trying to share what I learn, as I go evolve, and hopefully add to some of the existing knowledge that is floating around out there.&nbsp; This work on my building blocks API is still very much a work in progress, when it comes to my own understanding of hypermedia, but also how I can use it to craft a more meaningful story around API(s). The first major benefit I realized, was instead of just have a basic JSON representation of my API building blocks, I was immediately forced to consider some very important dimensions around the JSON data I was serving up. Properties - What are the properties of the collection returned, or individual data sets. Entities - What are the actual structured objects that I am returning, and how do they relate. Actions - What actions can be taken around my data, and how can a developer engage with it. Links - What relevant links about the entities, and the information it contains are present. Before this, I would just have a JSON array or object, which is essentially what I have under properties now, but now that I'm using Siren, I also have other meaningful relationships between my data present as entities. I also can provide relevant actions and links that any developer will potentially need, when they are working with the data provided. For me, this evolution is significant. It isn't just about alleviating my version control challenges, or providing &nbsp;the perfect client (well I do have some client ambitions in doing this), it is just about helping think more deeply about the relationships between all of...[<a href="/2015/12/07/going-beyond-just-json-data-and-considering-the-relationships-that-exist-and-the-actions-that-can-be-taken/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/12/07/a-fun-way-to-explore-http-status-codes-with-a-subway-map-from-restlet/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/restlet-http-status-codes.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/12/07/a-fun-way-to-explore-http-status-codes-with-a-subway-map-from-restlet/">A Fun Way To Explore HTTP Status Codes With A Subway Map From Restlet</a></h3>
			<p><em>07 Dec 2015</em></p>
			<p>If you were at @defrag or @apistrat in November, you know that I am working to better understand the often complex world of APIs using the Subway map concept. My goal is to better understand the overall API life cycle, as well as the life cycle of individual APIs, and how I can articulate, strategize, and execute on it all, using a subway experience.&nbsp;
It made me happy to see the folks over at Restlet playing with the same concept&nbsp;(we didn't coordinate on it honestly), to help articulate HTTP status codes, which is a very important topic for the space, and we need more education tools, and stories around it. Using the subway map analogy, Restlet provides a representation of the five areas of status codes, providing a simple way to explore them, and find a description of each individual status code.

The subway map they provide is currently a static map, but this is one of the biggest potential areas in using this analogy for me, is that with the right JavaScript + JSON voodoo, you can make it real-time, and interactive. This is something I'm working on to bring the entire lifecycle to the forefront this month.&nbsp;
Nice work Restlet team, I enjoy these efforts by providers to help educate the space, especially when they do it in creative and fun ways like this.
Disclosure: Restlet is an API Evangelist partner.
[<a href="/2015/12/07/a-fun-way-to-explore-http-status-codes-with-a-subway-map-from-restlet/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/12/07/75-of-your-api-efforts-in-the-enterprise-will-be-cultural-and-political-not-technical/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-roadblock.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/12/07/75-of-your-api-efforts-in-the-enterprise-will-be-cultural-and-political-not-technical/">75% Of Your API Efforts In The Enterprise Will Be Cultural And Political, Not Technical</a></h3>
			<p><em>07 Dec 2015</em></p>
			<p>I started API Evangelist, because I saw a huge deficiency in the overall API conversation--nobody was talking about the business of all of this, and how you actually make money doing this emerging web API thing. Over time, I also discovered that very few people were also studying, and discussing the politics of APIs. Sure, when something flares up around terms of service violations, or there is an acquisition that the community dislikes, we discuss it, but we have to talk about the political issues in real-time, not at polarize-time. From my vantage point, the business and politics of API operations, internal as well as external influences, continue to be the number one things that negatively impact API operations, over anything technical. Let's just look at a couple examples of this in action: Money - How are you going to operate an API without any money? Either from paying customers, or internally from other sources. Doers - If your business has been built on traditional sales and support models, evolving consumers to a doers mentality will not be an easy. Competing Interests - Various groups within an organization competing for budget, attention, and any other way regular current operations impact your API vision. Management Change - Your CTO had your back, and the new one not so much. It could be about lower level or mid-management support, all the way to the top. When the champions leave, API programs often dry up on the vine. Industry Regulation - Silicon loves to be in denial of the larger world, and the regulatory frameworks that are in place across many industries--once you grow big enough, or operate in the right space, this will become clearer. Scope - How big are things? Software? Teams? Systems? Processes? There are many things that are big in the enterprise and even small businesses, that will resist decoupling and unbundling. People just do not think of things in small, bite-size chunks--it just...[<a href="/2015/12/07/75-of-your-api-efforts-in-the-enterprise-will-be-cultural-and-political-not-technical/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/12/04/api-client-tool-garage-hub-playground-studio-workbench-and-builders/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/api-client-lifecycle-1.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/12/04/api-client-tool-garage-hub-playground-studio-workbench-and-builders/">API Client, Tool, Garage, Hub, Playground, Studio, Workbench, And Builders</a></h3>
			<p><em>04 Dec 2015</em></p>
			<p>I am spending some time taking another look at my "client research", which started out as just about Postman and PAW, but now contains ten separate services I'm and bundling into this area of research. As with all my research areas, these project repos shift, evolve, split and marge with time, as the API space changes, and my awareness of it grows.&nbsp; I &nbsp;completely understand the term "client" doesn't provide an adequate label for this bucket of research, but for now, it will have to do. As I add a couple of new services to the bucket, and made my way through some of the existing ones I had, I wanted to step back and look at what they were offering, but more importantly the message that went around quantify what tehse companies were offering. When it comes to what I call "lines along the API lifecycle", I saw these areas represented. This is where the API client line potentially intersects with all of these other API life-cycle lines. However, When you start to analyze the features or building blocks offered by these service providers, you begin to see each stop along along the API client line, which becomes pretty critical to other areas of the API lifecycle. I know that what I am saying might not be completely clear, it isn't for me either. That is why I tell stories, to try and find the patterns, and learn how to articulate all the moving parts. I'm still trying to figure out what to call my research, alongside all of these API service providers working to define just exactly what it is they are selling as well.&nbsp; The more time I spend with my API client research, the more all of this comes into focus. The problem is that these companies are rapidly adding in new features, in demand to what their customers are needing, which keeps me on my toes, as well as increases...[<a href="/2015/12/04/api-client-tool-garage-hub-playground-studio-workbench-and-builders/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/12/03/what-is-api-service-composition/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-conductor.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/12/03/what-is-api-service-composition/">What Is API Service Composition?</a></h3>
			<p><em>03 Dec 2015</em></p>
			<p>This is another one of those topics I talk a lot about, but only found few examples of me talking about on the blog--API service composition. If you aren't familiar with the concept, it is the art of taking digital resources (aka APIs), and mix and match them in different ways, until you find the right approach to delivering APIs, that provides value for both provider and consumer. API service composition is about taking the basic building blocks of any web API, the URL, path, and VERBS (ability to get, add, update, and delete), and put them into as many different configurations as you think makes sense. Limiting who can access, how much they use, restrict by time frame, and crafting different pricing for different users or groups, require trial periods, setup costs, and even restricting to specific countries. API service composition is all about taking your APIs, and if you are using modern API infrastructure like from 3Scale, you can compose any service you desire, serving it up to anyone, in a secure way, using the open Internet. This is the magic of modern API-driven solutions, when an API can be any digital resource, from simple data and content, to media like images, audio, and video, all the way to an increasing number of devices like fitness trackers, thermostats in our homes, and even our cars. When you have all of these resources at your finger tips, and the ability to compose them into any possible package, to satisfy any group of consumers--you have unlimited potential. This is why so many companies, organizations, institutions, and government agencies are jumping on the API train. When you do APIs right, you gain a new level of control over the increasing amount of digital resources that are dominating our lives. API service composition is the key to all of this, and is one of the parts of the journey I enjoy the most--composing meaningful API service that...[<a href="/2015/12/03/what-is-api-service-composition/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/12/03/automating-api-key-management-using-api-service-provider-apis-and-other-open-source-solutions/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-key-management-api.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/12/03/automating-api-key-management-using-api-service-provider-apis-and-other-open-source-solutions/">Automating API Key Management Using API Service Provider APIs, And Other Open Source Solutions</a></h3>
			<p><em>03 Dec 2015</em></p>
			<p>I'm working my way through some of the low hanging fruit in my API notebook, when it comes to stories, and found a story thread I was working on regarding automating API key management. I'm personally storing my keys, across the private master branch for my API reps, because I don't have any super-sensitive data, and it helps me manage across hundreds of APIs, in a central way.&nbsp; I've talked about the need to automate API key management in the past--with the number of APIs we are using, to reach the level of security we will need, the lower level of keys will need a global refresh and management process. This level of keys most likely won't ever result in large scale security breaches, but will cause plenty headaches for both API providers and consumers. If you use one of the following API management solutions, they provide you with an API for managing your API keys: 3Scale Apigee Tyk This will help you manage your keys, if you are an API provider, but doesn't do a lot for you to manage your API keys across providers, as an API consumer. Amazon provides a key management solution, but at first glance it appears to be something you can use to manage keys across your AWS infrastructure (am I wrong?)--which makes sense for supporting AWS objectives. ;-) When I wrote my last post on the growing need for API key management solutions, I received a number of email and DMs, which yielded two pretty interesting open source key management solutions, Vault and Keywhiz. I'm going to evaluate these solutions for their viability as a back-end for an API driven, API key management solution, but I have a lot more work to do.&nbsp; I'm also working with a partner of mine, SecureDB, and consider the possibility fo developing an encrypted API key management solution, which then would be accessible via their secure API. They are looking for some...[<a href="/2015/12/03/automating-api-key-management-using-api-service-provider-apis-and-other-open-source-solutions/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/12/02/what-licensing-should-i-be-considering-when-i-take-open-source-software-and-offer-up-as-an-api/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-open-source.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/12/02/what-licensing-should-i-be-considering-when-i-take-open-source-software-and-offer-up-as-an-api/">What Licensing Should I Be Considering When I Take Open Source Software And Offer Up As An API?</a></h3>
			<p><em>02 Dec 2015</em></p>
			<p>
I've done this a couple of times now. I took&nbsp;PhantomJS, and created my Screenshot API, and used&nbsp;ImageMagick to create my Image Manipulation API. These are two openly licensed software solutions, which I took, and am using as an API.&nbsp;
What are my licensing considerations? If I keep my server side code licensed according to the specifications, am I fine? PhantomJS is licensed under BSD, and ImageMagick is Apache 2.0. Does the licensing extend itself to the commercial services I would potentially offer via an API interface? There are lots of questions to satisfy, before I move forward--I guess I am looking for a precedent.
I am evaluating at a number of openly licensed software solutions right now to deliver a variety of stops along the API life-cycle, ranging from design, to deployment, virtualization, and much more. As always, I am trying to better understand the layers involved, and how software licenses, patent, and potentially copyright might apply.
Just putting it out there to the universe, and curious to see what comes back.
[<a href="/2015/12/02/what-licensing-should-i-be-considering-when-i-take-open-source-software-and-offer-up-as-an-api/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/12/02/using-the-wikimedia-objective-revision-evaluation-service-and-move-beyond-just-get-with-your-api/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/Objective_Revision_Evaluation_Service_logo.svg.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/12/02/using-the-wikimedia-objective-revision-evaluation-service-and-move-beyond-just-get-with-your-api/">Using The Wikimedia Objective Revision Evaluation Service And Move Beyond Just GET With Your API</a></h3>
			<p><em>02 Dec 2015</em></p>
			<p>
I stumbled across&nbsp;Objective Revision Evaluation Service (ORES)&nbsp;last night,&nbsp;a web service running in Wikimedia Labs that provides machine learning as a service across Wikimedia Projects, and is designed to help automate vandalism detection and removal for content, being developed as part of the&nbsp;R:Revision scoring as a service&nbsp;project.
As I came across, I was also considering different access plans across my APIs, with some of the plans allowing for updating existing content in the system--the topic of abuse of API access was on my mind. I'm curious if ORES could be applied to any sort of content or data post via a PUT / PATCH API request?
Even if it didn't 100% out of the repo, maybe it could it be evolved to help manage the PUT / PATCH layer of API operations, allowing platforms to open up a little bit more, and open up more of their HTTP verbs, to a wider audience. Something like this could go a long way to helping API providers secure, and stabilize their API operations, and loosen service composition restrictions a little further.
Just a thought, as I'm kicking the tires of some of the open source API offerings I come across. Seems like to me, there is an opportunity for someone to deploy these open solutions as a service, and help API providers open up a little more. Just sharing with my audience, as a possible service that would benefit the API space, and hopefully make someone a little beer money--who knows!
[<a href="/2015/12/02/using-the-wikimedia-objective-revision-evaluation-service-and-move-beyond-just-get-with-your-api/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/12/02/realizing-i-need-hypermedia-to-bring-my-api-lifecycle-vision-to-life/"><img src="https://s3.amazonaws.com/kinlane-productions2/talks/november-2015/subway-map-15.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/12/02/realizing-i-need-hypermedia-to-bring-my-api-lifecycle-vision-to-life/">Realizing I Need Hypermedia To Bring My API Lifecycle Vision To Life</a></h3>
			<p><em>02 Dec 2015</em></p>
			<p>I have been learning about hypermedia over the last three years now, and only earlier this year, I began playing with Siren to help me craft a better experience around my API industry news and link curation API. My motivations in going down this hypermedia road was never about easing my client side pain, or helping me with future versions of my API--I am just not that sophisticated of an operation. I started playing with hypermedia to help evolve the experience around the API news I was curating each week, making it so you could browse week by week, month by month, but also by topic, company, author, etc. I'm still trying to figure it out all out, and honestly the project is currently in the ditch after hitting the wall this fall, and not really giving a shit about the flow of API news. (I am better now, thx!) Now in December, I'm trying to take my building block API, which provides access to over 600 of the common patterns I've tracked on across the API space. These are the features offered by API service providers, and the competitive advantage brought to the table by the successful API providers I keep an eye on, and they are all potential stops along the API life-cycle I am working to define. My API building block API is a pretty standard content API, providing each element broken down by category, and type, with other supporting details. However, now I need to be able to plot them on a subway map, with an endless number of configurations, and dimensions to the journey. Via my building block API, I need to return any single stop along the API life-cycle, but along with it I need to provide the next stop in the line, the previous stop (paging 101), but then if I hit a transfer station, or other element, I need to offer an unlimited number of dimensions. While...[<a href="/2015/12/02/realizing-i-need-hypermedia-to-bring-my-api-lifecycle-vision-to-life/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/12/02/api-economy-tooling-for-the-business-masses/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-masses.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/12/02/api-economy-tooling-for-the-business-masses/">API Economy Tooling For The Business Masses</a></h3>
			<p><em>02 Dec 2015</em></p>
			<p>
Most of the tooling and services I come across in the API space, are designed for developers. As I play with more services, and put tools to work, trying understand their role in the API space, some take a lot of work to figure out, while others are pretty clear--it will be these tools and services that the masses of business users adopt, as part of the API evolution that is occurring online currently.
There are just a handful of services out there right now, that I think are mainstream ready, and are something that the average business user of the web, should be playing with right now--here are three of them:

Restlet - Deploy API from a Google Spreadsheet.
Blockspring - Use APIs in a Google Spreadsheet.
Form.io - Deploy an API as form, via Single Page App.

There are other services and tools out there that will help you deploy and consume APIs, but these stand out, because they help the average business user solve real world business problems they are facing, without needing to write code. They also anchor there solutions in existing tooling that are ubiquitous, and part of every day business operations--the spreadsheet and the form.
Developers might care about the technical details of APIs, and evangelists like me might be able to convince some of the average business users of the potential of APIs, but before we can bring the masses on-board, we will need the right tools. Restlet, Blockspring, and Form.io have the potential to be these tools, and help the "normals" become active participants in the API economy, but more importantly find the (API driven) solutions they need for the problems they face every day.
[<a href="/2015/12/02/api-economy-tooling-for-the-business-masses/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/12/01/the-growing-need-for-api-virtualization-solutions/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-virtulization.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/12/01/the-growing-need-for-api-virtualization-solutions/">The Growing Need For API Virtualization Solutions</a></h3>
			<p><em>01 Dec 2015</em></p>
			<p>This conversation has come up over 10 times this month, at Defrag, APIStrat, and online conversations via Skype and GHangouts. The concept of API virtualization solutions. I am not talking about virtualization in the cloud computing and Docker sense, although that will play a fundamental role in the solutions I am trying to articulate. What I am focusing on is about providing sandbox, QA environments, and other specialized virtualization solutions for API providers, that make API consumers worlds much easier.&nbsp; I've touched on examples of this in the wild, with my earlier post on&nbsp;API sandbox and simulator from Carvoyant, which is an example of the need for virtualization solutions that are tailored for the connected automobile solution. Think of this, but for every aspect of the fast growing Internet of Things space. The IoT demand is about the future opportunity, I've talked about the current need, when I published, I Wish All APIs Had Sandbox Environment By Default. I see envision 1/3 of these solutions being about deploying Docker containers on demand, 1/3 being about virtualizing the API using common API definitions, and the final 1/3 being about the data provided with the solutions. This is where I think the right team(s) could develop some pretty unique skills when it comes to delivering specialized simulations tailored for testing home, automobile, agriculture, industrial, transportation, and other unique API solutions. We are going to need "virtualized" versions of our APIs, whether or not it is for web, mobile, devices, or just for managing APIs throughout their life cycle. You can see a handful of the current API virtualizations out there on my research in this area, but I predict the demand for more robust, and specialized API virtualization solutions is going to dramatically increase as the space continues its rapid expansion. I just wanted to put it out there, and encourage all y'all to think more about this area, and push forward the concept of API virtualization...[<a href="/2015/12/01/the-growing-need-for-api-virtualization-solutions/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/12/01/freemium-access-for-your-api-is-not-bad-it-is-just-one-tool-in-your-providers-toolbox/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-tools.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/12/01/freemium-access-for-your-api-is-not-bad-it-is-just-one-tool-in-your-providers-toolbox/">Freemium Access For Your API Is Not Bad, It Is Just One Tool In Your Providers Toolbox</a></h3>
			<p><em>01 Dec 2015</em></p>
			<p>I get regular links sent to me, and foiks telling me that freemium API access is a bad idea. That it doesn't help your API sales funnel, and was something that was just a thing, for a brief moment in time. The folks who always bring me these stories, are not API consumers, they are business folks.&nbsp; I agree, there are some really bad examples of freemium in play across the API space, and with the bad behavior we see from API consumers, I fully understand why stories make their rounds--leaving a bad taste in the mouths of API providers for freemium access. The disconnect that allows this to happen in my opinion, is folks not thinking through their monetization, plans, and pricing in an API centric way. Folks approach it as a across the board monetization approach, and do not think of it as a tool to apply on a resource by resource basis.&nbsp; Freemium is just one tool in your toolbox, and should evaluated at every step in the monetization planning for your APIs, and used, or not used, based upon your well planned on-boarding funnel for your API consumers. Consider educational access to your API resources (also one tool in your toolbox), which is a common offering from API providers. You wouldn't offer this in all scenarios, it just doesn't make sense, but you aso wouldn't just dismiss it as a bad idea--you keep in your toolbox for when it makes sense. I see API operations let by business folks dismiss freemium as a bad idea because they don't experience on how it influences in the on-boarding process, but I also see API operations let by developers dismiss the need for traditional sales approaches, and hurt themselves in similiar ways. Ultimately, I recommend iterating through the list of common API monetization building blocks I've aggregated from leading API providers, for each resource you are planning to release. If you have a modern...[<a href="/2015/12/01/freemium-access-for-your-api-is-not-bad-it-is-just-one-tool-in-your-providers-toolbox/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/12/01/evolving-my-api-stack-to-be-a-public-repo-for-sharing-api-discovery-monitoring-and-rating-information/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-api-sharing.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/12/01/evolving-my-api-stack-to-be-a-public-repo-for-sharing-api-discovery-monitoring-and-rating-information/">Evolving My API Stack To Be A Public Repo For Sharing API Discovery, Monitoring, And Rating Information</a></h3>
			<p><em>01 Dec 2015</em></p>
			<p>My API Stack began as a news site, and evolved into a directory of the APIs that I monitor in the space. I published APIs.json indexes for the almost 1000 companies I am trackig on, with almost 400 OADF files for some of the APIs I've profiled in more detail. My mission around the project so far, has been to create an open source, machine readable repo for the API space. I have &nbsp;had two recent occurrences that are pushing me to expand on my API Stack work. First, I have other entities who want to contribute monitoring data and other elements I would like to see collected, but haven't had time. The other is I that I have started spidering the URLs of the API portals I track on, and need a central place to store the indexes, so that others can access. Ultimately I'd like to see the API Stack act as a public repo, where anyone can grab the data they need to discovery, evaluate, integrate, and stay in tune with what APIs are doing, or not doing. In addition to finding OADF, API Blueprint, and RAML files by crawling and indexing API portals, and publishing in a public repo, I want to build out the other building blocks that I index with APIs.json, like pricing, and TOS changes, and potentially monitoring, testing, performance data available. Next I will publish some pricing, monitoring, and portal site crawl indexes to the repo, for some of the top APIs out there, and start playing with the best way to store the JSON, and other files, and provide an easy way explore and play with the data. If you have any data that you are collecting, and would like to contribute, or have a specific need you'd like to see tracked on, let me know, and I'll add to the road map. My goal is to go for quality and completeness of data there, before...[<a href="/2015/12/01/evolving-my-api-stack-to-be-a-public-repo-for-sharing-api-discovery-monitoring-and-rating-information/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/12/01/deploying-an-api-from-your-critical-twitter-data-without-being-a-programmer/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/twitter-to-restlet.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/12/01/deploying-an-api-from-your-critical-twitter-data-without-being-a-programmer/">Deploying An API From Your Critical Twitter Data Without Being A Programmer</a></h3>
			<p><em>01 Dec 2015</em></p>
			<p>I am continuing my series on helping non-developers realize they can publish, and put APIs to work, without having an API expert in their pocket, using Zapier, Google Sheets, and Restlet. Its no secret that Restlet is an API Evangelist partner, and they are my partner because they are the easiest way to deploy a web API--something I am trying to help the "normals" understand the untapped potential of. As I finish up my @APIStrat conference again, for the sixth time, I'm reminded that I need to harvest the essential Twitter exhaust from the conference, otherwise if I wait too long, I won't be able to get it. You see, Twitter limits what you can grab from the Twitter API by either time, or number of Tweets, so I can only gather X amount of Tweets, and if I wait too long, I'm often out of luck. It is critical that I do this right away, and depending on how loud the Twitter exhaust is, I need to do it while the event is still going on. To start, you obviously need a Twitter account, but you will also need a Zapier, Google and Restlet account. Then using Zapier you can gather the following Twitter data points, and send to a Google Sheets: New Mentions New Followers New Favorites New Tweets How you store these in Google Sheets is up to you, but I recommend breaking each data point down as its own sheet, and even by separate time-frame like day, week, or month. It helps to keep things broken up into smaller chunks, when you are using Google Sheets as a data store--tricks of the trade! Zapier gives you everything you need to setup the Zaps that route mentions, followers, favorites, and your tweets to the Google Sheet(s), and once they are there, you can clean up, edit, and organize as you see fit. Next Restlet comes into the picture, allowing you deploy an...[<a href="/2015/12/01/deploying-an-api-from-your-critical-twitter-data-without-being-a-programmer/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/11/30/when-intelligent-programmers-realize-they-do-not-understand-http-and-the-web-that-they-use-daily/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-http.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/11/30/when-intelligent-programmers-realize-they-do-not-understand-http-and-the-web-that-they-use-daily/">When Intelligent Programmers Realize They Do Not Understand HTTP And The Web That They Use Daily</a></h3>
			<p><em>30 Nov 2015</em></p>
			<p>
I've seen something at an ever increasing pace lately, situations where very intelligent software engineers hit a wall, and realize they do not understand the fundamental building blocks of HTTP, and the web that we are all using daily. It makes my heart ache, because I remember when I found myself in the same place, and still suffer from the deprivation I experienced.
Whether it was my time programming in Microsoft-land, Drupal, WordPress, or any other Web 2.0-land, I eventually realized how much was hidden from me behind the curtain. When you bundled this with the fact I'm a fairly privileged white male software engineer who can be fairly clueless about what is around me, I missed a lot. Something I still find myself recovering from in 2015, even after five years of exclusively studying web APIs--you know, the ones that use HTTP for transport?&nbsp;
I'm not stupid, but with my lazerfocus &trade;, I often miss a lot. I feel that many of the smart people I know suffer from a similar illness, but do not have the fortitude for transparency, or the humbleness to accept, that will allow them to move on. Programming language dogma, and platform or framework dependencies can be a powerful thing, but they can also do a lot protect us from what we need to learn to actually be successful, and grow.
At this point, i question everything. What I know. What a platform might be hiding from me, to sell back to me as feature, and what is the bigger picture of the Internet that I use everyday, and often take for granted.
[<a href="/2015/11/30/when-intelligent-programmers-realize-they-do-not-understand-http-and-the-web-that-they-use-daily/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/11/30/making-sure-everything-you-offer-as-an-api-service-provider-is-portable/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/runscope-api-tests.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/11/30/making-sure-everything-you-offer-as-an-api-service-provider-is-portable/">Making Sure Everything You Offer As An API Service Provider Is Portable</a></h3>
			<p><em>30 Nov 2015</em></p>
			<p>
Runscope added the ability to import and export your API tests as JSON, helping make API monitoring a much more flexible and portable thing. You can import and export using the Runscope UI, as well as import via their API, help you automate the setup of your API tests.&nbsp;
I judge API service providers based upon whether they have an API, and I am increasingly encouraging my readers to do the same. I will also be studying the portability of services that are being sold to API providers, and pushing for more import / export features like Runscope offers.
I will be tracking on the API definitions used by service providers like Runscope, across the 26+ areas I monitor, and trying to better understand the JSON schemas they are using to encourage the portability of their services. The API definition, response, and request models put forth by companies, tells a lot about the service they offer in my opinion, and I'd say the overall portability of services is another strong characteristics I will be keeping an eye out for.
[<a href="/2015/11/30/making-sure-everything-you-offer-as-an-api-service-provider-is-portable/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/11/30/i-like-being-able-to-verify-a-developer-is-real-before-giving-them-access-to-my-apis/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-imperial-droid.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/11/30/i-like-being-able-to-verify-a-developer-is-real-before-giving-them-access-to-my-apis/">I Like Being Able To Verify A Developer Is Real Before Giving Them Access to My APIs</a></h3>
			<p><em>30 Nov 2015</em></p>
			<p>As I think about the bad behavior that occurs on the API consumption side of API operations, I'm considering ways that I can help API providers address these problems when they arise within their ecosystems. What can you do when bad actors have access to your APIs? Also more critically for some providers, what can you do to prevent bad actors from on-boarding with your API program at all? I strongly believe that companies should be as public with their API efforts as possible, but when it comes to which developers you let in, and which ones you don't, I'm finding I'm becoming more conservative in my thoughts--as long as you are transparent about the process. I'm still forming all of my thoughts around this (hence the blog post), and I'm sure is something that will keep evolving as I continue to push forward my awareness of the API space. When I see a new sign-up for my own APIs, I like to be able to verify who the new consumer is. I like to see a real name, and potentially a company name, but also when I Google the combination, I like to see an active Twitter, LinkedIn, or Github account. It is easy to tell real people, from personas that live n the shadows, and I prefer verifiable people use my APIs. If you are a public API consumer, I do not think it is unreasonable to ask you to maintain some sort of public presence, to verify who you are, and what you do. I know for many enterprise developers this is insanity, which is why I put LinkedIn profiles in the mix--I do not expect everyone to be super popular on Twitter, and a die-hard Github user. However, in 2015, you really should consider! As I'm going through my own API on-boarding process, trying to make smoother (it isn't the best right now), I am considering how I will articulate what...[<a href="/2015/11/30/i-like-being-able-to-verify-a-developer-is-real-before-giving-them-access-to-my-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/11/30/how-do-i-price-my-api-resources/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-dollar-sign.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/11/30/how-do-i-price-my-api-resources/">How Do I Price My API Resources?</a></h3>
			<p><em>30 Nov 2015</em></p>
			<p>
I am continuing to push my research around API monetization, plans, and partners forward, whilep preparing for my API lifecycle keynote at @Defrag and @APIStrat. Along the way, I am also exercising some of my API pricing and planning strategies with my partner in crime at APIware, as we think through some new products that we are developing.
How I approach pricing for API products, is on a resource by resource basis, considering all of the API monetization tools in my toolbox. For example, when i launch two new API endpoints for exploding API definitions, and telling me how big my APIs are, I quickly run down my list of monetization building blocks to see which areas will apply to these new resources. The reality is, until these APIs leave an alpha stage, they will just exist in my internal consumption tier.
Even though these APIs aren't ready for prime time yet, I am already thinking through which of my API monetization building blocks will apply. Will I charge for access? Are they available in the freemium tier? Do I offer only a trial version of them? Ultimately it all comes down to who I will be targeting with these resources, and in this case it will be primarily hardcore API architects--something that helps me define how I will price these resources, and which service tiers I make them available in.
When it comes to generating revenue from APIs, rarely are there a one size fits all solution. You should be considering each resource based upon the value it brings to the table, who you are targeting with this resource, and weighing all the tools in a modern API monetization toolbox. Remember the business of APIs resembles the technology of APIs, where you do things in small chunks, and you iterate, until you find the optimal value proposition that works for the platform, and your consumers.
[<a href="/2015/11/30/how-do-i-price-my-api-resources/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/11/30/bridging-how-we-currently-document-our-apis-now-with-how-we-should-be-experiencing-apis-via-hypermedia/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/foxycart-api-screenshot.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/11/30/bridging-how-we-currently-document-our-apis-now-with-how-we-should-be-experiencing-apis-via-hypermedia/">Bridging How We Currently Document Our APIs Now With How We Should Be Experiencing APIs Via Hypermedia</a></h3>
			<p><em>30 Nov 2015</em></p>
			<p>I am still catching up on my feeds, and open browser tabs, and one tab that has been open for a couple of weeks is Why Your Colleagues Still Don&rsquo;t Understand Hypermedia APIs, by Luke Stokes (@lukestokes) of FoxyCart. The post is very thought provoking for me, and represents what I feel is the very pragmatic front of the hypermedia movement, from someone who has helped move the concept of a hypermedia API from academic discussion to reality, with the FoxyCart API. His challenges at the end of his post really set the stage for me: So how do we find a balance between idealism about what Hypermedia API documentation systems &ldquo;should&rdquo; be and what they practically are? How can we move the whole ecosystem forward by encouraging client developers to code to link relationships instead of hard-coded URLs? How do we help pave the way for the future but not look like unsophisticated outsiders in the process? What pragmatic steps should we take to be like the other cool kids using standard documentation presentations while at the same time saying, &ldquo;Um, yeah, don&rsquo;t do that. Don&rsquo;t code to the URL, code to the link relationship instead.&rdquo; For me, his questions illuminate the canyon between where the API community is currently with API design, and the vision of where we should be going with our API design practices. The more I play and learn with hypermedia, the less I see it as the lofty vision for the future, and the more I see it as a set of practical design patterns that will make my API work more meaningful. The shortcomings of API definitions like Swagger (now OADF), is that it was designed for documenting your API, after it was already designed--awesome, but not remotely about API design. Where the concept of hypermedia is all way back the other direction, where you have to put some serious thought into your API design, before you ever...[<a href="/2015/11/30/bridging-how-we-currently-document-our-apis-now-with-how-we-should-be-experiencing-apis-via-hypermedia/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/11/30/apis-dedicated-to-elections-at-the-city-county-state-or-federal-level/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-voting.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/11/30/apis-dedicated-to-elections-at-the-city-county-state-or-federal-level/">APIs Dedicated To Elections At the City, County, State, Or Federal Level</a></h3>
			<p><em>30 Nov 2015</em></p>
			<p>
I'm neck deep in government open data again, and as we are gearing up for the presidential election, you really begin to see the potential for accurate, real-time election data via APIs. There are a number of leading election-related APIs at the federal level like we have from the&nbsp;Sunlight Foundation, and you see the emergence of high value APIs out of government like the&nbsp;Federal Election Commision (FEC) API from the 18F, but with the amount of money in politics, and scope of what is at stake, I can't help but feel there is a huge opportunity out there for more election APIs.
Seems to me that there is an opportunity for some API savvy activistpreneur to step up at the city, county, state, and even the federal level. I'm not just talking about election districts, candidate, and other common building blocks of elections we experience, but real-time sentiment, superpac spending, and other influential information that if availablle for distribution via APIs, could shift the balance one way or another. It would take a healthy assessment of the current landscape, but I think you could identify some low hanging fruit to get started with.
One you get going on the API journey around election data, if you do it right, you will learn a lot, and discover other valuable content or data sources, and see patterns that the rest of might not see. The use of social platforms over the last 8+ years of elections was all API driven, and is just the tip of the iceberg--an API dedicated to elections seems like a huge opportunity to me, in coming months and years.
Let's get to work!
[<a href="/2015/11/30/apis-dedicated-to-elections-at-the-city-county-state-or-federal-level/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/11/29/the-bad-actors-on-both-sides-of-the-api-fence/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-unhappy.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/11/29/the-bad-actors-on-both-sides-of-the-api-fence/">The Bad Actors On Both Sides Of The API Fence</a></h3>
			<p><em>29 Nov 2015</em></p>
			<p>
I've always been a strong advocate for the API consumer, which is one of the primary motivations for me working to define best practices that API providers can follow across their operations. The majority of my negative experiences, when it comes to APIs, has been as an API consumer, not as an API provider.
As I do this API Evangelist thing longer, and longer, the bad behavior by API consumers becomes more clear to me, and I'd say rivaling much of the bad behavior by API providers that I have seen, and in some cases helping actually drive it. I do not have any bad actors in my API community, but through conversations I have had with leading API providers, I'm hearing some pretty crazy stories.
Badly behaved API consumers range from signing up for multiple accounts, rather than paying for higher levels of access, to trolling within the community, treating other developers badly, platform owners horribly, and just being a shitty API community citizen. You will never truly understand how badly API consumers can behave, until you've operated an API platform, and had a large number of consumers putting an API to use.&nbsp;
While I will always keep my critical stance towards API providers, as I feel they often set the tone for a community, I am increasingly more understanding when platforms have to tighten things down, and get more critical when it comes to the public availability of API resources. In the end, I will always push for more public transparency around every aspect of API operations, but I am increasingly advising companies to have a tight grip on their API service composition, and what resources developers get access to, before they prove they are trustworthy.
[<a href="/2015/11/29/the-bad-actors-on-both-sides-of-the-api-fence/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/11/29/the-api-lifecycle-my-talk-from-defrag-and-apistrat/"><img src="https://s3.amazonaws.com/kinlane-productions2/talks/november-2015/Beck_Map_1933.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/11/29/the-api-lifecycle-my-talk-from-defrag-and-apistrat/">The API Lifecycle (My Talk From @Defrag and @APIStrat)</a></h3>
			<p><em>29 Nov 2015</em></p>
			<p>I recently told the story of how I view the API life-cycle, based upon my research across the space, at the Defrag Conference in Broomfield, CO, and at my API Strategy &amp; Practice conference in Austin, TX. I spent two weeks pushing my research forward in preparation for these talks, and wanted to take a moment to gather my thoughts, and share the narrative of my talk. When I first gave this title and abstract for both the Defrag and APIStrat keynotes, I called it "the 17 stops along a modern API lifecycle". After pushing my research forward, to support these talks, it became 26 stops, then those became what I am calling "lines", resulting in me just call the talk "the API life-cycle". I use my public speaking as a vehicle for my API research, helping me polish my work, and ultimately pushing me to craft better narratives around my work, but most importantly, make it more coherent, and make sense to the average individual. One way that I do this, is to root my stories in history, build upon the earlier work in the tech space, and anchor them to other relevant areas of our everyday lives. Everything I do as the API Evangelist is built on the hard work of men and women who came before me. From the 1940s... The 1950s... The 1960s... The 1970s... The 1980s... The 1990s... The 2000s... Getting us to the current decade, where I saw the potential of delivering the compute resources we needed for the mobile devices, that were quickly becoming ubiquitous in our daily personal as well as business lives. Designing, deploying, and managing APIs in support of mobile was the catalyst for my research as the API Evangelist in the summer of 2010. As the API Evangelist, all that I do is map out what I am seeing across the API space, mapping out what API pioneers like Amazon and Salesforce are doing,...[<a href="/2015/11/29/the-api-lifecycle-my-talk-from-defrag-and-apistrat/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/11/29/keeping-a-window-open-into-how-power-flows-within-algorithms-using-apis/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-power-button.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/11/29/keeping-a-window-open-into-how-power-flows-within-algorithms-using-apis/">Keeping A Window Open Into How Power Flows Within Algorithms Using APIs</a></h3>
			<p><em>29 Nov 2015</em></p>
			<p>I just read The Pill versus the Bomb: What Digital Technologists Need to Know About Power, by&nbsp;Tom Steinberg (@steiny), and I'm reminded of the important role APIs will (hopefully) continue to play in helping provide a transparent window into some of the power structures being coded into the algorithms we are increasingly relying on in this digital world we are crafting. In this century, we are seeing a huge shift in how power flows, and despite the rhetoric of some of the Silicon Valley believers, this power isn't always being democratized along the way. Much of the older power structures is just being re-inscribed into the algorithms that drive network switches, decide pricing when purchasing online, via our online banking, and virtually ever other aspect of our personal and business worlds. APIs give us a window into how these algorithms work, providing access to 3rd party developers, government regulators, journalists, and many other essential actors across our society and economy. Don't get me wrong, APIs are no magic pill, or nuclear bomb, when it comes to making algorithmic power flows more transparent and equitable, but when they are done right, they can have a significant effect. If APIs are a complete (or near complete) representation of the algorithms that are driving platforms, they can be used to better understand how decisions behind the algorithmic curtain are made, and exactly how power is flowing (or not) on web, mobile, and increasingly connected device platforms--API does not equal perfect transparency, but will help prevent all algorithms from being black boxes. We may not fully understand Uber's business motivations, but through their API we can test our assumptions. We may not always trust Facebook's advertising algorithm, but using the API we can develop models for better understanding why they serve the ads they do. Drone operators may not always have the best intentions, but through mandatory device APIs, we can log flight times and locations. These are just...[<a href="/2015/11/29/keeping-a-window-open-into-how-power-flows-within-algorithms-using-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/11/25/providing-api-json-as-a-discovery-media-type-every-one-of-my-api-endpoints/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-api-discovery.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/11/25/providing-api-json-as-a-discovery-media-type-every-one-of-my-api-endpoints/">Providing API.json As A Discovery Media Type Every One Of My API Endpoints</a></h3>
			<p><em>25 Nov 2015</em></p>
			<p>It can be easy to stumble across the base URL for one of my APIs out on the open Internet. I design my APIs to be easily distributed, shared, and as accessible as possible--based upon what I feel the needs for the resource might be. You can find most of my APIs, as part of my master stack, but there are other APIs like my screen capture API, or maybe my image manipulation API, that are often orphaned, which I know some people could use some help identifying more of the resources that are behind API operations. To help support discovery across my network of APIs, I'm going to be supporting requests for Content-Type: application/apis+json for each endpoint, as well as an apis.json file in the root of the API, and supporting portal. An example of this in action, can be seen with my blog API, where you can look into the root of the portal for API (kin-lane.github.io/blog/apis.json), and in the root of the base URL for the API (blog.api.kinlane.com/apis.json), and for each individual endpoint, like the (blog.api.kinlane.com/blog/) endpoint, you can request the&nbsp;Content-Type:&nbsp;application/apis+json, and get a view of the APIs.json discovery file. It will take me a while to this rolled out across all of my APIs, I have worked out the details on my blog, and API APIs. Providing discovery at the portal, API, and endpoint level just works. It provides not just access to documentation, but the other critical aspects of API operations, in a machine readable way, wherever you need it. It is nice to be on the road to having APIs.json exist as the media type (application/apis+json), something that isn't formal yet, but we are getting much closer with the latest release, and planned releases. Next, I will push out across all my APIs, and do another story to capture what things look at that point. Hopefully it is something I can encourage others to do eventually, making API discovery...[<a href="/2015/11/25/providing-api-json-as-a-discovery-media-type-every-one-of-my-api-endpoints/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/11/24/i-am-thankful-for-another-amazing-apistrat/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/apistrat-austin-2015.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/11/24/i-am-thankful-for-another-amazing-apistrat/">I Am Thankful For Another Amazing APIStrat</a></h3>
			<p><em>24 Nov 2015</em></p>
			<p>
I am back home in Los Angeles, after another great edition of API Strategy &amp; Practice--this time in Austin, TX. I have had a few day to decompress, and took a day to reboot my brain by crafting 235K+ API definitions for the English language, resulting in some time to reflect on what happened last week in Austin.
First of all I want to thank 3Scale. Without the API infrastructure provider, APIStrat would not happen. Second I want to thank all the sponsor s who get involved, without your support the conversation wouldn't happen. Third, I want to thank the speakers and attendees for making it such a meaningful conversation.
I tend to use that word, "conversation" a lot when describing APIStrat, but I feel pretty strongly that it is the conversation that occurs at APIStrat that helps move the entire API community in a very meaningful way. The conference always renews my energy, and strengthens my relationships with other important folks in the space that I rely on for my research and storytelling.
Thank you so much to everyone who came to Austin last week and participated, and special thanks to Steve and the 3Scale team for investing so much into the API community, while asking for so little in return.
[<a href="/2015/11/24/i-am-thankful-for-another-amazing-apistrat/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/11/23/sharing-235k-api-definitions-with-the-english-language-api-recipe-book/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-api-copyright.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/11/23/sharing-235k-api-definitions-with-the-english-language-api-recipe-book/">Sharing 235K API Definitions With The English Language API Recipe Book</a></h3>
			<p><em>23 Nov 2015</em></p>
			<p>I needed a side project to reboot my mind after @APIStrat this last weekend, so I opened up my notebook and picked a project that I've been meaning to give some attention to, one that would help me clean my slate, and let me get back to my regular work levels. The project I picked is one that I came up with a little over a year ago, but recently had flushed out my vision further, as I hung out at my favorite watering whole drinking an IPA. It took me several iterations before I landed on a name for this project, but my working title is the English Language API Recipe Book. I find myself in an awkward position these days, when it comes to the concept of API copyright, which is something I have taken a firm stance on with my work around the Oracle v Google ava API copyright case, and the release of the API licensing format API Commons, but is something, in the end, I just do not believe in. You see, in my opinion, API definitions should NOT fall under copyright. Like recipes and menus, API definitions should not be open for anyone to use. To help me make my point, I wanted to craft the English Language API Recipe Book, publishing an open API definition for almost every word in the English dictionary. I found a reasonably complete list of every English word, and auto-generated an Open API Definition Format (OADF) specification for each of the 235K+ words.&nbsp; For each API definition, I cover the base GET, POST, PUT, and DELETE verbs for each word, providing a basic query via a parameter, and return a name, and description as the basic underlying data model. I am already playing with other variations of database models, and have also generated another dimension for each word, by again iterating through each word, and adding it as a secondary level resource. I...[<a href="/2015/11/23/sharing-235k-api-definitions-with-the-english-language-api-recipe-book/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/11/13/the-apistrat-austin-schedule-has-reached-that-level-of-amazing-for-me-again/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/16672086073_12b6e018c1_z.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/11/13/the-apistrat-austin-schedule-has-reached-that-level-of-amazing-for-me-again/">The APIStrat Austin Schedule Has Reached That Level Of Amazing For Me Again</a></h3>
			<p><em>13 Nov 2015</em></p>
			<p>
This is the 6th edition of API Strategy &amp; Practice, happening in Austin, TX next week. As one of the organizers, I can say that pulling together the perfect lineup of speakers and topics is always a daunting challenge, but then at some point before the event happens, the schedule always seems to take on a life of its own.
The APIStrat Austin schedule has reached that point again. We have enough killer speakers and companies present, it has attracted other killer speakers and companies, resulting in a mindblowing 3 days of workshops, keynotes, panels, and sessions--if you haven't taken a look at the schedule lately, take a few moments.
I was going through, looking for problems, missing photos, etc, and the scope of the people and companies present just struck me how amazing it has become, and I had to share. If you aren't registered, make sure and do so, and if there is someone you think that should be in attendance, feel free to ping me directly--you won't want to miss it.
See all y'all in Austin next week!
[<a href="/2015/11/13/the-apistrat-austin-schedule-has-reached-that-level-of-amazing-for-me-again/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/11/07/thinking-through-the-licensing-for-an-api-stack/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/bw-licensing-stack.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/11/07/thinking-through-the-licensing-for-an-api-stack/">Thinking Through The Licensing For An API Stack</a></h3>
			<p><em>07 Nov 2015</em></p>
			<p>I've spent a lot of time thinking through the licensing we apply to APIs, as part of my work on the Oracle v Google API copyright case. The licensing around APIs is still in flux, with the current precedent being that APIs are copyrightable. Even though I do not believe this stance, I encourage API designers to make sure and apply one of the more liberal Creative Commons licenses to your API definitions, taking a pre-emptive stance in the conversation. In my experience most API providers, let alone consumers and the public at large, do not understand the separation between an APIs definition, and the code that runs the API, and often even the code that consumes an API. To help us visualize the separation, as well as think through the licensing implications of each layer, I have setup a specific research project that addresses API licensing, in hopes of spending time regularly researching the topic, as well as telling stories that help people navigate how to license their APIs. Here is how I'd break down the five most common layers of the API licensing stack, and some ideas for how you can apply licenses to these layers of API operations. Server Code -&nbsp;For many APIs, your server code will be your secret sauce and kept proprietary, but for those of you who wish to open source this critical layer, here are some options. To help you navigate the licensing, I recommend using&nbsp;Github's Choose a License. Apache&nbsp;- The Apache License is a free software license written by the Apache Software Foundation (ASF). The Apache License requires preservation of the copyright notice and disclaimer. Like other free software licenses, the license allows the user of the software the freedom to use the software for any purpose, to distribute it, to modify it, and to distribute modified versions of the software, under the terms of the license, without concern for royalties. GPL&nbsp;- The GNU General Public License...[<a href="/2015/11/07/thinking-through-the-licensing-for-an-api-stack/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/11/05/the-swagger-spec-is-reborn-as-open-api-definition-format-oadf-after-being-put-into-open-api-initiative-oai/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/open-api-logo.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/11/05/the-swagger-spec-is-reborn-as-open-api-definition-format-oadf-after-being-put-into-open-api-initiative-oai/">The Swagger Spec Is Reborn As Open API Definition Format (OADF) After Being Put Into Open API Initiative (OAI)</a></h3>
			<p><em>05 Nov 2015</em></p>
			<p>
We reached another significant milestone in the API space today, after being acquired by SmartBear this spring, the Swagger specification is being moved into a Linux Foundation grouped called the Open API Initiative (OAI).
SmartBear has been working with the core group of vendors including 3Scale, Apigee, Capital One, Google, IBM, Intuit, Microsoft, PayPal, and Restlet over the summer to hammer out the details of the organization, and the charter that drives the group forward.
Its no secret, I am a pretty big support of the specification, and happy to see it be reborn, within the community driven group, as a community driven open spec. I&rsquo;m looking forward to continuing my development of interesting things on top of the OADF  specification, and telling stories about what the community is building as well.
If you have a cool tool or service that you have built on the spec, make sure and let me know, so I can share the story with my network.
[<a href="/2015/11/05/the-swagger-spec-is-reborn-as-open-api-definition-format-oadf-after-being-put-into-open-api-initiative-oai/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/11/05/contemplating-hypermedia-when-my-focus-is-on-experience/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-happy-face.jpeg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/11/05/contemplating-hypermedia-when-my-focus-is-on-experience/">Contemplating Hypermedia When My Focus Is On Experience</a></h3>
			<p><em>05 Nov 2015</em></p>
			<p>
I wish I had more time to spend on designing, and deploying APIs the way I desired. Without any real funding of individual APIs, I can only go so far with them, which usually doesn't go beyond the minimal viable API. However, even with this reality, I have two APIs I would love to see done right, and keep nagging at me.
One API is my curated news API, which I currently have a pretty bare bones JSON definition to represent each news article I curate from the API space (date, title, author, body, url). As I have time, I've been trying to craft a Siren representation of this same resource. The opportunities for exploration of my archive of curated API news going back to 2011 is pretty huge (in my opinion).
Recently, I've also been having delusions of a hypermedia enabled version of my audio API, which I use store audio files I find, create, or publish. It is a CRUD version of what I'd like to see, but recently I've been thinking of ways I could craft a more audible version of API Evangelist, but in order to do it right, I need a hypermedia enabled API experience.
For me, ,this takes hypermedia beyond many of the discussions I have been exposed to, moving my motivations into the realm of user experience, and not about building a client that will rule them all, or just as a matter of principle--I just want to deliver the right experience. How do I allow consumers of my audio API to define their own experience? How do I craft some experiences, based upon my view of the API space--as I see the world?
This is where hypermedia goes beyond the technical, and moves into the experiential realm where I'm hoping that I can manifest some more money to pay for tehse API designs to become a reality. ;-) Thank you for your support!
[<a href="/2015/11/05/contemplating-hypermedia-when-my-focus-is-on-experience/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/11/04/the-30-areas-i-am-working-to-define-in-the-api-space/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-watching-api-space.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/11/04/the-30-areas-i-am-working-to-define-in-the-api-space/">The 30 Areas I Am Working To Define In The API Space</a></h3>
			<p><em>04 Nov 2015</em></p>
			<p>When I started API Evangelist in 2010, I tracked on one area--API management. Over the years this expanding to be about API deploy, and design, and most recently monitoring and discovery. As I approach the end of 2015, I've expanding this to be 30 separate areas of research. I have almost 200 projects I'm pushing forward in one way or another, but these 30 years reflect the API space I am working so hard to make sense of in 2015. While all of my research is a work in progress, I have these core projects as part of my regular monitoring, and I will be updating as much as possible. Design Hypermedia Definitions DNS Deployment Virtualization Containers Management Monitoring Testing Performance Security Terms of Service Privacy Branding Discovery Client SDK IDE Embeddable Webhooks Aggregation Reciprocity Real-Time Voice Spreadsheets Monetization Plans Partners Evangelism While this may seem like a lot of areas to keep track of, I'm finding it easier and easier to do, as it all continues to come into focus for me. I also have other research areas I'd like to merge in here, and maybe some other areas I'd like to to migrate out of existing research, into new areas. As I'm preparing for my keynotes at Defrag in Colorado, and APIStrat in Austin this month, I'm refreshing all of my research, and trying to use my work to craft a hopefully interesting talk, while also sharing some nuggets of wisdom from the vantage point I enjoy. All of my research is licensed CC-BY, is machine readable by default, and runs on Github, so if you have any questions you can submit an issue, or ping me directly. If you are feeling adventurous you are also welcome to fork any of my work and incorporate it with your own work, or even submit a pull request and contribute your own thoughts to my research. As always you can find this working list of...[<a href="/2015/11/04/the-30-areas-i-am-working-to-define-in-the-api-space/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/11/04/slashdb-created-the-ranking-digital-rights-corporate-accountability-index-api-i-was-asking-for/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/slashdb-new-logo-sideways-medium.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/11/04/slashdb-created-the-ranking-digital-rights-corporate-accountability-index-api-i-was-asking-for/">@SlashDB Created The Ranking Digital Rights Corporate Accountability Index API I Was Asking For</a></h3>
			<p><em>04 Nov 2015</em></p>
			<p>I read a lot of blog posts, and press releases about open data these days, and when I find a dataset I think offers a lot of value, or is just interesting enough to help push forward, I either try to incorporate into my Adopta open data work, or I just put it out to my followers to see if anyone can help. As I was monitoring the space yesterday I came across the&nbsp;Ranking Digital Rights 2015 Corporate Accountability Index, which "evaluates 16 of the world&rsquo;s most powerful Internet and telecommunications companies on their disclosed commitments, policies, and practices that affect users&rsquo; freedom of expression and privacy."--I saw there was an excel and CSV versions of the report, but I didn't see an API, so I tweeted out: Done @kinlane https://t.co/f69iFoYgDJ &mdash; SlashDB (@slash_db) November 4, 2015 Victor Olex (@agilevic) from SlashDB, turned around an API endpoint in a matter of a couple of hours. Here is what Victor sent me: I took your Twitter challenge and created the API for Ranking Digital Rights data. The data model does not include scores for individual lines of business, but it does have all qualitative data needed to make sense of it. I did not write any data aggregation queries, but we can add those later. The whole thing works off a MySQL database model, which I designed and fed with data from the spreadsheet. Using SlashDB, Victor quickly generated the following endpoints for quick access to the digital rights data behind the report: Root API endpoint -&nbsp;http://demo.slashdb.com/db/rdr.html Privacy indicators -&nbsp;http://demo.slashdb.com/db/rdr/indicator/category_cd/P.html All privacy grades -&nbsp;http://demo.slashdb.com/db/rdr/indicator/category_cd/P/grade.html American companies' grade on C1 (Commitment - Policy and Leadership) -&nbsp;http://demo.slashdb.com/db/rdr/company/country_cd/US/grade/indicator_cd/C1.html Companies, which scored at least 75% on at least privacy indicator -&nbsp;http://demo.slashdb.com/db/rdr/indicator/category_cd/P/grade/value/0.75..1/company.html All grades in Telecom -&nbsp;http://demo.slashdb.com/db/rdr/industry/industry_cd/TELCO/company/grade.html As above, but pull in company and indicator details too -&nbsp;http://demo.slashdb.com/db/rdr/industry/industry_cd/TELCO/company/grade.json?depth=1 All grades with company and indicator data inline -&nbsp;http://demo.slashdb.com/db/rdr/grade.json?depth=1 These are very resource oriented API endpoints, meaning they look like the raw resource...[<a href="/2015/11/04/slashdb-created-the-ranking-digital-rights-corporate-accountability-index-api-i-was-asking-for/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/11/04/educating-api-developers-with-each-login-over-at-cloudelements/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/cloud-element-login.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/11/04/educating-api-developers-with-each-login-over-at-cloudelements/">Educating API Developers With Each Login Over At @CloudElements</a></h3>
			<p><em>04 Nov 2015</em></p>
			<p>
I am a big advocate for making sure the on-boarding process for developers is as friction-less as possible. Developers should be able to signup, and login without anything getting in their way. This is why normally I wouldn't suggest adding anything unnecessary to to signup and login process, but I saw something over at Cloud Elements that I thought was interesting.
First, let me know that Cloud Elements gets bonus points because they emphasize signing in with your Github or Google account. I am a big fan of keeping all my API accounts linked to my Github profile--it just makes sense to me. I'd love it if API providers allowed me to store keys, SDKs, and other resources within my private Github repository, that I use across all the APIs I depend on. (I'm sure someone will tell me not to do this, but nobody has yet to convince me of why)
What really caught my eye logging in, was the updates they provided at the bottom of the login screen. There was an image, with a simple message telling me that v1 of the Cloud Elements API was sunsetting, with a simple "Read More" link, so I can get more details. I like this concept of adding these type of critical updates to the login screen for developers.
I am going to add a flexible messaging area to signup and login screen, as part of my suggested on-boarding building blocks. Developers may not be regularly logging into their API developer portals, so I wouldn't depend on this channel for everything, but in addition to the blog, Twitter, and other channels, it might make sense as a way to share important information with API consumers.
[<a href="/2015/11/04/educating-api-developers-with-each-login-over-at-cloudelements/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/11/04/adding-an-oauth-scope-page-as-one-of-my-api-management-building-blocks/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/slack-oauth-scopes.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/11/04/adding-an-oauth-scope-page-as-one-of-my-api-management-building-blocks/">Adding An OAuth Scope Page As One Of My API Management Building Blocks</a></h3>
			<p><em>04 Nov 2015</em></p>
			<p>
I've had a handful of suggested building blocks when it comes to authentication, as part of my API management research, but after taking a look at the OAuth Scopes page for the Slack API, I'm going to add another building block just for listing out OAuth scopes.
For platforms who provide OAuth, scopes are how access to users content and data is being broken down, and negotiated. When it comes to industry levels, OAuth scopes are how power and influence is being brokered, so I'm going to start tracking on how leading providers are defining their scopes--I am sure there are some healthy patterns that we all can follow here.
I have had the pleasure of sitting in on OAuth negotiations between major utility providers, as part of my work with the White House and Department of Energy&nbsp;in the past.&nbsp;This work has given me a glimpse into the future of how access and sharing of data will be negotiated in the future, with OAuth scopes and APIs playing a central role.
It will take me some time to standardize how I gather, store, and publish the OAuth scopes for each API, but I can get started by bookmarking any provider who shares their OAuth scopes, and encourage other API providers to do, by suggesting a formal OAuth scopes page as one possible building block you should consider when crafting your API strategy.
[<a href="/2015/11/04/adding-an-oauth-scope-page-as-one-of-my-api-management-building-blocks/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/11/04/a-social-api-performance-report-from-apimetrics/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/apimetrics-social-api-performance-report.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/11/04/a-social-api-performance-report-from-apimetrics/">A Social API Performance Report From @APIMetrics</a></h3>
			<p><em>04 Nov 2015</em></p>
			<p>
APImetrics just released their second API Performance Report for Social Networks, aggregated from data they have been gathering from monitoring social networks since 2014. APImetrics is publishing the report to "..understand the impact these APIs were having on social media based on geographic location and specific cloud service provider."
I'll let you read the report yourself, I just wanted to highlight the importance of this type of API monitoring from 3rd party services like APImetrics. The other providers I watch closely like Runscope and API Science also monitor 3rd party APIs like this, but I think publishing formal reports on a regular basis like APImetrics is doing, is healthy for the space.&nbsp;
Eventually, I would like to see an aggregate location where all API monitoring service providers can publish their data, in a common format, and the larger API community could process, and help establish an API rating solution that we can all take advantage of. Historical, and real-time data will be key to establishing the open rating system that we need.
I would say that social, cloud, and messaging apps kind top the list of APIs we should be monitoring and rating, but eventually it would be nice to have this be commonplace for any public API in the space. Part of helping us evolve the API discovery conversation, is establishing a baseline for rating the good APIs from the bad ones, and work like the social network report from APImetrics helps us get closer to this possible future.
[<a href="/2015/11/04/a-social-api-performance-report-from-apimetrics/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/11/03/to-incentivize-api-performance-load-and-security-testing-providers-should-reduce-bandwidth-and-compute-costs-asscociated/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-low-price.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/11/03/to-incentivize-api-performance-load-and-security-testing-providers-should-reduce-bandwidth-and-compute-costs-asscociated/">To Incentivize API Performance, Load, And Security Testing, Providers Should Reduce Bandwidth And Compute Costs Asscociated</a></h3>
			<p><em>03 Nov 2015</em></p>
			<p>
I love that AWS is baking monitoring testing by default in the new Amazon API Gateway. I am also seeing new service from AWS, and Google providing security and testing services for your APIs, and other infrastructure. It just makes sense for cloud platforms to incentivize security of their platforms, but also ensure wider success through the performance and load testing of APIs as well.
As I'm reading through recent releases, and posts, I'm thinking about the growth in monitoring, testing, and performance services targeting APIs, and the convergence with a growth in the number of approaches to API virtualization, and what containers are doing to the API space. I feel like Amazon baking in monitoring and testing into API deployment and management because it is in their best interest, but is also something I think providers could go even further when it comes to investment in this area.
What if you could establish a stage of your operations, such as QA, or maybe production testing, and the compute and bandwidth costs associated with operations in these stages were significantly discounted? Kind of like the difference in storage levels between Amazon S3 and Glacier, but designed specifically to encourage monitoring, testing, and performance on API deployments.
Maybe AWS is already doing this and I've missed it. Regardless it seems like an interesting way that any API service provider could encourage customers to deliver better quality APIs, as well as help give a boost to the overall API testing, monitoring, and performance layer of the sector. #JustAThought
[<a href="/2015/11/03/to-incentivize-api-performance-load-and-security-testing-providers-should-reduce-bandwidth-and-compute-costs-asscociated/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/11/03/api-consumption-moves-to-the-main-stage-at-apistrat-austin-this-month/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-consumption-api.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/11/03/api-consumption-moves-to-the-main-stage-at-apistrat-austin-this-month/">API Consumption Moves To The Main Stage At @APIStrat Austin This Month</a></h3>
			<p><em>03 Nov 2015</em></p>
			<p>When planning the API Strategy &amp; Practice Conference, the team works very hard to make the speaker and session line up reflect what we see across the API space. The conference is meant to be an open, non-vendor and non-product focus, discussion about what individuals and companies are facing when it comes to being API providers, as well as API consumers. When we closed the call for papers for APIStrat this year, it was clear that API consumption would be one of the sessions, but &nbsp;as we progressed in the process of locking down talks it was clear that API consumption should be something that we should move to the main stage. To help highlight the importance of this discussion, I wanted to ask Mark Boyd (@mgboydcom), the conference chair for APIStrat his thoughts on why we did this: This year has seen two major API consumption challenges: For API providers looking to continue their growth, 2015 has often been about putting their API in front of non-dev users and making their API accessible to a wider audience. We're seeing an increasing use of tools like Google Sheets and slackbot integrations trying to make API functionality available to people who don't code. For businesses and enterprises generally, the increasing use of external APIs has meant more challenges for dev teams in aggregating APIs and using multiple APIs consistently. Each API they are using might come with different terms of service, differing rate limits, different terminology for the same subject matter, and different ways of measuring units. For example, most API consumers I hear from are frustrated that each API they use seems to have a different way of measuring and displaying time formats! As APIs keep growing in mainstream business use, there becomes a tipping point in scaling the API economy where it starts adding complexity rather than removing it. We think that 2015 is that tipping point and we need to start solving how...[<a href="/2015/11/03/api-consumption-moves-to-the-main-stage-at-apistrat-austin-this-month/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2015/11/02/please-tell-your-api-stories/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-story.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2015/11/02/please-tell-your-api-stories/">Please Tell Your API Stories</a></h3>
			<p><em>02 Nov 2015</em></p>
			<p>Many of you that have attended any of my talks, have heard me tell the audience about the importance of sharing your API stories. As an API provider it is the most important tool in your toolbox, above and beyond any technical or business advantage you have. I'm spending more time lately, gathering up the things I say over and over in my talks, and other in-person conversations, and craft simple stories that echo these little nuggets of wisdom on the blog. If you do not tell the story of what your API is doing, nobody will know--it really is that simple. The drumbeat from your blog, should echo the activity that is going on via your API. Your day might be filled with a hectic stack of activity from your view, but your API consumers, analysts, and storytellers like me, we do not see any of this activity, and we all need to hear about your day on your blog, amplified by your active Twitter account. I can tell you that the APIs who are doing interesting things, and are telling the story of these things, end up on my blog, and in the major tech blogosphere much more often, than those that do not. I'm not telling you to craft amazing essays about your operations, I'm just asking that you blog daily, or every couple days, on the often mundane, but potentially highly valuable stories from the trenches of your API operations--it is something that, the more you do, the easier it wil gets. While the goal of blogging is to communicate externally with your API consumers, and the public at large, my secondary motive is to expose you to a very beneficial by-product of blogging in this way. When you get into a rhythm where you are working through your ideas, operations, and API road-map, in such a public way, you develop a very different view of your platform, one that is...[<a href="/2015/11/02/please-tell-your-api-stories/">Read More</a>]</p>
			<p><hr /></p>
	  

		<hr />
		<ul class="pagination" style="text-align: center;">
			
				<li style="text-align:left;"><a href="/blog/page18" class="button"><< Prev</a></li>
			
				<li style="width: 75%"><span></span></li>
			
				<li style="text-align:right;"><a href="/blog/page20" class="button">Next >></a></li>
			
		</ul>

  </div>
</section>

              <footer>
	<hr>
	<div class="features">
		<article>
			<div class="content">
				<p align="center"><a href="https://www.postman.com" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/partners/postman-logo.png" width="60%" style="padding: 15px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
		<article>
			<div class="content">
				<p align="center"><a href="https://github.com/postmanlabs/newman" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/postman/newman-logo.png" width="60%" style="padding: 15px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
	</div>
</footer>


            </div>
          </div>

          <div id="sidebar">
            <div class="inner">

              <nav id="menu">
  <header class="major">
    <h2>Menu</h2>
  </header>
  <ul>
    <li><a href="/">Home Page</a></li>
    <li><a href="/blog/">The Blog</a></li>
    <li><a href="https://101.apievangelist.com/">API 101</a></li>
    <li><a href="http://history.apievangelist.com">History of APIs</a></li>
    <li><a href="https://women-in-tech.apievangelist.com/">Women in Technology</a></li>    
  </ul>
</nav>

              <section>
	<div class="mini-posts">
		<header>
			<h2 style="text-align: center;"><i>API Evangelist Sponsors</i></h2>
		</header>
		<article>
			<div class="content">
				<p align="center"><a href="https://www.postman.com" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/partners/postman-logo.png" width="75%" style="padding: 5px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
		<article>
			<div class="content">
				<p align="center"><a href="https://tyk.io/" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/tyk/tyk-logo.png" width="75%" style="padding: 5px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
		<article>
			<div class="content">
				<p align="center"><a href="https://www.openapis.org/" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/specifications/openapi.png" width="75%" style="padding: 5px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
		<article>
			<div class="content">
				<p align="center"><a href="https://www.asyncapi.com/" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/asyncapi/asyncapi-horiozontal.png" width="75%" style="padding: 5px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
		<article>
			<div class="content">
				<p align="center"><a href="https://json-schema.org/" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/specifications/json-schema.png" width="75%" style="padding: 5px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
		<article>
			<div class="content">
				<p align="center"><a href="https://github.com/postmanlabs/newman" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/postman/newman-logo.png" width="75%" style="padding: 5px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
	</div>
</section>


            </div>
          </div>

      </div>

<script src="/assets/js/skel.min.js"></script>
<script src="/assets/js/util.js"></script>
<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
<script src="/assets/js/main.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-1119465-51"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-1119465-51');
</script>


</body>
</html>
