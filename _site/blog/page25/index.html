<!DOCTYPE html>
<html xmlns="https://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
  <html>
  <title>API Evangelist </title>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
  <!--[if lte IE 8]><script src="/assets/js/ie/html5shiv.js"></script><![endif]-->
  <link rel="stylesheet" href="/assets/css/main.css" />
  <link rel="stylesheet" href="/assets/css/bootstrap.min.css" />
  <!--[if lte IE 9]><link rel="stylesheet" href="/assets/css/ie9.css" /><![endif]-->
  <!--[if lte IE 8]><link rel="stylesheet" href="/assets/css/ie8.css" /><![endif]-->

  <!-- Icons -->
  <link rel="shortcut icon" type="image/x-icon" href="https://apievangelist.com/favicon.ico">
	<link rel="icon" type="image/x-icon" href="https://apievangelist.com/favicon.ico">

  <link rel="alternate" type="application/rss+xml" title="API Evangelist Blog - RSS 2.0" href="https://apievangelist.com/blog.xml" />
  <link rel="alternate" type="application/atom+xml" title="API Evangelist Blog - Atom" href="https://apievangelist.com/atom.xml">

  <!-- JQuery -->
  <script src="/js/jquery-latest.min.js" type="text/javascript" charset="utf-8"></script>
  <script src="/js/bootstrap.min.js" type="text/javascript" charset="utf-8"></script>
  <script src="/js/utility.js" type="text/javascript" charset="utf-8"></script>

  <!-- Github.js - http://github.com/michael/github -->
  <script src="/js/github.js" type="text/javascript" charset="utf-8"></script>

  <!-- Cookies.js - http://github.com/ScottHamper/Cookies -->
  <script src="/js/cookies.js"></script>

  <!-- D3.js http://github.com/d3/d3 -->
  <script src="/js/d3.v3.min.js"></script>

  <!-- js-yaml - http://github.com/nodeca/js-yaml -->
  <script src="/js/js-yaml.min.js"></script>

  <script src="/js/subway-map-1.js" type="text/javascript"></script>

  <style type="text/css">

    .gist {width:100% !important;}
    .gist-file
    .gist-data {max-height: 500px;}

    /* The main DIV for the map */
    .subway-map
    {
        margin: 0;
        width: 110px;
        height: 5000px;
        background-color: white;
    }

    /* Text labels */
    .text
    {
        text-decoration: none;
        color: black;
    }

    #legend
    {
    	border: 1px solid #000;
        float: left;
        width: 250px;
        height:400px;
    }

    #legend div
    {
        height: 25px;
    }

    #legend span
    {
        margin: 5px 5px 5px 0;
    }
    .subway-map span
    {
        margin: 5px 5px 5px 0;
    }

    </style>

    <meta property="og:url" content="">
    <meta property="og:type" content="website">
    <meta property="og:title" content="API Evangelist">
    <meta property="og:site_name" content="API Evangelist">
    <meta property="og:description" content="A network of research sites dedicated to the technology, business, and politics of APIs.">
    <meta property="og:image" content="http://s3.amazonaws.com/kinlane-productions/api-evangelist/t-shirts/KL_InApiWeTrust-1000.png">

    <meta name="twitter:url" content="">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="API Evangelist">
    <meta name="twitter:site" content="API Evangelist">
    <meta name="twitter:description" content="A network of research sites dedicated to the technology, business, and politics of APIs.">
    
      <meta name="twitter:creator" content="@apievangelist">
    
    <meta property="twitter:image" content="http://s3.amazonaws.com/kinlane-productions/api-evangelist/t-shirts/KL_InApiWeTrust-1000.png">


</head>

  <body>

			<div id="wrapper">
					<div id="main">
						<div class="inner">

              <header id="header">
	<a href="http://apievangelist.com" class="logo"><img src="https://kinlane-productions2.s3.amazonaws.com/api-evangelist/api-evangelist-logo-400.png" width="75%" /></a>
	<ul class="icons">
		<li><a href="https://twitter.com/apievangelist" class="icon fa-twitter"><span class="label">Twitter</span></a></li>
		<li><a href="https://github.com/api-evangelist" class="icon fa-github"><span class="label">Github</span></a></li>
		<li><a href="https://www.linkedin.com/company/api-evangelist/" class="icon fa-linkedin"><span class="label">LinkedIn</span></a></li>
		<li><a href="http://apievangelist.com/atom.xml" class="icon fa-rss"><span class="label">RSS</span></a></li>
	</ul>
</header>

    	        <section>
	<div class="content">

		<h3>The API Evangelist Blog</h3>

	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-hypermedia.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/27/hypermedia-feels-like-we-are-still-learning-to-communicate-with-apis/">Hypermedia Feels Like We Are Still  Learning To Communicate With APIs</a></h3>
			<p><em>27 Jul 2014</em></p>
			<p>
I&rsquo;m looking through each of the worlds, of my hypermedia panelists, Mike Amundsen (@mamund), Mike Kelly (@mikekelly85), Steve Klabnik (@steveklabnik), Kevin Swiber (@kevinswiber), J&oslash;rn Wildt (@JornWildt), and Markus Lanthaler (@MarkusLanthaler),&nbsp;for API Craft tomorrow, reaquainting myself on what they bring to the hypermedia table, adding to my knowledge, and hopefully sharing some of the findings with you.
As I look through each of the hypermedia definitions, developed by my panelists, I keep feeling, that as API providers, there is still a lot of education that has to occur, to not just helping us better communicate with APIs, but also be more skilled at sharing and interacting around the resources we are making available via APIs.
I&rsquo;ve been brushing up my knowledge on Collection+JSON, UBER, ALPS, HAL, Siren, Hydra, JSON-LD, json:api, Mason--9 spearate format that contribute to how we design our APIs.
When I think about the state of APIs, i see that we are barely using our words in our communication using APIs, what we say, and how we are saying it with our APIs, is still very crude, and unstructured. I feel like we are just toddlers, learning to use our words, sentences and playing nicely together. With the rich formats available to us, I feel that in 2014, I think we have to collectively get our butts to hypermeida school, and get educated&mdash;a lot of the work has been done for, we just need to get up to speed.
I see a handful of API providers employing hypermedia in their designs, but they are still few and far between.
[<a href="/2014/07/27/hypermedia-feels-like-we-are-still-learning-to-communicate-with-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/api-evangelist/indix/indix-logo.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/25/new-indix-api-kickstart-program-reduces-costs-for-developers/">New Indix API KickStart Program Reduces Costs For Developers</a></h3>
			<p><em>25 Jul 2014</em></p>
			<p>
I like to showcase examples of companies who use their API communities as incubators, establishing them as a sort of external R&amp;D lab that invests in 3rd party developers who are building cool stuff on top of their API driven resources.
I came across an announcement from product intelligence platform Indix, in my usual monitoring of the API space, and they have a pretty cool program for their developers:
Indix KickStart &ndash; a program to help startups and small businesses accelerate the development of product-aware applications and deliver rich product-aware experiences.
Indix is looking to jumpstart early stage startups use of the Indix product API. Companies that have less than $1 million in funding and $100,000 in revenue are eligible apply, and Indix will evaluate the startups potential for receiving access to the Indix API at a reduced price point.
There are numerous ways to incentivize developers usage of an API, and Indix&rsquo;s approach is one possible way to established a trusted developer access tier, where you can raise access limits, reduce costs, and potentially reducing a new startup&rsquo;s overhead, and their chances of success.
[<a href="/2014/07/25/new-indix-api-kickstart-program-reduces-costs-for-developers/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-analytics-4.jpeg" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/25/a-shared-distributed-experiencemetrics-layer-for-the-api-driven-application-stack/">A Shared, Distributed Experience(Metrics) Layer For The API Driven Application Stack</a></h3>
			<p><em>25 Jul 2014</em></p>
			<p>I&rsquo;m in the middle of processing multiple emails, as well as coming down off an early morning conversation, all on the subject of analytics. A portion of the conversations are about analytics at the web site, web or mobile app level, and a portion of it was around analytics for API developers, as well as API platform providers&mdash;basically the full stack of analytics including platforms, developers, apps, all the way to the end-user. Increased visibility into the API layer, and how developers and their apps are consuming API resources, is a cornerstone of API management. There are numerous solutions out there to give you analytics in websites and web apps (Google Analytics), and within the mobile app itself (Mixpanel), and there are analytics at the API layer for both API providers, and the many developers who are integrating APIs into their applications and systems (3Scale). API providers, with the assistance of API infrastructure solutions like 3Scale, have done very well in making sense of how resources are composed through a service composition layer, that includes a robust number of metrics and analytics for both provider and developer. This is great for allowing API providers to understand how developers, and their applications are consuming API resources, while at the same time delivering a subset of analytics for each individual developer regarding their individual API usage. This is great, but if a developer wants more application level information, they usually have to look elsewhere to other tools and services. (this is evolving) After my conversations this morning, I was left thinking big picture about the future of analytics for the API driven, multichannel, website, single page, mobile, and Iot application stack. I am left with a vision of a tool that can handle all channels, not just the needs of the platform, and its developers, but also bring the end-users in the conversation. I need a standalone, open source framework, that I can use for not just...[<a href="/2014/07/25/a-shared-distributed-experiencemetrics-layer-for-the-api-driven-application-stack/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/api-evangelist/hall/hall-api-integrations.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/24/showcasing-your-api-integrations-with-other-platforms/">Showcasing Your API Integrations With Other Platforms</a></h3>
			<p><em>24 Jul 2014</em></p>
			<p>I saw two tweets from Zapier the other day, where they were highlighting two separate SaaS platforms, who had integrated Zapier into their own platform. Both Gumroad and Hall took the time to highlight the other platforms they are integrated with. I think there are a couple of interesting items in these stories&hellip; Zapier &amp; IFTTT Integration A while back I added reciprocity to this list of API management building blocks, because I was seeing enough API providers, taking it upon themselves to make sure their platform had both Zapier and IFTTT integration. Ensuring your API is working with leading reciprocity providers will become even more critical for API providers, as more non-developers are putting APIs to work managing their daily personal, and professional lives. Dedicated Integration Page The fact that hall has a dedicated integration page is interesting. I think it is valuable to show the platforms that an API has been officially integrated with. It helps developers, and non-developers understand the potential that exists around a platform and its API. I can also see the benefit of opening up the ability for the API ecosystem to submit their own integrations as well--you never know it might encourage other platforms to integrate, if they know they have an opportunity to be showcased. I like how Hall does their integration page, and they 15+ integrations, they have a custom option, which is basically their very simple API, allowing you to post messages from your app. Hall doesn&rsquo;t seem to have a full blown API, allowing you to interact with all aspects of the platform, but I still their approach is interesting. I think that integration with reciprocity providers like Zapier and IFTTT should be default for all API providers. I also think that API providers should consider highlighting other common platform integrations like with Heroku or Github, depending on the nature of your API. You can consider providing seamless integration between platforms, as well as...[<a href="/2014/07/24/showcasing-your-api-integrations-with-other-platforms/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/api-evangelist/priorities/university-of-api.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/24/increasing-the-focus-on-apis-in-higher-education-is-important/">Increasing The Focus On APIs In Higher Education Is Important</a></h3>
			<p><em>24 Jul 2014</em></p>
			<p>Maybe I&rsquo;m a little biased at the moment, after participating in a Reclaim Your Domain hackathon with some really smart folks from multiple universities, as well as working on my first white paper on APIs in higher education, but I feel pretty strongly that higher education institutions focusing on APIs will extremely important in the next two years. I&rsquo;m constantly working to understand the big picture of the emerging API economy, the importance of the government API development phase, and working to understand what is next for the US government API strategy, while also acknowledging we need the enterprise to continue waking up to the potential of APIs. I think, right along with government, and the enterprise, another importance piece of the overall API puzzle is increasing the focus on APIs in higher education. The University Argument If I am making a pitch to a university, I would tell my Amazon API story, and how APIs can open up access to institutional resources, making them more accessible across campus, and externally with partners and vendors. APIs are how startups, SMB, enterprise, and the government are increasing efficiency, agility, and delivering the web and mobile apps that are part of a larger, healthier digital strategy vision. Top universities like University of Washington, UC Berkeley, and Brigham Young University or leading the way with modern API platforms, that are changing the way they do business on campus&mdash;take a look at the 250+ APIs from BYU, to get a idea. The Student Argument If I am making the pitch for why students should care about APIs, during the most formative years of their lives, I would point out that APIs are already touching every aspect of their lives, from the websites they visit, to the mobile phone in their pocket. If your college years are about preparing you for the world, APIs need to front and center in your education, giving you the basics, but also allowing you...[<a href="/2014/07/24/increasing-the-focus-on-apis-in-higher-education-is-important/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/api-evangelist/strongloop/strongloop-logo.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/23/the-new-strongloop-api-server-provides-a-look-at-future-of-api-deployment/">The New StrongLoop API Server Provides A Look At Future Of API Deployment</a></h3>
			<p><em>23 Jul 2014</em></p>
			<p>I&rsquo;m looking through the most recent API server release from StrongLoop, and I can&rsquo;t help but see echoes of what I&rsquo;ve been researching, and covering across the API Evangelist network.&nbsp;API management has been front and center for years, but API deployment is something that is just now being productized, with a wealth of new service providers emerging to provide API deployment solutions that go beyond DIY frameworks, and enterprise API gateways. Let start with walking through their announcement of their StrongLoop API Server: LoopBack 2.0 - An open source framework for quickly creating APIs with Node, including the client SDKs. mobile Backend-as-a-Service - An mBaaS to provide mobile services like push, offline-sync, geopoint and social login either on-premise or in the cloud. Connectors - Connectivity for Node apps leveraging over ten supported data sources including Oracle, SQL Server, MongoDB and SOAP. Controller - Automated DevOps for Node apps including profiling, clustering, process management and log management capabilities. Monitoring - A hosted or on-premise graphical console for monitoring resource utilization, response times and function tracing with the ability to send metrics to existing monitoring tools. Just as StrongLoop did in their release post, let&rsquo;s dive deeper into LoopBack 2.0, the open source core of StrongLoop, which they say "acts as a glue between apps or devices and data via APIs written in Node&rdquo;: Studio - A graphical interface to complement the command-line tooling and assist developers in building Loopback models. Yeoman and Grunt - The ability to script tasks, scaffold, and template applications and externalize their configurations for multiple environments. ExpressJS 4.0 - The latest update, for the well known Node.js package, bringing improvements by removing bundled middleware and refactoring them into maintainable modules, revamped router to remove confusion on HTTP verb usage and decoupling Connect, the HTTP framework of Node from the Express web framework. It is also the E in the MEAN stack (MongoDB, ExpressJS, AngularJS, Node.js). Project Structure - An expanded directory structure...[<a href="/2014/07/23/the-new-strongloop-api-server-provides-a-look-at-future-of-api-deployment/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-fist.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/22/reclaim-your-domain-la-hackathon-wrapup/">Reclaim Your Domain LA Hackathon Wrap-up</a></h3>
			<p><em>22 Jul 2014</em></p>
			<p>I spent the weekend hacking away with a small group of very smart folks, at the Reclaim Your Domain Hackathon in Los Angeles. Fifteen of us gathered at Pepperdine University in west LA, looking to move forward the discussion around what we call &ldquo;Reclaim Your Domain&rdquo;. This conversation began last year, at the #ReclaimOpen Hackathon, continued earlier this year at Emory University, and we were looking to keep the momentum building this weekend at Pepperdine. Here is a breakdown of who was present this weekend: Jim Groom - University of Mary Washington (@jimgroom) Michael Caulfield - WSU Vancouver - http://hapgood.us/ - (@holden) Michael Berman - California State University Channel Islands (@amichaelberman) Chris Mattia - California State University Channel Islands (@cmmattia) Brian Lamb - Thompson Rivers University (@brlamb) Timothy Owens - University of Mary Washington (@timmmmyboy) Mikhail Gershovich - Vocat (@mgershovich) Amy Collier - Stanford (@amcollier) Rolin Moe - Pepperdine (@RMoeJo) Adam Croom - University of Oklahoma (@acroom) Mark C. Morvant - University of Oklahoma (@MarkMorvant) Ben Werdmuller &mdash; Withknown (@benwerd) Erin Richey &mdash; Withknown (@erinjo) Kin Lane &mdash; API Evangelist (@kinlane) Audrey Watters &mdash; Hack Education (@audreywatters) If you are unsure of what #Reclaim is all about, join the club, we are trying to define it as well. You can head over to Reclaim Your Domain, or you can also look at Reclaim Hosting, and the original Domain Of Ones Own at University of Mary Washington which has provided much of the initial spark behind the #Reclaim movement, for more information. Ultimately, #Reclaim will always be a very personal experience for each individual, but Reclaim Your Domain is primarily about:&nbsp; Educating, and empowering individual to define, reclaim, and manage their digital self The primary thing I got out of this weekend, beyond the opportunity to hang out with such a savvy group of educators, was the opportunity to talk through my own personal #Reclaim process, as well as my vision of how we can use...[<a href="/2014/07/22/reclaim-your-domain-la-hackathon-wrapup/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/api-evangelist/sendgrid/sendgrid-will-smidlein+.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/17/will-you-add-me-to-api-evangelist-and-how-to-spot-the-cool-kids/">Will You Add Me To API Evangelist And How To Spot The Cool Kids</a></h3>
			<p><em>17 Jul 2014</em></p>
			<p>
In the API space it is easy to recognize the cool kids, the ones that are in the know. These types of personalities just understand how to get things done, don't take no for an answer, and understand the DIY, self-service nature of APIs.
I get a lot of folks who ask me to add them to my API Management provider section, or my API Integration area. I always add these people to my Evernote queue, and when I get time I go through and profile them, I add them to my master CRM, and when I publish the latest round of content and data to the API Evangelist network site in question, the blog post, or company listing will be updated&mdash;something that can take minutes or weeks, depending on my workload.
In contrast, the savvy people in the space, understand that the API Evangelist network runs on Github, as 60+ separate research projects, and that they can add themselves. All you do is fork the project you want to update, add yourself to the blog post, or the JSON file that drives the data listing, and submit a pull request. I don&rsquo;t always guarantee I will accept your addition, but if it is correct, and brings value to the API community, there is a good chance I will.
I just finished publishing a list of all of the SendGrid developer evangelists, and I mistakenly left off Will Smidlein (@ws), one of the SendGrid developer evangelists. Will, being one of the cool kids, didn&rsquo;t ask, he just forked API Evangelist, added himself to the list, and submitted a pull request. Minutes later, he&rsquo;s on the blog, listed correctly as one of the evangelist.
I wonder how long it will take for more of my audience to realize they can help curate, and publish to API Evangelist, right alongside me--it has been this way since January of 2013. ;-)
[<a href="/2014/07/17/will-you-add-me-to-api-evangelist-and-how-to-spot-the-cool-kids/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-key.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/17/when-i-remix-apis-using-swagger-how-do-i-deal-with-authentication-across-multiple-apis/">When I Remix APIs Using Swagger How Do I Deal With Authentication Across Multiple APIs</a></h3>
			<p><em>17 Jul 2014</em></p>
			<p>One of the things I&rsquo;m loving about where the API space is going, is the simplicity, and remixability of available API resources, when they are defined with machine readable API definitions like Swagger. An example of this, can be found in my recent work to make federal government APIs more discoverable. I generated machine readable API definitions using Swagger, for four separate APIs out of the GSA. The APIs were spread across two separate domains:&nbsp;usa.gov&nbsp;&amp;&nbsp;explore.data.gov. You can follow the details of research, at each of the project repositories, but as I continue with my work, I keep thinking about the power that having a machine readable definition for all four of these APIs, and my ability to now remix these simple, and powerful API resources into virtual stacks. After I work my way through the 120 government APIs I have targeted, I will have an amazing index of government API resources to compose from. My vision around all of this goes beyond just API discovery, and finding government APIs. I want to make it so we can compose virtual stacks of API resources, that can be used in different scenarios. If you are building a public engagement app for an election, you can assemble exactly the API resources your developers will need, aggregate them using their API definition, into a single developer area&mdash;even though the APIs may span multiple federal agency developer areas. In this scenario, developers don't have to go find all the API resources they need, an architect, or API lead can aggregate everything into a one-stop-shop for what the developers will need. This evolution in API delivery makes me very happy, right up until I come up against the current state of on-boarding with APIs, to get the credentials you need to use the API resource. In this particular scenario, you would have to sign up for an account with 10 or 20 separate agencies, or outside groups&mdash;stripping away any benefits gained...[<a href="/2014/07/17/when-i-remix-apis-using-swagger-how-do-i-deal-with-authentication-across-multiple-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/api-evangelist/sendgrid/sendgrid-logo.jpeg" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/17/it-takes-a-team-of-evangelists-to-raise-an-api/">It Takes A Team Of Evangelists To Raise An API</a></h3>
			<p><em>17 Jul 2014</em></p>
			<p>There are a lot of lessons to be learned from the leaders of the API space, pioneers like Amazon, Twilio and SendGrid, when it comes to running our own API programs. Fortunately for the community, most of the leading API providers are willing to share their experience and wisdom with us, such as SendGrid, with their latest series Tips and Tricks for a Beginner Developer Evangelist. The blog series delivers some great API evangelism wisdom, from the mouths of evangelists, who are in the trenches, getting the word out about the email API platform, and supporting its large ecosystem of application developers. I'll let you read the tips from the SendGrid team, what I thought was interesting, was the makeup of their evangelist team. You have two managers leading the charge: Tim Falls @timfalls) - Director of Developer Relations Brandon West (@bwest) - Manager of Developer Relations Then 8 developer evangelists, making up the evangelist team: Nick Quinlan (@YayNickQ) - Developer Evangelist Scott Motte (@scottmotte) - Developer Evangelist Martyn Davies (@martynd) - Developer Evangelist Robin Johnson (@rbin) - Developer Evangelist Kunal Batra (@kunal732) - Developer Evangelist Yamil Asusta (@elbuo8) - Developer Evangelist Heitor (Burger) Sergent (@heitorburger) - Developer Evangelist Eddie Zaneski (@eddiezane) - Developer Evangelist Will Smidlein (@ws) - Developer Evangelist And one distinguised hacker in residence: Elmer Thomas (@thinkingserious) - Hacker in Residence You can check out their full team here. I think the blog series from SendGrid is a look into, what it takes to run a successful API evangelism campaign. I&rsquo;ve had multiple conversations in the last couple days with API providers who are just now beginning to build their API teams, and were looking for on advice on who to hire, and how to grow and train their evangelists. To anyone who is just now constructing their API team, follow the SendGrid blog and Twitter account, then follow each of the SendGrid evangelist team on Twitter&mdash;they produce a lot of great...[<a href="/2014/07/17/it-takes-a-team-of-evangelists-to-raise-an-api/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/api-evangelist/terms-of-service-didnt-read/tos-didnt-read-logo.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/16/machine-readable-terms-of-service-didn039t-read-applied-to-apis-via-apis-json/">Machine Readable Terms of Service Didn&#039;t Read Applied To APIs Via APIs.json</a></h3>
			<p><em>16 Jul 2014</em></p>
			<p>I&rsquo;ve long been fascinated by the Terms of Service Didn&rsquo;t Read project. i&rsquo;m on the mailing list, and try to make time to stay in tune, but have yet to ever contribute any bandwidth to the EXTREMELY important project, around making sense of the crazy terms of services (TOS), that we agree to in our daily lives. I finally found myself at a point where I'm forced to start paying more attention to API terms of service, and hopefully will be able to slice off a little bit of dedicated bandwidth to Terms of Service; Didn&rsquo;t Read. I have two projects that have floated up on my list, and deserve some priority attention. First I&rsquo;m applying the TOS Didn't Read work to a side project of mine called Reclaim Your Domain, which is a project to help me define my digital self, and reclaim some of the content, data and other value I generate on a daily basis online. I&rsquo;m hoping TOS Didn't Read will provide a machine readable moral backbone to the #Reclaim process&mdash;which is a work in progress. Second, I&rsquo;m looking to build on the TOS Didn't Read work, and apply further to the world of APIs, by defining another one of the machine readable API.json properties. The first of which are machine readable properties like API Blueprint, RAML, and Swagger API definitions, and the API Commons manifest, which allows you to reference the copyright for a specific API interface. I want to build on the work TOS Didn&rsquo;t Read has done, apply their tracking and ranking system of online services, to the APIs that I monitor. Using APIs.json I want to encourage API providers to publish this machine readable index of their available APIs, allowing them to be indexed by API search engines like APIs.io. Then, as part of each APIs.json I want to help API providers understand the benefits of machine readable API definitions, API copyright declarations, and API terms of...[<a href="/2014/07/16/machine-readable-terms-of-service-didn039t-read-applied-to-apis-via-apis-json/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/api-evangelist/zapier-google-docs-api-spark.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/16/api-deployment-for-nondevelopers-using-zapier-google-docs-and-apispark/">API Deployment For Non-Developers Using Zapier, Google Docs, and APISpark</a></h3>
			<p><em>16 Jul 2014</em></p>
			<p>I&rsquo;m exploring different ways that APIs can be deployed, with an emphasis on deployment by non-developers. There are numerous cloud services available, that allow non-developers to execute common business tasks like registration forms, surveys, payments, and product sales, and when you combine these business functions with Zapier, Google Docs and APISpark&mdash;you can deploy an API, no code skills required. This story begins with the ability to deploy an API from any Google Spreadsheet using APISpark, putting API deployment within the grasp of the average business user. Next, I want the easiest possible way to get data, from multiple sources, into a Google Spreadsheet? Answer: Zapier (or other reciprocity provider, like IFTTT). &nbsp;To support this, I started looking through the numerous Zapier recipes, that allow my me to publish results to a Google Spreadsheet&mdash;there are 167! The most obvious data source I see is Twitter. Everyone time there is a Tweet from specific user, or from a specific Twitter search, you can have it published to a Google Spreadsheet, and when you have that spreadsheet connected to an APISpark API, the results will be automatically available via API. The second most common source of data I see, would be cloud based forms. I see providers like Wufoo, Gravity Forms, and JotForm, to name a few, that allow you to submit form submissions to any Google Spreadsheet, and with the APISpark integration, all your form submissions are automatically available via API. After that, I see numerous commerce, payments, and other key business functions, that Zapier enables publishing of data and content into a Google Spreadsheet from. All of these services have APIs, that is why Zapier is able to do what they do, but that would require a developer to tackle with custom API integration (not for this story). This story is all about enabling non-developers to deploy APIs, from common business functions, no coding necessary--Zapier is our middleman. Beyond Twitter, forms, payments, and product sales, I...[<a href="/2014/07/16/api-deployment-for-nondevelopers-using-zapier-google-docs-and-apispark/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/events/api-craft/api-craft-logo.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/15/state-of-hypermedia-today-api-craft-in-detroit/">State of Hypermedia Today @ API Craft In Detroit</a></h3>
			<p><em>15 Jul 2014</em></p>
			<p>
I&rsquo;m working with Brian Mulloy (@landlessness) of Apigee, to organize six of the leading hypermedia experts for a 2 hour panel discussion on the state of hypermedia, at API Craft, in Detroit, Michigan this month.  I couldn't imagine a more distinguished panel of hypermedia experts, than this lineup:

Mike Amundsen (@mamund)
Mike Kelly (@mikekelly85)
Steve Klabnik (@steveklabnik)
Kevin Swiber (@kevinswiber)
J&oslash;rn Wildt (@JornWildt)
Markus Lanthaler (@MarkusLanthaler)

The 2 hour panel is going to be broken into an hour of 10 minute presentations from each of the six panelists, followed by another hour of QA discussion between myself, the panelists, and the API Craft audience.
I&rsquo;ve started a Github repository to gather thoughts for the discussion, from the panelists, and if you have anything you'd like me to discuss, feel free to submit an issue, and I'll consider including in the discussion.
See you in Detroit!
[<a href="/2014/07/15/state-of-hypermedia-today-api-craft-in-detroit/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/federal-government/18f/18F_logo.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/15/need-a-formal-api-standard-for-your-government-agency-fork-18fs-and-make-it-your-own/">Need A Formal API Standard For Your Government Agency?  Fork 18Fs, And Make It Your Own!</a></h3>
			<p><em>15 Jul 2014</em></p>
			<p>
The elite technology group at the GSA, known as 18F, has released the latest copy of&nbsp;API guidance for federal government agencies to follow when designing their own APIs.
Using 18F&rsquo;s own description:
This document captures 18F's view of API best practices and standards. We aim to incorporate as many of them as possible into our work.APIs, like other web applications, will vary greatly in implementation and design, depending on the situation and the problem the application is solving. 
I like the mix of info that is delivered as well:

High level design guidance that individual APIs interpret to meet their needs.
Low level web practices that most modern HTTP APIs use.

To top it off, the API Standards is hosted on Github, in its own repository, and as Gray Brooks from 18F says:
 "Want a formal API Standards for your agency to adopt?  Fork ours, add your name to the top, and make it your own." 
Simple guidance like this goes a long way in helping, sometimes even very experienced developers, understand the best practices when it comes to designing, simple, modern APIs&mdash;a world where consistency and simplicity goes a long way!
[<a href="/2014/07/15/need-a-formal-api-standard-for-your-government-agency-fork-18fs-and-make-it-your-own/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-turntable.jpg" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/15/cors-makes-your-api-portable-and-remixable/">CORS Makes Your API Portable And Remix-able</a></h3>
			<p><em>15 Jul 2014</em></p>
			<p>Swagger is now Open API Definition Format (OADF) -- READ MORE I was looking through federal government APIs the other day, looking for the low hanging fruit, when it came to making government APIs more discoverable using APIs.json. During my initial work, I played with three separate APIs from www.usa.gov, which I think demonstrates the importance of CORS, and how opening it up for APIs, makes them more portable and remix-able. When it comes to the the three APIs from www.usa.gov, I do not have control over the API itself, but I wanted to create a self contained, site that showcased the government APIs, and provide interactive API documentation generated using Swagger. I made sure all three of the APIs had machine readable API definitions using Swagger, then I setup a simple HTML page, which allowed anyone to play with each of the APIs. This worked great until I reached the third API, which was at a different domain than the previous two, and didn't have CORS enabled. If you aren't familiar with CORS, or Cross-origin resource sharing (CORS), which is a mechanism that allows many resources on a web page to be requested from another domain outside the domain the resource originated from&mdash;behavior that you may want to control on a web page, but for an API it is something you want to encourage. CORS being enabled, is the difference between an API being portable, and remix-able, and it being locked down to its original developer portal. If an API is RESTful and has CORS enabled, any outside party (like me), can generate a machine readable API definitions for it, and compose a developer experience, that that includes the API&mdash;with or without consent of the original API provider. While this might scare the shit out of some API providers, it is the future of API driven, application architecture. You can't expect all developers to find your API developer portal, and APIs need to be...[<a href="/2014/07/15/cors-makes-your-api-portable-and-remixable/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/digital-strategy/logos/commerce.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/15/chief-data-officer-needs-to-make-the-department-of-commerce-developer-portal-the-center-of-api-economy/">Chief Data Officer Needs To Make The Department Of Commerce Developer Portal The Center Of API Economy</a></h3>
			<p><em>15 Jul 2014</em></p>
			<p>Today, the U.S. Secretary of Commerce Penny Pritzker (@PennyPritzker), announced that the Department of Commerce will hire its first-ever Chief Data Officer. I wanted to make sure that when this new, and extremely important individual assumes their role, they have my latest thoughts on how to make the Department of Commerce developer portal the best it possibly can be, because this port will be the driving force behind the rapidly expanding API driven economy. Secretary Pritzker does a pretty good job of summing up the scope of resources that are available at Commerce: Secretary Pritzker described how the Department of Commerce&rsquo;s data collection &ndash; which literally reaches from the depths of the ocean to the surface of the sun &ndash; not only informs trillions of dollars of private and public investments each year and plants the seeds of economic growth, but also saves lives. I think she also does a fine job of describing the urgency behind making sure Commerce resources are available: Because of Commerce Department data, Secretary Pritzker explained, communities vulnerable to tornadoes have seen warning times triple and tornado warning accuracy double over the past 25 years, giving residents greater time to search for shelter in the event of an emergency. To understand the importance of content, data and other resources that are coming out the Department of Commerce, you just have to look at the list of agencies that are underneath Commerce, who already have API initiatives: Bureau of Economic Analysis Bureau of the Census International Trade Administration (ITA) National Institute of Standards and Technology (NIST) National Oceanic and Atmospheric Administration (NOAA) National Telecommunications and Information Administration Patent and Trademark Office Then take a look at the other half, who have not launched APIs: Bureau of Industry and Security Committee for the Implementation of Textile Agreements Economics and Statistics Administration Economic Development Administration (EDA) Minority Business Development Agency National Technical Information Service The data and other resources available through these agencies,...[<a href="/2014/07/15/chief-data-officer-needs-to-make-the-department-of-commerce-developer-portal-the-center-of-api-economy/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-contract.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/15/an-api-definition-as-the-truth-in-the-api-contract/">"An API Definition As The Truth In The API Contract"</a></h3>
			<p><em>15 Jul 2014</em></p>
			<p>Swagger is now Open API Definition Format (OADF) -- READ MORE One conversation I had at #Gluecon this year, was around the role an API plays in being a contract between providers and consumers, with Tony Tam (@fehguy) from Reverb. API contract, is a common phrase to describe how API services are consumed, and depending on the on-boarding process, an API provider and consumer can enter into a contract for services around a set of resources, in a self-service way. In the last couple years, with the increased use of API definition formats like API Blueprint, Swagger, and RAML, we often reference this API definition as a tangible representation of the contract API providers and consumers enter into. In my mind, I see the API definition as one building block, in a larger set of building blocks, that are working together to form a contract, with the API definition acting as the truth. If you step back and look across multiple API providers, you start to see a variety of building blocks that contribute to the overall "API Contract", that is negotiated between API provider and consumer, starting with the API definition. Definition A machine readable definition of an API interface, using a common format like API Blueprint, Swagger or RAML, providing a definition of the surface area of the resources that are available via API. API definitions are proving to be very useful in establishing a common way to describe, communicate and collaborate around APIs, which are often extremely abstract. Terms of Service Terms of service are the legal portion of the API contract, determining how the service can be used, keeping the company&rsquo;s interest in mind, but should also be liberal enough to allow developers and 3rd party integrators to be successful. Plain english version of terms of service go a long way in seamlessly fitting into the API contract, allowing API consumers to quickly understand where they stand. Privacy The privacy of...[<a href="/2014/07/15/an-api-definition-as-the-truth-in-the-api-contract/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-telescope.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/14/look-at-existing-apis-in-the-space-before-designing-your-own/">Look At Existing APIs In The Space Before Designing Your Own</a></h3>
			<p><em>14 Jul 2014</em></p>
			<p>It is a pretty basic concept&mdash;look at other competing or complimentary APIs in the space, before designing your own. This seems like common sense to me, but I look at APIs for a living, and I&rsquo;m interested in finding the best API patterns across business or government sectors. Even though this topic seems like a no-brainer to me, I still encounter many folks who contact me to discuss their API strategy, but have not looked at any APIs, in the same genre as the one they are looking to enter--which tells me I should be writing about this topic on a regular basis. My first advice to any API provider, looking to begin new API effort, is to&nbsp;look at as many of the leading APIs out there, as you have time for. Even if they aren&rsquo;t in the same genre as your API, they are leaders for a reason, and do many things that you can learn from. If nothing else, at least look at the pioneers like SalesForce, Amazon, Twitter and Google&mdash;they know what they are doing. Secondarily I urge developers to go look at any APIs that are doing the same thing, or portentially exist in the same genre, as your API. If you are doing a bookmark API, go look at Delicious and Pinboard. If you are doing an image API go look at Flickr and Instagram. Even if your API will be slightly different, you should look at all, accessible, patterns, that are similar to what you are trying to do do. Try to understand why these APis providers designed their interface the way they did, and actually make calls against the API, to see what you like, and what you don&rsquo;t like about their approach. Once you have looked at all the APIs you can, take the best patterns you found, and make it into your own. Even if you come back around, and still think your API design is...[<a href="/2014/07/14/look-at-existing-apis-in-the-space-before-designing-your-own/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/api-evangelist/libraries-hack/libraries-hacked.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/14/libraries-hacked-uk-library-api-data-and-technology-hacks/">Libraries Hacked: UK Library API, Data And Technology Hacks</a></h3>
			<p><em>14 Jul 2014</em></p>
			<p>I stumbled across a pretty cool site, dedicated to educating, and providing librarians with the tools they need to hack--of course with an emphasis on APIs. Libraries Hacked&nbsp;mission is&nbsp;"analyzing and promoting open source technology hacks and projects in libraries", and providing a wealth of resources for institutions along the way: APIs - open systems online to integrate into your hacks source code - open-source apps, and projects to explore and enhance data - links around the web to download reports and stats in various formats (pdf, excel...) hack events - past and future events to get involved in and get inspiration from articles - articles on relevant subjects to the site, with guest contributions tutorials - how-to guides and reviews of software tools and apps to use when hacking In the API section, they provide a nice introduction to what is an API, and why you would use an API, including nine library focused APIs: copac - search over 70 UK and irish academic national &amp; specialist library catalogues culture grid - provides uk library listings, searchable by location, authority, region - and also lists associated collections europeana - an interface giving full and searchable remote access to all of the Europeana collection data european library api v2.0 - data describing the collections and catalogues of national and research libraries in 48 countries google books family - APIs to integrate with google data on books such as searching via title and retrieving data such as isbn and cover images nature.com website data - bibliographic search for content on nature.com: news, research articles and citations oclc worldcat search - provides catalogue search facilities across all participating libraries (worldwide). also search for libraries by location open library - one web page for every book. open library exposes an API to gain access to all their book data in various formats rluk linked open data - not really an API, but research libraries uk have published nearly 20...[<a href="/2014/07/14/libraries-hacked-uk-library-api-data-and-technology-hacks/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/api-evangelist/yodlee/yodlee-logo.jpeg" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/14/financial-data-aggregator-yodlee-looking-for-a-director-of-developer-evangelism/">Financial Data Aggregator Yodlee Looking For A Director of Developer Evangelism</a></h3>
			<p><em>14 Jul 2014</em></p>
			<p>I spoke with the leading financial data API aggregation providers&nbsp;Yodlee last week, regarding their hunt for a director of developer evangelism. Yodlee provides an aggregation API that is designed for developers who need secure access to their users&rsquo; bank, credit card, investment, and loan accounts&mdash;if you think about it, this is a pretty critical API, in what we are all calling the &ldquo;API Economy&rdquo;. Yodlee isn&rsquo;t just looking for a junior evangelist, they are looking for a director&mdash;someone to lead the charge, when it comes to evangelizing Yodlee to potential API consumers, while also supporting the community and applications that are already integrated with the financial data aggregation platform. While there are well published job descriptions for the API evangelist role, there are no universities training up, cranking out the next generation of evangelism leaders&mdash;they are a unique breed, leaving a major hurdle for API providers like Yodlee to jump. Evangelists are equal parts engineer, business development, product development, sales, and marketing&mdash;a combination that is not easy to find. Yodlee and I discussed the difficulties of finding the right candidates for the role, and whether or not you emphasize the technical or the marketing skills? There are extremely few candidates who know they are evangelist material, you often have to sculpt one out of many different personality traits, and both technical and business skils. Evangelism talent, at both junior, and leadership levels is going to continue to be a major stumbling block for the expanding API economy. Even with some movement in the world of API discovery in 2014, we will never be able to fully automate API discovery, let alone evangelism, management and support. At some point we are going to need more agencies, and institutions focusing on training up the next generation of evangelists, similar to social media marketing did in the last 5 years&mdash;of course, hopefully we can scale a little more sensibly, than the social media marketing world did. If you...[<a href="/2014/07/14/financial-data-aggregator-yodlee-looking-for-a-director-of-developer-evangelism/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/api-evangelist/autodevbot/autodevbot-logo.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/14/autodevbot-open-sources-their-api-monitor/">AutoDevBot Open Sources Their API Monitor</a></h3>
			<p><em>14 Jul 2014</em></p>
			<p>
The&nbsp;API monitoring service AutoDevot has opened sourced their JavaScript API monitoring solution, built on Frisby.js, called API Monitor Runner. The API monitoring tool, allows for a pretty robust configuration file, that lets you detail exactly what the service should monitor, and how it should behave when something out of the ordinary happens.
I though the trigger actions stood out, allowing you to take common actions when something occurs with an API:

TRIGGER_EMAIL - enable email notification
TRIGGER_PAGER_DUTY - enable PagerDuty notification
TRIGGER_WEBHOOK - enable a generic webhook notification
TRIGGER_HIPCHAT- enable HipChat notification

AutoDevBot, even takes things to another level, providing a ready to go Docker container, to quickly deploy API Monitor Runner, and then configure it on setup, using Docker environment params--a very interesting approach to deploying open tooling to support APIs.
I really like this type of deployment for vital API services, focusing on providing a simple, valuable, cloud-based service, as well as an open source version that anyone can put to use. We just saw the same moves from 3Scale with the release of APITools, and now AutoDevBot with API Monitor Runner.
I&rsquo;d love to see other critical building blocks of the API economy emulate this approach&mdash;there is plenty of money to be made from cloud services, while also providing open tool that will stimulate API growth across many business sectors. Which, creates more need for services.
[<a href="/2014/07/14/autodevbot-open-sources-their-api-monitor/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-government.jpg" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/10/low-hanging-fruit-for-api-discovery-in-the-federal-government/">Low Hanging Fruit For API Discovery In The Federal Government</a></h3>
			<p><em>10 Jul 2014</em></p>
			<p>I looked through 77 of the developer areas for federal agencies, resulting in reviewing approximately 190 APIs. While the presentation of 95% of the federal government developer portals are crap, it makes me happy that about 120 of the 190 APIs (over 60%) are actually consumable web APIs, that didn't make me hold my nose and run out of the API area.&nbsp; Of the 190, only 13 actually made me happy for one reason or another: OpenFDA - Well, I've already gushed about OpenFDA. Climate Data Online Web Services&nbsp;- Just a clean, valuable, well done API for government. National Climate Data Center - Nice portal, valuable datasets, just needs some nice APIs and BOOM! National Renewable Energy Laboratory - NREL just get it, they are doing some great APIs. Department of Labor - DOL's approach to their API design and developer area makes me happy. VA Facilities Locator Web Service - Only makes me happy because I did the work already. ;-) VA Press Releases - Only makes me happy because I did the work already. ;-) Consumer Financial Protection Bureau - Slick stuff. Nice Area. Great APIs. interactive docs. MyUSA Citizen API - Interestingly simple API, yet massive API concept, curious of the scope, implementation and use of oAuth in federal gov. ExoAPI - Very cool API. Space yo!&nbsp; SkyMorph/NEAT API&nbsp; - Very cool API. Space yo!&nbsp; {MAAS} API -&nbsp;Very cool API. Space yo!&nbsp; Predict the Sky API -Very cool API. Space yo!&nbsp; Don't get me wrong, there are other nice implementations in there. I like the simplicity and consistency in APIs coming out of GSA, SBA, but overall federal APIs reflect what I see a lot in the private sector, some developer making a decent API, but their follow-through and launch severeley lacks what it takes to make the API successful. People wonder why nobody uses their APIs? hmmmmm.... A little minimalist simplicity in a developer portal, simple explanation of what an API...[<a href="/2014/07/10/low-hanging-fruit-for-api-discovery-in-the-federal-government/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-government.jpg" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/10/looking-at-77-federal-government-api-developer-portals-and-190-apis/">Looking At 77 Federal Government API Developer Portals And 190 APIs</a></h3>
			<p><em>10 Jul 2014</em></p>
			<p>I spent most of the day yesterday, looking through 77 of the developer portals listed on the 18F Github portal. While I wanted to evaluate the quality and approach of each of the agencies, my goal for this review cycle was to look for any APIs that already had machine readable API definitions, or would be low hanging fruit for the creation of Swagger definitions, as part of my wider API discovery work. I had just finished updating all my API Evangelist Network APIs to use verion 0.14 of APIs.json, and while I wait for the search engine APIs.io to update to support the new version, I wanted to see if I could start the hard work of applying API discovery to federal government APIs.&nbsp; Ideally all federal agencies would publish APIs.json on their own, placing it within the root of their domain, like they do with data.json, and provide an index of all of their APIs. Being all to familiar with how this stuff work, I know that if I want this to happen, I will have to generate APIs.json for many federal agencies first. However for the APis.json to have their intended impact, I need many of the APIs to have machine readable API definitions that I can point to--which equals more work for me! yay? ;-( My thinking is that I will look through all of the 77 developer areas, and resulting APIs looking for the low hanging fruit. Basically I would grade each API on its viability to be included in my federal government API discovery work. I spent minimal amount of time look at each API, and in some cases looking for the API, before giving up. I would inspect the supporting developer area, and the actual interface for complexity, helping me understand how hard it would be to hand craft a Swagger spec, and APIs.json for each agency and their APIs.&nbsp; (warning contains my raw un-edited notes from doing...[<a href="/2014/07/10/looking-at-77-federal-government-api-developer-portals-and-190-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/apis-json/apisdotjson.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/10/applying-apis-json-to-api-discovery-in-the-federal-government/">Applying APIs.json To API Discovery In The Federal Government</a></h3>
			<p><em>10 Jul 2014</em></p>
			<p>I recently updated my APIs.json files for all my API Evangelist network domains, to use version 0.14, which is getting pretty close to a stable version. While I await APIs.io to be updated to use this version, I wanted to to spend some time publishing APIs.json files, but this time across federal government APIs. The thing I like most about APIs.json, is that you can do one for anybody else&rsquo;s APIs. In the case of our federal government, I don't anticipate any agency getting on board with APIs.json anytime soon, but I can do it for them! There are a lot of APIs in federal government, where do I get started? To help me understand the scope of API discovery in our federal government I looked through 77 developer portals, outlined by 18F. While browsing these developer portals for federal government agencies, I look at almost 190 APIs--with a goal of&nbsp;identifying the low hanging fruit, when it came to API discovery across hundreds of government APIs. Out of the 190 APIs, around 120 of them were actual web APIs, that were something I felt I could work with. I settled on a handful of APIs out of the GSA, hosted at www.usa.gov, and explore.data.gov, and got to work creating APIs.json for their APIs. Before I could generate an APIs.json at each of the two domains (www.usa.gov and explore.data.gov), I needed machine readable API definition for the four APIs. I purposely picked federal agency APIs that were REST(flu), and were something I could easily generate a Swagger definition for. The federal agency domain API at explore.data.gov was pretty easy, ony taking me a few minutes to handcraft a Swagger definition. Then I moved on to the Federal Agency Directory API at www.usa.gov, and I was happy to see there was already a Swagger definition for the API. After that I tackled the Social Media Registry API, and Mobile App Gallery API, both of which I had...[<a href="/2014/07/10/applying-apis-json-to-api-discovery-in-the-federal-government/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/apis-json/apis-json-gears.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/09/the-power-in-api-discovery-for-apis-json-will-be-in-the-api-url-type/">The Power In API Discovery For APIs.json Will Be In The API URL Type</a></h3>
			<p><em>09 Jul 2014</em></p>
			<p>An APIs.json&nbsp;file lives in the root of any domain, or subdomain, and provides references to a collection of API resources. The APIs.json is meant to be a lightweight framework, where someone can build a collection of APIs, give it a name, description, some tags, and the APIs collection points you where you need to go, to get more information about those APIs. For each API, you can define a list of URLs, each with a defining &ldquo;type&rdquo;, letting you know what to expect when you visit the URL. Right now, most of those URLs are just for humans, pointing to the developer portal, document, and terms of service (TOS). We are adding other API url types, that API search engines like APIs.io can expose in their search interfaces, like code samples, and application gallery, to the next version of APIs.json. These human API URL types provide a reference, that API search engines can use to guide human users who are searching for APIs. However, where the real power of APIs.json comes in, is when an API URL type references a machine readable source, like a Swagger definition, or an API Commons manifest. When it comes to API discovery, we need as many meaningful locations, that we can point human API consumers to, but also machine readable locations, that will help make API discovery much more rich, automated, and precise. Imagine when I can do more than just search name, description, and tags, by keyword, much like APIs.io works currently. Imagine when you can specify that you only want APIs that are in the API Commons, and openly licensed. Imagine when I can search for APIs that allow me to use all my HTTP verbs, not just GET. Now, go even more in the future, when I can search for APIs who have a specific allowance in their terms of service, with a machine readable TOS type for APIs.json. This is where I want to take...[<a href="/2014/07/09/the-power-in-api-discovery-for-apis-json-will-be-in-the-api-url-type/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-machine-learning.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/09/fixing-the-machine-readability-in-api-commons/">Fixing The Machine Readability in API Commons</a></h3>
			<p><em>09 Jul 2014</em></p>
			<p>
When I first published 11 simple API definitions, I had developed using schema.org, into the API Commons, I made a mistake when I referenced the Swagger specifications for each of the APIs. I linked to the machine readable Swagger spec, but not the raw JSON stored on Github, errorneously I linked directly to the Github page.
I want the machine readable API datastore, at API Commons, which is used to drive the API listing page, to be completely machine readable, referencing all APIs, their machine readable API Commons manifest, as well as machine readable API definition. As the smart folks over at APIMatic pointed out to me, I had been flip-flopping on this. Some of my later entries were machine readable pointers, but my earlier entries were not.
Now all of the entries in the commons, have machine readable references to both their API Commons manifest, and API definition. I've also added a &ldquo;format&rdquo; page, to explain each of the fields, in the the API Commons manifest format, to help API providers better understand, and not make the same mistake I made.
The API Commons manifest is meant to be a standalone, machine readable pointer to an APIs central truth (a machine readable API definition), and associated CC-BY-SA or CC0 licensing, and now, I think we have achieved our original goals around making this happen.
[<a href="/2014/07/09/fixing-the-machine-readability-in-api-commons/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/api-evangelist/apimatic/apimatic-logo.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/07/evolving-how-we-approach-the-api-lifecycle-with-apimatic/">Evolving How We Approach The API Lifecycle With APIMatic</a></h3>
			<p><em>07 Jul 2014</em></p>
			<p>I&rsquo;ve expanded my monitoring on the world of APIs, from just API management, which I&rsquo;ve been doing for four years, into tracking on APIs across multiple buckets I'm calling design, deployment, management, monetization, evangelism, discovery, integration, aggregation, reciprocity, and real-time. I am always working to understand who the key players are across the API space, but also make sure they are categorized into one, or many of these expanding buckets--helping me quantify things. It is always very interesting to see how an API service provider fits into more than one of these buckets, as well as when new players emerge to cater to just one of these buckets, like Apiary did with API design. Playing on this theme, I was introduced to new a new API service provider, called APIMatic the other day, who on the surface seems to cater to API providers with the automatic generation of SDKs, but really is a cross-over into API design, discovery, and integration, bringing a new perspective to the table. Generating SDKs Is The Carrot As soon as you land on the APIMatic home page, they state very clearly what they do "Automatic SDK Generation for APIs&rdquo;. You can search common APIs that are available in the APIMatic API marketplace, import your own API definition, or build one using their web-based user interface&mdash;which pretty squarely makes APIMatic for API consumers, providing clear API integration benefits, but via the generation of SDKs. GUI Tool For API Design The third option for generating an SDK from an API, is using the APIMatic web-based user interface, which allows you to build a definition of your API, using a web interface&mdash;no coding necessary. You can create a new definition, manage its settings, define endpoints, and the underlying data model. When ready, you can generate your SDK, which is rendered, I&rsquo;m guessing using the default APIMatic format, and then also allows you to generate mock APIs, and sandbox environments--pretty squarely in the world...[<a href="/2014/07/07/evolving-how-we-approach-the-api-lifecycle-with-apimatic/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/api-evangelist/absolut/absolut-vodka-logo.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/07/apis-can-open-up-your-company-to-outside-ideas/">APIs Can Open Up Your Company To Outside Ideas</a></h3>
			<p><em>07 Jul 2014</em></p>
			<p>
I talk about this concept often, but couldn't find any definitive post on APIs opening up a company, organization, or agency to outside ideas. This is something I hear from startups, up to federal government agencies, and from well known business brands, such as Absolut Vodka.
Absolut was one of the keynotes at API Strategy &amp; Practice in Amsterdam, this last march. Eva Sjokvist, from Absolut, walked us through the development of their Absolut Drinks Database API.&nbsp;An amazing story by itself, but one thing she said that stood out to me, which is an interestingly common by-product of the API lifecycle, was the process itself opened up the company, making it more receptive to outside ideas, and collaboration.
I hear this sentiment often from groups who are developing API programs at their companies, and you see shining examples, like from Edmunds.com with their internal API Summit, but rarely do I see a metric to measure API driven, cultural change. APIs don't just open up your company&rsquo;s assets and resources for access by trusted partners, or potentially the public, establishing a sort of external R&amp;D lab, it has the potential to open up a valuable feedback loop as well, bringing in new ideas that have the potential to change how a group sees the world--evolving internal culture.
The potential for opening up a company, bringing them closer to their partners and customers, or a government agency, opening up healthier dialogue with constituents, is the most important results of an API program&mdash;greater than any single application that will get built on an API.
[<a href="/2014/07/07/apis-can-open-up-your-company-to-outside-ideas/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-apartments.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/07/apis-are-often-just-a-facade-that-is-covering-up-the-legacy-view-of-world/">APIs Are Often Just A Facade That Is Covering Up The Legacy View Of World</a></h3>
			<p><em>07 Jul 2014</em></p>
			<p>I was exchanging emails with someone regarding API design considerations at their large institutions today, and where they could find healthy patterns for API designs within their industry. As with any API provider, they were concerned with emulating the best API design patterns they could, and evolve the design of their own services. They put it like this: ..."our APIs largely expose our internal mess and legacy design rather than presenting a well thought out, consistent view of the important resources and operations"... We all want to deploy the best designed API that we possibly can, but with a lack of meaningful API definition formats (until recently), and nowhere to go and search or browse for common API design patterns (something 3Scale and API Evangelist want to fix with API Commons, APIs.json, and APIs.io), it can be difficult to know exactly what is good API design for our respective industries. It would be nice, if all of the APIs we designed were brand new, perfectly architected to follow best of breed REST patterns, and we had all the time in the world to research and design. In reality, many of the APIs we design will ony act as a facade for some legacy beast of a system, that won't go away anytime soon. We are working to get more places like API Commons and APIs.io available to find the best API design patterns, and you should always look at as many of the APIs in your industry as you can, when designing your APIs, but most importantly, don't be concerned with a perfect interface--right out of the gate. In reality, we have to just walk a line between the perfect API design, and the ugly legacy IT worlds, we are building these API facades to hide. The sooner we get the first version of the facade up, we can then iterate, and turn our APIs into the mirror image of the designs we ultimately desire&mdash;until...[<a href="/2014/07/07/apis-are-often-just-a-facade-that-is-covering-up-the-legacy-view-of-world/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/company/university-of-michigan-logo.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/07/a-mobile-developer-toolkit-with-the-university-of-michigan-apis/">A Mobile Developer Toolkit With The University Of Michigan APIs</a></h3>
			<p><em>07 Jul 2014</em></p>
			<p>I am continuing my research into how universities are using APIs, and while I was going through the developer areas for the universities I track on, I noticed an interesting mobile developer toolkit, from University of Michigan. When you land on the homepage of the University of Michigan developer portal, to the right you will see some valuable resources that is looking to help developers think through the bigger picture of designing, developing, deploying, testing and distributing, mobile application that are built on campus resources. The University of Michigan mobile developer toolkit is broken down into four separate groups: Design Requirements and Features User Interface (UI) Design Graphic Design Usability Accessibility Guide Get Started Developer Guide Set Up a Development Machine Resource List Distribute U-M Intellectual Property Rules Licensing and Distribution Develop &amp; Test Choosing a platform Multi-device development Integrating Single Sign-On or CoSign U-M (APIs) Using Emulators and Simulators Testing Your App I think the resources they provide, represent a very long term vision around delivering API resources to developers, who will be building applications for the institution--something that all universities should look at emulating. You want developers, who are building mobile applications on top of campus API resources to be successful, so providing them with the education, training and resources they need to deliver, is critical. I also think it is cool, that at the bottom of the mobile developer toolkit, they provide two other links: Collaborate - Campus and local developer groups. Opportunities - App competition notices. They want their app developers to socialize with other campus application developers, and be aware of opportunities to compete in hackathons and other competitions--on and off campus. Developing mobile applications is the number one incentive for universities to deploy APIs, and jumpstart their API efforts like at BYU, UW and UC Berkeley, and&nbsp;it just makes sense to provide a mobile developer toolkit for developers. Education around APIs and mobile application development is critical to the...[<a href="/2014/07/07/a-mobile-developer-toolkit-with-the-university-of-michigan-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-puppet.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/04/kicking-off-image-manipulation-api-work/">Kicking Off Image Manipulation API Work</a></h3>
			<p><em>04 Jul 2014</em></p>
			<p>
I'm working a wider campaign focused on getting my shit together around my images, and part of that is continueing work I had started with my screen capture API, and launch more image manipulation API resources.
I have a wide range of needs to resize, crop, filter, and apply other filters to photos I work with, as part of my storytelling, and if I had a set of image manipulation APIs, life would be better--so as I do with anything, I got to work building an API.
The result is the first, in a series of&nbsp;image manipulation APIs. Right now I focused on some low hanging fruit, like applying filters to images, which includes Charcoal, Oil Painting, Polaroid, and Sketch. Next, I will tackle some more utility APIs like resize, crop, and rotate.
Like my other APIs, I will use my operational harness, and operate a cloud version of my image manipulation API, where anyone can access, and take advantage of my API resources. Using my API service composition, I setup access tiers for public, partners and internal usage.&nbsp;
I will also open source any code behind so that others can deploy image manipulation within their own infrastructure, or I'm happy to setup for you--for a fee! :-)
I have a number of APIs I want to get built, and image manipulation has been on my list for a while, I'm glad I finally was able to get this work started.
[<a href="/2014/07/04/kicking-off-image-manipulation-api-work/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-light-bulb-bright.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/04/an-api-for-api-ideas/">"An API For API Ideas"</a></h3>
			<p><em>04 Jul 2014</em></p>
			<p>
I have a lot of ideas while being the API Evangelist. It just comes with the territory. I have an Evernote folder that I publish these ideas to, and some of them, like my Screen Capture API, I actually make a reality.
The other night while writing, Shadow API: Launching An API Before Someone Else Does, I went to add the Nebraska homestead record API idea to my Evernote, and I said, ENOUGH! I need a public place to store these ideas, and while I'm at it, I'll enable others to publish ideas there too.
What better way to allow collaboration around a content store or dataset, than a Github repository plus API. So I launched API Ideas, as an individual API project, on the API Evangelist Network. I allows me to retrieve, and add to a list of API ideas, all stored on Github, using a simple web API.
I&rsquo;ll be evolving the API over time, you can engage with me on the roadmap, and see stories around the project on the updates page. It is just a start, and I will be adding a lot more bells and whistles, and improve search, as I have time.

[<a href="/2014/07/04/an-api-for-api-ideas/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/IFTVT-logo.jpg" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/03/if-this-then-visualize-that-iftvt/">If This Then Visualize That (IFTVT)</a></h3>
			<p><em>03 Jul 2014</em></p>
			<p>In the tech space, when we see a pattern that works, we run with it. This is why you hear, &ldquo;It is the Uber for X&rdquo;, or &ldquo;It is the Github for X&rdquo;, and I recently talked about how I&rsquo;m starting to see more of, &ldquo;It is the If This Then That (IFTT) for X&rdquo;. The IFTTT model, or what I call &ldquo;reciprocity&rdquo;, is an evolution on the classic enterprise ETL model, resulting in over 25 companies that I&rsquo;m tracking on in the space. Reciprocity works, because it is about solving a simple problem for everyday users, using APIs to take a single action&mdash;if this happens over there, use APIs, to do that over there. There are many other words used to describe this evolution of ETL in the clouds, including interoperability, and automation, I use reciprocity because it better describes what is happening as part of the growing global API economy. I recently went through all 65+ of my research projects, one of them being reciprocity, and as I was working on new research areas around open data, analysis, and visualization, I started thinking about how the IFTTT (reciprocity) model could be applied to analysis and visualization&mdash;resulting in a draft model I would call If This Then Visualize That (IFTVT). The IFTVT model provides the similar feedback loop as IFTTT, but instead of a resulting action, the end goal is a visualization. If &ldquo;end of month&rdquo;, show me overview of Foursquare checkins. If &ldquo;Tweet receives 10 favorites&rdquo;, show me a list of Twitter users. If &ldquo;bank account goes below $50&rdquo;, show me last 25 charges. How you get your IFTVT visualizations would be up to you, maybe it is email, maybe SMS, maybe some sort of iGoogle like dashboard unit. As with the IFTTT model, IFTVT gives us actionable, meaningful results from our increasingly disparate digital worlds. Using reciprocity, we are slowly being able to get a handle on the cloud versions of ourselves,...[<a href="/2014/07/03/if-this-then-visualize-that-iftvt/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/eclipse/eclipse-ide-logo.jpeg" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/03/expanding-the-layer-of-api-discovery-from-within-the-developers-ide/">Expanding The Layer Of API Discovery From Within The Developers IDE</a></h3>
			<p><em>03 Jul 2014</em></p>
			<p>Much like API design and integration, the world of API discovery is heating up in 2014. We are moving beyond the API directory as our primary mode of API search, in favor of a distributed approach using APIs.json, and supporting open source search engines like APIs.io. Another area of API discovery I&rsquo;ve been watching for a while, and predict will become an important layer of API discovery, will be via the Integrated Development Environment (IDE) plugin. Open Source SalesForce API IDE Plugin SalesForce just announced they have just open sourced their API IDE plugin on Github, after developing on it since 2007, when APEX was born. The plugin is old, but is very much in use in the SalesForce ecosystem, something I&rsquo;ve written about before. They will be accepting pull requests on the main branch, looking to improve on the codebase, while looking to also maintain a community branch, as well as encouraging you to establish your own branch. Does Your API Have An IDE Plugin? How far along are you on your own APIs Eclipse Plugin? Are you trying to reach enterprise developers with your API resource? You should probably look at the pros and cons of providing your API developers with a plugin, for leading IDEs. With the open sourcing of SalesForce API IDE plugin, you can reverse engineer their approach and see what you can use for your own APIs IDE plugin&mdash;smells like a good opportunity to me. Opportunity For General Or Niche API IDE Plugins Not that using SalesForce open source IDE would be the place to start for this kind of project, but I think there is a huge opportunity to develop API focused IDE plugins, for top developed environments, across many popular APIs. Developers shouldn&rsquo;t have to leave their development environments to find the resources they need, they should be able to have quick access to the APIs they depend on te most, and discover new API resources right...[<a href="/2014/07/03/expanding-the-layer-of-api-discovery-from-within-the-developers-ide/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/eclipse/eclipse-ide-logo.jpeg" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/03/expanding-the-layer-of-api-discovery-from-with-the-developers-ide/">"Expanding The Layer Of API Discovery From With The Developers IDE"</a></h3>
			<p><em>03 Jul 2014</em></p>
			<p>Much like API design and integration, the world of API discovery is heating up in 2014. We are moving beyond the API directory as our primary mode of API search, in favor of a distributed approach using APIs.json, and supporting open source search engines like APIs.io. Another area of API discovery I&rsquo;ve been watching for a while, and predict will become an important layer of API discovery, will be via the Integrated Development Environment (IDE) plugin. Open Source SalesForce API IDE Plugin SalesForce just announced they have just open sourced their API IDE plugin on Github, after developing on it since 2007, when APEX was born. The plugin is old, but is very much in use in the SalesForce ecosystem, something I&rsquo;ve written about before. They will be accepting pull requests on the main branch, looking to improve on the codebase, while looking to also maintain a community branch, as well as encouraging you to establish your own branch. Does Your API Have An IDE Plugin? How far along are you on your own APIs Eclipse Plugin? Are you trying to reach enterprise developers with your API resource? You should probably look at the pros and cons of providing your API developers with a plugin, for leading IDEs. With the open sourcing of SalesForce API IDE plugin, you can reverse engineer their approach and see what you can use for your own APIs IDE plugin&mdash;smells like a good opportunity to me. Opportunity For General Or Niche API IDE Plugins Not that using SalesForce open source IDE would be the place to start for this kind of project, but I think there is a huge opportunity to develop API focused IDE plugins, for top developed environments, across many popular APIs. Developers shouldn&rsquo;t have to leave their development environments to find the resources they need, they should be able to have quick access to the APIs they depend on te most, and discover new API resources right...[<a href="/2014/07/03/expanding-the-layer-of-api-discovery-from-with-the-developers-ide/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/api-evangelist/apis-io/apis-io.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/03/an-open-source-distributed-api-search-engine/">An Open Source Distributed API Search Engine</a></h3>
			<p><em>03 Jul 2014</em></p>
			<p>I wanted to stop and reflect for a moment on the open source, distributed API search engine, that 3Scale and API Evangelist developed, in support of the APIs.json discovery format. When we conceived the APIs.json API discovery format, we knew that the project would be dead in the water, if there wasn&rsquo;t a clear incentive for API providers to generate an APIs.json&mdash;helping them get their APIs found. Until 2014, when you said "search for APIs", it meant going to a website (programmableweb.com), and searching for an API in a curated directory of APIs. In the last couple years, we&rsquo;ve seen an evolution on this directory search model from Mashape, in the form of a hub or marketplace. Managed directories have their place in the world of API discovery, similar to the web directory realm, but as the number of APIs grow, we are desperately needing to go beyond just directory based API discovery, and like with the web, establish a meaningful search layer&mdash;we need a Google of API search. This is why 3Scale and API Evangelist developed APIs.json, and the first open tooling on top of the API discovery format, we called APIs.io. We do not believe APIs.json + APIs.io is the next Google, but we do feel it will jumpstart the conversation around what is needed when it comes to API discovery. How do we find the best of breed APIs, not just on keyword search in the title and description, or driven from tags? We need a way for API providers to describe their APIs, and supporting building blocks, in a machine readable, distributed way, that can be indexed by many API discovery solutions. When searching for APIs, we will need to find specific API interfaces, with very specialized terms of service, and pricing. We will need API rating solutions like API Rating Agency baked into our API search algorithms. We need an extensible API discovery format, this is APIs.json. We need an...[<a href="/2014/07/03/an-open-source-distributed-api-search-engine/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/kin-aud-shadow.jpg" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/02/shadow-api-launching-an-api-before-someone-else-does/">Shadow API: Launching An API Before Someone Else Does</a></h3>
			<p><em>02 Jul 2014</em></p>
			<p>In a perfect world, every government agency, non-profit organization, and company would have an API, and the content and data available via their website, mobile applications, and other systems, would be accessible in an easy, machine readable way. This perfect world does not exist. Even though many government agencies, non-profit organizations, and companies are getting hip to the world of APIs, there is still massive amounts of work to be done, and I'm afraid if we want to see APIs across our government, we are going to have to do much of it ourselves. I was listening to an NPR story on the release of files detailing Nebraska's homesteading history, a project between the National Archives and National Park Service, today. I wish I could be at all federal agencies, in all meetings, advocating for an API first approach to these projects--I can&rsquo;t. So, while we can celebrate the fact that the records around Nebraska&rsquo;s history have been digitized, and the website is very nice, and usable for humans, THERE IS NO API! This is when the private sector has to step in and help our federal government realize the importance and potential of an API--we need a shadow API for the homestead records database. While the website is great for human consumption, we also need a simple, machine readable API that other applications can put to use. It would be nice if the National Archives and National Park Service had made the API a priority, but I think this is where the private sector needs to step in, and make it happen. I have direct orders from my super secret White House contact(s) to challenge you, Joe and Jane citizen to see who can launch an API faster, around content or data that is already public (no hacking)&mdash;the federal government, or you the average tech savvy citizen. I won&rsquo;t give up my sources, but I&rsquo;m dead serious when I say the White House asked...[<a href="/2014/07/02/shadow-api-launching-an-api-before-someone-else-does/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/smallest-federated-wiki/smallest-federated-wiki.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/02/making-more-time-to-play-with-the-smallest-federated-wiki/">Making More Time To Play With The Smallest Federated Wiki</a></h3>
			<p><em>02 Jul 2014</em></p>
			<p>I'm always working to better understand the best of breed technology solutions available online today, and to me, this means, lightweight, machine readable apps that do one thing and do it well. One solution I&rsquo;m looking at is called the&nbsp;Smallest Federated Wiki, from Mike Caulfield(@holden), which has been on my list for several weeks now, but one of his latest posts has floated it back onto my priority list. To understand what the Smallest Federated Wiki (SFW) is, check out the video. I haven&rsquo;t personally downloaded and installed yet, which is something I do with all solutions that I&rsquo;m evaluating. SFW is Node.js, and available on Github, if you want to play with as well--I'm going to be installing on AWS if you need an AMI. This post is all about understanding SFW, and light the fire under my own use of SFW, and hopefully stimulating your interest. Simple Building off the simplicity of the Wiki, SFW borrows from the best features of Wiki, Github, and rolled together into simple, but ultimately powerful implementation that embraces the latest in technology from Node.js to HTML5. I know how hard it can be to achieve "simple", and while playing with SFW, I can tell a lot of work has gone into keeping things as fucking simple as possible. #win Federated I love me some Wikipedia and Github, but putting my valuable content, and hard work into someone else&rsquo;s silo is proving to be a very bad idea. For all of my projects, I want to be able maximize collaboration, syndication and reach, without giving away ownership of my intellectual exhaust (IE) . SFW reflects this emotion, and allows me to browse other people&rsquo;s work, fork, re-use, while also maintaining my own projects within my silo, and enable other people to fork, and re-use from my work as well--SFW is a sneak peak at how ALL modern applications SHOULD operate. JSON Extensible SFW has the look and feel...[<a href="/2014/07/02/making-more-time-to-play-with-the-smallest-federated-wiki/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/Corvette-Aft-Cat-Exhaust-System1.jpg" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/02/intellectual-exhaust-ie/">Intellectual Exhaust (IE)</a></h3>
			<p><em>02 Jul 2014</em></p>
			<p>As I generate shitloads of content playing the API Evangelist&nbsp;on the Internets, I struggle with certain words, as I write each day&mdash;one of these words is intellectual property (IP), which Wikipedia defines as: Intellectual property (IP) rights are the legally recognized exclusive rights to creations of the mind.[1] Under intellectual property law, owners are granted certain exclusive rights to a variety of intangible assets, such as musical, literary, and artistic works; discoveries and inventions; and words, phrases, symbols, and designs. Common types of intellectual property rights include copyright, trademarks, patents, industrial design rights, trade dress, and in some jurisdictions trade secrets. I don&rsquo;t like the phrase intellectual property, specifically because it includes &ldquo;property&rdquo;. Nothing that comes from my intellect is property. Nothing. It isn&rsquo;t something you can own or control. Sorry, what gets generated from my intellect, wants to be free, not owned or controlled&mdash;it is just the way it is. I cannot be creative, generate my ideas and projects, if I know the output or results will be locked up. With this in mind I want to craft a new expression to describe the result of my intellectual output, I&rsquo;m going to call intellectual exhaust (IE). I like the term exhaust, which has numerous definitions, and reflects what can be emitted from my daily thoughts. You are welcome to collect, observe, remix, learn from, or get high off of the exhaust off my daily work&mdash;go right ahead, this is one of the many reasons I work so hard each day. You my loyal reader. One. Single. In my opinion, you can even make money off my intellectual exhaust, however, no matter what you do, make sure you attribute back, letting people know where your ideas come from. And if you do make some money from it, maybe you can kick some of that back, supporting the things that fuel my intellectual exhaust: sleep, food, water, beer, and interactions with other smart people around the...[<a href="/2014/07/02/intellectual-exhaust-ie/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/amazon/Amazon_S3_Site.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/02/deploying-an-api-from-amazon-s3-file-store/">Deploying An API From Amazon S3 File Store</a></h3>
			<p><em>02 Jul 2014</em></p>
			<p>I'm spending a lot of time updating my API deployment research&nbsp;lately, making sure it reflects what is truly going on out there in the space. In addition to tracking on legacy approaches to API deployment like enterprise API gateways, or using an open-source API frameworks, I am also trying to understand the realities of scraping data for deployment of APIs, and new solutions from API platforms like APISpark, StrongLoop, Orchestrate.io, and Import.io. When it comes to the realities of deploying an API, your data or content sources is likely to come from a myriad of file stores, databases, and other systems, and I&rsquo;m looking to explore as many of the as I possibly can. Todays exploration is focused on deploying an API, using Amazon S3 as a file store. I use Amazon S3 for all my heavy object storage which includes images, PDFs, XML, JSON and CSV data stores&mdash;it makes sense that someone companies would want to deploy APIs using their Amazon S3 stores. I&rsquo;m using APISpark as my API deployment platform, which allows me to first establish a datastore, which is mapped to a specific bucket within my Amazon S3. What I put into my buckets, and folders is up to me. I might use it to quickly provide access to my images, a folder of XML files, PDFs, or other resource. Once I have my datastore defined, I can deploy a simple web API using APISpark, which gives me all the expected features of an API&mdash;URL API endpoints, documentation, code samples, basic authentication (username / password), analytics, and much more. As with the Google Spreadsheet to API example I wrote on Monday, this scenario allows anyone who manages content and data, to easily organize it on S3, then deploy an API for access, with no IT or developer experience required. You might need to share images, files, or other content with another department within your company or organization, partners outside the corporate firewall,...[<a href="/2014/07/02/deploying-an-api-from-amazon-s3-file-store/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-api-deployment-2.jpg" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/07/01/building-blocks-of-api-deployment/">Building Blocks Of API Deployment</a></h3>
			<p><em>01 Jul 2014</em></p>
			<p>As I continue my research the world of API deployment, I'm trying to distill the services, and tooling I come across, down into what I consider to be a common set of building blocks. My goal with identifying API deployment building blocks is to provide a simple list of what the moving parts are, that enable API providers to successfully deploy their services. Some of these building blocks overlap with other core areas of my research like design, and management, but I hope this list captures the basic building blocks of what anyone needs to know, to be able to follow the world of API deployment. While this post is meant for a wider audience, beyond just developers, I think it provides a good reminder for developers as well, and can help things come into focus. (I know it does for me!) Also there is some overlap between some of these building blocks, like API Gateway and API Proxy, both doing very similiar things, but labeled differently. Identifying building blocks for me, can be very difficult, and I'm constantly shifting definitions around, until I find a comfortable fit--so some of these will evolve, especially with the speed at which things are moving in 2014. CSV to API&nbsp;- Text files that contain comma separate values or CSVs, is one of the quickest ways to convert existing data to an API. Each row of a CSV can be imported and converted to a record in a database, and easily generate a RESTful interface that represents the data stored in the CSV. CSV to API can be very messy depending on the quality of the data in the CSV, but can be a quick way to breathe new life into old catalogs of data lying around on servers or even desktops. The easiest way to deal with CSV is to import directly into database, than generate API from database, but the process can be done at time of...[<a href="/2014/07/01/building-blocks-of-api-deployment/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-spreadsheet-api.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/06/30/deploy-an-api-from-a-google-spreadsheet-using-apispark/">Deploy An API From A Google Spreadsheet Using APISpark</a></h3>
			<p><em>30 Jun 2014</em></p>
			<p>Spreadsheet are the most used datastore in business. When Google came out with their web-based spreadsheet, it was a game changer (for those who have access), when it came to managing, collaborating and sharing small data sets. When it comes to data management, not all of us live in the world of big data, and spreadsheets are a quick and dirty data store that gets the job done. As the web was maturing, Google saw an opportunity, and launched the labs version of Google Spreadsheets in mid 2006, bringing spreadsheets into the web 2.0 era of the Internet. In 2014, the next step, in the evolution of the spreadsheet, is to be able to plug spreadsheets directly into the API economy, allowing spreadsheet data stewards to make their valuable content and data available to web, mobile and Internet of things (Iot) developers via simple web APIs. Google Spreadsheets allows for accessing data via a JSON feed natively, and I wrote about adding an API, plus management layer on top of a public or private Google Spreadsheet, but there is also an instant, cloud-based approach to deploying an API from Google Spreadsheet, using APISpark. Restlet has taken their open source REST framework, launched it as a service, and opened up the possibility for anyone to deploy an API, from an existing Google Spreadsheet&mdash;no coding necessary. APISpark has provided both the API deployment, plus API management layer, spreadsheet owners will need. This is an important evolution in the API economy, because it allows people who are actually managing vital data to securely expose it, for use in applications, without needing any developer or IT resources. This will bring data stewards closer to the actual people who need their data, whether it be internally between systems or business units, externally with partners, or even publicly for anyone looking to use a dataset on a website or application. A lot can be lost in translation, when a dataset has...[<a href="/2014/06/30/deploy-an-api-from-a-google-spreadsheet-using-apispark/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/legos.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/06/30/apis-json-api-property-types/">APIs.json API Property Types</a></h3>
			<p><em>30 Jun 2014</em></p>
			<p>I&rsquo;m working the great feedback we've had on APIs.json, an adding everything to the Github issues for consideration in the next version. Today I&rsquo;m spending a little time thinking through the big picture of APIs.json, and some of the building blocks I'd like to see reflected when API providers generate their APIs.json. Each API listed in an APIs.json has what we are calling: "Properties Elements&rdquo;. The properties element is a collection, with two values: type and url. While we provide you with a base set of property element types you can reference: Swagger RAML Blueprint WADL WSDL TermsOfService InterfaceLicense StatusPage Pricing Forums AlertsTwitterHandle Our goal is to continue providing, &ldquo;reserved&rdquo; types that we recognize, while also leaving properties elements, being as organic as possible&mdash;meaning you can define your own references, and tell the story of why these are important building blocks in your own API strategy. We will continue adding the best properties we see being used, to the APIs.json spec. To prepare for the next version of APIs.json, I want to have the next list of reserved property types. Working from my list of API management building blocks I&rsquo;ve identified X I&rsquo;d like to see in the next version: GettingStarted FrequentlyAskedQuestions Signup BestPractices ServiceAccord Documentation Explorer ErrorCodes AuthenticationOverview AuthenticationTester CodeLibraries ApplicationGallery SoftwareDevelopmentKits StackExchange Calendar OfficeHours Blog BlogRSS LinkedIn Twitter Github Facebook GooglePlus Roadmap ChangeLog RateLimits Affiliate Advertising CaseStudies WhitePapers HowToGuides Webinars Ideas Labs Opportunities Branding PrivacyPolicy ServiceLevelAgreement DataLicense CodeLicense DeprecationPolicy Widgets Buttons Badges These are the building blocks I think are important to API operations. Currently all of these will be links to human readable pages, within an APIs developer portal, but eventually I envision all of these potentially being machine readable. I know, this is a big vision, but I intend to make it a reality. The first machine readable element on this list is the InterfaceLicense, which will reference the machine readable JSON manifest for API Commons. Next on the list is...[<a href="/2014/06/30/apis-json-api-property-types/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/whitepapers/api-deploy-white-paper.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/06/30/api-design-white-paper/">API Design White Paper</a></h3>
			<p><em>30 Jun 2014</em></p>
			<p>Download as PDF My research for API Evangelist spans 50+ projects, but my core research is focused on seven projects in&nbsp;API 101, history, design, deployment, management, discovery and integration. In each of these areas, I evaluate who the key players (companies and individuals) are, and the tools and services they produce. Using my own, custom developed system, I monitor these key players, in all of the research areas, consuming blog posts, tweets, code commits, and much more, trying to establish a deep awareness in each of these fundamental layers of the API economy. The goal of my monitoring is to help me in producing blog posts (short form), and white papers (long form), while generating valuable analysis for my research, and increasing my own understanding and awareness of the API economy. I have already produced white papers for API 101, History of APIs, API Deployment, and API Management, and I just now finished one for API Design. As with all of my research projects, and the resulting white papers, they are a work in progress, and meant to be a living snapshot of my research. I generate this white paper using the same tools I publish my API design research to Github. My CMS lets me format the static content, while also pulling dynamic content from my tracking system(s), and rolls it up into single PDF white paper, you can take with you and learn about the world of API design--it isn't perfect, but provides a good summary of my research. The other white papers I've produced are all due for an update, but first I need to focus on producing the first version white paper for API discovery, and integration, both areas that are extremely relevant, fast moving layers of the API economy. Looking at the date on my other white papers, June 2013, it seems that summer is a good time to hibernate and produce these new, long form snapshots of my ongoing...[<a href="/2014/06/30/api-design-white-paper/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-comment-bubbles.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/06/28/developing-the-language-we-need-to-communicate-throughout-the-api-lifecycle/">Developing The Language We Need To Communicate Throughout The API Lifecycle</a></h3>
			<p><em>28 Jun 2014</em></p>
			<p>We are still in the infancy of the API economy, and now with barely 14 years of evolving web API design, we are only just now developing the languages we will need to communicate around APIs throughout their lifecycle, from the first mock of the API resource, to monitoring of a production API in the wild, or making available to a new breed of API search engines. There has long been standards for describing APIs, such as WSDL for SOAP, and WADL for web APIs, but these formats would never actually enable the meaningful interactions around APIs that it would take to find widespread adoption. WSDL was too programmatic, and heavy handed, while WADL never possessed the incentives for API providers to take the time to define their APIs using the heavy XML format. It wasn't until early 2011, we would see the first signs of a meaningful language for defining web APIs, that would enable us to have productive conversations, and take action around our API designs. In February 2011, online word meaning and definition site Wordnik, launched a new API developer portal, complete with a new way to document APIs, that was interactive, and allowed developers to make live API calls, while learning about an API. In an effort to keep their API documentation up to date, Wordnik has also established a new way to not just document and communicate with an API, but allow us to actually have a shared conversation about the actual design of the API itself. Later on that year, API management provider Mashery emulated Wordnik's approach, and launched their I/O Docs. Immediately after, in August 2011, Wordnik formally launched their approach to defining APIs, generate interactive documentation, and server or client side code&mdash;which they called Swagger. Over the next two years the Swagger ecosystem would grow and evolve, producing new versions, tooling, and implementations of both private and public API implementations. During this time, the concept of API...[<a href="/2014/06/28/developing-the-language-we-need-to-communicate-throughout-the-api-lifecycle/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/api-service-providers/api-spark/restlet-apispark.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/06/27/the-restlet-open-source-and-api-spark-cloud-business-model/">The Restlet (Open Source) and API Spark (Cloud) Business Model</a></h3>
			<p><em>27 Jun 2014</em></p>
			<p>I&rsquo;m always on the hunt for common patterns that are working within the API space, and shine light on them, work to understand why they work, so that others can emulate these successful patterns in the space. One approach I&rsquo;ve seen work well, in many situations, is a combination of open source and a Platform as a Service (PaaS), and I&rsquo;m going to highlight the implementation of this model by one of the API Evangelist partners&mdash;Restlet / APISpark. Open Source For Developers First and foremost, Restlet is an open source web API framework, that any developer can download, and install to deliver their own API. The community benefits from this, Restlet benefits from this&mdash;open source API tooling is a fundamental building block for all of this to work. Many companies feel that open sourcing their core platform is just giving away their intellectual property, when in reality many consumers of your software won&rsquo;t have the resources to implement on their own, and will still need consulting resources to get the solution off the ground. Platform as a Service (PaaS) For Everyone If you want the power of Restlet, but don&rsquo;t have the time or resources to download and install, and you just want to get up and running with APIs, Restlet provides a PaaS version of Restlet, called APISpark. Using APISpark, anyone can deploy an API from new or existing data or file stores--no coding resources necessary. APISpark is a natural companion for Restlet, providing an out-of-the-box web API framework, that anyone can put to use--providing a viable commercial layer built on top of the open source Restlet.&nbsp; Professional Services For Everything Else Of course, at any stage of development, whether you are looking to put Restlet or APISpark to work, there are professional services to help you achieve your goals. The Restlet team provides professional services, commercial licensing, and other opportunities to get the skills and resources you need to make your API deployment...[<a href="/2014/06/27/the-restlet-open-source-and-api-spark-cloud-business-model/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/api-evangelist/nest/nest-developer-program.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/06/27/nest-provides-a-realtime-layer-by-default-for-api-consumers/">Nest Provides A Real-Time Layer By Default For API Consumers</a></h3>
			<p><em>27 Jun 2014</em></p>
			<p>
I had several folks point me to the Nest API release the other day. I enjoy this, because I&rsquo;m not always the fastest in finding news&mdash;eventually I&rsquo;ll find it, but I rely on my human API monitoring network, just as much as my algorithmic API monitoring network, to bring stories to my attention. I&rsquo;m still reviewing the Nest API release, but one thing that stood out to me, was how real-time is baked into the API by default, and specifically using Firebase.
The Nest API documentation states:
Use the official Firebase client libraries (Web, iOS, Java, and Node), which allow you to synchronize your data with a subscription-based, near-real time platform. As you develop your client, you'll find these resources useful: Firebase Data Structure, Reading and Writing data.
Nest also provides options, if you can&rsquo;t use the Firebase library (not sure why this would be):
In cases where the platform you're developing your integration on has no available Firebase library, you may want to use REST or REST Streaming instead.
I track on real-time technology like Firebase as part of my API trends research, and much like other trends like aggregation and reciprocity,&nbsp;I think we&rsquo;ll start seeing these trending layers baked into API operations by default. I&rsquo;ve seen APIs reference default API reciprocity, using platforms like Zapier, and I think we&rsquo;ll see more APIs adopt real-time frameworks by default in the future.

API providers need to focus on what they do best, providing API access to their valuable data, content and other programmatic resources. It is wise for providers to leverage existing providers to deliver real-time, aggregation, reciprocity, voice, and other complimentary API layers. I will continue to keep my eye out for how APIs are providing a much fuller stack of resources for developers, using their own resources, while also augmenting with other leading technology platforms.
[<a href="/2014/06/27/nest-provides-a-realtime-layer-by-default-for-api-consumers/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/google/Google-Developers-Console.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/06/27/monitoring-your-resources-becomes-default-with-google-developer-console/">Monitoring Your Resources Becomes Default With Google Developer Console</a></h3>
			<p><em>27 Jun 2014</em></p>
			<p>
I&rsquo;m not at Google I/O this week, enjoying some downtime in SoCal, but I am watching some of the news coming out of the event. One thing I noticed, was the addition of monitoring to the Google Developer Console, where&nbsp;Google is slowly working their StackDriver acquisition into their fast growing API driven, cloud development platform.
You have to request access to the new monitoring services, and Google will open up "Stackdriver's monitoring capabilities available to select Google Cloud trusted testers at no charge&rdquo;. Wile Stackdriver is about monitoring your cloud infrastructure, it also provides granular level, API endpoint monitoring solutions that you can use to monitor the health of the API resources you depend on in your apps.
When Google makes a move to support a specific feature across its world of APIs, I take notice. Much like when Google adopted OAuth 2.0 across all APIs, I think their move to provide monitoring services, is a sign that monitoring of the resources you depend is going mainstream--something all web, mobile and Iot API resource providers need to have in place by default in 2014.
[<a href="/2014/06/27/monitoring-your-resources-becomes-default-with-google-developer-console/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/events/edmunds-api-summit/edmunds-panel.jpg" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/06/27/internal-api-summit-within-every-company/">Internal API Summit Within Every Company</a></h3>
			<p><em>27 Jun 2014</em></p>
			<p>
I participated in the API Summit at Edmunds.com yesterday. The event brought in API professionals from Mashery, Netflix, SOA Software, Ticketmaster, and EPAM Systems to discuss APIs, internally with the Edmunds team.
The API gathering was just like any other API event I have participated in, with a lineup of 30-60 minute keynotes from API professionals, accompanied by food, drink and networking in between, as well as after the event. The only difference was the API Summit was smaller and all about Edmunds.com, occurring internally at Edmunds.com office, and with Edmunds.com staff in attendance.
The internal API summit format is something that every company should employ. Following the trend of hackathons being executed internally, as well as publicly, let&rsquo;s move the API conference format that has been evolving from API Strategy &amp; Practice, and API Days, and bring it inside the corporate firewall to help get your entire company on board with APIs.
Let me know if you need assistance in making this happen, I am happy to help.
[<a href="/2014/06/27/internal-api-summit-within-every-company/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/api-evangelist/swagger/swagger-editor.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/06/25/if-i-could-design-my-perfect-api-design-editor/">"If I Could Design My Perfect API Design Editor"</a></h3>
			<p><em>25 Jun 2014</em></p>
			<p>Swagger is now Open API Definition Format (OADF) -- READ MORE I&rsquo;ve been thinking a lot about API design lately, the services and tooling coming from Apiary, RAML and Swagger, and wanted to explore some thoughts around what I would consider to be killer features for the killer API design editor. Some of these thoughts are derived from the features I&rsquo;ve seen in Apiary and RAML editor, and most recently the Swagger Editor, but I&rsquo;d like to *riff* on a little bit and play with what could be the next generation of features. While exploring my dream API design editor, I&rsquo;d like to walk through each group of features, organized around my indentations and objectives around my API designs. Getting StartedWhen kicking off the API design process, I want to be able to jumpstart the API design lifecycle from multiple sources. There will be many times that I want to start from a clean slate, but many times I will be working from existing patterns. Blank Canvas - I want to start with a blank canvas, no patterns to follow today, I&rsquo;m painting my masterpiece.&nbsp; Import Existing File - I have a loose API design file laying around, and I want to be able to open, import and get to work with it, in any of the formats.&nbsp; Fork From Gallery - I want to fork one of my existing API designs, that I have stored in my API design taller (I will outline below).&nbsp; Import From API Commons - Select an existing API design pattern from API Commons and import into editor, and API design gallery. My goals in getting started with API design, will be centered around re-use the best patterns across the API space, as well as my own individual or company API design gallery. We are already mimicking much of this behavior, we just don&rsquo;t have a central API design editor for managing these flows. Editing My API DesignNow we get...[<a href="/2014/06/25/if-i-could-design-my-perfect-api-design-editor/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://federal-government.apievangelist.com/images/logos/labor.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/06/23/federal-government-so-slow-to-adopt-new-technologies-wait-what-a-swift-api-sdk/">Federal Government So Slow To Adopt New Technologies...Wait, What, A Swift API SDK?</a></h3>
			<p><em>23 Jun 2014</em></p>
			<p>
It is a common theme, that government of any kind, especially the US federal government is too slow when it comes to adopting new technology. While this may be a popular meme for anti-government crusaders, and is true in many areas of government, there are growing pockets of resistance across federal agencies, who are not just keeping up with the latest technology, but they are leading.
An example of this is out of the Department of Labor (DOL), with their new Swift Federal Data SDK, which provides a powerful SDK that allows you to work with multiple federal government data APIs, using the new Swift programming language. Swift is only a couple weeks old, and DOL didn't miss a beat in getting a new SDK published on Github for developers to take advantage of.
In my opinion, we can no longer use the tired old meme, that government is just too slow to adopt new technology. There are an increasing number of examples out there that prove otherwise. In the future when you want to criticize an agency for being to slow in their adoption of tech, don&rsquo;t tell the same old tired story&mdash;point to examples like what DOL and 18F are up to, and incentivize the agencies to change in a positive way.
[<a href="/2014/06/23/federal-government-so-slow-to-adopt-new-technologies-wait-what-a-swift-api-sdk/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/apis-json/apisdotjson.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/06/18/multiple-types-of-apis-json-for-discovery/">Multiple Types of APIs.json For Discovery</a></h3>
			<p><em>18 Jun 2014</em></p>
			<p>I&rsquo;m working through thoughts around a suggestion for future versions of&nbsp;APIs.json API discovery format, and as I do with other things I&rsquo;m trying to make sense of, I wanted to write a blog post on API Evangelist. If you aren't familiar with the format, APIs.json is meant to be a machine readable JSON file that provides an overview and listing APIs available within a specific domain. Authoritative APIs.json This is an APIs.json that is made available in the root of a domain, that is providing detail on an API that is managed within the same domain. This use case is for API providers to list the APIs that they offer publicly. Tribute APIs.json There is an API you use, and want to see it indexed in an API search engine like APIs.io&mdash;so you create a tribute APIs.json. This APIs.json index is not done by the owner of the API, but by a fan, or outside contributor. Tributes will weave together the world of APIs, when providers do not have the time. Facade APIs.json There is an API you use, but doesn&rsquo;t have exactly the interface you would want. Some resourceful API architects will be building facades to existing, external API resources. In the API economy you do not settle if an API isn't exactly what you need. The remix able nature of APIs allow for extending by designing facades that transform and extend existing API resources. Cache APIs.json If I learned anything working in the federal government last year, it is that APIs can go away at any point. In the future there will be a need for cached versions of existing APIs, providing redundancy and access to some important data and content. Aggregate APIs.json In fast growing areas of the API economy, we are seeing API aggregation trends, with sectors like social, media, cloud, financial, analytics, and other areas that have matured, and users are depending on potentially multiple API platforms. Derived APIs.json I...[<a href="/2014/06/18/multiple-types-of-apis-json-for-discovery/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/api-evangelist/api-tools/api-tools-logo.jpeg" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/06/18/apitools-raises-the-bar-with-open-onpremise-api-testing-and-monitoring-tools/">APITools Raises The Bar With Open, On-Premise API Testing and Monitoring Tools</a></h3>
			<p><em>18 Jun 2014</em></p>
			<p>
APITools, the cloud-based API integration services is raising the bar for the space by introducing an open source, on-premise version of their API monitoring service. APITools only launched this year, and because of consumer demands, they moved up the timeframe for open sourcing the platform, which was already on the roadmap.
I&rsquo;d say after API design, API integration services and tooling, for testing, monitoring, and transforming API calls is one of the fastest growing segments of the API space. We are seeing solid solutions from SmartBear, Runscope, TheRightAPI, Nomos Software, and from API pioneer John Musser, with API Science, but APITools is definitely raising the stakes with open sourcing theirs offering.
The world of API integration service and tooling is rapidly expanding, and only time will tell whether developers prefer running in the cloud, or on-premise, and what features they are looking for, something I've been documenting as I study what each of the companies offer.
I suspect, that along with other API design, deployment, and management tools we'll need a mix of freemium, open tiers, on-premise, and enterprise API integration services and tooling, to meet the demands of this fast growing segment that overlaps with both providing and consuming APIs.
Disclosure: APITools is a 3Scale service, and 3Scale is an API Evangelist partner.
[<a href="/2014/06/18/apitools-raises-the-bar-with-open-onpremise-api-testing-and-monitoring-tools/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/federal-government/fda/open-fda-logo.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/06/17/adding-data-visualization-layer-to-interactive-api-documentation/">Adding Data Visualization Layer to Interactive API Documentation</a></h3>
			<p><em>17 Jun 2014</em></p>
			<p>
I recently reviewed a new API initiative from the Food &amp; Drug Administration, called OpenFDA. I gave a whole list of things that they did right when launching the API, but one item that I thought was particularly interesting, was the actual interactive documentation for the Drugs API endpoint.
I talk a lot about interactive documentation for APIs, something that has become commonplace, and a building block that developers are starting to expect. What is different about the OpenFDA Drug API, is that the interactive documentation provides a visual interface for building API calls, going beyond the interactive, and often very form based documentation that is commonly seen in other developer areas.
Via the OpenFDA Drug API documentation you can actually build an API query by selecting from radio button values, which then updates the resulting URL query, some summary text, and generates a graph visualization of the resulting query. After building your filter, you can run the API query, and see the request and response, which is a common feature other interactive API documentation implementations.

The addition of a visualization, that is driven by each endpoint is very interesting, and something I&rsquo;d like to see baked into the DNA of interactive API documentation.  Helping me build an API call, visualize and understand the value contained within an API has huge potential. Currently we have Swagger, API Blueprint, and RAML generated interactive documentation solution, which are pretty similar&mdash;I&rsquo;d love to see more visualizations integrated into future interactive documentation implementations.
[<a href="/2014/06/17/adding-data-visualization-layer-to-interactive-api-documentation/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/events/api-days-san-francisco-2014/api-days-sf-june-2014.jpg" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/06/16/thinking-beyond-just-the-car-at-api-days-in-san-francisco/">Thinking Beyond Just The Car At API Days in San Francisco</a></h3>
			<p><em>16 Jun 2014</em></p>
			<p>After speaking at API Craft SF on Thursday, I kept the API talk going with two days of API car talk at API Days San Francisco. While there is a lot of focus specifically on the car itself, there was also a lot of talk beyond the auto at API Days San Francisco, which was dubbed "Disrupting the Car Industry and Driver Experience with APIs". Public Transportation In 2014, you just can&rsquo;t talk about disrupting the car industry, without including public transportation. With smart phones in our pockets, we need to get "smarter" about when and how we drive our cars, but also when should not drive our cars. Public transportation has to be part of the conversation when developers are looking to &ldquo;disrupt the car industry&rdquo;. Bicycle Culture I was pleased to also hear bicycles mentioned during several of the talks, and that developers should think about bicycle culture when developing apps. Many automobile owners are also bicyclists, and merging car and bike culture, expanding the opportunities to ride to work, large public events, or just for recreation, should be part of the consideration when developers are looking to &ldquo;disrupt the car industry&rdquo;. Self-Driving Car Skepticism It is easy to be captivated by the work coming out of Google around the self-driving car, but I was also so surprised to hear several folks express skepticism around whether or not the self-driving car will live up to the hype, and whether or not we even need the self-driving car at all&mdash;with investment around public transportation being a preferred alternative. When preparing for API Days, I expected the usual API crowd, educating people generally on the API opportunity, with a handful of high level car talks from people who have worked for the major car companies, or those working for aftermarket startups. This existed, but I was pleasantly surprised to see so much "out of the box" conversation as well. Seeing that the conversation wasn't just...[<a href="/2014/06/16/thinking-beyond-just-the-car-at-api-days-in-san-francisco/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/api-evangelist/ifthisthenthat/IFTTT-logo.jpeg" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/06/16/its-if-this-then-that-for-x/">Its If This Then That For X</a></h3>
			<p><em>16 Jun 2014</em></p>
			<p>
One interesting theme I heard at API Days San Francisco&nbsp;last week, was the concept of API reciprocity, or If This Then That(IFTTT) moving into more niche areas. This edition of API Days was focused on "Disrupting the Car Industry and Driver Experience with APIs&rdquo;, and I heard several times, people saying, &ldquo;Its If This Then That for cars&rdquo;.
After If This Then That put an iconographic face on the classic practice of Extract, Transform, and Load (ETL), and focused on not traditional database and IT system, but API driven software as a service (SaaS), I saw over 30 other providers follow in their footsteps. It is my mission to understand how these companies are evolving the ETL world, and write about it across the API Evangelist network.
In 2014, I think the concept has reached a maturity point, where reciprocity and interoperability between API driven platforms is being applied to niche areas. With the popularity of IFTTT and Zapier, in helping tech savvy users understand how they can take control over how data and content flow in our increasingly digital worlds, it makes total sense that startups would look to apply this successful pattern to niche areas like the automobile experience.
While Zapier, IFTTT and many other reciprocity providers are providing general purpose recipes for keeping your online world in sync, there is a growing number of focused providers, like SortMyInbox for email, Puppet Labs for cloud computing, and RoadRules.io which was present at API Days in San Francisco.
I think this new breed of API focused ETL startups, delivering niche recipes of automation, interoperability and reciprocity in our digital worlds, will continue to expand. You will hear more startup pitches, where the founder says, &ldquo;Its like If This Then That for X&rdquo;.
[<a href="/2014/06/16/its-if-this-then-that-for-x/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/api-evangelist/dropcam/dropcam.jpg" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/06/16/i-would-review-your-api-dropcam-but-i-cannot-access-it/">I Would Review Your API Dropcam, But I Cannot Access It</a></h3>
			<p><em>16 Jun 2014</em></p>
			<p>One of the mutiple requests to review APIs currently in my inbox, is from the camera platform Dropcam. Every email or tweet I get, asking me to review an API, I at least click in to see what is happening, looking for that good story.&nbsp; Sometimes the API itself, can be good enough to be the &ldquo;thing&rdquo; that I tell a story about, but most often it is about a specific approach the API provider takes. Regardless, I look throughr all aspects of an API, sign up for an account, play with endpoints, look through documentation and code, and terms of service&mdash;trying to find any angle for a compelling story. When I clicked into Dropcam's developer area, I can&rsquo;t sign up for the API, play with endpoints, review documentation and code, but I can look at terms of service! Dropcam asks that you apply to be part of their beta program, before you can look at or play with anything. Dropcam assures me that their API is RESTful and uses its verbs, with all endpoints using HTTPS, and requests and responses in JSON. Dropcam uses oAuth for authentication and authorization, showing that all the proper technology and security building blocks are in place--thing is I need to see for myself. I can understand putting an approval layer at the point someone wants to take their application public, but if someone owns a Dropcam, they should be able to signup and start hacking on their device and the supporting cloud infrastructure. With modern API management infrastructure you have the power to control what resources developers have access to, with identify the bad actors, without limiting who has access to learn about your platform. Most importantly it prevents people like me from just reviewing the endpoints, documentation and the real meat of the Dropcam developer program. I&rsquo;m not building an application, I just want to write a story about what is possible, and without playing with it...[<a href="/2014/06/16/i-would-review-your-api-dropcam-but-i-cannot-access-it/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/events/api-craft/san-francisco/api-craft-sf-june-2014.jpg" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/06/16/api-craft-san-francisco-wrapup-for-june-2014/">API Craft San Francisco Wrap-up For June 2014</a></h3>
			<p><em>16 Jun 2014</em></p>
			<p>
I participated in an API Craft meetup this last Thursday, hosted by 3Scale in San Francisco. The gathering included Uri Sarid(@usarid)&nbsp;representing RAML, Jakub Nesetril(@jakubnesetril)&nbsp;on behalf of API Blueprint, Tony Tam(@fehguy) with his Swagger, and myself, discussing the fast growing world of API design.
While there are other formats for defining APIs, API Blueprint, RAML and Swagger represent the leading API definition formats, tools, and services in the space right now. I assumed we'd be talking about each of the API definition formats, but the conversation was more about how we got here, and the motivations behind generating API descriptions.
There are numerous reasons why API providers would want to generate API designs, ranging from the ability to mock interfaces, to generating interactive documentation that helps onboard API consumers. Having this conversation is important, as not all API providers are generating API definitions, and many of those who do, do not understand all the benefits of have machine readable API definitions.
Thank you to Emmanuel Paraskakis(@manp)&nbsp;who organized the meet up, 3Scale for hosting and sponsoring the conversation, the beer (which included Stone IPA w00t!), and making it possible so the leaders in the space can discuss the increasingly relevant topic of API design, and share the insight with the San Francisco API audience.
[<a href="/2014/06/16/api-craft-san-francisco-wrapup-for-june-2014/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/api-evangelist/netflix/netflix-logo.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/06/15/netflix-finally-shutters-support-for-public-api/">Netflix Finally Shutters Support For Public API</a></h3>
			<p><em>15 Jun 2014</em></p>
			<p>
Netflix officially announced they will be ending support for their public API. Its no surprise, as they announced early in 2013 that they would longer accept new registrations for the API.
While I think that Netflix could have put more resources into their API, and fought harder to make their public API a success, I still consider Netflix to be one of API pioneers that we can learn from when crafting our own API strategy.
While the public Netflix API was not a success, the internal and partner API strategy at Netflix was a success. APIs have allowed the company to scale into the cloud, grow internationally, and expand to sever over 1000 devices via their trusted partner network.
In addition to the internal API success at Netflix, they have been amazing at sharing their knowledge and experience with the wider API community via their blog, conferences like API Strategy &amp; Practice, and in books like APIs: A Strategy Guide, available on O'Reilly Publishing, written by Daniel Jacobsen, Greg Brail and Dan Woods.
Another positive byproduct of Netflix API operation, is that the company has been prolific in open sourcing the technology that goes into the API stack. When you visit the Netflix Github account, you will find a wealth of open tooling that they have worked hard on, and opened up for public use.
API success varies widely from company to company, sector to sector, and it doesn't always look like you think it will&mdash;this is part of the API experience. Just because Netflix doesn't reflect one vision of API success that open developers believed in, it doesn't mean Netflix as a whole was an API failure. There are plenty of lessons to learn from their public API failure, as well as their internal API success.
[<a href="/2014/06/15/netflix-finally-shutters-support-for-public-api/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-recycling.jpg" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/06/10/stackexchange-twitter-and-github-as-default-feedback-loop-for-apis/">StackExchange, Twitter, And Github As Default Feedback Loop For APIs</a></h3>
			<p><em>10 Jun 2014</em></p>
			<p>
I&rsquo;m still extracting great examples of API design, deployment, and management, that other API providers can follow, from recent API projects out of our federal government, with FBOpen&nbsp;from&nbsp;18F, and&nbsp;OpenFDA out of the Food &amp; Drug Administration (FDA).
This particular post is about the approach to establishing a feedback loop with consumers of the OpenFDA API. If you visit the OpenFDA portal,&nbsp;you will find that API consumers can seek help via three self-service channels:

GitHub
StackExchange
Twitter

If you don&rsquo;t get your question answered by searching through existing Github, StackExchange, and Twitter conversations, you have three ways to directly ask the OpenFDA team questions:

StackExchange
GitHub
Email

What is notable (thanks Gray Brooks), is that OpenFDA uses existing services to establish the feedback loop with API consumers&mdash;meaning they use Github, StackExchange, and Twitter rather than rolling their own tool. OpenFDA understands that there are existing conversation that are already occurring on StackExchange, and developers are used to going here to find the answers they need.
Additionally by stimulating the conversation on StackExchange and Twitter you are generating valuable social media and SEO exhaust that will help new consumers, potentially learn about the OpenFDA API, and how it is being used by developers.  This type of feedback loop doesn&rsquo;t just provide support for community, it establishes itself as the heartbeat of your API, showing that someone is home, and is there to support and listen.
The best part is that using Twitter, StackExchange, and Github are free for public conversations, and take almost no time to setup. OpenFDA directly links to the form for asking a question on StackExchange, they don&rsquo;t for Github, but easily could. They also directly link to #OpenFDA hashtag to join existing conversations on StackExchange and Twitter, which is a pretty slick way to weave external searches into your API feedback loop.
Lots of good patterns to follow, from the leading groups deploying APIs in the US federal government.
[<a href="/2014/06/10/stackexchange-twitter-and-github-as-default-feedback-loop-for-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/api-evangelist/edx/edx-logo.jpg" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/06/09/the-edx-api/">The edX API</a></h3>
			<p><em>09 Jun 2014</em></p>
			<p>This post should tell you about how behind I am in my storytelling&mdash;this story is from an event I attended in Arlington TX, on April 30th, and May 1st. While in Arlington, I spoke to a group of professionals who were crafting an online data &amp; analytics course. A couple of the participants were from edX, the online course platform partnership between MIT, Harvard, UC Berkeley and other universities. Over the course of two days, I had a cance ask the question, where was the edX API? Seemed like an obvious question, to which Emily Watson, the program manager at edX, responded, &ldquo;Its on our roadmap&rdquo;! An answer I get from many online companies, but Emily pulled up their roadmap on the wiki, and indeed it was on their roadmap. I told Emily, I&rsquo;d review the edX platform, and provide some feedback, that they could incorporate into their strategy. This one is easy, and is my basic feedback for any company with an online website and/or application&mdash;you make everything currently available on your site or application, available via an API. A quick glance at edX, these would be: Courses - The 175+ courses available on edX, should also be available in a machine readable format, via the edX API. Faculty &amp; Staff - The 400+ faculty and staff involved in producing edX courses should be available in a machine readable format, via the edX API. Schools &amp; Partners- All edX partners should be available in a machine readable format, via the edX API. You start with the low hanging fruit, by establishing three, simply designed web APIs for those already, publicly available resources, then move on to providing the essential business building blocks for any API: Dedicated API Portal - Simple, dedicated portal for edX API integrations, that isn&rsquo;t just for developers. It should be easy enough for anyone to learn about the edX API, without too much technical detail front and center. Simple Landing...[<a href="/2014/06/09/the-edx-api/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/federal-government/fda/open-fda-logo.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/06/06/four-reasons-openfda-api-launch-was-successful-hint-not-just-the-tech/">Four Reasons OpenFDA API Launch Was Successful (Hint: Not Just The Tech)</a></h3>
			<p><em>06 Jun 2014</em></p>
			<p>My friends over at Social Health Insights, wrote about their experience being one of the beta users for the new OpenFDA API, and what they thought contributed to the success of the API launch from the Food and Drug Administration. What I found interesting about their post, is that contributing factors were not technical: Getting Feedback Early - The openFDA team solicited feedback early on in the API development process from end users and consumers of the API. This feedback was listened to and ultimately helped shape a very nice API at launch. Being Collaborative - If you are going to do #1 then you must be willing to be collaborative. From the get-go, the openFDA team collaborated with a number of stakeholders and was open all the feedback that streamed in. This ultimately resulted in a great product at release. Beyond the initial collaboration they are still listening and we bet they will be open to the feedback that comes in. Being Responsive - Send a tweet or message to the team and see what you get. You will be shocked at how fast they get back with you to answer your question. We saw questions over Twitter being answered by the community and openFDA team members within minutes (pretty cool)! Explaining Use Cases Well - Go to the openFDA website and you will see several queries tied to real wold questions about the data exposed by the new adverse event API. This helps consumers understand the possibilities and content of the API quicker and simpler. Beyond this, they solicited private beta testers to build solutions on top of the API which also provided additional sample use cases of solutions that could be created using the API. I am present on the backchannel for the OpenFDA rollout, so I saw some of the back and forth on the technical aspects of OpenFDA, and there was definitely lots of tech talk, but ultimately the success...[<a href="/2014/06/06/four-reasons-openfda-api-launch-was-successful-hint-not-just-the-tech/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-carrot.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/06/05/what-are-the-incentives-for-creating-machine-readable-api-definitions/">What Are The Incentives For Creating Machine Readable API Definitions?</a></h3>
			<p><em>05 Jun 2014</em></p>
			<p>
After #Gluecon in Colorado the other week, I have API design on the brain. A portion of the #APIStrat un-workshops were dedicated to API design related discussion, and API Design is also the most trafficked portion of API Evangelist this year, according to my Google Analytics.
At #Gluecon, 3Scale and API Evangelist announced our new API discovery project APIs.json, and associated tooling, API search engine APIs.io. For APIs.json, APIs.io, and API Commons to work, we are counting API providers, and API consumers creating machine readable API definitions.
With this in mind, I wanted to do some exploration--what would be possible incentives for creating machine readable API definitions?



JSON API Definition
 


Interactive Documentation
 


Server Side Code Deployment
 


Client Side Code generation
 


Design, Mocking, and Collaboration
 


Markdown Based API Definition
 


YAML Based API Definition
 


Reusability, Interoperability and Copyright
 


Testing &amp; Monitoring
 


Discovery
 


Search
 



The importance of having an API definition of available resources, is increasing. It was hard to realize the value of defining APIs with the heavy, top down defined WSDL, and even its web counterpart WADL, but with these new approaches, other incentives are emerging&mdash;incentives that live throughout the API lifecycle.
The first tangible shift in this area was when Swagger released the Swagger UI, providing interactive documentation that was generated from a Swagger API definition. Apiary quickly moved the incentives to an earlier stage in the API design lifecycle with design, mocking and collaboration opportunities.
As the API design world continues to explode, I&rsquo;m seeing a number of other incentives emerge for API providers to generate machine readable API definitions, and looking to find any incentives that I&rsquo;m missing, as well as identify any opportunities in how I can encourage API designers to generate machine readable API definitions in whatever format they desire.
[<a href="/2014/06/05/what-are-the-incentives-for-creating-machine-readable-api-definitions/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/api-evangelist/swagger/swagger-editor.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/06/05/swagger-levels-the-api-design-playing-field-with-new-editor-and-yaml-definitions/">Swagger Levels The API Design Playing Field With New Editor And YAML Definitions</a></h3>
			<p><em>05 Jun 2014</em></p>
			<p>In January I started taking a closer look at the world of API design, by reviewing the top movers in the space, Swagger from Wordnik, API Blueprint from Apiary, and RAML from Mulesoft. My goal was to quantity the world of API design, and help me understand where it might be going, or where there are opportunities for new tools and services. My intention is to write a white paper on API Design, but haven&rsquo;t reached this point, with the crazy amount of events and travel I&rsquo;ve had in the last couple months. Looking back, at where I left off in my research, the major difference between providers was that Swagger was JSON, and didn't have all the tooling that was available with API Blueprint and RAML. Fast forward 60 days, and I find myself at Gluecon, hanging out with Tony Tam of Reverb, creator of Swagger. On the last day of the conference,Tony shows me the new Swagger editor, with a new focus on YAML, as well as JSON Swagger definitions. With one release Tony addresses any gap in the space, leveling the API design playing field between API Blueprint, Swagger, and RAML. While there are many differences between each providers, which you can see in my reposting of Ole Lensmar of SmartBear explored in his talk at #APIStrat Amsterdam with how they model REST, and what is behind the name, each of these top API design solutions will get you there, it just depends on your preferences. 60 days ago I would say that RAML and API Blueprint had a leg up on Swagger because of markdown / YAML focus, and with the amount of tooling they had. With one release Swagger has closed the gap, and with the traction they have amongst developers with a first mover advantage, this could put them squarely in the lead for adoption. I&rsquo;m predicting I&rsquo;ll have more time this month to finish up my API design...[<a href="/2014/06/05/swagger-levels-the-api-design-playing-field-with-new-editor-and-yaml-definitions/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/api-service-providers/api-spark/apispark-logo.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/06/05/publish-your-api-into-the-api-commons-from-apispark/">Publish Your API Into The API Commons From APISpark</a></h3>
			<p><em>05 Jun 2014</em></p>
			<p>
I&rsquo;m still playing catch up on many of my stories from over the last month, and one of them is the ability to publish your API definition straight from your API deployment using APISpark. If you aren&rsquo;t familiar with APISpark, it is a cloud-based API deployment service built on the open source RESTlet framework.
Using APISpark you can deploy APIs from existing Google Spreadsheets, machine readable files on Amazon S3, or directly from a fresh datastore. APISpark gives you all the control you need over generating your endpoints, securing and monitoring the resulting APIs&mdash;all without any programming or back-end infrastructure.
For me, the best part is that once you have your API deployed with APISpark, it automatically generates an API Commons manifest, and serves up the URL you need to publish into the commons.

It means a lot that APISpark understands the importance of publishing your APis to the commons, allow users to publicly showcase their API designs, acknowledging that API definitions should be interoperable, and licensed for re-use. Thanks for baking this feature directly into your API platform, and ensuring all your users play healthy role in the API economy.
[<a href="/2014/06/05/publish-your-api-into-the-api-commons-from-apispark/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-hypermedia.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/06/05/help-developers-understand-what-to-do-next-with-your-api-response/">Help Developers Understand What To Do Next With Your API Response</a></h3>
			<p><em>05 Jun 2014</em></p>
			<p>
There are numerous reasons for API designers to follow hypermedia patterns when crafting their internal, partner or publicly available APIs. One of the most fundamental reasons for offering hypermedia is to help developers understand what to do next, once receiving a response from your API.
Hypermedia APIs mimic the default characteristics of the web, and how you always know what do next with a web page, because there are many available links either in the form of navigation, in the body or footer. Reflecting this behavior, each hypermedia API resources comes with a set of related links giving developers clear actions to take once the response is received.
It can be easy to get lost in the numerous hypermedia debates online, not quite understanding all of the benefits of this fast growing API design pattern, but one clear reason is to help developers understand what to do next. Without clear instructions, developers can make obvious mistakes, misuse or misrepresent API resources, and be out of alignment with your own business goals in providing the API resource in the first place.
[<a href="/2014/06/05/help-developers-understand-what-to-do-next-with-your-api-response/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/api-evangelist/heroku/heroku-logo.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/06/05/deploying-apis-using-heroku-and-3scale-addon/">Deploying APIs Using Heroku And 3Scale Add-On</a></h3>
			<p><em>05 Jun 2014</em></p>
			<p>I am playing around with deploying APIs using multiple cloud platforms, and using popular container solutions. Next up is quickly deploying one of my utility APIs, to Heroku, complete with access control, traffic reports, and supporting analytics with 3Scale infrastructure. Application - Simple Screen Capture API I&rsquo;ve been working through an operational harness for deploying all my APIs, and the API I use to push forward my approach to API deployment, is a screen capture API. This is what I will be deploying on Heroku, creating a simple application, that will take screen captures of web pages that I pass to it. 3Scale Heroku Add-On To make API deployment on Heroku easier, 3Scale has created a Heroku add-on that you can easily deploy for any application you have running on the PaaS platform. With just a single click I added the 3Scale Heroku add-on to my screen capture API--now I can apply 3Scale API infrastructure to my API. API Access Control Using 3Scale I can control who has access to my screen capture API, by setting rate limits and quotas, and if I want I can even charge for access. I can compose any type of service levels for my API that I want. I will create tiers for internal access, external partners, and a public tier where I charge a fee for each API call. API Traffic Report and Analytics With all of my screen capture API traffic managed with 3Scale, I can now see traffic analytics and reports, broken down any account, application or for specific service. Any developer who signs up for my screen capture API, will get access to the reports for their account usage as well. Ready-To-Go Developer Portal One of the benefits of using 3Scale for deploying your API on Heroku, is that you get a developer portal to go with your APIs. This is where developers will to learn about your API, register for API keys, and view...[<a href="/2014/06/05/deploying-apis-using-heroku-and-3scale-addon/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-broken-chain.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/06/05/beta-testing-linkrot-js-on-api-evangelist/">Beta Testing Linkrot.js On API Evangelist</a></h3>
			<p><em>05 Jun 2014</em></p>
			<p>
I started beta testing a new JavaScript library, combined with API, that I&rsquo;m calling linkrot.js. My goal is to address link rot across my blogs. There are two main reasons links are bad on my site, either I moved the page or resource, or a website or other resource has gone away.
To help address this problem, I wrote a simple JavaScript file that lives in the footer of my blog, and when the page loads, it spiders all the links on the page, combining them into a single list and then makes a call to the linkrot.js API.
All new links will get a URL shortener applied, as well as a screenshot taken of the page. Every night a script will run to check the HTTP status of each link used in my site&mdash;verifying the page exists, and is a valid link.
Every time link rot.js loads, it will spider the links available in the page, sync with linkrot.js API, and the API returns the corresponding shortened URL, or if a link shows a 404 status, the link will no longer link to page, it will popup the last screenshot of the page, identifying the page no longer exists.
Eventually I will be developing a dashboard, allowing me to manage the link rot across my websites, make suggestions on links I can fix, provides a visual screen capture of those I cannot, while also adding a new analytics layer by implementing shortened URLs.
Linkrot.js is just an internal tool I&rsquo;m developing in private beta. Once I get up and running, Audrey will beta test, and we&rsquo;ll see where it goes from there. Who knows!
[<a href="/2014/06/05/beta-testing-linkrot-js-on-api-evangelist/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/api-commons/api-commons-icon.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/06/05/api-commons-added-to-the-api-commons/">API Commons Added To The API Commons</a></h3>
			<p><em>05 Jun 2014</em></p>
			<p>
Even with the risk of possible creating some sort of API wormhole, I just added the API Commons API to the API Commons. The API for adding and searching for APIs that are in the commons, now has an API definition that is publicly declared as part of the commons, with a CC-BY license.
It just makes sense to have the API for the commons in the commons, so anyone can establish their own commons, complete with common API. 3Scale and API Evangelist are taking a particular stance on the API copyright discussion, and if our approach doesn&rsquo;t match your vision of the API economy, we encourage you to fork and establish your own commons.
We only launched the API Commons API two months ago, so the definition is still fairly new, and we would love to hear your thoughts on the API definition, and the underlying format of the API Commons Manifest. It is up to all of us to help keep the surface area of the API economy as open, accessible, reusable and interoperable as possible.
[<a href="/2014/06/05/api-commons-added-to-the-api-commons/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/twitter/romain-huet-twitter-slide-twitter-pulse-of-planet.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/06/04/twitter-as-the-platform-for-learning-about-apis-and-the-internet-of-things/">Twitter As The Platform For Learning About APIs And The Internet Of Things</a></h3>
			<p><em>04 Jun 2014</em></p>
			<p>I&rsquo;ve had the pleasure of watching Romain Huet (@romainhuet), developer evangelist at Twitter, give his very entertaining talk three times now, and if you haven&rsquo;t seen it, I recommend looking it up on the APIStrat Youtube channel. Romain walks us through the world of Twitter, showing us the power of the platform and its API, but the really entertaining part is the two Internet of things (Iot) demos that he executes during his talk. The first demo Romain does, is taking an audience selfie using a Raspberry Pi driven camera, triggered by a Tweet. The second demo involves flying a quadcopter drone on stage, that uses NodeCopter&nbsp;as the&nbsp;interface, and Twitter as the communication layer. Both demos are crowd pleasers, which makes for not just an entertaining talk, but shows the potential of Iot + APIs, while also making the audience part of the experience. I think the demos that Romain delivers are important, because they offer a unique learnng gateway to both Iot and APIs. While Twitter as a communication layer for the Internet of things may not be a scalable, production ready solution for talking to devices, I think it is a great learning platform for individuals to learn not just about APIs, but how APIs can be used to communicate with the devices in their world. Simple Communication Twitter is a simple communication platform, which posseses a social graph that is easy to understand by people who are new to the world of APIs. When individuals are experimenting with both APIs and Iot, Twitter provides a great 101 level sandbox to learn from fun, simple, meaningful IoT + API tutorials. Simple API The Twitter API is very mature, providing a simple, yet robust communication API to jumpstart their education. The overhead to get up and running on Twitter API by new users is very low, and with simple tutorials based upon demos like Romain&rsquo;s selfie photo, and drone, the platform provides a great...[<a href="/2014/06/04/twitter-as-the-platform-for-learning-about-apis-and-the-internet-of-things/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/api-evangelist/terms-of-service-didnt-read/tos-didnt-read-logo.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/06/04/the-machine-readable-questions-we-should-ask-of-terms-of-service/">The Machine Readable Questions We Should Ask Of Terms Of Service</a></h3>
			<p><em>04 Jun 2014</em></p>
			<p>
I&rsquo;ve been following the work of Terms of Service Didn&rsquo;t Read for some time now. In my opinion this work is some of the most important legal work out there right now, which is guiding all of our activity not just online, but increasingly in our offline worlds. If you aren't familiar with Terms of Service Didn&rsquo;t Read, I think their slogan sums it up well:
&ldquo;I have read and agree to the Terms&rdquo; is the biggest lie on the web. We aim to fix that.
More clarity and balance in the terms of service that online services employ is critical to the future of society and the web, this single checkbox is deciding our fate, whether you realize it or not. One of the projects I&rsquo;m working on in coming months, is forking and extending the Terms of Service Didn't Read work into the world of APIs.
While I was aware that the Terms of Service Didn&rsquo;t Read work is openly licensed, I wasn't aware of the degree of openness, until I started digging through their Github account and found machine readable inventory of the questions they ask of TOS. This is huge!
To achieve their rating of each online service, TOS Didn't Read asks questions of each service providers TOS. This list of questions is critical to making sense of the complex legalese that TOS contain, allowing for them to derive a rating for each service, and provide a list of plain english description of what you face when signing up for each online service.
In coming months, I will be working on a forked version of TOS Didn't Read, applying their machine readable questions specifically to APIs, and hopefully contributing cycles to the central TOS Didn&rsquo;t Read. My intention is to make machine readable API definitions for this critical building block of the API economy.
[<a href="/2014/06/04/the-machine-readable-questions-we-should-ask-of-terms-of-service/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-surveillance-camera.jpg" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/06/04/retrieve-my-data-like-retrieving-video-surveillance-photos-from-cctv/">Retrieve My Data Like Retrieving Video Surveillance Photos From CCTV</a></h3>
			<p><em>04 Jun 2014</em></p>
			<p>I&rsquo;m an advisor to the camera API platform, EverCam. I don&rsquo;t advise the startup because I&rsquo;m super excited about the opportunities for APIs for security cameras. I'm involved because I believe in the Evercam team, and I want to be aware of this fast growing aspect of the Internet of things and API economy. Security cameras are not going away, and I want to help lend some critical thought to how we use security cameras, and apply APIs to help introduce transparency and accountability into this easily abused layer of our society. One of the things I learned from Evercam, is that in the UK you can request any photos of you taken on the vast closed circuit television, that is ubiquitous across the UK landscape. You can submit a request for a time, day and location and request any photo or video footage taken of you. Its kind of like a visual FOIA request for the surveillance layer of our society. This concept intrigued me, and I wanted to explore in relationship to other layers of convergence between the API economy and our increasingly digital society. Imagine if there was FOIA process for data. I could submit a request to a single organization that would then make requests to leading technology, and big data companies, asking them for a copy of all data they possess about me, and disclose any partners that they have shared this data with. I know portions of this exist from companies like Acxiom, but I would like to see a more coherent, intra-company solution that could better serve individuals who wish to understand how companies are using their data. A concept like FOIA for data across any company will not please corporate america, especially in a landscape where exploitation of users data is the predominant business model. However we are in the early years of the Internet, and things are very much the wild wild west, and it is...[<a href="/2014/06/04/retrieve-my-data-like-retrieving-video-surveillance-photos-from-cctv/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/federal-government/census/us-census-api-ideas.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/06/04/how-will-the-us-census-bureau-api-influence-the-2020-census/">How Will The US Census Bureau API Influence the 2020 Census?</a></h3>
			<p><em>04 Jun 2014</em></p>
			<p>
I've been tracking on the API from the US Census Bureau since they launched in 2012, and even met with them to discuss their strategy over the last couple years. The team at the Census Bureau has slowly integrated an external API into their operations, opening up conversations around census survey data, that is harder to achieve from just downloads only.
I recently saw a post that Census Bureau is gearing up for the 2020 census. As I was reading the post, I couldn't help but think about how the Census API will influence how the 2020 census is executed. Additionally I wonder if any other APIs will be used during the census process, such as Twitter or other social platforms.
In my opinion, the census, and its resulting data will continue to be a cornerstone of the API and open data space. Census data adds a lot of value to other websites, mobile apps, and data visualizations and analysis, and is critical in providing context for both our online and offline worlds. I will continue to keep an eye on the US Census API, and look for signs of how APIs are influencing the 2020 census.
[<a href="/2014/06/04/how-will-the-us-census-bureau-api-influence-the-2020-census/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/federal-government/fda/open-fda-logo.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/06/04/another-strong-api-implementation-in-federal-government-with-openfda/">Another Strong API Implementation In Federal Government With OpenFDA</a></h3>
			<p><em>04 Jun 2014</em></p>
			<p>I am really impressed with the quality of API deployments coming out of the federal government recently. I wrote about the FBOpen API from 18F a couple months ago, and the latest is the OpenFDA API from the Food &amp; Drug Administration. I&rsquo;ve been watching the rollout of the API from behind the scenes for a while now, but with all my travel and speaking I haven't had time to write about or participate, but now that they've officially launch publicly, I wanted to help showcase what they've been up to at the FDA. Meaningful First Impression When you first land on OpenFDA, you immediately understand what it does, thanks to the interactive visual on the homepage introducing OpenFDA, letting you know that it contains more than 3 million adverse drug event reports, with frequently reported indications for drug use among women, 55 to 90. This simple simple description, combined with an interactive visual that demonstrates the value contained within this government API resource, leaves a meaningful first impression upon arrival. Not Just Talk Of Being Open We&rsquo;ve misused the word open when it comes to APIs, so that I&rsquo;m always skeptical when I see it use, but not in the case of OpenFDA. At the top of the home page, it gives three distinct examples of how OpenFDA embraces open, with data, code, and in community, and through making the API openly accessible, simply by requesting a key, in exchange for your email address. Explaining What It Is All About OpenFDA explains what the OpenFDA is all about with a detailed about page, telling what the API does, who worked on the project, and how you can get involved. This type of background is often overlooked by API providers, requiring API consumers to have to piece together what the big picture is around an API&mdash;not with OpenFDA. On-boarding with the API starts with an overview of the project, and resulting API, then dropping you...[<a href="/2014/06/04/another-strong-api-implementation-in-federal-government-with-openfda/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/federal-government/we-the-people/we_the_people.jpg" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/06/03/significance-of-the-we-the-people-api-being-first-modern-read-write-web-api-in-government/">Significance Of The We The People API Being First Modern Read / Write Web API In Government</a></h3>
			<p><em>03 Jun 2014</em></p>
			<p>I finished up my response to the Department of Education RFI focused around the use of APIs at the government agency, a place where I&rsquo;m not just advocating for APIs, but pushing very hard for read / write APIs. I finished up my response to the RFI while waiting for my flight out of Barcelona where I spoke at API Days Mediterranea, where I the heard echoes of the importance role that write APIs will play in government, during a talk from Xavier Badosa (@badosa). All of this primed the pump for me thinking about write APIs in government, while on my flight back to Los Angeles. This will be one of the biggest challenges API evangelists in government will face in coming years, something that scares the shit out of government leaders and their legal advisors, but will also be essential to government assuming its role in the API economy. A read and write strategy for some government APIs, will evolve government resources from being just a download, to being a conversation with private sector interests that are putting those resources to use. As I highlighted in my Department of Education RFI response, allowing reading and writing to government resources, combined with development of sensible service composition around these resources, and establishment of trusted access tiers, will be the connector between the public and private sector, in the API economy. I&rsquo;m not API delusional enough to believe that deploying of APIs, or even read / write APIs will automatically be a good thing in all scenarios. However the opportunity to increase access to government resources by the private sector, in a secure and controlled way, should be considered by all government agencies. When appropriate, the design and deployment of read / write APIs is bundled with all the essential building blocks for API management, it has the potential to allow for a new, real-time, two way partnership to emerge between the public and private...[<a href="/2014/06/03/significance-of-the-we-the-people-api-being-first-modern-read-write-web-api-in-government/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/romain-apistrat-ams.jpg" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/06/03/pushing-the-space-forward-with-talks-at-apistrat-did-you-submit-yours-for-chicago/">Pushing The Space Forward With Talks At #APIStrat - Did You Submit Yours For Chicago?</a></h3>
			<p><em>03 Jun 2014</em></p>
			<p>I&rsquo;m working my way through the collection of talks from API Strategy &amp; Practice Amsterdam that are available on Youtube, and I'm reminded of what an amazing lineup of speakers we've managed to assemble at not just #APIStrat Amsterdam, but also in San Francisco and New York. Today I re-watched three videos which I think reflect not just #APIStrat, but also where we are at in the industry: Mike Amundsen - In an effort to understand where we are going with the API economy , Mike looks back at the history of computing, trying to understand how we got here, uncovering some interesting patterns, while weaving it all together into a compelling story worthy of a Ken Burns PBS documentary. Romain Huet - When selecting talks for #APIStrat we don't just select big brands, we look for the most compelling speakers, and the #APIStrat audience got both with a walk through the Twittersphere and bonus look at the convergence of Internet of Things and APIs, by taking an audience selfie, and flying a drone on stage, from Romain Huett of Twitter. Eva Sjokvist - Eva from Absolut Vodka wowed the #APIStrat audience with the story of their cocktail database API, which went beyond tech, and internally changed culture at the leading vodka manufacturer, teaching them how to look outside the company walls and realize the benefits of external partnerships. I&rsquo;m still working my way through other talks, but these three stand out as examples of what we look for from presenters at #APIStrat. Our speakers tell stories, wow the audience with entertaining demonstrations of the power of APIs, while showcasing how APIs have made an impact at companies, and within industries around the globe. If you have an idea for a talk that you would like to share at #APIStrat in Chicago, something that you think will not just benefit the 700+ attendees, but will also push the API space forward, we want to hear...[<a href="/2014/06/03/pushing-the-space-forward-with-talks-at-apistrat-did-you-submit-yours-for-chicago/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://federal-government.apievangelist.com/images/logos/ed.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/06/02/my-response-to-how-can-the-department-of-education-increase-innovation-transparency-and-access-to-data/">My Response To How Can the Department of Education Increase Innovation, Transparency and Access to Data?</a></h3>
			<p><em>02 Jun 2014</em></p>
			<p>I spent considerable time going through the Department of Education RFI, answering each question in as much detail as I possibly could. You can find my full response below. In the end I felt I could provide more value by summarizing my response, eliminating much of the redundancy across different sections of the RFI, and just cut through the bureaucracy as I (and APIs) prefer to do. Open Data By Default All publicly available data at the Department of Education needs to be open by default. This is not just a mandate, this is a way of life. There is no data that is available on any Department of Education websites that should not be available for data download. Open data downloads are not separate from existing website efforts at Department of Education, they are the other side of the coin, making the same content and data available in machine readable formats, rather than available via HTML&mdash;allowing valuable resources to be used in systems and applications outside of the department&rsquo;s control. Open API When There Are Resources The answer to whether or not the Department of Education should provide APIs is the same as whether or not the agency should deploy websites&mdash;YES! Not all individuals and companies will have the resources to download, process, and put downloadable resources to use. In these situations APIs can provide much easier access to open data resources, and when open data resources are exposed as APIs it opens up access to a much wider audience, even non-developers. Lightweight, simple, API access to open data inventory should be default along with data downloads when resources are available. This approach to APIs by default, will act as the training ground for not just 3rd party developers, but also internally, allowing Department of Education staff to learn how to manage APIs in a safe, read-only environment. Using A Modern API Design, Deployment, and Management Approach As the usage of the Internet matured...[<a href="/2014/06/02/my-response-to-how-can-the-department-of-education-increase-innovation-transparency-and-access-to-data/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/api-evangelist/swagger/Swagger-Logo.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/05/29/the-swagger-specification/">The Swagger Specification</a></h3>
			<p><em>29 May 2014</em></p>
			<p>This post is an exact copy from the Swagger specification page, on the Swagger Github project. As I was reviewing the latest Swagger 2.0 release, I read this descripton, and I really felt it caputred not ust the mission of Swagger, but spoke to the essence of API design. With this in mind I wanted to re-post, as part of my ongoing coverage of the API design space.&nbsp; The goal of Swagger&trade; is to define a standard, language-agnostic interface to REST APIs which allows both humans and computers to discover and understand the capabilities of the service without access to source code, documentation, or through network traffic inspection. When properly defined via Swagger, a consumer can understand and interact with the remote service with a minimal amount of implementation logic. Similar to what interfaces have done for lower-level programming, Swager removes the guesswork in calling the service. Use cases for machine-readable API interfaces include interactive documentation, code generation for documentation, client, and server, as well as automated test cases. Swagger-enabled APIs expose JSON files that correctly ahere to the Swagger Specification, documented in this repository. These files can either be produced and served statically, or be generated dynamically from your application. Without going into a long history of interfaces to Web Services, this is not the first attempt to do so. We can learn from CORBA, WSDL and WADL. These specifications had good intentions but were limited by proprietary vendor-specific implementations, being bound to a specific programming language, and goals which were too open-ended. In the end, they failed to gain traction. Swagger does not require you to rewrite your existing API. It does not require binding any software to a service--the service being described may not even be yours. It does, however, require the capabilities of the service be described in the structure of the Swagger Specification. Not all services can be described by Swagger--this specification is not intended to cover every possible use-case...[<a href="/2014/05/29/the-swagger-specification/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/api-evangelist/sensedia/sensedia-logo.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/05/24/api-evangelist-now-available-in-portugese/">API Evangelist Now Available In Portugese</a></h3>
			<p><em>24 May 2014</em></p>
			<p>
The mission of API Evangelist is to increase awareness of APIs amongst not just the developer community, but also business, organizational, and government leaders around the globe. It is very important to me that as many people as possible read my API stories, and this is why I&rsquo;m very pleased to hear that select API Evangelist stories are being translated into Portuguese, by my friends over at Sensedia.
Sensedia is an API management provider in Brazil, and asked if they could translate and re-publish my stories on their blog, for their customers. Of course! All of my stories are licensed CC BY 3.0, so you are more than welcome to republish, and extend the reach of my stories&mdash;with attribution, and in a professiona manner, of course!
I&rsquo;ve also had requests from other providers in Spain, Germany, and France to syndicate stories from API Evangelist. If you have an API industry focused site or blog, feel free to republish my stories for your audience, and if you translate into another language, I would be happy to showcase here on API Evangelist.  Thank you to Sensedia for helping spread my stories across Brasil.
[<a href="/2014/05/24/api-evangelist-now-available-in-portugese/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/api-evangelist/linguistics/why-apis-should-be-designed-by-linguists.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/05/23/why-apis-should-be-designed-by-linguists/">Why APIs Should Be Designed By Linguists</a></h3>
			<p><em>23 May 2014</em></p>
			<p>I&rsquo;m constantly evangelizing how APIs bring individuals and companyies out of their silos and stimulate conversations internally amongst distributed groups,co and externally with partners and the public. During a federal government panel this Monday in Maryland, I was facilitating a discussion between NASA, GSA, the White House, with participation from Energy, FEMA and other agencies. It was mentioned several times that APIs were facilitating conversation beyond what just a data download does, in a way that changed culture, making APIs more about people than technology&mdash;something that is core to my mission as the API Evangelist. A well crafted API, with essential building blocks like interactive documentation, blogs, forums, active social media accounts, create valuable feedback loops that stimulate conversation around valuable API resources, and the applications and sites that put them use. Then later this week, at Gluecon in Colorado, I saw a talk from Rebecca Standig (@understandig), linguist and software engineer at Keen.io, that blew my mind, taking the concept of APIs and communication to a whole new level. Rebecca connected the dots between linguistics, the need for linguists to have programming skills, and the potential when they design APIs. I&rsquo;m still processing everything she said, and told her I&rsquo;d like to work together more to tell stories about lingistics and APIs, so there will be more stories on this subject, but I had to share my initial thoughts while I was processing my Evernote from the talk. I&rsquo;m always working to craft meaningful stories in the API space, that will help people understand the potential of APIs. Throughout my evangelism I&rsquo;m encouraging companies, organizations and government agencies to employ APIs that will help stimulate conversation with employees, partners and the public. What Rebecca is proposing takes this to a whole new level for me, and opening up new possibilities for how we configure applications to communicate, in a way that is rooted in, and derived from our own understanding of how humans communicate....[<a href="/2014/05/23/why-apis-should-be-designed-by-linguists/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-restaurant-menu.jpg" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/05/23/restaurant-menus-as-analogy-for-api-copyright/">Restaurant Menus As Analogy For API Copyright</a></h3>
			<p><em>23 May 2014</em></p>
			<p>One of the interesting conversations that came out of the APIStrat Un-Workshops at Gluecon this week, was the exploration of the analogy of applying copyright to restaurant menus, and applying copyright to APIs. This type of conversations is why 3Scale and API Evangelist support these types of events. When you Google the topic of restaurant menu API copyright, you get a wealth of contradictory answers that show the difficulty of applying copyright to menus. In practice you can put a copyright on your menu, and you could probably spend a lot of energy enforcing this if someone copies your menu. In reality, it will probably be pretty hard to win, unless your menu is exactly copied, and a fair use claim couldn&rsquo;t be enforced. One interesting layer in this discussion, is the ubiquity of restaurant menus, and even the order, naming and organization of these menus. A phase I don&rsquo;t think APIs have reached, but will at some point. It is pretty difficult to argue that menus are essential to interoperability, meaning you can sit down at any restaurant and the menu contributes to you on boarding with the restaurant experience. Imagine if you had to know to ask for food via a chalkboard, or pick up some phone to call in what you wanted, without knowing any orderly way of understanding what a restaurant provided? Each restaurant would be different, and screw up the whole thing. I would argue that bookmarks, images, video and other common API designs are just like hamburgers, steaks, and salads, when I explore this analogy. I think a lot of the confusion in the API copyright discussion is around the separation between an API and the API definition. The order and layout of restaurant menu is not the restaurant, just like the API design is not the API. Could you imagine enforcing copyright on a american restaurant or diner menu layout? Maybe with fast food, which is not about...[<a href="/2014/05/23/restaurant-menus-as-analogy-for-api-copyright/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-sad-face.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/05/23/one-characteristic-of-many-of-the-enterprise-api-folks-i-meet/">One Characteristic Of Many Of The Enterprise API Folks I Meet</a></h3>
			<p><em>23 May 2014</em></p>
			<p>
When I run into enterprise folks at events, one of the common characteristics I notice, is they always tell me how much they read my blog. Yay! Many of these people have Twitter accounts, which follow me and I follow them, and they can usually reference specific topics or posts I've written&mdash;demonstrating they do indeed read.
Most of these people I'm aware of online, and I usually consider them fence sitters. They rarely retweet posts, or engage in conversations online, they just consume. I think this is fine, because not all everyone is suited for actively engaging in the social media world. What I do think is interesting is how interested they are in my work, and they let me know how my work reaches them, and reference specific topics and stories, but don&rsquo;t actually contribute to the conversation.
In my opinion this isn't individuals faults, this is enterprise culture. Businesses of this scale are not equipped to deliver value unless it is sanctioned and specifically part of the larger brand. The enterprise generates value, but only when in service of their business objectives. Generating open value for a community, even as small as a retweet, comment, or a response in blog post, is not in the DNA.
I strongly believe that businesses should generate just as much value as they consume. I&rsquo;m not stupid. I understand that capitalism is about extracting value and monetizing for shareholders, but can&rsquo;t help but think about what this existence is like for these individuals.
Personally, I find it very rewarding to contributing to communities, and the overall health of the API community, by contributing ideas, engaging in conversations, without the expectation that it will all result in revenue for API Evangelist. Ultimately all of this effort comes back to me, and ensures I will be able to sustain my evangelism efforts, while also nourishing my own individual needs.
[<a href="/2014/05/23/one-characteristic-of-many-of-the-enterprise-api-folks-i-meet/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/steve-apistrat-gluecon.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/05/23/keeping-the-api-conversation-moving-forward-at-the-gluecon-apistrat-unworkshops/">Keeping The API Conversation Moving Forward At The Gluecon APIStrat Un-Workshops</a></h3>
			<p><em>23 May 2014</em></p>
			<p>I&rsquo;m still gathering my thoughts from the deep technical conversations that occurred on Tuesday at the Gluecon APIStrat Un-Workshops&nbsp;in Colorado. Before the official Gluecon festivities kicked off, 3Scale and API Evangelist held a 5 hour un-workshop where approximately 70 API professionals gathered to discuss some of the most pressing topics in the API space. Internet of Things One of the fastest growing areas of the API design and deployment, is in support of the Internet of things (IoT). During the IoT portion we had some interesting conversation around how APIs enable communication in Iot world, including some heated discussion about whether or not HTTP will scale and handle the fast growing Iot space. API Versioning One of the hot topics proposed within the API design un-workshop was API versioning, which I thought would be a technical dive into versioning, but ended up being more of the human side of versioning, and communicating with your API consumers&mdash;clearly setting expectations around the how and why of API versioning. Real-Time Dovetailing nicely with the Iot discussion, there was a very enlightening discussion around real-time, which covered one of the most fundamental issues of real-time&mdash;what is it? As with the API versioning discussion, the conversation took gave a nod to the human side of tech, acknowledging real-time was more about expectations of end-users and providers, than about technology. API Copyright As expected the topic of API copyright was a major part of the discussion, not just at the APIStart Un-workshops, but also the wider Gluecon. A group of us walked through the legal case, where everything stands with API Commons, and how we can best take the offensive attack on the issue as a community, which includes educating more API providers, consumers and business owners. API Design &amp; Discovery Emphasizing the importance of the release of APIs.json and APIs.io, and the conversations around API Commons, a portion of the API design workshop walked through the available API definition formats,...[<a href="/2014/05/23/keeping-the-api-conversation-moving-forward-at-the-gluecon-apistrat-unworkshops/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-design.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/05/23/api-design-may-take-on-new-meaning-when-api-copyright-comes-into-the-picture/">API Design May Take On New Meaning When API Copyright Comes Into The Picture</a></h3>
			<p><em>23 May 2014</em></p>
			<p>In 2014 API design is exploding, proving to be one of the fastest growing areas of the API industry. For many years we&rsquo;ve talked purely about API management, but after consolidation in the space, and serious growth, the conversation has shifted. The API conversation is moving upstream in the API lifecycle, focusing on designing, mocking, and collaborating around designing the best quality APIs possible, that will meet the needs of consumers--before any code is written and deployed. A new wave of API design companies have zeroed in on supporting healthy API design practices by providing tools like Apiary.io which allow you to mock, design and collaborate early on in API design process. This new wave of tools and service is meant to foster the healthiest possible design practices, and is cultivating an expanding army of knowledgeable API designers, who demonstrate that API design can be more art than science and technology. Amid this rapid expansion we are witnessing the potentially damaging effects of the Oracle v Google legal battle, which is looking to inject unnecessary concerns around copyright into this blossoming API design sector. What will the copyright of APIs do to the API design process? Will API design be as creative when you have to be concerned with designing unique interfaces vs creating with the best of breed API design patterns that are already available in the space? Will you design for quality of interfaces, the needs of your consumers and interoperability, the lifeblood of APIs, when you are focused on copyright and your API definitions become about legal protection and not access and innovation as they were intended? If the precedent is set that copyright indeed applies to web APIs, I think that one of the chilling waves that will ripple through the industry will be extremely visible in the API design layer. API definitions are not one of the layers where control and monetization should be applied, allowing for more creative energy...[<a href="/2014/05/23/api-design-may-take-on-new-meaning-when-api-copyright-comes-into-the-picture/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-api-discovery.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/05/20/solving-the-problem-of-api-discovery/">Solving The Problem Of API Discovery</a></h3>
			<p><em>20 May 2014</em></p>
			<p>
API discovery has not changed much since 2005, when John Musser launched ProgrammableWeb, the API directory we've all come to know and love. In 2014 (9 years later), we have Mashape and a handful of other API directory and discovery tools, but we have not made progress on truly being able to discover the best APIs possible, in a distributed, machine-readable way.
Steve Willmott of 3Scale, and Kin Lane of API Evangelist, are at it again, looking to provide a possible solution, that we are calling APIs.json&mdash;a machine readable listing of your APIs and supporting building blocks that lives in the root of your domain.
The objective of APIs.json is to help fix this problem by making it easy for people to signpost where the APIs on a given domain are and provide information on how they work. The format is simple and extensible and can be put into any web root domain for discovery.
We are just getting started, so make sure and get involved via the Github repository or via the Google Group we've setup to facilitate discussion.
[<a href="/2014/05/20/solving-the-problem-of-api-discovery/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-windows.jpg" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/05/16/when-reviewing-an-api-should-i-condemn-providers-for-a-lack-of-public-access/">When Reviewing An API Should I Condemn Providers For A Lack of Public Access?</a></h3>
			<p><em>16 May 2014</em></p>
			<p>I&rsquo;m torn on a matter that I face when reviewing APIs for companies. I get emails from people who want me to review their API implementation, and they state they want public developers to get excited about an API, but the program isn't fully available out in the open. Most often these APIs just have some sort of landing page, which is really just a press release, and email address of someone to contact to gain access. I&rsquo;m all for people being able to have any grade of privacy for their APIs ranging from internal to completely public, but I just it difficult when API providers express interest in public developers learning about and potentially using an API, but don't provide any of the common building blocks developers are used to with a modern API. In my mind, if you are courting public developers, you should provide as much information as you possibly can, and manage access at the registration and API access levels. In the end I guess I'm just exploring the best way to educate companies about the benefits of opening up, provide more information about their developer program, helping them understand that this how it is done with modern web APIs. With the right on-boarding, and API management strategy you can control who actually gets access to your API, and I can't think of why you would want to hide documentation, forums, code libraries, app showcases and other things for an API that is generally available to the public. In 2014, if you are going to provide API resources to the public, you should expose as much of the developers area and as man of the supporting building block to the public as you can. At least talk through each one, and discuss the pros and cons of this being public. In a world where there are over 10K APIs available, it can be difficult to stand out, and the more public...[<a href="/2014/05/16/when-reviewing-an-api-should-i-condemn-providers-for-a-lack-of-public-access/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-hypermedia.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/05/15/hypermedia-adoption-will-not-be-about-the-perfect-api-client/">Hypermedia Adoption Will Not Be About The Perfect API Client</a></h3>
			<p><em>15 May 2014</em></p>
			<p>
As I&rsquo;m working to add yet another API example to my growing list of hypermedia APIs in the wild, I can't help but think about the long evolution of hypermedia, and how it will eventually become part of the mainstream API consciousness.
I first started following the often heated discussions around hypermedia a couple years ago as leading API technologists began discussing this significant evolution in API design. Hypermedia has numerous benefits and features, but one you often hear in discussions is that if we use hypermedia we can stop designing custom clients that consume APIs.
The logic is that if every API call comes bundled with URLs for discovering and navigating the resources that are made available via an API, clients can just use this as a blueprint for any app to API interactions. This became a fairly large argument between hypermedia architects and hypermedia haters, something that I think turned a lot of people off to the concept, forcing us to stick with many of the bad habits we already knew.
As I review these new hypermedia APIs, few of them are perfect by any hypermedia measurement, but they use the sensible portions of hypermedia discovery and navigation to deliver a better API experience for developers. I don't think API providers are doing it because of the perfect hypermedia vision we've heard articulated in the past, they are borrowing the pieces that make sense to them and that meet their goals.
Someday we may achieve a world where API clients aren't custom, with every application automatically knowing how to discover, interact, and navigate any API resource it will need. However I think in the currently reality, we will see hypermedia being adopted because it just makes sense as a next step for sensible API design, and this is how we should communicate it to curious API designers, looking to understand exactly what is this concept called hypermedia.
[<a href="/2014/05/15/hypermedia-adoption-will-not-be-about-the-perfect-api-client/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/two-way.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/05/15/18f-pushing-for-write-apis-in-government-to-become-a-reality/">18F Pushing For Write APIs In Government To Become A Reality</a></h3>
			<p><em>15 May 2014</em></p>
			<p>We&rsquo;ve seen a significant growth in the number of APIs in government, but to date most of these APIs are read-only, meaning you can just retrieve content or data from these APIs, not actually add, update or delete any of the resources made available via these APis. I've written about the lack of write APIs in government before, trying to kickstart the conversation amongst existing API advocates at various agencies, and now 18F, the elite tech group at the GSA is doing the same. 18F has a page dedicated to the conversation around write APIs in government, with eight active examples of write APIs, nine potential examples, and two that are "under consideration". What 18F is doing, is a key part of the process that will demonstrate to existing API owners at government agencies, that write APIs are possible, by showcasing the existing implementations, as well as others that are under development. Agencies need clear examples to follow, reassuring them that this is possible in government, giving them potential mentors, and in some cases incentivize agencies by making them feel they are behind the curve, and missing out on opportunities to lead when serving their constituents. The importance thate government agencies have read / write APIs goes beyond the obvious benefits around content and data being more complete and up to date--a two way street, when it comes to API operations requires a more dedicated approach, bringing agencies closer to both private and public sector partners who will be consuming and contributing to the API(s). This process reduces the chance an API will be launched and forgotten about, which really does nobody any good, and contributes to giving APIs in government a bad name. If you work at a federal agency, or are a contractor working on APIs within government, make sure and reach out to 18F and see how you can be part of this significant change in how federal government operates. For all...[<a href="/2014/05/15/18f-pushing-for-write-apis-in-government-to-become-a-reality/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/api-evangelist/zapier/zapier-introduction-to-apis.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/05/14/zapier-looks-to-educate-everyone-with-an-introduction-to-apis/">Zapier Looks To Educate Everyone With An Introduction To APIs</a></h3>
			<p><em>14 May 2014</em></p>
			<p>
API interoperability and reciprocity provider Zapier is looking to get everyone up to speed on the world of APIs, by providing an introduction to APIs that is meant for both developers who are new to APIs, and easy enough for non-developers to follow.
To help get people up to speed on APIs, Zapier&rsquo;s introduction has eight chapters covering the big picture:


Chapter 1: Introduction
Chapter 2: Protocols
Chapter 3: Data Formats
Chapter 4: Authentication, Part 1
Chapter 5: Authentication, Part 2
Chapter 6: API Design
Chapter 7: Real-Time Communication
Chapter 8: Implementation

It is good to see providers like Zapier develop an introductory course for people to learn about APIs. It is in Zapier&rsquo;s interest to help get people up to speed&mdash;the more folks who understand that APIs exist, the more chance they will use Zapier as the platform they depend on to orchestrate their lives in the cloud.
Zapier&rsquo;s move reflects my original vision behind API Evangelist, and my belief that everyone should understand APIs, and I mean everyone! Much like personal finance, not everyone needs to understand the inner workings of APIs, but every individual should understand they exist, and how they can use services like Zapier to take control of our digital self.
[<a href="/2014/05/14/zapier-looks-to-educate-everyone-with-an-introduction-to-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/oauth-logo.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/05/14/the-future-of-public-private-sector-partnerships-being-negotiated-at-the-api-oauth-scope-level/">The Future Of Public Private Sector Partnerships Being Negotiated At The API oAuth Scope Level</a></h3>
			<p><em>14 May 2014</em></p>
			<p>A couple of weeks ago I attended a two day API specification session between major California utilities, Southern California Edison (SCE), San Diego Gas &amp; Electric (SDG&amp;E), and Pacific Gas and Electric (PG&amp;E), that was organized by Hypertek Inc. for National Institute of Standards and Technology (NIST), that is looking to push forward the Green Button data and API agenda of the White House and Department of Energy. The Green Button API and open data model already exists, but the current hurdle for the initiative is to get leading utilities to agree to specific implementation definitions that serve their customers, so it can be ratified as a standard. This entire two day session was dedicated to walking through line by line, and establish the oAuth scope that each of the three utility companies would implementing when providing Green Button data via the API to 3rd party developers, who are building solutions for utility customers. An example of this in the wild, would be if a utility customer wanted to get a quote for a rooftop solar installation, the installer could use a software solution that was developed by a 3rd party vendor, that pulls that customers energy usage via the Green Button API, and generate a precise quote for the number of solar panels they&rsquo;d need to cover their energy usage. Now this is just one example of how energy data could be used, but a very powerful and relevant one in 2014, that give customers access and control over their data. Before we even get there, the Green Button API definition, data model, and oAuth scope has to be finalized with utility providers, before it can be submitted as a standard&mdash;with the final oAuth scope being what will be agreed to by each 3rd party developer that integrates with each utility's Green Button API. This oAuth scope sets the tone for the conversation that 3rd party software providers, and vendors can ultimately have with...[<a href="/2014/05/14/the-future-of-public-private-sector-partnerships-being-negotiated-at-the-api-oauth-scope-level/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-handshake.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/05/14/one-of-the-problems-with-api-terms-of-service-is-that-there-is-no-negotiation/">One Of The Problems With API Terms of Service Is That There Is No Negotiation</a></h3>
			<p><em>14 May 2014</em></p>
			<p>There is a laundry list of problems with the current state of terms of service, affectionality called TOS--those legal documents we all agree to as part of our usage of online services, and are defining relationships between API providers and their consumers. API Voice is dedicated to exploring this, and other building blocks that make up the politics of APIs, an area you will see increased coverage of in 2014. As I continue to develop a better understanding of how API terms of service influence the API economy, I can't help but think one of the fundamental flaws of API terms of use is that there is no room for negotiation. Earlier this month I explored the concept of being able to pay for alternate options within a terms of service, as part of my ongoing journey towards a machine readable TOS. I strongly believe that to fully realize the API economy as many of us technologists see it, the terms of service have to be machine readable, allowing for seamless integration into the other political building blocks like privacy policies, service level agreements, partner access tiers, and pricing. If you think about it, current API terms of service reflect the command and control governance style of SOA, not the flexible, agile and innovative approach that APIs are often known for. Why aren't API terms of service negotiable? Well they are, it just isn't built into the existing API platform. Many API ecosystem allow for circumventing and negotiating at the terms of service level behind closed doors, with partners, and API consumers who share the same investors, it just isn't a conversation that occurs out in the open. This approach reflects legacy ways of doing business, where if you are in the know, have the right connections, you can negotiate, and not the new API driven approach that will allow the API economy to scale as required. The ability for API consumers to negotiate the...[<a href="/2014/05/14/one-of-the-problems-with-api-terms-of-service-is-that-there-is-no-negotiation/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/events/api-strategy-practice-gluecon/gluecon.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/05/14/join-me-for-iot-realtime-and-api-design-at-gluecon-in-colorado-next-week/">Join Me For Iot, Realtime And API Design At Gluecon In Colorado Next Week</a></h3>
			<p><em>14 May 2014</em></p>
			<p>The time has come for one of my favorite events in the tech space&mdash;Gluecon. If you have never been to Gluecon or Defrag, read some of my previous posts about just how different the event is. Gluecon has brought together tech leaders, who have helped define the API space for the last six years, to a small resort in Colorado, creating an environment for conversation I have not experienced anywhere else. This year Gluecon is exceptionally special for me, because 3Scale and API Evangelist are doing a special first day of un-workshop discussions on API design and the Internet of Things and Realtime, continuing the API Strategy &amp; Practice conversation. You can find all the details over at the APIStrat site, and even register and be part of the conversation. The topic of API design has dominated my blog traffic, with every story I do on the subject filling the top 10 most visited posts for the last 3 months. The conversation of how to design APIs has exploded, with the introduction of languages and tooling from Swagger, API Blueprint and RAML, and as we realize that API design is more art than science&mdash;something that developers and business leaders should all be part of. The first Gluecon / APIStrat un-workshop is dedicated to this fast growing area of the API sector. In 2014 you can&rsquo;t have a conversation about APIs without discussing the next wave of Internet enabled devices&mdash;dubbed Internet of Things (Iot). We are seeing a new breed of APIs, and frameworks emerge that don&rsquo;t just connect devices to the Internet, but also facilitate realtime communications between devices and the cloud&mdash;merging realtime and Iot. The second Gluecon / APIStrat un-workshop is bringing together a wide range of practitioners to discuss what is next for APIs in the context of realtime IoT. It isn&rsquo;t too late to get your tickets to Gluecon and register for the APIStrat un-workshops. Tickets to Denver are pretty inexpensive from...[<a href="/2014/05/14/join-me-for-iot-realtime-and-api-design-at-gluecon-in-colorado-next-week/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/events/moc-2014/2014-moc-management-of-change.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/05/14/i-will-be-moderating-open-data-and-api-workshop-discussion-with-gsa-disa-dni-nasa-and-white-house-next-week-in-maryland/">I Will Be Moderating Open Data And API Workshop Discussion With  GSA, DISA, DNI, NASA And White House Next Week In Maryland</a></h3>
			<p><em>14 May 2014</em></p>
			<p>I was invited to moderate a workshop panel in Maryland next week at the The American Council for Technology (ACT) - Industry Advisory Council (IAC) Management of Change 2014 event. If you arenat familiar with ACT-IAC, they are a non-profit, public-private partnership dedicated to improving government through the application of information technology--with the event bringing government leaders together, and discussing open data, open source, and APIs. The workshop is described as: Open Data isn&rsquo;t just data sets. It&rsquo;s APIs, it&rsquo;s open source and, most importantly &mdash; it&rsquo;s people. Working within these new concepts and methods requires a change in culture by our programs, executives, and contracting offices. In order to execute on providing open source to the public, we need new skills for the workforce that let us contract appropriately, and learn how to design our systems from the ground up with APIs and open source in mind. I will be leading the discussion between a panel of X subject matter experts: Kevin Youel-Page - Assistant Commissioner, Integrated Award Environment, General Services Administration Dan Gahafer - Forge.mil Program Manager, Defense Information Systems Agency Leigh Heyman - Director of New Media Technologies, the White House Dan Lockney &ndash; Technology Transfer Program Executive, The National Aeronautics and Space Administration Pamela Wise-Martinez - Senior Strategic Enterprise Architect, Office of the Director of National Intelligence I&rsquo;m honored to have been invited to help lead the discussion, which is in alignment with my mission to bring awareness of the power of APIs amongst government leaders. I&rsquo;m looking forward to what I, and the rest of the event, can learn from these government leaders regarding how they are using open data, open source software, and APIs to effect change within their agencies. The fact that we are having conversations like this at the highest levels of government in 2014, after four years of API evangelism, makes me hopeful that we are making progress, in not just changing how we do business,...[<a href="/2014/05/14/i-will-be-moderating-open-data-and-api-workshop-discussion-with-gsa-disa-dni-nasa-and-white-house-next-week-in-maryland/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/api-evangelist/priorities/university-of-api.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/05/12/gathering-my-thoughts-with-apis-in-higher-education/">Gathering My Thoughts With APIs In Higher Education</a></h3>
			<p><em>12 May 2014</em></p>
			<p>I had too many scribbles in my Evernote about work I&rsquo;m doing for APIs in higher education, so I decided I need to publish as a story, which hopefully will help me organize my thoughts, figure out my next moves, and share what I&rsquo;m doing to a couple of folks who asked what I&rsquo;m up to in this area. APIs In Higher Education Institutions To keep API Evangelist operating I have some very supportive partners who invest in my research, and one of the areas 3Scale&nbsp;and I work together on is understanding how APIs are currently being used in higher education. As part of my recent research I went back through the universities I track on who have APIs, to see whats changed, and I stumbled upon the fact that BYU&rsquo;s API inventory has grown to a mind blowing 261 APIs, covering almost all aspects of university operations. I will be continuing this research on what BYU is up to, but also the 10 other institutions I&rsquo;m tracking on, and as I do with other areas of the API space, try to identify some of the common building blocks universities are employing&mdash;hoping to create a blueprint that other institutions can follow. You can find all this research, kindly supported by 3Scale, up on the Github repository designated for the project. Dept of Education and FAFSA APIBeyond the general use of APIs by universities, last November I started working on a prototype of an API for the Free Application for Federal Student Aid or FAFSA form, looking to jump start a conversation at the Department of Education around APIs. It worked, and in January they announced that they would looking to get feedback on what an API for FAFSA would look like. Behind the scenes I was contacted to provide a proposal for a FAFSA API, hoping to chase after some budget that could fund such a project. I worked for two days on a proposal,...[<a href="/2014/05/12/gathering-my-thoughts-with-apis-in-higher-education/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api-voice/oraclevgoogle/oraclevgoogle.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/05/10/where-will-your-api-stand-in-the-oracle-v-google-api-copyright-debate/">Where Will Your API Stand In The Oracle v Google API Copyright Debate?</a></h3>
			<p><em>10 May 2014</em></p>
			<p>I wanted to comment on the response yesterday in the Oracle v. Google case being played out in the United States Court of Appeals for the Federal Circuit. This appeal is important to me because it will not just set the tone for how APIs are designed, deployed and managed, but also because I worked with the EFF to craft the Amicus Brief, and signed on as one of the computer scientists in opposition of API copyright--making the response a huge blow to me personally. The case is far from settled, so I will refrain from using hyperbole when I describe the situation, but will echo the EFF&rsquo;s statement that &ldquo;the implications of this decision are significant, and dangerous&rdquo;. For me, it doesn&rsquo;t change the conversation, it just re-enforces what I already believe, and hopefully it will do the same amongst API providers across the space. Steve Willmott of 3Scale and I read the writing on the wall when we started API Commons last year, that a political line was being drawn by the Oracle v Google appeal, and would not just continue to play out in the courts, but also within the heart of the API economy, and that we needed to collectively stand up and push back--API Commons is a back-burn strategy for the wildfire that Oracle has set. API Commons basically declares that API definitions are ultimately copyrightable or licensable as code, depending on your viewpoint, all you do is hang your definition in the API Commons, and provide a reference to the license that matters to you, whether it licensed as content (CC) or software (FSF)&nbsp;is your call. Giving every API provider a torch, and the ability to participate in setting the back-burn, taking a stance in the Oracle v Google wildfire that has been set by Oracle, that could potentially burn down all of our collective resources. In my opinion, Oracle v Google is just one of many battles that...[<a href="/2014/05/10/where-will-your-api-stand-in-the-oracle-v-google-api-copyright-debate/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/acme/acme-corp.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/05/07/partnering-for-me-is-about-sharing-of-ideas-research-and-stories/">Partnering For Me Is About Sharing Of Ideas, Research and Stories</a></h3>
			<p><em>07 May 2014</em></p>
			<p>I just turned down a potential partnership with a major enterprise company. As I do with many stories, I will scrub the names of those involved, because there is no reason to blame a single company, this is a lesson any large entity can learn from&mdash;for this story, we&rsquo;ll just call them Acme Inc. Acme Inc. contacted me a couple weeks ago, stating they were looking to do some research into the API space, and have been following my work for some time. After a few emails we made time to get on the phone and talk about what each of us were up to. We spent about an hour, where I gave my history, why I do API Evangelist, and how I go about generating short form, and long form content as part of my research across the API space. Acme Inc. shared their interest in exploring how APIs could be applied to a couple of business sectors, and were looking to generate white paper(s) that they could distribute internally, and amongst partners. Acme was extremely vague on details, and I understand that not everyone can be as open as me, especially when you work at a big company. We ended the call, agreeing that we&rsquo;d explore what a potential partnership might look like, around research projects, but they would need me to sign an NDA first&mdash;no problem. I received an NDA via email a couple days later, as I was on my way to IBM Impact in Las Vegas, and while I was busy in Las Vegas I received an a reminder to please sign the agreement. When I was done in Las Vegas, on my way to Texas for another engagement, I signed the NDA, printed a PDF and sent it back. A few days later, as I was leaving Texas, on my way home to LA for about 8 hours, before I left to Berlin, I received another email requesting that...[<a href="/2014/05/07/partnering-for-me-is-about-sharing-of-ideas-research-and-stories/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/federal-government/green-button/green-button.jpg" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/05/07/green-button-energy-api-added-to-api-commons/">Green Button (Energy) API Added To API Commons</a></h3>
			<p><em>07 May 2014</em></p>
			<p>One of the most meaningful API projects I work on with the US government is the Green Button API, which provides access to energy data for US consumers across the country. First, what is the Green Button API? The Green Button builds on top of the Green Button data initiative which is: ...an industry-led effort that responds to a White House call-to-action: provide electricity customers with easy access to their energy usage data in a consumer-friendly and computer-friendly format via a "Green Button" on electric utilities' website. Which Todd Park, Assistant to the President and U.S. Chief Technology Officer states: Giving residential and commercial customers secure access to their own energy data in a standard, easy-to-understand format will help them visualize their energy use and identify opportunities to save money. At the same time, Green Button is spurring the development of new online tools and services that add value to this information, creating an innovative new domain for entrepreneurship and job creation. The Green Button API delivers flexible access to Energy Usage Information through a set of RESTful interfaces, providing access any consumers Green Button data. The Green Button API is being designed by EnergyOS, providing a solution that any utility can download and run to mediate access between their retail energy customers, and 3rd parties who will provide energy data driven services to them. I&rsquo;m very excited to announce that the Green Button API definition has been added to the API Commons. The Green Button API represents why 3Scale and API Evangelist launched API Commons, to provide a place where we can hang the most important, and meaningful API interfaces, and underlying data models, to encourage re-use. You can find the Swagger specification for the Green Button API on Github, complete with interactive documentation and other resources. The project is a work in progress, with the final specification still being hammered out by EnergyOS and utilities across the country, but the API is fully...[<a href="/2014/05/07/green-button-energy-api-added-to-api-commons/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-walking-path.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/05/07/api-docs-are-an-error-bridging-where-we-should-be-and-where-we-are-currently/">API Docs Are An Error: Bridging Where We Should Be And Where We Are Currently</a></h3>
			<p><em>07 May 2014</em></p>
			<p>I heard an interesting statement this week at APIDays Berlin that I&rsquo;ve heard before, "API document is an bug not a feature". The logic behind this is that if you design a proper API, using proven REST and hypermedia patterns, you shouldn&rsquo;t need documentation. While this is true, and I agree with 100%, it ignores the vital process of getting the average person up to speed--simply stating that what many of us are actively doing, and what we currently know is a bug. I work with any folks who barely know what an API is, or what JSON is, yet have a lot of influence and control over whether some very important APIs exist, or not! I know that these API experts are speaking to the correct path that we should be taking, yet there is very little consideration to understanding where most folks are on the path, and how many forks there are in the road, before we get to where we need to be. To help those understand the path, think of the numerous APIs in the past with no documentation, then all of a sudden static API documentation was the norm, and now in 2014, interactive documentation has become commonplace. Alongside this journey the debate around REST, and recently hypermedia has been going on, with only recently getting to a place where healthy patterns are being used across many APIs, not just a handful of demos. Understanding this will help you see the path that we are on. A path that we can only move down at a certain speed, because it takes careful education and planning to move not just developers, but business leaders down. Maybe eventually the path will be a highway, and at some point a freeway that we can get more people down, but for now it takes a lot of planning to shepherding to move everyone along. I fully respect those that wish to exclusively remain in...[<a href="/2014/05/07/api-docs-are-an-error-bridging-where-we-should-be-and-where-we-are-currently/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/kin-lane/kin-lane-api-days-berlin-respect-privacy.jpg" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/05/06/remembering-why-this-whole-api-thing-is-working-apidays-berlin/">Remembering Why This Whole API Thing Is Working - APIDays Berlin</a></h3>
			<p><em>06 May 2014</em></p>
			<p>This is my speaker notes from my talk this week at APIDays Global in Berlin. You can find my slide deck in my talks repository on Github, and find more photos from the event on Flickr. We live in a very exciting time, one where the resources we need to build meaningful websites and applications, that have the opportunity to impact how we do business, and potentially make change in how the world around us, is rapidly expanding. Once upon a time, many of these digital resources took millions of dollars of investment to deliver, if they were available at all. Now, with the introduction of web APIs, many valuable resources are available in a self-service, pay as you go manner, allowing anyone to integrate these valuable resources their own business or personal worlds. History of APIs Over the last 14 years of the Internet, companies have been using a new approach to APIs, built on the same technology that drives the web&mdash;HTTP. Web APIs are not a new, proprietary way of building applications on the Internet, but a way of delivering the vital resources web and mobile applications need, side by side with the same websites that humans consume&mdash;except APIs are raw data, minus the visuals that a human would require, enabling developers to deliver exactly the experience that end users will need. Delivering On Original Visions of Digital Commerce This low cost approach to deliver resources on the web has been pioneered by tech giants like SalesForce in delivering the next generation of customer relationship management, and sales in the clouds. We&rsquo;ve also seen web APIs transform world of ecommerce from tech giants like Amazon, and shift auctions online from eBay. The payments needed to transact in this new world of commerce also emerged via APIs from Paypal, and a newer generation of payment API providers like Stripe. A Social Web The distributed effect of web APIs allowed for the evolution of a...[<a href="/2014/05/06/remembering-why-this-whole-api-thing-is-working-apidays-berlin/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-politics.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2014/05/01/would-you-pay-for-alternate-options-for-an-api-terms-of-service/">Would You Pay For Alternate Options For An API Terms Of Service?</a></h3>
			<p><em>01 May 2014</em></p>
			<p>
Terms of service guide every aspect of how we provide and consume an APIs&nbsp;that drive&nbsp;our web and mobile applications. As an excercise, lets imagine a future where API terms of service (TOS) are machine readable, and always in alignment with the multiple partner tiers, and the service composition of an API platform.
Right now, the options available to API consumers is organized into service packages, allowing us multiple tiers of access, based upon usage + cost, when registering for and consuming API resources. Imagine if during this process the API TOS were integrated into the registration and account management workflows. Imagine you could fully understand each portion of the API TOS, and be provided with options, instead of a single, rigid level of service.
Currently options for API access are throttled across TOS, privacy policy, branding, service level agreements, pricing, and service composition and partner access tiers. I want to explore the possibility that these building blocks could be machine readable, allowing for variances on each aspect of API operations. This scenario would allow for API consumers to prioritize which aspects of operations are most important to them, allowing them to pay more for premium access to API services.
I&rsquo;m just working through my thoughts on the politics of APIs, expanding on ideas of machine readable terms of service (TOS) introduce to me by Tyler Singletary (@harmophone)&nbsp;of @KloutAPI, and also a tweet from Antony Falco (@antonyfalco)&nbsp;of Orchestrate.io&nbsp;about the potential to allow for variances of TOS.
I would love to hear your thoughts on this subject. Am I off in left field, or is this something we should play with more?
[<a href="/2014/05/01/would-you-pay-for-alternate-options-for-an-api-terms-of-service/">Read More</a>]</p>
			<p><hr /></p>
	  

		<!-- Pagination links -->
		<table width="100%">
			<tr>
				<td align="left" width="33%">
				  
				    <a href="/blog/page24" class="previous">
				      &#8592; Previous
				    </a>
				  
			</td>
			<td align="center" width="33%">
			  <span class="page_number ">
			    Page: 25 of 37
			  </span>
			</td>
			<td align="right" width="33%">
		  
		    <a href="/blog/page26" class="next">Next &#8594;</a>
		  
			</tr>
			</tr>
		</table>

  </div>
</section>

              <footer>
	<hr>
	<div class="features">
		<article>
			<div class="content">
				<p align="center"><a href="https://www.postman.com" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/partners/postman-logo.png" width="75%" style="padding: 15px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
		<article>
			<div class="content">
				<p align="center"><a href="https://github.com/postmanlabs/newman" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/postman/newman-logo.png" width="75%" style="padding: 15px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
	</div>
	<hr>
	<p align="center">
		relevant work:
		<a href="http://apievangelist.com">apievangelist.com</a> |
		<a href="http://adopta.agency">adopta.agency</a>
	</p>
</footer>


            </div>
          </div>

          <div id="sidebar">
            <div class="inner">

              <nav id="menu">
  <header class="major">
    <h2>Menu</h2>
  </header>
  <ul>
    <li><a href="/">Home</a></li>
    <li><a href="/blog/">Blog</a></li>
  </ul>
</nav>

              <section>
	<div class="mini-posts">
		<header>
			<h2 style="text-align: center;"><i>API Evangelist Sponsors</i></h2>
		</header>
		<article>
			<div class="content">
				<p align="center"><a href="https://www.postman.com" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/partners/postman-logo.png" width="75%" style="padding: 5px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
		<article>
			<div class="content">
				<p align="center"><a href="https://tyk.io/" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/tyk/tyk-logo.png" width="75%" style="padding: 5px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
		<article>
			<div class="content">
				<p align="center"><a href="https://www.openapis.org/" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/specifications/openapi.png" width="75%" style="padding: 5px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
		<article>
			<div class="content">
				<p align="center"><a href="https://www.asyncapi.com/" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/asyncapi/asyncapi-horiozontal.png" width="75%" style="padding: 5px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
		<article>
			<div class="content">
				<p align="center"><a href="https://json-schema.org/" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/specifications/json-schema.png" width="75%" style="padding: 5px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
		<article>
			<div class="content">
				<p align="center"><a href="https://github.com/postmanlabs/newman" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/postman/newman-logo.png" width="75%" style="padding: 5px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
	</div>
</section>


            </div>
          </div>

      </div>

<script src="/assets/js/skel.min.js"></script>
<script src="/assets/js/util.js"></script>
<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
<script src="/assets/js/main.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-1119465-51"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-1119465-51');
</script>


</body>
</html>
