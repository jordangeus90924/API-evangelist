<!DOCTYPE html>
<html xmlns="https://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
  <html>
  <title>API Evangelist </title>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
  <!--[if lte IE 8]><script src="/assets/js/ie/html5shiv.js"></script><![endif]-->
  <link rel="stylesheet" href="/assets/css/main.css" />
  <link rel="stylesheet" href="/assets/css/bootstrap.min.css" />
  <!--[if lte IE 9]><link rel="stylesheet" href="/assets/css/ie9.css" /><![endif]-->
  <!--[if lte IE 8]><link rel="stylesheet" href="/assets/css/ie8.css" /><![endif]-->

  <!-- Icons -->
  <link rel="shortcut icon" type="image/x-icon" href="https://apievangelist.com/favicon.ico">
	<link rel="icon" type="image/x-icon" href="https://apievangelist.com/favicon.ico">

  <link rel="alternate" type="application/rss+xml" title="API Evangelist Blog - RSS 2.0" href="https://apievangelist.com/blog.xml" />
  <link rel="alternate" type="application/atom+xml" title="API Evangelist Blog - Atom" href="https://apievangelist.com/atom.xml">

  <!-- JQuery -->
  <script src="/js/jquery-latest.min.js" type="text/javascript" charset="utf-8"></script>
  <script src="/js/bootstrap.min.js" type="text/javascript" charset="utf-8"></script>
  <script src="/js/utility.js" type="text/javascript" charset="utf-8"></script>

  <!-- Github.js - http://github.com/michael/github -->
  <script src="/js/github.js" type="text/javascript" charset="utf-8"></script>

  <!-- Cookies.js - http://github.com/ScottHamper/Cookies -->
  <script src="/js/cookies.js"></script>

  <!-- D3.js http://github.com/d3/d3 -->
  <script src="/js/d3.v3.min.js"></script>

  <!-- js-yaml - http://github.com/nodeca/js-yaml -->
  <script src="/js/js-yaml.min.js"></script>

  <script src="/js/subway-map-1.js" type="text/javascript"></script>

  <style type="text/css">

    .gist {width:100% !important;}
    .gist-file
    .gist-data {max-height: 500px;}

    /* The main DIV for the map */
    .subway-map
    {
        margin: 0;
        width: 110px;
        height: 5000px;
        background-color: white;
    }

    /* Text labels */
    .text
    {
        text-decoration: none;
        color: black;
    }

    #legend
    {
    	border: 1px solid #000;
        float: left;
        width: 250px;
        height:400px;
    }

    #legend div
    {
        height: 25px;
    }

    #legend span
    {
        margin: 5px 5px 5px 0;
    }
    .subway-map span
    {
        margin: 5px 5px 5px 0;
    }
    
    .container {
        position: relative;
        width: 100%;
        height: 0;
        padding-bottom: 56.25%;
    }
    .video {
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
    }    

    </style>

    <meta property="og:url" content="">
    <meta property="og:type" content="website">
    <meta property="og:title" content="API Evangelist">
    <meta property="og:site_name" content="API Evangelist">
    <meta property="og:description" content="A network of research sites dedicated to the technology, business, and politics of APIs.">
    <meta property="og:image" content="http://s3.amazonaws.com/kinlane-productions/api-evangelist/t-shirts/KL_InApiWeTrust-1000.png">

    <meta name="twitter:url" content="">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="API Evangelist">
    <meta name="twitter:site" content="API Evangelist">
    <meta name="twitter:description" content="A network of research sites dedicated to the technology, business, and politics of APIs.">
    
      <meta name="twitter:creator" content="@apievangelist">
    
    <meta property="twitter:image" content="http://s3.amazonaws.com/kinlane-productions/api-evangelist/t-shirts/KL_InApiWeTrust-1000.png">


</head>

  <body>

			<div id="wrapper">
					<div id="main">
						<div class="inner">

              <header id="header">
	<a href="http://apievangelist.com" class="logo"><img src="https://kinlane-productions2.s3.amazonaws.com/api-evangelist/api-evangelist-logo-400.png" width="75%" /></a>
	<ul class="icons">
		<li><a href="https://twitter.com/apievangelist" class="icon fa-twitter"><span class="label">Twitter</span></a></li>
		<li><a href="https://github.com/api-evangelist" class="icon fa-github"><span class="label">Github</span></a></li>
		<li><a href="https://www.linkedin.com/company/api-evangelist/" class="icon fa-linkedin"><span class="label">LinkedIn</span></a></li>
		<li><a href="http://apievangelist.com/atom.xml" class="icon fa-rss"><span class="label">RSS</span></a></li>
	</ul>
</header>

    	        <section>
	<div class="content">

		<h3>The API Evangelist Blog</h3>

	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2014/01/06/what-is-next-for-the-us-government-api-strategy/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/Building-a-21st-century-platform-to-better-serve-the-american-people-1.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2014/01/06/what-is-next-for-the-us-government-api-strategy/">What Is Next For The US Government API Strategy</a></h3>
			<p><em>06 Jan 2014</em></p>
			<p>I was asked to provides some thoughts on what is next for the US Government API strategy. I've been thinking about it during my work and travels over the last couple months, and I keep coming back to one thought:&nbsp;Strengthen What We Have! I wish I had some new technology or platform for the next wave of government APIs that would ensure success with APIs in Washington, but in reality we need to do what we've been doing, but do it at scale, and get organized and collaborative about how we do it. Release More Data Sets There are thousands of data sets available via Data.gov, across 176 agencies and numerous categories. We need more. When any content or data is published via a government website, that data needs to also made available via agencies data repositories and Data.gov. Agencies need to understand that releasing open data sets it not something you do every once in a while to meet a mandate or deadline--it is something you do always, forever. Refine Existing Data Sets There is a lot of data available currently. However much of it is in various formats, inconsistent data models and isn't always immediately available for use in spreadsheets, applications, visualizations or analysis. There is a great deal of work to be done in cleaning, normalizing and refining of existing data, as well as deploying APIs around open data that would increase adoption and the chances it will be put to use. Refine Existing APIs Like open data, there are many existing APIs across the federal government, and these APis could use a lot of work to make them more usable by developers. With a little elbow grease, existing APIs could be standardized by generating common API definitions like Swagger, API blueprint and RAML, which would help quantify all APIs, but also generate interactive documentation, code samples and provide valuable discovery tools for helping understand where interfaces are and what they offer....[<a href="/2014/01/06/what-is-next-for-the-us-government-api-strategy/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2014/01/06/state-of-apis-in-journalism-the-guardian/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/guardian-open-platform.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2014/01/06/state-of-apis-in-journalism-the-guardian/">State of APIs In Journalism: The Guardian</a></h3>
			<p><em>06 Jan 2014</em></p>
			<p>Major newspapers having APIs is nothing new. We've heard stories out of the Guardian, New York Times and USA Today having APIs, but after several years where are these API initiatives headed? What is next? Is there innovation going on in the area journalism when it comes to APIs? This dive into the world of journalism will take some time, but I will start with what I consider to be the leader, The Guardian Open Platform. The UK paper has all the essential building blocks I would want in an API provider, starting with a clean overview and getting started pages to get developers and data journalists up to speed. The Guardian Open Platform revolves around two API resource, the Content API and Politics API and a vast data store of spreadsheets and other data sets that the Guardian has gathered throughout news cycles. There is an API Explorer which allows you to quickly get your hands dirty with the Guardian APIs, which is essential. There is also a variety of code libraries including Java, Scala, Ruby and ColdFusion flavors, as well as an App Gallery showcasing what has been built on the Guardian APIs. The Guardian Open Platform is supported by an active blog, forum and Twitter account, providing the necessary building blocks to build community around the API. There appears to be some unique gems under the surface with the Guardian Wordpress plugins and their MicroApp Framework looks like it could be interesting, but I just don't see a lot of information available on it. The Guardian Github account is pretty active, but most of it is around the Guardian front-end, not for any innovation that you'd expect around open data and APIs. On the surface, the Guardian Open Platform appears to have everything you need for a successful API platform, but I just don't see anything that stands out and screams "innovation in journalism using APIs". With that said, I have to...[<a href="/2014/01/06/state-of-apis-in-journalism-the-guardian/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2014/01/06/creating-my-own-screenshot-api/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/api-evangelist-screenshot-2.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2014/01/06/creating-my-own-screenshot-api/">Creating My Own Screenshot API</a></h3>
			<p><em>06 Jan 2014</em></p>
			<p>
I use screenshots across the API Evangelist network. I take screenshots of stories I curated, companies I track on and API developer areas I'm monitoring. Historically I've used a variety of screenshot APIs, to generate the 1000's of screenshots I need to make my network function.
This last week I was running through my network, and noticed the screenshot API had stopped working. It isn't a critical piece of infrastructure so I've used free services and don't really feel the need to monitor in real-time, I just respond when I stop seeing screenshots on the news listing page.
This is the 3rd or 4th time this has happened, and when I started looking for a new screenshot API I noticed the majority of them now charge, and was in a range I just didn't feel I couldn't afford being a one man show. I knew in the back of my mind that I could develop my own screenshot API solution.
After test driving several image libraries I settled in with PhantomJS, which allows me to load and manipulate web pages in an object, and then take a screenshot of the web page in that state. I quickly wrapped in a web API using the Slim Framework in PHP.
Once I had the API deployed I wrapped with my 3Scale API management infrastructure, which requires an API key before you can use any of my APIs. Next I updated my company, API and news screenshot tool to use my new screenshot API.
After I get some free time I will clean up the code and publish via Github, so others can deploy their own screenshot API and take the same path I chose.
[<a href="/2014/01/06/creating-my-own-screenshot-api/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/12/20/the-holy-grail-of-apis/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/bw-irs-logo.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/12/20/the-holy-grail-of-apis/">The Holy Grail of APIs</a></h3>
			<p><em>20 Dec 2013</em></p>
			<p>I look at a lot of APIs, I work hard to brainstorm ideas for potential new APIs, and I can't think of a more important API to not just the API economy, but to the overall economy, than an IRS API that would give citizens access to their income and tax history. We know the APIs exists, since the same resources are made available via the IRS Modernized e-File system to tax professionals. I'm not talking about an API that gives access to every detail of my tax history, but the data I've entered into common forms like W2, 1099, and 1042. This IRS API would provide simple REST API access to these values, along with an oAuth framework allowing any approved application developer to access all or portions of our most relevant income and tax data. With oAuth being the access layer to all of this, it would give us, the citizen control over who has access to our history, and how applications can use it. An IRS API would be used to streamline numerous processes like home loans, student financial aid and other transactions actions we take in our everyday lives. These transactions occur over and over each year, and require manual entry, manual validation and other often cumbersome interactions. The introduction of an IRS API with oAuth, would also do amazing things for basic digital literacy around oAuth, and who is accessing to our vital information. This type of literacy around APIs, oAuth, and data access, is critical to not just a healthy API economy, but is quickly blending with the regular economy. I'm not naive regarding the politics of such a move, which would uncover huge amounts of corruption, false statements, potentially disrupt existing jobs that are dedicated to these bureaucratic functions, and introduce a new wave of security concerns. However I think the benefits will outweigh the negatives and this represents the next generation of financial literacy. It is up...[<a href="/2013/12/20/the-holy-grail-of-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/12/19/every-form-should-be-an-api/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/example-form.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/12/19/every-form-should-be-an-api/">Every Form Should Be An API</a></h3>
			<p><em>19 Dec 2013</em></p>
			<p>
I'm working on an API design for the free application for federal student aid form, also known as FAFSA, over the last couple weeks. I took the form which had over 150 separate fields, and turned into a basic create, read, update and delete (CRUD) API. I even added an endpoint that allows you to query and get a list of the fields.
The project is a proof of concept to show the Department of Education what is possible around a FAFSA API. I'm not sure if the API will ever be deployed or adopted by the Department of Education or if by other 3rd party providers, establishing a sort of federated FAFSA API network. My goal is to just generate the API definition with supporting server and client side tooling, to show what is possible.
As I assess my work over the last couple weeks on FAFSA, I can't help but think how this should be standard practice for all forms. If you do a simple search at google for "forms", you get IRS forms, immigration, legal, voter registration and yes the FAFSA forms. It is clear that forms still dominate our lives--print and PDF.
I'm thinking that simple, open designs and tooling around forms would help us continue evolve the concept of the "form" beyond the just the PDF. Sure the PDF still has a place, and some tooling can work with consuming and publishing as PDF, but APIs could help us innovate around what is a form, how users enter their data into them, and take advantage of newer technologies like tablets.
In my opinion, every form should be an API. If you'd like help developing a new form as an API or evolving an older print or PDF form as an API, feel free to reach out.
[<a href="/2013/12/19/every-form-should-be-an-api/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/12/19/an-api-is-research-and-development-for-your-business-model/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/pop-up-archive-logo.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/12/19/an-api-is-research-and-development-for-your-business-model/">An API Is Research And Development For Your Business Model</a></h3>
			<p><em>19 Dec 2013</em></p>
			<p>I spend a lot of time talking to folks on the phone, Skype, in Google Hangouts and in person about their API business models. Not everyone I talk with is willing to share their story public, so I'm also happy when I meet folks who are as open and transparent about figuring all of this out as I am. This morning I spoke with Anne and Bailey over at the Pop Up Archive about their upcoming API, and potential business model(s) for their API when ready. We talked about their immediate API release and then brainstormed about how to get the word out, how people might use the API, and possible approaches monetization. The Pop Up Archive is an audio transcription service, allowing you to publish audio files and receive back full text transcriptions of the audio. It is a pretty straightforward service, and they will be releasing an API so others can use the audio transcription service in their own apps, as well as access the wealth of audio resources they are amassing in their archive. Even with the straightforward nature of this upcoming API resource, the question of who will use this service, and what they are willing to pay comes up--something we spent the good part of an hour discussing. We should have recorded, then we'd have the transcription, but since we didn't here are some of my thoughts from today's discussion. Your API Is Tech and Business Research &amp; Development The tech space moves fast, and success is all about getting your API up and running, allow for developers to use, even if it is just within a trusted group, then iterate and evolve as you gain more knowledge about what people want and how they will be using it. You can speculate from now until the cows come home about how people will use, but until you have it up and running you won't know for sure. When you approach...[<a href="/2013/12/19/an-api-is-research-and-development-for-your-business-model/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/12/16/charging-for-higher-levels-of-access-to-government-data-and-apis/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/hawaii-gov-logo.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/12/16/charging-for-higher-levels-of-access-to-government-data-and-apis/">Charging For Higher Levels Of Access To Government Data and APIs</a></h3>
			<p><em>16 Dec 2013</em></p>
			<p>The question of whether government should charge for APIs and other digital services came up again this week during a Google Hangout I did with Luke Fretwell(@lukefretwell) of @GovFresh. I began exploring this concpet last year in my post, Should the Government Subsidize and Profit from Data Market, after talking with several city government open data folks. Luke had pointed me to a page on the Hawaii.gov website that described their subscriber services: A subscriber account offers the benefit of monthly invoicing and payment and provides convenience to users who conduct large volumes of online transactions through our website. In some cases, a subscriber account is also required to access a specific online service. Many people I talk to in the open data space have reacted negatively when I propose the idea of government charging for access to services, but as reflected in Hawaiis approach, this is just for higher volume and heavy commercial use cases. It costs money to gather and organize government data, design, deploy and manage APIs. I feel strong that many of the resources coming out of government should be free and open for access, but in the cases where it is incurring huge costs for government to provide, it might make sense to pass costs off to consumers. Think of any other physical government assets like city, county, state, or national parks. These are open for anyone to access, and many are even free, but if you want to use them for commercial purposes, you have to pay. Virtual resources should be seen in a similar light. However, this could easily evolve into a negative analogy, because park access fees sometimes can seem ridiculous, and I want to incentivize consumption of government open data and APIs through as wide of access as possible--not scare people away. My goal here is to not take a for or against stance, but to stimulate conversation around the topic and see where it makes...[<a href="/2013/12/16/charging-for-higher-levels-of-access-to-government-data-and-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/12/16/api-terms-of-service-wizard-from-swedish-api-license/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/swedish-api-license-2.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/12/16/api-terms-of-service-wizard-from-swedish-api-license/">API Terms of Service Wizard From Swedish API License</a></h3>
			<p><em>16 Dec 2013</em></p>
			<p>The terms of service for APIs is the single most important building block of an API strategy, one that dictates how developers can access and put API resources to use and sets the tone for an entire API ecosystem. Your API can be publicly available, but the terms of service and licensing will determine whether it is truly open. Even with the importance of this area of API operations, there aren't a lot of open resources to help guide you through crafting your API licensing and terms of service properly--until now. A group of swedish entrepreneurs Daniel Rudmark of Viktoria Swedish ICT, Elias Arnestrand of Samtrafiken, Anna Mirsch lawyer at Mannheimer Swartling,&nbsp;and Andreas Krohn at Dopter have come together to create a new project to address this need, called Swedish API License. The goals with the project was to create an API license that... Is open and free for anyone to use, encouraging maximal adoption Is flexible enough to fit many different use cases Respects both the publisher and the consumer of the API. Easy to understand for people without a law degree The Swedish API license covers the following areas: License Intellectual Property Rights Processing of Personal Data Technical Requirements and Limitations Other Requirements of Use Liability Changes Terms and Conditions The Swedish API license even has an API license wizard that walks you through 13 steps of constructing and customizing your license, keeping within the legal and commercial considerations your company has around your API. While the Swedish API License is published in Sweden, the site and licenses are in english and all the work is licensed under CC-BY license. This opens up a whole lot of opportunity to use the model around the globe. I will be spending more time getting familiar with the approach to developing terms of service by the Swedish API License, and consider it side by side with existing efforts like Terms of Service Didn't Read and TOS...[<a href="/2013/12/16/api-terms-of-service-wizard-from-swedish-api-license/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/12/12/an-api-evangelist-review-of-your-api/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/technology-business-politics-apis.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/12/12/an-api-evangelist-review-of-your-api/">An API Evangelist Review Of Your API</a></h3>
			<p><em>12 Dec 2013</em></p>
			<p>Over the last 3 years I have looked at all the APIs available in ProgrammableWeb API directory, with about 2500 of which I monitor regularly. Throughout this process I've evolved an eye for what building blocks go into a successful API program. When I review an existing API area or program, public or private, I spend as little or as much time as I need to look at an API initiative through the following 20 lenses: Overview&nbsp;- The general look, feel and initial impression of an API at the high level. Endpoints&nbsp;- Review of API endpoints, looking at the detail. On-boarding&nbsp;- How easy is it to get up and going? Where is the friction? Documentation&nbsp;- General API documentation review and critique. Authentication&nbsp;- What is involved with authentication and security. Code&nbsp;- A look at all available code libraries, SDKs, apps and language or platform availability. Mobile&nbsp;- Is there a mobile fit and how does an API address this world. Support&nbsp;- What do direct and indirect support practices look like and what are activity levels. Communications&nbsp;- How are communications handled, and is it done in a transparent way. Change Practices&nbsp;- How are updates, changes, and communication around the roadmap handled. Business Model&nbsp;- What is the business model of an API, how does it make ends meet. Resources&nbsp;- What resources are provided from how-to, case studies to videos and workshops. Research &amp; Development&nbsp;- Does an API reflect a research &amp; development group. Legal Department&nbsp;- Covering the legal areas of terms of use, privacy and branding. Embeddable&nbsp;- How portable and embeddable are aspects of the API? Can it be distributed easily? Environment&nbsp;- A look at the underlying environment of the API, sandboxing, testing, monitoring, etc. Developers&nbsp;- What does this look like for a developer? What tools do we get to ensure success? Consistency&nbsp;- How consistent are API endpoints and the support resources, and the overall operations. Openness&nbsp;- If the API is public, to what degree of open are API...[<a href="/2013/12/12/an-api-evangelist-review-of-your-api/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/12/11/understanding-the-french-api-economy-at-api-days/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/api-days-logo.jpeg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/12/11/understanding-the-french-api-economy-at-api-days/">Understanding the French API Economy At API Days</a></h3>
			<p><em>11 Dec 2013</em></p>
			<p>
I got back from Paris, France this Sunday, after Audrey (@audreywatters) and I spoke at API Days last Thursday. This was the second annual API event, which kicked off last year around the same time. I've been a supporter of the event since Mehdi (@medjawii) of Webshell told me about the idea.
Last years event was small, and over half the audience seemed to be imported API specialists such as myself, where this year it was clear--this was a french conference. A passionate community of API enthusiasts has grown over the last year, producing an impressive line-up of speakers and attendees.
I learned a lot about the space ranging from containers and oAuth to revelations about how we can learn from history and make the right decisions as we move forward in a world of APIs.
I encountered some pretty smart folks who knew a lot about technology, APIs and open data, that I hadn't encountered before in the online API world. This shows me the value of this type of event, and the importance of bringing folks together from around the world and share API stories.
Thanks Webshell and FaberNovel for making it happen, and bringing Audrey and I out to be part of such an important event.
[<a href="/2013/12/11/understanding-the-french-api-economy-at-api-days/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/12/11/my-free-application-for-federal-student-aid-fafsa-api-project/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/fafsa-form.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/12/11/my-free-application-for-federal-student-aid-fafsa-api-project/">My Free Application for Federal Student Aid (FAFSA) API Project</a></h3>
			<p><em>11 Dec 2013</em></p>
			<p>I was able to give my FAFSA API project a little more attention in preparation for some data jams later this week. While there is still a lot of work to happen, I feel pretty good about what I have been able to get done. I'd love to reflect on the API design, get some feedback before I move it forward too much more. 75% Github As with all of my projects, the FAFSA API is mostly deployed via Github, except for the actual API. The project was born as a Github repository and expanded as a Github Page. Using Github I'm able to manage the project, while also making it open by default so anyone else can fork and put the work to use. Designing The API Once the repository was created, I got to work on an API design. For this project I started with a Swagger specification, and developed a basic CRUD interface and data model that was derived from the list of 100+ fields from the FAFSA form. Now I had a basic API design I could work with as guide for developing my API, generating my documentation and code samples. It isn't perfect, but it is a good start. Deploying The API Next with API design in hand, I got to work deploying an actual API that would allow developers to build applications that could create, update and manage FAFSA application. I selected the Slim framework and PHP to deploy the first iteration of the FAFSA API. This allowed me to rapidly produce server side code in a common programming language. I will be deploying Python, Ruby and Node.js versions in the near future. Interactive Documentation The first step in quantifying an API interface and make it something you can see and understand, is by developing documentation. In 2013 the common way to do this is with interactive documentation, which you can generate directly from the previously generated Swagger specification....[<a href="/2013/12/11/my-free-application-for-federal-student-aid-fafsa-api-project/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/12/11/it039s-between-copyright-and-fair-use-in-oracle-vs-google-api-case/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/oraclevgoogle.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/12/11/it039s-between-copyright-and-fair-use-in-oracle-vs-google-api-case/">It&#039;s Between Copyright And Fair Use In Oracle vs Google API Case</a></h3>
			<p><em>11 Dec 2013</em></p>
			<p>I'm just getting time to read through the news coming out of the United States Court of Appeals for the Federal Circuit, and the next phase of the Oracle v. Google case, which kicked off December 4th in California courts. A panel of three judges presided over the Oracle v. Google Android/Java copyright appeal hearing, and after reading several accounts of the hearing, all three judges seem to all agree that the Java API should protected under copyright, but whether Google's use of portions of the Java API is fair use, is still unclear--potentially overturning Judge William Alsup earlier ruling. I strongly feel that APIs are the "fair use tip" of software that could potentially be covered by copyright and patents. As demonstrated by my support of the Electronic Frontier Foundation amicus brief, I think API definitions remaining fair use is critical to interoperability and and not just a healthy API economy, but the the larger economy. The hearing last week is just the beginning, the legal battle is likely to go on for a while, potentially making its way to the Supreme Court and / or possibly heading back to a lower court. Even if the earlier Oracle vs. Google ruling, that APIs aren't copyrightable is upheld, I anticipate we will see many, many legal battles on this front in coming years. As we increase our vocabulary for describing and designing API interfaces, with approaches such as Swagger, RAML and API Blueprint, attempts to protect these definitions by copyright will increase. While I will continue to support efforts to defend APIs in their entirety as being protected under fair use and free from copyright, I will be focusing my efforts on encouraging healthy API design, sharing and collaboration through placement of API definitions into the API Commons. While Oracle vs. Google remains a critical case that will have a major impact on the world of APIs, whichever way the case goes, it won't change...[<a href="/2013/12/11/it039s-between-copyright-and-fair-use-in-oracle-vs-google-api-case/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/12/01/adding-the-opened-api-to-the-api-commons/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/open-ed-logo-2.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/12/01/adding-the-opened-api-to-the-api-commons/">Adding The OpenEd API To The API Commons</a></h3>
			<p><em>01 Dec 2013</em></p>
			<p>
We have added the OpenEd API to the API Commons. OpenEd provides open educational resources like courses, videos and games for teachers to use in their classes.
Using the API, developers can read and write resources to the platform, which currently houses 250K openly licensed educational resources.
In addition to making all of the content openly licensed, the OpenEd.io site is also open sourced on Github. Making the OpenEd API definition a perfect candidate for the API commons.
The OpenEd team designed their API using Apiary.io, defining it using API Blueprint, a web API language that allows for the description of APIs using markdown.
OpenEd is a great open educational content API blueprint to follow, and we are honored to have it in the commons!
[<a href="/2013/12/01/adding-the-opened-api-to-the-api-commons/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/11/30/pr-people-for-apis/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/bw-microphone.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/11/30/pr-people-for-apis/">PR People For APIs</a></h3>
			<p><em>30 Nov 2013</em></p>
			<p>
I'm getting more PR folks reaching out to me trying to get me to review their client's API program. I'm happy to add these to my list and make time each week to review them alongside the other new APIs I find each week.
I'm not willing to jump on the phone and hear a pitch about the API. You should send me a short succinct email, or even better a Tweet with a URL and I'm happy to add to my list and make time when i can.
I'm not the usual blogger who just wants to regurgitate what you told me in a briefing or in a press release. Your API and its supporting area should do the talking. I should be able to click on a single link, understand what you do, and be able to find what I need within 5 minutes or less.  If I can't? Well I will let you know.
Think of me as a developer. I will be reviewing your product from that perspective.
So if you are doing PR for an API company, make sure and read my blog, engage me on Twitter and save the briefings and emails for other bloggers. I'm more concerned with the value your client is bringing to the table, and their approach to delivering a self-service API platform.
No briefing required. :-)
[<a href="/2013/11/30/pr-people-for-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/11/30/i-will-be-at-api-days-in-paris-this-week-will-you-be-there/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/api-days-fonz.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/11/30/i-will-be-at-api-days-in-paris-this-week-will-you-be-there/">I Will Be At API Days in Paris This Week, Will You Be There?</a></h3>
			<p><em>30 Nov 2013</em></p>
			<p>
I'm pretty excited about heading to Paris this week to speak at API Days.  The is the 2nd edition of the original french edition of API Days, and they have organized over 60 talks across two days: December 4th and 5th.
I'm particularly excited about sitting in on these talks:

Mike Admundsen, LAYER7 - Telephones, Mechanical Turks, and the Future of APIs
Joffrey Fuhrer, Docker.io - Shipping code in a service oriented world
St&eacute;phane Legouffe, CTO of Paris - APIs and Cities
Renaud Visage CTO, Eventbrite - From a Monolithic to a Distributed Architecture 
Steve Klabnik - JSON API: convention driven API design 
Romain Huet, Twitter - Twitter APIs: connecting to the pulse of the planet
Guillaume Balas, 3SCALE - Which Business Model to Win in the API Economy?

I will be talking about API Commons, and Bringing API Design Out Of The Shadows And Into The Commons--helping share the vision Steve Willmott and I have behind the new project that 3Scale and API Evangelist are partnering on.
I'm looking forward to hanging out with all these API freaks, and of course experiencing the amazing city of Paris again.
OMG! I almost forgot. My girlfirend @AudreyWatter is speaking too!! Education APIs: The Good, The Bad, and The Ugly!! Its gonna be wild!
[<a href="/2013/11/30/i-will-be-at-api-days-in-paris-this-week-will-you-be-there/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/11/29/government-services-schemas-with-jsonld/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/bw-government.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/11/29/government-services-schemas-with-jsonld/">Government Services Schemas With JSON-LD</a></h3>
			<p><em>29 Nov 2013</em></p>
			<p>This fall while working in Washington D.C. I was introduced to the concept ofrepresenting government services with JSON-LD. Using the&nbsp;civic services schema.org&nbsp;proposal you can represent common government services that target indvidiuals and businesses, providing a standard that developers can use when presenting government services in websites and mobile applications. I was working on a project to help publish services from the Department of Veterans Affairs, and I wanted to enable people who work at the VA, as well as other agencies to be able to generate and manage JSON-LD representations of their services in the easiest way possible. So I thought to myself, what is the number one way for people in government to manage data? Spreadsheets of course! I decided to start with Google Docs, and generate a simple JavaScript tool to take a Google Spreadsheet template that was setup with the required fields for a government services schema. Next I wrote an import script using Tabletop.js that would grab the contents of the Google Spreadsheet template and using JavaScript to generate the JSON-LD. This thanksgiving holiday I decided to add one more tool to my work with government services and JSON-LD, and build a form that anyone could fill out and generate their own government services JSON-LD. The result is a Bootstrap, JQuery form that you can fill out, then hit publish JSON and using JavaScript it generates the JSON-LD representation for you. I started a project to organize my work around government services and published the Google Spreadsheet to JSON-LD and the form to JSON-LD generators. Next I will be adding the ability to save generated files to the Github master repository, making the whole thing a formable, government JSON-LD generator and storage repo. I'm enjoying developing forms that generate JSON lately. I built an API Commons manifest generator the other night, and using the same momentum I developed the government services JSON-LD generator. I couldn't think of a more worthy project...[<a href="/2013/11/29/government-services-schemas-with-jsonld/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/11/25/early-thoughts-on-robots-json/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/bw-robot-json.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/11/25/early-thoughts-on-robots-json/">Early Thoughts on Robots.json</a></h3>
			<p><em>25 Nov 2013</em></p>
			<p>My friend @harmophone, Director of Platform for the Klout API, wrote up a great piece before #APIStrat, called A Short Proposal for Robots.json. This is a topic that I've been meaning to make time to discuss, but only now finding time. I love exchanging ideas with @harmophone, because we tend to disagree on some important API related topics, however he is extremely knowledgeable on the space, and like me he possesses some strong opinions and is very open to lively discussion via blogs, twitter and on stage at events. On the topics of web scraping, API rate limits, and API access that exist in the realm of what I call the politics of APIs, @harmophone and I couldn't disagree more on what is acceptable use in the API economy. What is interesting though, within this disagreement we find affinity in the topic of the robots.json. @harmophone&nbsp;has a very succinct description of what a robots.json file would be: A Robots.json file, or something like it, would contain all desired rules for retention, caching, access control, license rights, chain of custody, business models and other use cases allowed and encouraged for developers. I think a machine readable file that provides access to all aspects of an APIs terms of use is a great idea. Beyond the obvious benefits of publishing a robots.json file for API providers and consumers, I think the practice would help standardize industry best practices for API terms and conditions. In my experience most API providers just emulate what they see in the space and if top players lead on this subject, others will follow. @harmophone and I both agree that there should be a robots.json, however we come at it from two opposing viewpoints. @harmophone is coming at from an API vendor position, and I'm coming at from the stance of an API consumer. @harmophone wants to establish a definition of where the provider stands, setting the "rules of the road" as Twitter...[<a href="/2013/11/25/early-thoughts-on-robots-json/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/11/21/university-of-california-student-senate-submits-bill-stating-student-information-systems-must-have-api/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/associated-student-university-california-logo.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/11/21/university-of-california-student-senate-submits-bill-stating-student-information-systems-must-have-api/">University of California Student Senate Submits Bill Stating Student Information Systems Must Have API</a></h3>
			<p><em>21 Nov 2013</em></p>
			<p>On November 6th, 2013 the Associated Students, University of California(ASUC) Senate submitted SB 48: A Bill in Support of Student Information Systems Application Developers, stating that "open data and API compatibility is a necessary feature in the new Student Information System". UC Berkeley has embarked on a "Student Information System Replacement Project" that is looking to "replace its constellation of aging, unique, disparate home-grown student systems with a modern, nimble and effective vendor-supported system". Systems including financial aid, registration, enrollment, admissions and records are being targeted for replacement. The existing Student Information Systems(SIS) has been in place for over two decades, and facing the same for future systems, the students led organization that represents over 35K students, is taking a stance to ensure that all future systems have APIs. That is some serious forethought and leadership on behalf on the ASUC Senate! SB 48 puts forth that: an API, or Application Programming Interface, is a foundation put in place on top of a system to securely make specific information and data public to developers for those developers to create third-party extensions and applications pertaining to their specific uses for the data and program API and Integration Architect of UC Berkeley, George Atala(@gmatala) adds: &ldquo;An SIS API would be critical for supporting the many user applications and other campus systems that serve students. These systems change and evolve continuously, and a real time read/write API is necessary to enable this. The API must cover the full range of core functionality in the SIS, and should support appropriate levels of security for private and public data.&rdquo; The bill authored by Sahil A Pandya and Quinn Z Shen nails some of the critical areas around APIs being a vital aspect of university operations, and that much of the SIS overhaul will not happen all at once, when in reality the evolution of all campus systems should happen in smaller, bite-size chunks. APIs would help evolve campus information systems...[<a href="/2013/11/21/university-of-california-student-senate-submits-bill-stating-student-information-systems-must-have-api/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/11/21/generating-the-utility-apis-i-need-for-each-developer-portal/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/bw-united-states.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/11/21/generating-the-utility-apis-i-need-for-each-developer-portal/">Generating The Utility APIs I Need For Each Developer Portal</a></h3>
			<p><em>21 Nov 2013</em></p>
			<p>I'm working on an API for Free Application for Federal Student Aid (FAFSA) form. I'm working my way through a document from Department of Education called the 2013-2014 Application Processing System Specifications for Software Developers. I'm isolating various datasets, and data models, trying to get a feel for all the API resources I will need for the FAFSA API. The specifications provides several tables of data and data models for me to use, including the actual fields for the FAFSA form. One dataset that is provided in the PDF is a list of states. It makes sense that a list of states is included for any developer who is building a federal student aid application. And I have a states API available elsewhere, that I've used in several other applications, so building this API will for the project will be easy. Next I'm thinking..how do I replicate this utility API easily for an external API project like this? One of the architectural considerations for the FAFSA API is to make an API that anyone could fork and easily setup for their own use. That includes the state API resource. This got me thinking about APIs in general. When it comes to APIs, they are ften attached to brands, like the Twilio API or Twitter API. We do not think of single API definitions as ubiquitous, as utilities or as commodities yet. However there are a lot of common API resources like states, IP addresses, counties, cities and many more, that are essential to many web and mobile applications. Sure these datasets are widely available, but you need to actually design and deploy the actual API. How do we make utility APIs like this deployable anywhere? Anytime? I should be able to select from a library of common API definitions and easily fork, then deploy to my AWS EC2, AWS Cloud Formation or OpenShift platform. I shouldn't have to rely on 3rd party services for all...[<a href="/2013/11/21/generating-the-utility-apis-i-need-for-each-developer-portal/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/11/21/free-application-for-federal-student-aid-fafsa-api/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/fafsa-form.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/11/21/free-application-for-federal-student-aid-fafsa-api/">Free Application for Federal Student Aid (FAFSA) API</a></h3>
			<p><em>21 Nov 2013</em></p>
			<p>
I was asked to help put some thought into an API for the Free Application for Federal Student Aid iniative. First, what is FAFSA:
The Free Application for Federal Student Aid (FAFSA) is the form the U.S. Department of Education (ED) requires to determine your Expected Family Contribution (EFC). The government conducts a &ldquo;need analysis&rdquo; based on financial information, such as income, assets, and other family information, which you (and your parents if you are a dependent student) will be asked to provide.
I'm just getting started with this project, and as I do with all my Public / Private Sector work, I created this umbrella site for my Department of Education open data and API work, and created an individual project site just for the Free Application for Federal Student Aid API.
You can participate in the design and development process via the Gitihub repositories, and feel free to ping me @kinlane if you want to get involved. I will post stories here, and on the individual site to chronical its progress, and reference on API Evangelist when applicable.
Next up, understanding what the details of the FAFSA form are, and start considering what some possible architectural designs might work for FAFSA...
[<a href="/2013/11/21/free-application-for-federal-student-aid-fafsa-api/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/11/21/an-api-for-your-github-geojson-stores/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/git-spatial-2.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/11/21/an-api-for-your-github-geojson-stores/">An API For Your Github GeoJSON Stores</a></h3>
			<p><em>21 Nov 2013</em></p>
			<p>
I've been pushing the boundaries of open data and API deployment using Github. I have a project I've been evolving since August called Simple API and its sister implementation api.ongithub.com, which allows you to launch an API by forking common API definitions that are hosted on Github.
I was recently introduced to similar approach to geospatial API deployment using GeoJSON stored on Github called GitSpatial. Using the same approach, GitSpatial lets allows you to oAuth into the API deployment platform using your Github login, then spiders your repositories and let's you sync the repositories that contain GeoJSON.
Then using three URL parameters:

user_name - Your GitHub user name
repo_name - A GitHub repo name
feature_set_name - A file in your repo that contains GeoJSON

GitSpatial allows you to construct a geo spatial API resource URI: http://gitspatial.com/:user_name/:repo_name/:feature_set_name
Pretty cool stuff! I might be a little biased here, but I think this type of API deployment via Github blueprints, plus JSON data stores is going to be big. I've been experimenting with API deployments from Github blueprints via Amazon Cloud Formations and Redhat OpenShift, and it seems like the next evolution in cloud driven API deployment to me.
The best part to this approach is that your data, configurations and core elements are maintained within your world as simple, open formats like JSON--then you get to externally connect, using Github, to premium API services that augment and enhance your existing resources.
Lookout for an increase in the number of Github + API solutions in the coming months...
[<a href="/2013/11/21/an-api-for-your-github-geojson-stores/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/11/20/server-side-api-templates-on-aws-cloud-formation-and-openshift/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/aws-CloudFormation.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/11/20/server-side-api-templates-on-aws-cloud-formation-and-openshift/">Server Side API Templates On AWS Cloud Formation And OpenShift</a></h3>
			<p><em>20 Nov 2013</em></p>
			<p>
I created 11 very simple API designs for the launch of API Commons. We needed some API definitions to show the potential of the commons, so I wanted to design a handful of common API patterns to seed the launch.
For all 11 API designs I started with a Swagger definition, then using PHP and the Slim framework I quickly generated server side code for each API. I generate this code programmatically from the Swagger spec, but I also prefer going through the generated code and giving it a human touch.
This approach isn't just for these 11 API design templates, I'm using it for all my projects right now. I'm designing the API definition, generating and modifying the server side code, publishing Swagger UI documentation, then any client side code libraries I will need.

I'm publishing the API definition and Swagger UI, plus a project overview completely on Github. Currently I'm generating PHP / Slim framework driven code on AWS EC2 instance. I'm will expand this to include server side frameworks in Ruby, Python, Node.JS.
Next I will take each API definition + server-side code in PHP, Ruby, Python and Node.js and running on Amazon EC2 and port to run in AWS Cloud Formation and OpenShift from RedHat--providing an open API blueprint that others can deploy in the cloud.
This will be my basic process for any standard API design I'm evolving for API Commons, APIs I develop internally, as well any API that I design, develop and build for external projects.  As with my stories and open data, I want any API I design to be open and reusable by anyone who is in need of the same API.
[<a href="/2013/11/20/server-side-api-templates-on-aws-cloud-formation-and-openshift/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/11/20/hypermedia-in-the-wild-amazon-appstream-api/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/amazon-appstream-main.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/11/20/hypermedia-in-the-wild-amazon-appstream-api/">Hypermedia In The Wild: Amazon AppStream API</a></h3>
			<p><em>20 Nov 2013</em></p>
			<p>
With the growing number of hypermedia API deployments, hypermedia haters&copy; are going to lose a major argument, that hypermedia is just an academic exercise and will never work in the wild. ;-)
The latest hypermedia API I was told about&nbsp;in the wild(thanks @johnmusser), is from Amazon Web Services with the recent AppStream API--"a flexible, low-latency service that lets you stream resource intensive applications and games from the cloud".
The AWS AppStream API is an API that uses Hypertext Application Language (HAL),  a consistent and easy way to hyperlink between API resources, created by Mike Kelly(@mikekelly85) of Stateless.co. When HAL is used, with each API request, you get a  wealth of links that allow you to programmatically explore the functionality of an API.
For example, you can explore the JSON returned in each response from the application API endpoint, about a specific app you are streaming including using the services, you will find links to determine application status, show information on current session and many more.
Normally with APIs, developers have to explore each API endpoint, and read through documentation to understand the different actions that can be taken against an API. With HAL, API owners can craft links that provide meaningful actions that can be discovered and implemented by developers along the way, teaching them about what is possible with each API call.
Hypermedia goes a long way in extending business rules to developers, not just directing them to what next steps may be taken at each API request, but really save them a lot of homework on how your API business model works, and how to best build an application around an API.
There are other hypermedia APIs in the wild, including the very important Public Media Platform (PMP), but the numbers are still low. I will keep finding quality hypermedia solutions in the wild and sharing them with you as I find.
[<a href="/2013/11/20/hypermedia-in-the-wild-amazon-appstream-api/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/11/20/api-search-endpoint-using-solr/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/apache-solr-logo.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/11/20/api-search-endpoint-using-solr/">API Search Endpoint Using Solr</a></h3>
			<p><em>20 Nov 2013</em></p>
			<p>
I was going through the Free Law Project Court Opinion API today, playing with the API and data, while developing some server and client side tooling.  All the API endpoints are pretty consistence because they used their Django model and the Tastypie framework to generate most of the API.
There is one endpoint that is radically different from the rest of the opinion API: the /search endpoint. The Free Law Project used Apache Solr to generate the /search endpoint results and instead of directly hitting just the database for information it utilized Solr index to do the heavy lifting.
Using Solr opens up a whole world of search by introducing common concepts like AND, OR, NOT, fielded queries, wildcards, fuzzy searches and much more when it comes to searching for court opinions.
While the on-boarding of Solr newbies to an endpoint like this takes some education, and the opinion API /search endpoint docs could use a little more polishing to  make it easier to start using, but the concept of a Solr driven endpoint is still very interesting.
Using Solr like this might not work for all API providers, but for some who are heavily using data stores that include document repositories as well, it might be a good idea.&nbsp;
While I have advocated for using Solr to generate an API before, this is the first time I've seen it bundled alongside another API offering so seamlessly, just to drive the search endoint.  I'll be keeping an eye out for others during my regular monitoring.
[<a href="/2013/11/20/api-search-endpoint-using-solr/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/11/19/the-free-law-projects-launches-court-opinion-api/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/free-law-project.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/11/19/the-free-law-projects-launches-court-opinion-api/">The Free Law Projects Launches Court Opinion API</a></h3>
			<p><em>19 Nov 2013</em></p>
			<p>
The Free Law Project has launched a U.S. court opinions API as part of the Court Listener project, which currently aggregates 2,204,339 court opinions, from 350 jurisdictions.
The Court Listener Opinions API is a well designed, dead simple REST API with 7 endpoints to search opinions, citations across jurisdictions, using Basic Auth to secure the API.
Along with the simple API and docs, the Court Listener provides a blog and forum to support developers, and bulk downloads of all data in addition to the REST API.
The court opinions API implementation is a model to follow for other public sector open data and API projects. The API and supporting developer area is simple and very well done, providing all the essential building blocks needed to grow an ecosystem around the API and data.
The entire API and data is released in the  public domain, and relies on donations to do the work and keep the lights on--something that should be the bar set for all public data projects.
This external, open approach to liberating, aggregating and improving on vital public sector data, is a model we need to replicate across all areas of city, county, state and federal government in all sectors.
[<a href="/2013/11/19/the-free-law-projects-launches-court-opinion-api/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/11/18/tracking-on-data-json-deployment-across-federal-agencies/"><img src="https://s3.amazonaws.com/kinlane-productions2/federal-government/FDA_-_Data.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/11/18/tracking-on-data-json-deployment-across-federal-agencies/">Tracking On Data.json Deployment Across Federal Agencies</a></h3>
			<p><em>18 Nov 2013</em></p>
			<p>
I'm tracking on the evolution of Executive Order 13642 from last May, which was the White House directive to make open and machine readable the new default for government information. The piece that I'm tracking on specifically right now is around the OMB Memorandum M-13-13 Open Data Policy-Managing Information as an Asset, in which one of the items require agencies to publish a data.json file that provides a machine readable inventory of each agencies public data assets.
Much like the tracking I did around the digital strategy, I've stood up a monitoring script that I got from Philip Ashlock's Github, which I will be running daily to track on which agencies have published their data.json in anticipation of the November 30th deadline. A handful of agencies already have their data.json file up, others show a green check, but in reality their HTTP status codes are incorrect, as I've talked about before.
I'll re-run this script nightly and keep an eye on which agencies publish their data.json and highlight what types of data sets they've made available. I think in reality, the challenges faced in taking inventory of open data, getting them published will prevent many agencies from making the deadline. Something that was just made worse by the government shutdown in October.
Even with these challenges, I'm hopeful that agencies will surprise us and publish some amazing stuff.
[<a href="/2013/11/18/tracking-on-data-json-deployment-across-federal-agencies/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/11/18/420-growth-in-dns-api-usage-over-at-dyn/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/dyn-api-request.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/11/18/420-growth-in-dns-api-usage-over-at-dyn/">420% Growth In DNS API Usage Over At Dyn</a></h3>
			<p><em>18 Nov 2013</em></p>
			<p>
The folks over at Dyn who provide traffic, message, remote access and domain services, including a suite of SOAP and REST based APIs, have released some interesting stats on their API usage.
Dyn has 500 managed DNS users and partners using their APIs, growing from 7.3 million monthly API requests in January 2012 to 38.1 million API requests in September 2013, that is a 420% growth over 20 months.
In their data they split out who is using SOAP vs REST APIs, with only 3.3% of their total API requests being SOAP, with almost no growth in same time period, compared to the 420% growth in REST usage.
I don't think the data is particularly noteworthy, it represents what we already know about the space and see reflected in other charts. What I think is noteworthy is Dyn sharing the data. You don't see many API publishers sharing their numbers, and its something I'd like to see more of.
[<a href="/2013/11/18/420-growth-in-dns-api-usage-over-at-dyn/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/11/17/on-losing-my-storytelling-voice/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/bw-voice.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/11/17/on-losing-my-storytelling-voice/">On Losing My Storytelling Voice</a></h3>
			<p><em>17 Nov 2013</em></p>
			<p>photo credit I'm totally thankful for the experiences I've had over the last 90 days in Washington D.C. as a Presidential Innovation Fellow, and even more thankful I'm able to keep doing much of the work I was doing during my fellowship. In reality, I'm actually doing more work now, than I was in DC. While there were several challenges during my time as a PIF, the one that I regret the most, and is taking the longest to recover from, is losing my storytelling voice. This is my ability to capture everyday thoughts in real-time via my Evernote, sit down and form these thoughts into stories, and then share these stories publicly as the API Evangelist. During my time in DC, I was steadily losing my voice. It wasn't some sort of government conspiracy. It is something that seems to happen to me in many institutional or corporate settings, amidst the busy schedule, back to back meetings and through a more hectic project schedule--eventually my voice&nbsp;begins to fade. In July I wrote 61 blog posts, August 41 and September 21. A very scary trend for me. My blog is more than just just stories for my audience and page views generated. My blog(s) are about me working through ideas and preparing them for public consumption. Without storytelling via my blog(s) I don't fully process ideas, think them through, flush them out and think about the API space with a critical eye. Without this lifecycle I don't evolve in my career, and maintain my perspective on the space. In October I've written 28 posts and so far in November I've already written 27 posts, so I'm on the mend. In the future, I'm using my voice as a canary in the coal mine. If a project I'm working on is beginning to diminish my voice, I need to stop and take a look at things, and make sure I'm not heading in a negative direction....[<a href="/2013/11/17/on-losing-my-storytelling-voice/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/11/17/getting-your-api-done-from-the-outsidein/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/bw-inside-out.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/11/17/getting-your-api-done-from-the-outsidein/">Getting Your API Done From the Outside-In</a></h3>
			<p><em>17 Nov 2013</em></p>
			<p>
Sometimes no matter how hard you try, you can't get the buy in for APIs within a company or organization. There are many reasons why API efforts will fail within entrenched companies, organizations or government agencies, but in the end you may have to look for alternatives.
If you want to fullfill your API vision, many times you will need to go outside normal operations to get things done. I have multiple projects on my plate right now that have been started as internal projects, but after hitting roadblock after roadblock, key players have approached me to consider doing as an outside project.
One of the best ways to get people interested in APIs, is to get everyone around them talking about APIs or even getting key partners to adopt an API driven approach to a problem. If you can get traction for an API design externally, you may be able to change attitudes.
APIs are about opening up resources for access and use. If you can't get an API designed, developed and deployed internally, consider maybe doing it from the outside-in.
[<a href="/2013/11/17/getting-your-api-done-from-the-outsidein/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/11/17/api-commons-is-more-than-just-the-definition-specification-or-schema/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/api-commons-icon.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/11/17/api-commons-is-more-than-just-the-definition-specification-or-schema/">API Commons Is More Than Just The Definition, Specification or Schema</a></h3>
			<p><em>17 Nov 2013</em></p>
			<p>
API Commons is about providing a simple and transparent mechanism for the copyright free sharing and collaborative design of API specifications, interfaces and data models. When learning about API Commons it can be easy to focus on the obvious technical deliverables of the project, API definitions, data models, schemas and specifications.
While API Commons is about providing a place to house these very technical design specifications, the largest benefit of API commons will be the process  , community and culture that will form around it. Bringing API design across government and industries out into the open, focusing on sharing, collaboration, reuse and operability will be the true end product--not just the tangible API definition.
As I work on a handful of new API designs for various projects, that I plan on putting in the commons when ready, the importance of API Commons becomes ever clearer. While the end goal appears to be populating the commons with API designs, the real work is about bringing everyone out of the shadows, working on their API designs in a collaborative, re-usable way.
Laying the right foundation for this new API economy.
[<a href="/2013/11/17/api-commons-is-more-than-just-the-definition-specification-or-schema/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/11/16/secure-api-deployment-from-mysql-json-and-google-spreadsheets-with-3scale/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/bw-toolbox.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/11/16/secure-api-deployment-from-mysql-json-and-google-spreadsheets-with-3scale/">Secure API Deployment From MySQL, JSON and Google Spreadsheets With 3Scale</a></h3>
			<p><em>16 Nov 2013</em></p>
			<p>
I'm doing a lot more API deployments from dead simple data sources since I started working in the federal government. As part of these efforts I'm working to put together a simple toolkit that newbies to the API world can use to rapidly deploy APIs as well.
A couple of weeks ago I worked through the simple, open API implementations, and this week I want to show how to secure access to the API by requiring an AppID and AppKey which will allow you to track on who has access to the API.
I'm using 3Scale API Management infrastructure to secure the demos. 3Scale has a free base offering that allows anyone to get up and running requiring API keys, analytics and other essentials with very little investment.
Currently I have four separate deployment blueprints done:

MySQL to API
Local JSON to API
Public Google Spreadsheet to API
Private Google Spreadsheet to API

All of these samples are in PHP and uses the Slim PHP REST framework. They are meant to be working examples that you can use to seed your own API deployment.
You can find the entire working repository, including Slim framework at Github.
[<a href="/2013/11/16/secure-api-deployment-from-mysql-json-and-google-spreadsheets-with-3scale/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/11/16/modular-apis-driven-from-github-blueprints-using-openshift/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/openshift-logo.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/11/16/modular-apis-driven-from-github-blueprints-using-openshift/">Modular APIs Driven From Github Blueprints Using OpenShift</a></h3>
			<p><em>16 Nov 2013</em></p>
			<p>I'm working on a variety of ways that anyone can easily deploy API on common cloud platforms. I'm working through a series of open and secure, modular API demos written in PHP, using the Slim framework. All of these demos are pretty basic, but currently I'm deploying them on Amazon EC2, because it is where most of my infrastructure runs and a top platform with wide user base. Ultimately my goal is to make them as simple to deploy as I possibly can, and while EC2 is definitely the leader, I know there are even simpler ways to launch simple APIs in the clouds. I was doing a survey of which PaaS platforms government agencies allow their workers to deploy projects on, via the US government API group and was reminded of OpenShift, from Redhat. If you aren't familiar with OpenShift, it is a PaaS platform that allows you to define applications in a variety of languages, then deploy, automate, manage and scale in a very modular way. With OpenShift I can define a very modular application, such as an API running PHP, using Slim framework and even apply what is known as a database cartridge, providing MySQL or Postgres storage for the API--all with a single command line. I can instruct each application to derive its code from a Git location, allowing me to manage a central library of applications, then deploy specific instances as needed. While I'm heavily using Github as the primary place to deploy single page applications, that are completely written in HTML, CSS, JavaScript and JSON, I still need server side locations to rapidly deploy API driven resources in PHP, Python, Ruby and Node. OpenShift is a much more modular approach that AWS, and while I'll still be using Amazon for many of my deployments I'm going to play around more with what is possible on OpenShift. What I really like about this approach, in addition to the modular design...[<a href="/2013/11/16/modular-apis-driven-from-github-blueprints-using-openshift/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/11/16/introducing-data-ongithub/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/github-matrix.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/11/16/introducing-data-ongithub/">Introducing Data Ongithub</a></h3>
			<p><em>16 Nov 2013</em></p>
			<p>I am a big fan of opening up data in city, county, state and federal government and across companies of all shapes and sizes. One thing I've learned in my 20+ years of working with data is that when it comes to data management, the spreadsheet is king. While there are always centralized database systems at companies and government organizations, the spreadsheet is actually how data is generally managed, shared and distributed by the average person. Data Ongithub is a project that is focused on tapping the wealth of data available in spreadsheet form and provide a simple platform for converting and managing open data, that anyone can use. While working on open data initiatives I consistently see two major hurdles for individuals who are opening up data: How Do I Convert My Data To JSON? JSON is the reigning open data format. It is a light-weight, portable, machine readable format and is the preferred format of programmers over CSV or XML. Even with this popularity there is no common way for individuals to easily convert common data formats like Excel, CSV or XML to JSON without being a programmer. Where Do I Put My Converted JSON Data Files? Once users are able to convert their data in JSON, they quickly struggle with where they should put these files to make publicly available. Even though website hosting is widely available and inexpensive, users have not associated open data with online website storage. Especially within government organizations, individuals struggle with easy storage of their open data files. Data Ongithub looks to address both these concerns by delivering a lightweight application for conversion of Excel and CSV files to JSON formats, that is developed completely in client-side JavaScript, which means it can run anywhere in any browser. Since it is JavaScript, Data Ongithub lends itself to running completely on the social coding platform Github, which in this scenario acts as the backend storage for the application. Data...[<a href="/2013/11/16/introducing-data-ongithub/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/11/16/deploy-secure-api-public-google-spreadsheet-to-api/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/bw-google-drive-icon.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/11/16/deploy-secure-api-public-google-spreadsheet-to-api/">Deploy Secure API: Public Google Spreadsheet to API</a></h3>
			<p><em>16 Nov 2013</em></p>
			<p>I'm working on a series of simple scripts that help people deploy APIs from some of the most common data sources. I'm starting with a series of PHP scripts, and a couple weeks ago I did a public Google Spreadsheet to API demo, and this week I want to show how to secure access to the API by requiring an AppID and AppKey which will allow you to track on who has access to the API. For this PHP implementation, I'm using the SLIM framework, which provides a dead simple REST framework you can use to deploy an API from a variety of data sources. To begin deploying an API from your Google Spreadsheet datastore, download the REST library and upload to your server that runs PHP. Slim is pretty straightforward to work with, to add each API endpoint you just add a single PHP file under methods. For this how-to guide we are going to add a simple endpoint from our spreadsheet products data store. Next you just add an include reference in the index page for your slim implementation. Everything up until now was the same as the open public Google Spreadsheet to API solution, but not on the index page we will wrap the entry point to the API, with a 3Scale API Management layer. 3Scale is free to sign up and you pay as you scale, so all it takes to get going is register for a 3Scale account and choose the base account, and under your account settings you will find your key to link this code to your account. This API just uses ID, Name, Price and Description of the product, and queries by a simple query parameter. You can use this as a template for your own product database, adding and removing fields as you need, or completely retrofitting for any database table. That is it, now you have a simple product API that pulls a list of...[<a href="/2013/11/16/deploy-secure-api-public-google-spreadsheet-to-api/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/11/16/deploy-secure-api-private-google-spreadsheet-to-api/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-google-docs.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/11/16/deploy-secure-api-private-google-spreadsheet-to-api/">Deploy Secure API: Private Google Spreadsheet to API</a></h3>
			<p><em>16 Nov 2013</em></p>
			<p>I'm working on a series of simple scripts that help people deploy APIs from some of the most common data sources. &nbsp;I'm starting with a series of PHP scripts, and last week I did a private Google Spreadsheet to API demo, and this week I want to show how to secure access to the API by requiring an AppID and AppKey which will allow you to track on who has access to the API. For this PHP implementation, I'm using the SLIM framework, which provides a dead simple REST framework you can use to deploy an API from a variety of data sources. To begin deploying an API from your Google Spreadsheet datastore, download the REST library and upload to your server that runs PHP. Slim is pretty straightforward to work with, to add each API endpoint you just add a single PHP file under methods. For this how-to guide we are going to add a simple endpoint from our private spreadsheet products data store. This project also depends on the Google Drive API and I use the Google API PHP Client to connect to Google and provide necessary oAuth connectivity.&nbsp; Before all of this works you need to have an oAuth token, which I created a simple script to handle: I leave it to you to figure out where you want to store your oAuth tokens, and other goods. I use a config.php file, but can easily be done from database or other: Next you just add an include reference in the index page for your slim implementation. Everything up until now was the same as the private Google Spreadsheet to API solution, but not on the index page we will wrap the entry point to the API, with a 3Scale API Management layer. 3Scale is free to sign up and you pay as you scale, so all it takes to get going is register for a 3Scale account and choose the base account,...[<a href="/2013/11/16/deploy-secure-api-private-google-spreadsheet-to-api/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/11/16/deploy-secure-api-mysql-to-api/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/bw-mysql.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/11/16/deploy-secure-api-mysql-to-api/">Deploy Secure API: MySQL to API</a></h3>
			<p><em>16 Nov 2013</em></p>
			<p>I'm working on a series of simple scripts that help people deploy APIs from some of the most common data sources. I'm starting with a series of PHP scripts, and a couple weeks ago I did a MySQL to API demo, and this week I want to show how to secure access to the API by requiring an AppID and AppKey which will allow you to track on who has access to the API. For this PHP implementation, I'm using the SLIM framework, which provides a dead simple REST framework you can use to deploy an API from a variety of data sources. To begin deploying an API from your MySQL database, download the REST library and upload to your server that runs PHP. Slim is pretty straightforward to work with, to add each API endpoint you just add a single PHP file under methods. For this how-to guide we are going to add a simple endpoint from our products database. Next you just add an include reference in the index page for your slim implementation. Everything up until now was the same as the open MySQL to API solution, but not on the index page we will wrap the entry point to the API, with a 3Scale API Management layer. 3Scale is free to sign up and you pay as you scale, so all it takes to get going is register for a 3Scale account and choose the base account, and under your account settings you will find your key to link this code to your account. This API just uses ID, Name, Price and Description of the product, and queries by a simple query parameter. You can use this as a template for your own product database, adding and removing fields as you need, or completely retrofitting for any database table. That is it, now you have a simple product API that pulls a list of products from a MySQL database. There are...[<a href="/2013/11/16/deploy-secure-api-mysql-to-api/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/11/16/deploy-secure-api-json-to-api/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/bw-json-data-store.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/11/16/deploy-secure-api-json-to-api/">Deploy Secure API: JSON to API</a></h3>
			<p><em>16 Nov 2013</em></p>
			<p>I'm working on a series of simple scripts that help people deploy APIs from some of the most common data sources. I'm starting with a series of PHP scripts, and a couple weeks ago I did a JSON to API demo, and this week I want to show how to secure access to the API by requiring an AppID and AppKey which will allow you to track on who has access to the API. For this PHP implementation, I'm using the SLIM framework, which provides a dead simple REST framework you can use to deploy an API from a variety of data sources. To begin deploying an API from your JSON datastore, download the REST library and upload to your server that runs PHP. Slim is pretty straightforward to work with, to add each API endpoint you just add a single PHP file under methods. For this how-to guide we are going to add a simple endpoint from our JSON products data store. Next you just add an include reference in the index page for your slim implementation. Everything up until now was the same as the open JSON to API solution, but not on the index page we will wrap the entry point to the API, with a 3Scale API Management layer. 3Scale is free to sign up and you pay as you scale, so all it takes to get going is register for a 3Scale account and choose the base account, and under your account settings you will find your key to link this code to your account. This API just uses ID, Name, Price and Description of the product, and queries by a simple query parameter. You can use this as a template for your own product database, adding and removing fields as you need, or completely retrofitting for any database table.&nbsp; There are any number of reasons you would want to secure an API driven from a JSON file, to offer...[<a href="/2013/11/16/deploy-secure-api-json-to-api/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/11/15/php-libraries-for-smithsonian-api-to-support-hackathon-this-weekend/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/smithsonian-statue-hackathon.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/11/15/php-libraries-for-smithsonian-api-to-support-hackathon-this-weekend/">PHP Libraries For Smithsonian API to Support Hackathon This Weekend</a></h3>
			<p><em>15 Nov 2013</em></p>
			<p>
I have a long list of little projects I'm working on across government, and since I'm not being paid for some of this work now (except for the support of my amazing partners), the publicity and page views for this work is all I got! :-) So I'm publishing the stories around everything I do.
This week I got a sneak peak of the Smithsonian EDAN API which provides access to meta data of collections housed at the Smithsonian Institute, along with the ability to tag items and build collections.
The Smithsonian is holding a hackathon this weekend and I wanted to contribute what I could, so I pulled together a PHP code library as I explored and hacked not the Smithsonian EDAN API. The library isn't a beautiful product ready SDK, but should help the average PHP developer get up to speed on the API and save some time building their app.
You can find the Smithsonian EDAN API PHP library on Github, learn more about the hackathon this weekend on Eventbrite, and follow any other work I'm doing for the Smithsonian around open data and APIs on my Smithsonian Data project on Github.
[<a href="/2013/11/15/php-libraries-for-smithsonian-api-to-support-hackathon-this-weekend/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/11/15/interactive-feedback-on-the-fda-recall-api/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/fda-recall.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/11/15/interactive-feedback-on-the-fda-recall-api/">Interactive Feedback On The FDA Recall API</a></h3>
			<p><em>15 Nov 2013</em></p>
			<p>
I have a long list of little projects I'm working across government, and since I'm not being paid for some of this work now (except for the support of my amazing partners), the publicity and page views for this work is all I got! :-) So I'm publishing the stories around everything I do.
Up next: I was asked for some feedback on the FDA Recall API that is in pre-production currently, and I thought, what better way to offer feedback on API design than actually sculpting a Swagger definition of the changes and making it usable via Github.
Overall the FDA Recall API design was perfectly suitable for launch, even though the interface isn't perfect and some of the data is pretty messy, but I'm a big fan of just getting things out there, letting developers hack on it and gather feedback for the next iteration.
The existing FDA Recall API allows you to pull weekly recalls for 5 separate product types including Food, Drugs, Veterinarian, Devices and Biologics. Using the API you can pull each week listing of recalls as well as pull detail on individual recalls.
To get a handle on where they should take the interface I needed to hack on it like I was a developer, so I setup a proxy that runs on AWS EC2 and started coding against each endpoint, then adjusting a Swagger definition until I had something that was acceptable for a v.01.
You can find the result of this work over at the FDA Recall API working project I stood up on Github, it should work until they make any adjustments to the pre-production API. You can follow any work I do on FDA open data and APIs at the main project site I setup.
[<a href="/2013/11/15/interactive-feedback-on-the-fda-recall-api/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/11/15/apis-give-you-the-ability-to-define-and-execute-on-the-actions-that-are-most-important-to-you/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/IFTTT___Connect_YouTube_to_SoundCloud.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/11/15/apis-give-you-the-ability-to-define-and-execute-on-the-actions-that-are-most-important-to-you/">APIs Give You The Ability To Define And Execute On The Actions That Are Most Important To You</a></h3>
			<p><em>15 Nov 2013</em></p>
			<p>I am a programmer with a full understanding of how to deploy, consume and put APIs to use. Even with this knowledge and ability I'm continually blown away by the opportunities APIs afford, even without possessing any programming skills whatsoever. One API I depend on for my daily monitoring of the API space is the Pinboard API. As I browse the web, using the Pinboard bookmarklet I can pin any web page for use later, then using the Pinboard API I pull these curated pages into my monitoring, reporting and story development platform. To take this feature one step further, when I star a Tweet on Twitter, Pinboard watches this and automatically bookmarks the Tweet, adding it to my curation as well. This approach to using APIs has allowed me to define how I use bookmarking as well as what a favorited Tweet means in my personal world of online curation. Using APIs I'm able to wield this power, and drive my story curation and development lifecycle. Of course I wrote the code that interfaces with Pinboard API, but it still shows the ability to define and execute actions in my world using APIs. As I was pondering this self-defined action that I use on a daily basis, I was trying to think of any new actions that I could define and add to my toolbox. I was looking through the Youtube videos from my recent #APIStrat conference, and I thought how nice it would be to turn these into audio segments available as podcasts through SoundCloud. After a quick search I found an IFTTT recipe that does this automatically when I flag any Youtube video for watching later and automatically uploads as an audio file to SoundCloud. Sweet! This type of action again shows the power of being able to define and execute your own actions that you can take in your everyday worlds, but in this case you don't have to be a...[<a href="/2013/11/15/apis-give-you-the-ability-to-define-and-execute-on-the-actions-that-are-most-important-to-you/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/11/12/if-gov-then-that/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/bw-github.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/11/12/if-gov-then-that/">If Gov Then That</a></h3>
			<p><em>12 Nov 2013</em></p>
			<p>
I just found an interesting brainstorm going on via Github, about how to make government more efficient and interoperable using APIs, that was created by government consultant Leah Bannon (@leahbannon), called If Gov Then That.
The idea?  Promote gov APIs by making them dead simple and suggesting clever recipes (like IFTTT and Zapier)
Leah has started a rough list of some possible recipes, but needs your help to brainstorm what you'd like to see for developing interoperability and automation recipes in our government.
You can contribute via the Github project, on the conversation thread she started on the US Government APIs Google Group, and she will be working on as part of Code for DC.
[<a href="/2013/11/12/if-gov-then-that/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/11/12/deploy-api-private-google-spreadsheet-to-api/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/bw-google-docs.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/11/12/deploy-api-private-google-spreadsheet-to-api/">Deploy API: Private Google Spreadsheet to API</a></h3>
			<p><em>12 Nov 2013</em></p>
			<p>I'm working on a series of simple scripts that help people deploy APIs from some of the most common data sources. I'm starting with a series of PHP scripts, and next up is a private Google Spreadsheet to API, using JSON stored in Github. For this PHP implementation, I'm using the SLIM framework, which provides a dead simple REST framework you can use to deploy an API from a variety of data sources. To begin deploying an API from your Google Spreadsheet datastore, download the REST library and upload to your server that runs PHP. Slim is pretty straightforward to work with, to add each API endpoint you just add a single PHP file under methods. For this how-to guide we are going to add a simple endpoint from our JSON products data store. This project also depends on the Google Drive API and I use the Google API PHP Client to connect to Google and provide necessary oAuth connectivity.&nbsp; Before all of this works you need to have an oAuth token, which I created a simple script to handle: I leave it to you to figure out where you want to store your oAuth tokens, and other goods. I use a config.php file, but can easily be done from database or other: Next you just add an include reference in the index page for your slim implementation: This API just uses ID, Name, Price and Description of the product, and queries by a simple query parameter. You can use this as a template for your own product database, adding and removing fields as you need, or completely retrofitting for any database table. That is it, now you have a simple product API that pulls a list of products from a private Google Spreadsheet data store. This project is more excercise than anything else. I don't recommend deploying a public API driectly off a private Google Spreadsheet. Next up, will be to secure it using...[<a href="/2013/11/12/deploy-api-private-google-spreadsheet-to-api/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/11/12/common-data-sources-to-api-definition/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/bw-google-docs.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/11/12/common-data-sources-to-api-definition/">Common Data Sources To API Definition</a></h3>
			<p><em>12 Nov 2013</em></p>
			<p>
I've been working through several demos of how to go from common data sources like MySQL and Google Spreadsheet to API over the last couple of weeks.  So far I have five basic working demos:

MySQL to API
Local JSON to API
Github JSON to API
Public Google Spreadsheet to API
Private Google Spreadsheet to API

These demos are meant to show how easy it is to deploy a simple API from common places you already have data stored. Right now I'm building them in PHP, but will also be building Python, Ruby and Node.JS versions.
These exercises are meant for my newbie readers but are also helping me see API deployment in different ways. I realize how difficult it is to write code that will work for all scenarios. There is a lot of custom work on the data store side, as well as possible the API side, making me feel like it is best to use an API definition in the middle.
With this in mind, the next phase of my API deployment tools will be about generating API definitions, which currently will be Swagger, but will also develop RAML and API Blueprint versions of the same code eventually.
Once I have some data store to Swagger tooling I will evolve some of the code I have for generating APIs from Swagger definitions.
Then I will have the different custom parts decoupled from each other, all centered around an API definition and data model which I can publish in API Commons and evolve in an open, collaborative environment where everyone can benefit, and contribute to my API work.
[<a href="/2013/11/12/common-data-sources-to-api-definition/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/11/12/9-essential-languages-for-your-api-code-libraries/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/bw-google-drive-icon.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/11/12/9-essential-languages-for-your-api-code-libraries/">9 Essential Languages For Your API Code Libraries</a></h3>
			<p><em>12 Nov 2013</em></p>
			<p>
I was working with Google APIs over the last couple days while building Google Spreadsheet to API tools. It gave me a chance to look around the Google Developers Area and rediscover some of the positive approaches the API pioneer brings to the table.
In this post I wanted to highlight the Google Drive Code Libraries. While the Google approach isn't perfect, I think it sets a good bar for what can be achieved by API providers when delivering their own API code libraries.

I think the languages represented are the baseline for any modern API, and all API providers should consider providing the following languages:

.NET
Go
Java
JavaScript
Node.js
Objective-C
PHP
Python
Ruby

Languages like Go and Node.js are definitely forward leaning, but represent very fast growing areas of the API integration space.
Java and Objective-C represent the mobile space, something API providers can't be ignoring in 2013.
If your target audience is the enterprise, you have to have .NET and Java as part of your API library.
PHP, Python and Ruby are the web staples, that are default for any API that is catering to general web developers.
It should get easier to generate code libraries automatically for API providers who have developed some sort of API definition for their APIs, but for others you will still have eto hand-roll your own code lbiraries.
[<a href="/2013/11/12/9-essential-languages-for-your-api-code-libraries/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/11/08/dwolla-open-sources-mobile-payment-app/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/dwolla-open-source-iphone-app.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/11/08/dwolla-open-sources-mobile-payment-app/">Dwolla Open Sources Mobile Payment App</a></h3>
			<p><em>08 Nov 2013</em></p>
			<p>
Every API provider should provide code samples in a variety of languages, helping developers get up and running as fast as possible.
Dwolla is taking this one step further and providing a fully functional iOS app that developers can fork, tweak and use as they wish.
I've talked about what I call "starter kits" before, when I showcased Google+ sample social applications in a variety of languages, but it is still something I don't see from very many API providers.
Complete mobile applications is a great way to showcase what a complete API integration will look like, helping developers see the end goal clearly, while also teaching them best practices.
Do you have any applications you could open source and allow developers to reverse engineer? Or maybe an app you could developer to show developers what is possible!
[<a href="/2013/11/08/dwolla-open-sources-mobile-payment-app/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/11/08/automatic-rest-api-for-databases-as-complete-amazon-machine-image/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/slashdb-logo.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/11/08/automatic-rest-api-for-databases-as-complete-amazon-machine-image/">Automatic REST API for Databases As Complete Amazon Machine Image</a></h3>
			<p><em>08 Nov 2013</em></p>
			<p>
SlashDB aka /db, has recently been added to the Amazon Marketplace, providing a complete database to API solution as an Amazon Machine Image (AMI).
Companies can use the /db Amazon image to automatically generate REST APIs from common relational databases like Microsoft SQL Server, Oracle, MySQL, PostGreSQL, which includes Amazon RDS.
/db charges based upon the number of databases you launch and the number of users that are using the API for the database, and you will have to pay for the regular charges for any Amazon EC2 instances.
I like the idea of building API solutions and launching as Amazon Machine Images. I think ready-to-go platform solutions like this for AWS, Google, Heroku and other top cloud platforms are good for potential API providers.
[<a href="/2013/11/08/automatic-rest-api-for-databases-as-complete-amazon-machine-image/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/11/07/apis-ongithub/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/bw-github.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/11/07/apis-ongithub/">APIs Ongithub</a></h3>
			<p><em>07 Nov 2013</em></p>
			<p>I've created a new playground for some of my work. Pretty much everything at API Evangelist runs on Github, and each new project I produce starts its life as a Github repository. To support this work I established a new domain called ongithub. My first series in the ongithub realm is based upon an approach I'm using to deploy very simple APIs, while also introducing and educating people about APIs. I have a handful of simple API designs from working in the government, so I married them with data models derived from schema.org, and publish over 10 very simple API design patterns. Every one of these demo APIs began as a simple Swagger specification, which I quickly spun into a web API using the Slim REST Framework, then generated a simple API microsite complete with interactive documentation. These Swagger specifications were the seed of the recent API Commons that 3Scale and API Evangelist just launched. I have plenty of other API designs laying around, but this seemed like a good way to seed the API Commons with some simple and common designs. You can find the following 11 designs at api.ongithub.com: &nbsp; Businesses This is a simple API specification for a listing of businesses. Events This is a simple API specification for a listing of events. Images This is a simple API specification for a listing of photos and images. Jobs This is a simple API specification for a listing of jobs. Offices This is a simple API specification for a listing of offices. Places This is a simple API specification for a listing of places. People This is a simple API specification for a listing of people. Press This is a simple API specification for a listing of news and press releases. Products This is a simple API specification for a listing of products. Programs This is a simple API specification for a listing of programs. Videos This is a simple API specification for...[<a href="/2013/11/07/apis-ongithub/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/11/06/putting-the-open-in-api-with-the-api-commons/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/api-commons-logo.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/11/06/putting-the-open-in-api-with-the-api-commons/">Putting The Open In API With The API Commons</a></h3>
			<p><em>06 Nov 2013</em></p>
			<p>Steve Willmott(@njyx) from API infrastructure provider 3Scale and API Evangelist launched a new partner project yesterday at Defrag, that we are calling API Commons. The mission with API commons is to provide a simple and transparent mechanism for the copyright free sharing and collaborative design of API specifications, interfaces and data models. For a space that is about open access and interoperability the API industry has been very closed about their API designs, and after helping the EFF urge the courts to block copyright claims in the Oracle v. Google API fight, Steve and I thought it would be a good idea to introduce an API commons that would help put the "open" into API designs and data models, and back into the API space in gernal. API Commons is build entirely on Github and is meant to act as a common index of API definitions and data models that anyone can add by generating what we are calling an API Commons Manifest that points to your API definition(s). Using the existing layers of Github, anyone can fork, favorite or follow the best API design patterns and eventually help establish some clear best practices across any government or business sector. Everything you need to get going is on the site at apicommons.org. You can join the discussion on the Google Group or by following us on Twitter. We are in early stages, but will be dedicating a great deal of time over the holidays to get more API definitions in the commons. 3Scale and I strongly believe that API Commons is what the API industry needs to help deal with some of the clutter in the number of API designs, incentivize the development of open and common tooling around the best API designs and bring reuse, collaboration and copyright concerns out into the open. Also check out some of the great news coverage of API Commons over the last 24 hours: New API Commons Platform...[<a href="/2013/11/06/putting-the-open-in-api-with-the-api-commons/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/11/06/open-data-and-api-efforts-rendered-useless-when-privacy-is-ignored/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/open-government-partnership.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/11/06/open-data-and-api-efforts-rendered-useless-when-privacy-is-ignored/">Open Data And API Efforts Rendered Useless When Privacy Is Ignored</a></h3>
			<p><em>06 Nov 2013</em></p>
			<p>On the second anniversary of the Open Government Partnership (OGP), where we are celebrating a "global effort to encourage transparent, effective, and accountable governance", and that: OGP has grown to 60 countries that have made more than 1000 commitments to improve the governance of more than two billion people around the globe. OGP is now a global community of government reformers, civil society leaders, and business innovators working together to develop and implement ambitious open government reforms and advance good governance. That is some pretty significant platform growth! While reading this I'm reminded of how any amount of perceived growth and value delivered via an "open data or API platform" can be immediately muted by the omission of very fundamental building blocks like privacy. Let's review the building blocks of the Open Government Alliance: Expand Open Data -&nbsp;Open Data fuels innovation that grows the economy and advances government transparency and accountability. Government data has been used by journalists to uncover variations in hospital billings, by citizens to learn more about the social services provided by charities in their communities, and by entrepreneurs building new software tools to help farmers plan and manage their crops. Building upon the successful implementation of open data commitments in the first U.S. National Action Plan, the new Plan will include commitments to make government data more accessible and useful for the public, such as reforming how Federal agencies manage government data as a strategic asset, launching a new version of Data.gov, and expanding agriculture and nutrition data to help farmers and communities. Modernize the Freedom of Information Act (FOIA) -&nbsp;The FOIA encourages accountability through transparency and represents a profound national commitment to open government principles. Improving FOIA administration is one of the most effective ways to make the U.S. Government more open and accountable. Today, the United States announced a series of commitments to further modernize FOIA processes, including launching a consolidated online FOIA service to improve customers&rsquo; experience and...[<a href="/2013/11/06/open-data-and-api-efforts-rendered-useless-when-privacy-is-ignored/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/10/22/deploy-api-public-google-spreadsheet-to-api/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/bw-google-docs.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/10/22/deploy-api-public-google-spreadsheet-to-api/">Deploy API: Public Google Spreadsheet to API</a></h3>
			<p><em>22 Oct 2013</em></p>
			<p>
I'm working on a series of simple scripts that help people deploy APIs from some of the most common data sources. I'm starting with a series of PHP scripts, and next up is a public Google Spreadsheet to API, using JSON stored in Github.
For this PHP implementation, I'm using the SLIM framework, which provides a dead simple REST framework you can use to deploy an API from a variety of data sources.   To begin deploying an API from your Google Spreadsheet datastore, download the REST library and upload to your server that runs PHP.
Slim is pretty straightforward to work with, to add each API endpoint you just add a single PHP file under methods. For this how-to guide we are going to add a simple endpoint from our JSON products data store.

Next you just add an include reference in the index page for your slim implementation:

This API just uses ID, Name, Price and Description of the product, and queries by a simple query parameter. You can use this as a template for your own product database, adding and removing fields as you need, or completely retrofitting for any database table.  That is it, now you have a simple product API that pulls a list of products from a Google Spreadsheet data store.
[<a href="/2013/10/22/deploy-api-public-google-spreadsheet-to-api/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/10/22/deploy-api-github-json-to-api/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/bw-github.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/10/22/deploy-api-github-json-to-api/">Deploy API: Github JSON to API</a></h3>
			<p><em>22 Oct 2013</em></p>
			<p>
I'm working on a series of simple scripts that help people deploy APIs from some of the most common data sources. I'm starting with a series of PHP scripts, and next up is JSON to API, using JSON stored in Github.
For this PHP implementation, I'm using the SLIM framework, which provides a dead simple REST framework you can use to deploy an API from a variety of data sources.   To begin deploying an API from your JSON datastore located at Github, download the REST library and upload to your server that runs PHP.
Slim is pretty straightforward to work with, to add each API endpoint you just add a single PHP file under methods. For this how-to guide we are going to add a simple endpoint from our JSON products data store.

Next you just add an include reference in the index page for your slim implementation:

This API just uses ID, Name, Price and Description of the product, and queries by a simple query parameter. You can use this as a template for your own product database, adding and removing fields as you need, or completely retrofitting for any database table.  That is it, now you have a simple product API that pulls a list of products from a JSON data store stored at Github.
[<a href="/2013/10/22/deploy-api-github-json-to-api/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/10/22/api-deployment-from-mysql-json-github-and-google-spreadsheets/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/bw-toolbox.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/10/22/api-deployment-from-mysql-json-github-and-google-spreadsheets/">API Deployment From MySQL, JSON, Github and Google Spreadsheets</a></h3>
			<p><em>22 Oct 2013</em></p>
			<p>
I'm doing a lot more API deployments from dead simple data sources since I started working in the federal government. As part of these efforts I'm working to put together a simple toolkit that newbies to the API world can use to rapidly deploy APIs as well.
Currently I have four separate deployment blueprints done:

MySQL to API
Local JSON to API
Github JSON to API
Google Spreadsheet to API

All of these samples are in PHP and uses the Slim PHP REST framework. They are meant to be working examples that you can use to seed your own API deployment.
I'm also including these in my government API workshop at #APIStrat this week, hoping to get other people equipped with the necessary skills and tools they need to get APIs in the wild.
You can find the entire working repository, including Slim framework at Github.
[<a href="/2013/10/22/api-deployment-from-mysql-json-github-and-google-spreadsheets/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/10/21/deploy-api-mysql-to-api/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/bw-mysql.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/10/21/deploy-api-mysql-to-api/">Deploy API: MySQL to API</a></h3>
			<p><em>21 Oct 2013</em></p>
			<p>
I'm working on a series of simple scripts that help people deploy APIs from some of the most common data sources. I'm starting with a series of PHP scripts, and first up is MySQL to API.
For this PHP implementation, I'm using the SLIM framework, which provides a dead simple REST framework you can use to deploy an API from a variety of data sources.   To begin deploying an API from your MySQL database, download the REST library and upload to your server that runs PHP.
Slim is pretty straightforward to work with, to add each API endpoint you just add a single PHP file under methods. For this how-to guide we are going to add a simple endpoint from our products database.

Next you just add an include reference in the index page for your slim implementation:

This API just uses ID, Name, Price and Description of the product, and queries by a simple query parameter. You can use this as a template for your own product database, adding and removing fields as you need, or completely retrofitting for any database table.  That is it, now you have a simple product API that pulls a list of products from a MySQL database.
[<a href="/2013/10/21/deploy-api-mysql-to-api/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/10/21/deploy-api-json-to-api/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/bw-json-data-store.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/10/21/deploy-api-json-to-api/">Deploy API: JSON to API</a></h3>
			<p><em>21 Oct 2013</em></p>
			<p>
I'm working on a series of simple scripts that help people deploy APIs from some of the most common data sources. I'm starting with a series of PHP scripts, and next up is JSON to API.
For this PHP implementation, I'm using the SLIM framework, which provides a dead simple REST framework you can use to deploy an API from a variety of data sources.   To begin deploying an API from your JSON datastore, download the REST library and upload to your server that runs PHP.
Slim is pretty straightforward to work with, to add each API endpoint you just add a single PHP file under methods. For this how-to guide we are going to add a simple endpoint from our JSON products data store.

Next you just add an include reference in the index page for your slim implementation:

This API just uses ID, Name, Price and Description of the product, and queries by a simple query parameter. You can use this as a template for your own product database, adding and removing fields as you need, or completely retrofitting for any database table.  That is it, now you have a simple product API that pulls a list of products from a JSON data store.
[<a href="/2013/10/21/deploy-api-json-to-api/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/10/19/government-api-opportunities-bureau-of-labor-statistics/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/bureau-of-labor-statistics-logo.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/10/19/government-api-opportunities-bureau-of-labor-statistics/">Government API Opportunities: Bureau of Labor Statistics</a></h3>
			<p><em>19 Oct 2013</em></p>
			<p>I'm working to expand my awareness of APIs in our federal government by spending time each week discovering, reviewing and trying to brainstorm ways to expand and evolve existing government API efforts. Today I was reviewing the Bureau of Labor Statistics API, where I was pleased to find this valuable labor data available via single series, multiple series, one or more series specifying years. The API is a pretty straightforward web API, which could use some polishing, but overall it provides machine readable access to this very important data as I would expect. When I look at federal government APIs I'm trying to find at least one or two ways to help move the API forward, either as constructive criticism for the API providers or ways that the public (me included) can help evolve the community or the API itself from the outside. My current contributions to the Bureau of Labor Statistics is to add support for the Series ID to the API stack. The Series ID is the single, central parameter you pass to each of the API endpoints, but nowhere does it link to or help the users understand the Series ID, which plays a central role in API operations. This type of omission by API providers is common. You have the domain expertise in your area, you know the Series ID is the central character, but to people stumbling across or intentionally pulling up the Bureau of Labor Statistics API, this might not be common knowledge. With this in mind, the roadmap of the Bureau of Labor Statics API should include an API for all of the building blocks and meta data for the Series ID. There is a lot of rich data available on a Series ID, and while it would take a significant amount of work to develop additional APIs around this data, I think it would significantly add value to the Bureau of Labor Statistics API and increase adoption....[<a href="/2013/10/19/government-api-opportunities-bureau-of-labor-statistics/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/10/17/shutdown-of-government-open-data-and-apis-is-not-government-services-business-as-usual/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/bw-government.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/10/17/shutdown-of-government-open-data-and-apis-is-not-government-services-business-as-usual/">Shutdown of Government Open Data and APIs Is NOT Government Services Business As Usual</a></h3>
			<p><em>17 Oct 2013</em></p>
			<p>During the recent federal government shutdown many sources of open data and APIs were suddenly rendered unavailable, including the flagship Data.gov. As government workers went home and lights were turned off at federal agencies, so too were the servers that hosted much of the open data and APIs that have been opened up in the last couple years. Across the web I've encountered discussions from many individuals who state this is how government services work. When government funding disappears, the government services go away, suck it up. I'm sorry, but this is unacceptable in the Internet age. If you see things this way, you are part of the machine that allows government services to be used as a political tool. I agree, that human powered government services go away when funding disappears, but in the age of open data, APIs and the cloud, services are designed and deployed to be self-service and highly available. When you launch APIs in the cloud, you bundle your budget, service level agreement and the tech into a single package. My funding went away this month and couldn't afford my AWS bill on 10/1, but my server didn't shut down the minute the shutdown happened. I had until the end of the month. Ideally the federal government could go with reserved instances annually or at least quarterly, securing the funding needed to outlast any shutdown. Even with my heavy usage of AWS for much of my infrastructure, the majority of my world runs on open repositories on Github. I have carefully crafted my public presence using open formats like HTML, CSS, JavaScript and JSON and host these as openly licensed, public repositories that I can operate as no cost the social coding platform. There is no excuse for government open data data and API services to go away during a shutdown like we just experienced. Open data and APIs represent a new, self-service future for government services. This model won't...[<a href="/2013/10/17/shutdown-of-government-open-data-and-apis-is-not-government-services-business-as-usual/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/10/17/api-and-oauth-literacy-is-as-important-as-financial-literacy-in-the-api-economy/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/universal-library-sign.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/10/17/api-and-oauth-literacy-is-as-important-as-financial-literacy-in-the-api-economy/">API and OAuth Literacy Is As Important As Financial Literacy in the API Economy</a></h3>
			<p><em>17 Oct 2013</em></p>
			<p>The primary mission of API Evangelist is to spread awareness of APIs amongst the masses, expanding the audience beyond just the IT crowd, and developer community. Initially I wanted to make sure business leaders understood the potential of APis, so that they funded API initiatives within their companies. In 2012 I feel that APIs have hit a critical mass, and while I still evangelize APIs to business leaders I'm shifting a portion of my focus to the average Internet user. APIs impact almost every aspect of our daily lives from logging into Facebook on our mobile phones to purchasing gasoline at the corner gas station. As API usage spreads across business, the government and the Internet of Things (IoT), the everyday citizen will be using APIs more and more each day. While many of these citizens will never hack on an API at the code level, I'm seeing a need emerge for everyone individual to be aware of APIs, much like they need a certain level of economic and financial awareness in every day life. When it comes to our world of finances, every single adult must have a certain level of awareness of how our financial system operates. You don't need to understand the inner workings of banking and global markets, but you need to know how to setup a bank account, apply for credit or debit cards, balance your checkbook and pay your taxes. As our lives move online and the API economy grows, our data is fast becoming the online currency on Internet platforms like Facebook, Twitter and Pinterest, the need for us to understand the mechanisms at play in this new digital economy increases. Virtually every platform we use online employs APIs in some capacity. These platforms use APIs and often an open authentication standard called oAuth to allow us to give access to our data that resides on platforms to the applications and other systems we use daily. We login...[<a href="/2013/10/17/api-and-oauth-literacy-is-as-important-as-financial-literacy-in-the-api-economy/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/10/16/foundry-group-makes-investment-in-the-open-standards-api-driven-javascript-approach-of-mapbox/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/mapbox-logo.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/10/16/foundry-group-makes-investment-in-the-open-standards-api-driven-javascript-approach-of-mapbox/">Foundry Group Makes Investment In The Open Standards, API Driven, JavaScript Approach Of MapBox</a></h3>
			<p><em>16 Oct 2013</em></p>
			<p>On June 29th, 2006, Google launched Google Maps API allowing developers to put Google Maps on their own sites using JavaScript. The API launch was just shy of 6 months after the release of Google Maps as an application, and was in direct response to the number of rogue apps developed that were hacking the application--demonstrating the demand for a JavaScript based, API driven mapping solution for developers. Fast-forward 7 years, and maps are a central fixture of virtually every web and mobile application we depend on daily. While Google Maps is still the heavyweight in the space, their now classic map interface, proprietary tooling and search centric mindset leaves a huge opportunity for disruption in the app economy, and the venture capital firm Foundry Group is betting that startup mapping provider MapBox is the solution that will de-throne Google, with a 10M investment in MapBox&nbsp;earlier today. What makes MapBox such a good investment? At first look, it is clear that MapBox is winning over developers and existing players like Foursquare and Evernote by providing very clean, attractive mapping solutions that contain street, terrain and satellite layers, but when you take a closer look at the platform, you see the MapBox allure isn't just about maps. The value of MapBox is also about their approach to delivering a platform that begins with a heavy focus on open specifications, embracing of APIs, heavy investment in JavaScript, and a knowledge of modern cloud architecture, with strong support for mobile apps. Open SpecificationsIn 2013, when you are looking to deploy a true platform, you have to shed your self-centered approach to technology, do your homework on what are the best practices and standards that exist across your industry, and don't re-invent the wheel or try to keep things closed and proprietary, making everything you do a two-way street that benefits the entire ecosystem. This is how you establish a true platform ecossytem, one that developers will believe in...[<a href="/2013/10/16/foundry-group-makes-investment-in-the-open-standards-api-driven-javascript-approach-of-mapbox/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/10/15/visual-notes-from-my-talk-on-apis-and-the-future-of-education-at-openva/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/kinlane-openva-api-visual-notes.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/10/15/visual-notes-from-my-talk-on-apis-and-the-future-of-education-at-openva/">Visual Notes From My Talk On APIs And The Future of Education At OpenVA</a></h3>
			<p><em>15 Oct 2013</em></p>
			<p>Audrey and I went up to University of Mary Washington yesterday and participated in the #OpenVa discussion, where I gave a presentation on the importance of APIs and how they will play a significant role in the future of education.
During the talk Giulia Forsythe (@giuliaforsythe) sketched some visual notes that I think are pretty damn cool!

You can view her blog post and other sketches on her blog at Minding the Future [Visual Notes} #OpenVA.  You can also find the slides for my talk on Github under OpenVA - The Future of Educaiton.
I had a great time brainstorming with everyone up at UMW, and will have more posts in the near future about the other plotting and scheming we did regarding the future of education and APIs.
[<a href="/2013/10/15/visual-notes-from-my-talk-on-apis-and-the-future-of-education-at-openva/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/10/12/two-weeks-until-api-strategy-amp-practice-in-san-francisco/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/APIStrat-Home-Page-Slice-2.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/10/12/two-weeks-until-api-strategy-amp-practice-in-san-francisco/">Two Weeks Until API Strategy &amp; Practice in San Francisco</a></h3>
			<p><em>12 Oct 2013</em></p>
			<p>
I'm working through the schedule for API Strategy &amp; Practice Conference (#APIStrat) in San Francisco, preparing for the 3Scale / API Evangelist produced event October 23rd through 25th.
I'm pretty excited about the lineup we've managed to assemble including keynotes from Pamela Fox (@pamelafox) from Khan Academy, Daniel Jacobson (@daniel_jacobson) of Netflix, Wynn Netherland (@pengwynn) from Github and Kristin Calhoun (@KCalhoun) the director of the Public Media Platform, just to name a few of them.
We've worked hard to put together sessions that would speak to all aspects of the API space including creation, design and documentation of APIs, API discovery, hypermedia APIs, API testing &amp; debugging, API marketing &amp; evangelism and business models. The goal was to cover topics from basic to advanced, while covering APIs from start to finish.
I'm particularly stoked about the location of the conference. It is right downtown at the Parc55 Hotel, easy walking distance to and from anything.  I always hate conferences that are off the beaten path, and Parc55 will make it easy to hang out and eat, drink and network around the event before and after.
The New York City edition of #APIStrat back in February was sold out with over 350 people in attendance. San Francisco is also on track to be sold out, this time with over 600 people in attendance.  Steve Willmott(@njyx) of 3Scale and I have a blast MC'ing the entire event and facilitating the API conversations, both business and technology, and gearing up to make sure #APIStrat flows.
Make sure and GET REGISTERED. It was painful to turn away everyone last time, and I'd hate for you to not be able to get in. It is going to be an informative three days with the people who make the API space move forward. I look forward to seeing you there.
[<a href="/2013/10/12/two-weeks-until-api-strategy-amp-practice-in-san-francisco/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/10/12/from-extract-transform-amp-load-to-input-process-and-output-with-delray/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/delray-logo.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/10/12/from-extract-transform-amp-load-to-input-process-and-output-with-delray/">From Extract, Transform &amp; Load To Input, Process and Output With Delray</a></h3>
			<p><em>12 Oct 2013</em></p>
			<p>
I spend a lot of time finding valuable data sets and manually converting, processing and outputting into more usable formats, so that they can be used in APIs that drive mobile and web applications.
I am always on the lookout for new tools that will help me be more efficient in to my work. I'm currently test driving a new platform called Delray that focuses on taking an older concept of extract, transform and load (ETL) and bringing it into the API age by allowing me to define common data resources as inputs, process them one time or on schedule and output data in a cleaner, more usable format.

Using Delray I can define an input from CSV, JSON, MSSQL and other common formats, and save this as the input for my workflow.

Next I can setup a configure a cleansing stage to process the data, allowing me to trim whitespace, replace space, make lowercase and other common things I tend to do manually with my data sets.

Finally I can output the CSV inputed data as a JSON file for use in my APIs and other open data efforts.

Delray represents the next generation of tools that will turn anyone into a data steward, allowing non-developers to take control of critical data flows within your business, organization or government agency.
Opening up data in machine readable format is not just for IT and developers anymore.
[<a href="/2013/10/12/from-extract-transform-amp-load-to-input-process-and-output-with-delray/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/10/12/access-interoperability-privacy-and-security-of-technology-will-set-the-stage-for-the-future-of-education/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/tag-cloud-education.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/10/12/access-interoperability-privacy-and-security-of-technology-will-set-the-stage-for-the-future-of-education/">Access, Interoperability, Privacy and Security Of Technology Will Set The Stage For The Future of Education</a></h3>
			<p><em>12 Oct 2013</em></p>
			<p>In 2010 when I started API Evangelist I saw the technological potential of APIs, but while the rest of the online space was focused on what APis could do for developers, I was focused on what APIs could do for the average person. APIs don't just open up access for developers, they open up access for end-users, introducing interoperability, data portability and ultimately tools that give them control over their own data, content and other valuable resources. This realization has been central to my mission at API Evangelist, which is about educating the masses about APIs. What is an API? Why are APIs important? I strongly feel that APIs empower end-users to make better decisions about which platforms they use, which applications they adopt, and gives them more ownership, control and agency in their own worlds. When you help an individual understand they can host their own Wordpress blog and migrate from the cloud hosted version of Wordpress, or migrate their blog from Blogger to Wordpress via APIs, you are giving the gift of web literacy. Leading technology platforms like Amazon, Google, eBay and Flickr have long realized the potential of opening up APIs and empowering end-users. Since then, thousands of platform providers have also realized that opening up APIs enables developers and end-users to innovate around their platform and services, and that there is much more opportunity for growth, expansion and revenue when end-users are API literate. Users are much more likely to adopt a platform and deeply integrate it into their personal or business lives, if they are able to connect it with their other cloud services, taking control and optimizing their information and work flow. Helping business owners, developers and end-users understand the potential that APIs introduce is essential to the future of education, and will be the heart of a healthy and thriving economy. There is a key piece of technology that reflects this new paradign and is currently operating and...[<a href="/2013/10/12/access-interoperability-privacy-and-security-of-technology-will-set-the-stage-for-the-future-of-education/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/10/11/how-to-defrag-your-brain-and-tech-career-in-november/"><img src="https://s3.amazonaws.com/kinlane-productions2/events/defrag-2013/DEFRAG-2013-2.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/10/11/how-to-defrag-your-brain-and-tech-career-in-november/">How To Defrag Your Brain and Tech Career In November</a></h3>
			<p><em>11 Oct 2013</em></p>
			<p>I spend the year going from city to city, attending conferences, meet-ups and hackathons--speakng, networking and doing the things that makes my world go around. Every November I find myself a little spun out from the year and need to Defrag my brain, re-organize what I know and re-enforce the most meaningful relationships across my professional career. This is is done in Broomfield Colorado each November at the Defrag Conference. I arrive the evening before the conference at the Omni Interlocken Resort. It is late at night, the lobby is empty and I walk up to the counter and quickly get my room from the young lady running the desk. I turn around to head to the elevators and notice Brad Feld(@bfeld) sitting on the couch, lost in his phone. I spend some time engaging him about the latest trends in technology and investing and the current political climate in the country before I head off to bed. Where else do you get casual focus time with folks like Brad, then at Defrag? In the morning I wake up, grab some coffee and pastries and head for the main stage. As I walk in I feel like I've walked into a 1980's rock concert as I'm blasted a classic rock soundtrack from Tom Petty to AC/DC. I grab a seat in the dark and as I'm waiting for keynotes to start I notice I've accidently joined a table of the cloud computing mafia ranging from Alex Williams(@alexwilliams)&nbsp;of TechCrunch to cloud pundit Ben Kepes (@benkepes) of Diversity.net.nz. The morning moves by fast with a engaging array of talks from Amber Case of Esri, to Paul Kedrosky of Bloomber and Kauffman Foundation. After they are done, I roll out of the main stage and get in line for some lunch, which is the only conference lunch I will actually eat, as the Omni Interlocken catering is not the normal fare. As soon as I'm done I weave...[<a href="/2013/10/11/how-to-defrag-your-brain-and-tech-career-in-november/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/10/09/the-backend-as-a-service-space-is-maturing/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/baas-trends.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/10/09/the-backend-as-a-service-space-is-maturing/">The Backend As A Service Space Is Maturing</a></h3>
			<p><em>09 Oct 2013</em></p>
			<p>
I just got off the phone with a new Backend as a Service provider BizMobify, who is looking to deliver BaaS services to the enterprise.  The timing for the call couldn't be better, as I'm updating up my BaaS white paper this week, and one thing I'm expanding is looking at it through the enterprise lens.
As I dust off my research on BaaS I'm re-visiting my BaaS research site and re-watching the BaaS Panel from API Strategy &amp; Practice in NYC last February. This is helping me understand where the space what last winter and early spring.
As we move into the last quarter of 2013 I'm reminded of how fast the BaaS space is maturing. There are new providers continuing to enter the space, but I also see continued energy and releases from the BaaS leaders like Parse and Kinvey.
Kinvey, AnyPresence and StackMob will all be at #APIStrat on October 24th and 25th in San Francisco. While we won't be having another BaaS focused panel, they will be sharing their insight on the space in separate sessions.
From my vantage point I see BaaS providers being a key channel for API providers to reach developers in 2014, and definitely an area I will keep tracking on and working to understand.
If you are an API provider, you should be paying attention to BaaS providers, because they offer a channel for your API resources to reach developers. Developers may not care about your resource all by itself, but when bundled with the best of breed BaaS tools as well as other API resources, it may look much more appealing.
[<a href="/2013/10/09/the-backend-as-a-service-space-is-maturing/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/10/01/can-we-depend-on-federal-government-apis/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/data-gov-shutdown.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/10/01/can-we-depend-on-federal-government-apis/">Can We Depend On Federal Government APIs?</a></h3>
			<p><em>01 Oct 2013</em></p>
			<p>
The federal government shutdown today. At the Department of Veterans Affairs we are still working through next monday, so it was business as usual today for me.
One of my projects is preparing a list of APIs and data assets for a hackathon in NYC that is focusing on developing apps for veterans, called The Feast. My goal is to aggregate a list of as many usable assets as possible so developers don't have to go to multiple locations to locate them.
Many of the assets are available at VA.Gov, but there are others that I knew were on Data.Gov. As soon as the page loaded at Data.Gov, I got a friendly message:
Due to the lapse in federal government funding, this website is not available. We sincerely regret this inconvenience.
Basically, no data for me. No datasets for download, no APIs allowing me access information.  Which leaves me questioning the entire reason I'm in government. I came here to open up data and build APIs, then convince you to use them in your applications, widgets, visualizations and other innovation projects.
It is my way to find a way around ANY obstacle. There is nothing that will stop me. I will keep working no matter what. However, this is a pretty big obstacle, something that makes me question my faith in APIs in government. I can deal with just about anything, but if I evangelize APIs, that can be turned off at any point, for an unknown amount of time? Ummm&hellip;WTF? Unnacceptable!!
There is always a work-around. I will find a solution that will work for me(and you), but it leaves me questioning quite a bit about this API evangelism from within the federal government.
[<a href="/2013/10/01/can-we-depend-on-federal-government-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/09/29/providing-access-to-services-that-help-americans-with-their-food-security-using-apis/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/the-ohana-api.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/09/29/providing-access-to-services-that-help-americans-with-their-food-security-using-apis/">Providing Access To Services That Help Americans With Their Food Security Using APIs</a></h3>
			<p><em>29 Sep 2013</em></p>
			<p>
I had the pleasure to connect with the talented Code for America fellow, Moncef Belyamani(@monfresh)&nbsp;this week and talk about a very meaningful API project, called the Ohana API.
"The Ohana API is a project from the San Mateo County team of Code for America fellows that is aiming to create open access to community social services, with an initial emphasis on food security."
I couldn't' think of a more important use of APIs, than making sure people can find the soical services they need--especially services that ensure people are fed.
I'm also impressed with the approach of Code for America in giving Github a central role in the project. The API project, the API wrapper in Ruby and a cool API to PDF generator are all available on Github.
The Oahana API is only in alpha, they are looking for people to help the Code for America team take it to the next level with approaches to keep the data current and developing an SMS interface.
The Ohana API project itself, and the model used by Code for America, provides an important blueprint for how technology can be applied, and make a difference in our daily lives in a scalable way.
This type of work keeps me coming back back and working on API Evangelist, even after three years of covering a space that often leaves me pretty discouraged.
[<a href="/2013/09/29/providing-access-to-services-that-help-americans-with-their-food-security-using-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/09/25/start-with-your-public-website-when-you-begin-your-inventory-for-data-apis/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/bw-barcode.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/09/25/start-with-your-public-website-when-you-begin-your-inventory-for-data-apis/">Start With Your Public Website When You Begin Your Inventory For Data APIs</a></h3>
			<p><em>25 Sep 2013</em></p>
			<p>I'm working on taking inventory of data assets at the Department of Veterans Affairs. While eventually this will include private data assets, in the beginning we are focusing on data that can be made public without being worried about personally identifiable information or health information.
There are a lot of hurdles to get over, including educating people about what is a data asset, as well as the process of identifying, preparing, publishing and listing the data assets in a publicly available marketplace.
We are at the point where everyone is looking around for potential data assets that can be included in the current open data inventory cycle.  It is proving to be a challenge for folks to find datasets they can include. To help the process along I've set my focus on the public website, va.gov, and finding data that has already been published in various formats on the site.
Data and content is already available on the public web site represents the low hanging fruit when it comes to identifying open data that should be made available in machine readable formats like JSON and XML as well as available in APIs.
This approach works in both the public and private sector. If you feel it is valuable enough to have on your already, it is a perfect candidate to make available as open data or API.  Once you get the hang of identifying, processing and publishing this open data and APIs, you can start the much more difficult process of looking for harder to identify data sets and resources.
[<a href="/2013/09/25/start-with-your-public-website-when-you-begin-your-inventory-for-data-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/09/25/github-can-be-the-post-and-put-layer-for-federal-government-apis/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/bw-government.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/09/25/github-can-be-the-post-and-put-layer-for-federal-government-apis/">Github Can Be the POST and PUT Layer For Federal Government APIs</a></h3>
			<p><em>25 Sep 2013</em></p>
			<p>I'm playing with different approaches to rapidly design, develop, deploy and manage APIs using Github. While about 90% of what I'm building runs on Github, there is still about 10% that runs on Amazon EC2. There are just some aspects of a proper API interface that I can't do on Github. My recent prototypes use swagger and allow for much of the API interactions to occur via Github. I a working to carve off any elements I can from the architecture, including using JSON files stored at Github as the database backend for the API. If you look at my recent Dev Hub prototype, you can browse the API interface, thanks to Swagger, and when you make API calls to the endpoints via Amazon EC2, the REST interface is just acting as a search, filter and REST facade for the JSON files that are actually stored on Github--eliminating the need for a database backend. This approach allows me to develop light-weight REST facades for JSON data stores as well as for other APIs. I'm playing around with different ways that I can use this thought process to push government APIs to the next level, and building on my earlier thoughts today on the need for writable APIs in federal government. I'm evolving earlier designs I have in my archives of BeyondGET or OtherVerbs, an Augmented API Platform, where I'm looking to provide an augmented layer that makes existing APIs writable. Marrying these legacy thoughts with my current approaches using Github plus EC2 APIs, I strongly feel that Github has huge potential for being a POST, PUT and DELETE layer for federal government APIs. Using a REST facade on EC2 I can easily proxy existing government APIs, then using a swagger definition I could seamlessly weave in a POST, PUT and DELETE layer that would write to JSON files hosted at Github using the Github API. I'm in early thoughts on this work, and will start...[<a href="/2013/09/25/github-can-be-the-post-and-put-layer-for-federal-government-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/09/25/a-huge-need-for-writeable-apis-in-government/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/bw-pen-hand.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/09/25/a-huge-need-for-writeable-apis-in-government/">A Huge Need for Writeable APIs in Government</a></h3>
			<p><em>25 Sep 2013</em></p>
			<p>I asked a question on Twitter last night: Any examples of government APIs that allow for write (POST, PUT, PATCH) capabilities? I'm looking for existing agencies who have implemented already. While I was asking for examples of APIs, by motivations were specifically about finding an example of terms of use for a government writable API. After spending some time looking and listening to peoples responses, there isn't much in the wild when it comes to writable government APIs, however it is clear that there is a huge demand for writable APIs, and a lot of opinion that this could be the thing that changes how government operates for the better. The best examples that my followers pointed me to was with the Open 311 iniative: Washington, DC Chicago, IL Montgomery County MD There was another DoD API that allows users to POST information, and then only allows them to only update their own information, but wasn't exaclty the open write I was looking for. Clause Logic Service Clay Johnson (@cjoh), the author of The Information Diet, has a great post on how writable APIs can help fix the government procurement process. Demonstrating one solid example of how government could be more efficient through the sensible use of APIs. The biggest case study I can find of writable APIs in federal government was the IRS Modernized e-File (MeF) system, but the goal of this research is to find an existing example of terms of use for writable APIs in the federal government, and after looking through all the e-File documentation I couldn't find any terms of use that covered developers submitting tax forms to the IRS via MeF web services. I will spend more time looking, I'm sure they are in there somewhere. If you know of any examples of of the federal government using APIs and allowing the public to to submit data, content or forms through APIs, please let me know. It is something...[<a href="/2013/09/25/a-huge-need-for-writeable-apis-in-government/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/09/24/excel-and-csv-conversion-to-json-and-xml-in-javascript-that-runs-100-on-github/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/csv-converter-github.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/09/24/excel-and-csv-conversion-to-json-and-xml-in-javascript-that-runs-100-on-github/">Excel and CSV Conversion to JSON and XML in JavaScript That Runs 100% on Github</a></h3>
			<p><em>24 Sep 2013</em></p>
			<p>When it comes to building applications within the federal government, there are numerous road-blocks to innovation. I'm currently assisting with the inventorying of open data assets at the Department of Veterans Affairs, as well as across numerous other federal agencies. The two biggest bottlenecks of this process are: File Conversion - Converting Excel and CSV data assets into JSON and XML File Storage - Where do you put data assets once you have available in CSV, JSON and XML When I hit these road-blocks, it is my nature to find quick and dirty technical solutions (hacks) to get around these obstacles, and do it in a way that can be taught to others, allowing them to overcome these challenges in their own worlds. The solution I've employed involved discovering and forking of a kick ass data conversion tool called Mr. Data Converter, and quickly the tool retrofitted with some of my own enhancements: HTML5 File API - Allows me to acces file content without server side technology. oAuth.io - Dead simple, client side oAuth for Github and other platforms. Github.js - A JavaScript API wrapper for Github, enabling client-side interaction. I quickly stripped down Mr. Data Converter to have only the features I desired, added a file upload capabilities that used the File API to access CSV files without a server side layer, then after authenticating with oAuth.io via Github, I used Github.js to post the original CSV and converted JSON or XML files directly to the same Github repo that the file conversion application runs in. This approach allows me to run the Excel / CSV conversion app 100% on Github using Github Pages--an blueprint that allows anyone to fork and run within their own Github accounts. I'll spend more time hardening the code, and documenting it, to make it easier to use, and empower anyone to use in their own open data inventorying initiatives. You can see it in action live on Github...[<a href="/2013/09/24/excel-and-csv-conversion-to-json-and-xml-in-javascript-that-runs-100-on-github/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/09/22/html-to-markdown-api/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/fuck-yeah-markdown-api.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/09/22/html-to-markdown-api/">HTML to Markdown API</a></h3>
			<p><em>22 Sep 2013</em></p>
			<p>
I'm slowly getting my blog world in order after the move from my own proprietary blogging platform to using Github + Jekyll hosted using Github Pages.
I've been using HTML pages for blog posts at API Evangelist, Kin Lane and other blogs, with 3 years of blog posts at API Evangelist and about 6 years at Kin Lane. There is a lot of legacy content to move from my EC2 driven blogs to Github.
Every time I would try and publish the posts as is, Github would reject my commit when it hit posts that didn't have compliant HTML, making it near impossible to publish everything.  I was trying to clean up as much of it as I could, but it wasn't good enough.  I needed a way to convert to markdown and clean house.
Thankfully, Ben Balter(@BenBalter) from Github recommend a very cool API called Fuck Yeah Markdown, which takes my legacy HTML pages and converts it to much cleaner markdown.
When I first started using Jekyll I wasn't really sold on markdown, in my mind I didn't mind hand rolling my HTML tags--I have been doing it for years. After Ben suggested I use markdown in my newly minted Github Jekyll projects I started to see the benefits.  It is way easier to manage content that is being published as a blog, page or otherwise when it is markdown.
I am just finishing up converting all of API Evangelist and Kin Lane to use markdown, and will be using the Fuck Yeah Markdown API to convert blog posts from HTML generated in my blog editor to markdown before publishing to Github.
[<a href="/2013/09/22/html-to-markdown-api/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/09/15/irs-modernized-efile-mef-a-blueprint-for-public-amp-private-sector-partnerships-in-a-21st-century-digital-economy-draft/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/bw-irs-logo.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/09/15/irs-modernized-efile-mef-a-blueprint-for-public-amp-private-sector-partnerships-in-a-21st-century-digital-economy-draft/">IRS Modernized e-File (MeF): A Blueprint For Public &amp; Private Sector Partnerships In A 21st Century Digital Economy (DRAFT)</a></h3>
			<p><em>15 Sep 2013</em></p>
			<p>Download as PDF The Internal Revenue Service is the revenue arm of the United States federal government, responsible for collecting taxes, the interpretation and enforcement of the Internal Revenue code. The first income tax was assessed in 1862 to raise funds for the American Civil War, and over the years the agency has grown and evolved into a massive federal entity that collects over $2.4 trillion each year from approximately 234 million tax returns. While the the IRS has faced many challenges in its 150 years of operations, the last 40 years have demanded some of the agency's biggest transformations at the hands of technology, more than any time since its creation. In the 1970s, the IRS began wrestling with the challenge of modernizing itself using the latest computer technology. This eventually led to a pilot program in 1986 of an new Electronic Filing System (EFS), which aimed in part to gauge the acceptance of such a concept by tax preparers and taxpayers. By the 1980s, tax collection had become very complex, time-consuming, costly, and riddled with errors, due to what had become a dual process of managing paper forms while also converting these into a digital form so that they could be processed by machines. The IRS despereatly needed to establish a solid approach that would enable the electronic submission of tax forms. It was a rocky start for the EFS, and Eileen McCrady, systems development branch and later marketing branch chief, remembers, &ldquo;Tax preparers were not buying any of it--most people figured it was a plot to capture additional information for audits." But by 1990, IRS e-file operated nationwide, and 4.2 million returns were filed electronically. This proved that EFS offered a legitimate approach to evolving beyond a tax collection process dominated by paper forms and manual filings. Even Federal Agencies Can't Do It Alone Even with the success of early e-file technology, the program did not get the momentum it needed without...[<a href="/2013/09/15/irs-modernized-efile-mef-a-blueprint-for-public-amp-private-sector-partnerships-in-a-21st-century-digital-economy-draft/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/09/14/api-monetization-in-the-internet-of-things-nordic-apis/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/tag-cloud-internet-of-things.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/09/14/api-monetization-in-the-internet-of-things-nordic-apis/">API Monetization In The Internet of Things @ Nordic APIs</a></h3>
			<p><em>14 Sep 2013</em></p>
			<p>I have a panel this week at Nordic APIs called Business Models in an Internet of Things, with Ellen Sundh (@ellensundh) of Coda Collective, David Henricson Briggs of Playback Energy, Bradford Stephens of Ping Identity and Ronnie Mitra(@mitraman/a&gt;) of Layer 7 Technologies. My current abstract for the panel is: As we just begin getting a hold on monetization strategies and business models for APIs delivering data and resources for mobile development. How will we begin to understand how to apply what we have learned for the Internet of Things across our homes, vehicles, sensors and other Internet enabled objects that are being integrating with our lives. In preparation for the event I am working through my thoughts around potential monetization strategies and business models that will emerge in this fascinating adn scary new world where everything can be connected to the Internet---creating an Internet of Things (IoT). Where Is The Value In The IoT? When it comes to monetizing APIs of any type, there first has to be value. When it comes IoT where is the value for end-users? Is it the device themselves, is it the ecosystem of applications built around a device or will it be about the insight derived from the data exhaust generated from these Internet connected devices? Evolving From What We Know After almost 10 years of operating web APIs, we are getting a handle on some of the best approaches to monetization and building business models in this new API economy. How much of this existing knowledge will transfer directly to the IoT? Freemium, tiered plans, paid API access and advertising--which of these existing models will work, and which won't. Another existing model to borrow from when it comes to IoT is the telco space. The world of cellphone and smart phones are the seeds of IoT and one of the biggest drivers of the API economy. How will existing telco business models be applied to the world of...[<a href="/2013/09/14/api-monetization-in-the-internet-of-things-nordic-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/09/13/using-excel-for-crowdsourced-data-gathering-and-reporting/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/ramps-to-play-components-600.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/09/13/using-excel-for-crowdsourced-data-gathering-and-reporting/">Using Excel For Crowdsourced Data Gathering And Reporting</a></h3>
			<p><em>13 Sep 2013</em></p>
			<p>
I was impressed with some of the data journalism behind the recent NPR story, Playgrounds For Everyone, a community-edited guide to accessible playgrounds.
The story is definitely an important one, but it is the data behind it I think is significant to highlight. You can download the data of the 1700 playgrounds in 20 different cities in a CSV and JSON format. Something I think is ripe for an API, by the way.
Another interesting aspect is they are asking for submissions from the public, and they even provide a template Google spreadsheet, providing a framework for how the public should gather and organize data into a standard way, that NPR can import.
While I think this project could go further, I think it is an excellent example of using data journalism in public reporting.  The only suggestions I have is making the project a Github repository so the story, JSON and CSV can be versioned, forked and downloaded much more easily.
I think Google Spreadsheets and Excel templates are a perfectly acceptable way to gather data from the public and 3rd party sources. It allows you to solicit data from others in a format that they understand, while still making sure it is structured enough to easily merge with a master database.
Additionaly, it would be pretty easy to add the ability for users to email their spreadsheets to a central email address, and programmatically convert to JSON, and CSV, then commit to the Github repository that contains the master JSON and CSV files.  This way the repository administrator could accept or deny submissions as a pull request.
I'm enjoying seeing these scrappy spreadsheet, CSV and JSON solutions to data storytelling. Even if they aren't perfect I like seeing people play with different approaches, in hopes of finding an approach that works for them.
Lots to learn from. Nice work NPR.
[<a href="/2013/09/13/using-excel-for-crowdsourced-data-gathering-and-reporting/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/09/13/the-perils-of-api-transport-over-the-public-internet/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/bw-danger.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/09/13/the-perils-of-api-transport-over-the-public-internet/">The Perils Of API Transport Over The Public Internet</a></h3>
			<p><em>13 Sep 2013</em></p>
			<p>George Reese has a very interesting post from last week over at O'Reilly. It is about an earlier post he did on the unpublished Tesla REST API.&nbsp;I'll let you read the post, "The Myth of the Private API"--I highly recommend it. Reese talks about the mistakes made by Tesla, Phillips and other Internet of Things companies, when they take advantage of the power of web APIs, intending them to be private, but do not put any thought into what happens when you deploy APIs using the public without securing your API endpoints from unintended use. I find a particular statement he made, fascinating: I sincerely believe that ultimately there is no such thing as a private API for consumption over the public Internet. After reading his post, I have to agree. I think many technology companies are just considering the Internet to be some sort of constant, magic transport layer for anything we want to use it for. I think this can be true to a point, but as the Intenret matures, we have slow down a bit and consider deeply the impact of our actions, and the way we use Internet enabled technology. I wrote about a piece last week, which was about the first FTC case against an Internet of Things manufactuer, camera maker TrendNet--where much like Tesla, they took no considerations for the fact they were using the open Internet to drive their technology, and more importantly no thought regarding the privacy of their consumers. The world of APIs fascinates me. It reminds me of the bug zappers, where we are attracted by the openness and power of web APIs, but as you get closer and closer to the API light, you can easily get burned or zapped by the very thing that drew you in. I strongly believe in the power of web APIs, but I think there will be a lot of unintended consequences from opening up data, resources and...[<a href="/2013/09/13/the-perils-of-api-transport-over-the-public-internet/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/09/13/a-masking-scrubbing-anonymizing-api/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-question-mark.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/09/13/a-masking-scrubbing-anonymizing-api/">A Masking, Scrubbing, Anonymizing API</a></h3>
			<p><em>13 Sep 2013</em></p>
			<p>In government there is a fear of exposing public data via APIs--rightfully so. This is not just a government concern, it exists in all industries within each an every business and organization. We all possess private data, and when opening up API driven resources, we need to make sure none of this is exposed in un-desired ways. I find it hard to believe, that after almost 10 years of public APIs, there isn't a reasonable solution to masking, scrubbing and anonymizing data that is made available via APIs. I wrote about research into finding a solution at UC Berkeley a while back, but to date I have not seen any real solutions to this problem yet. I was talking with another Presidential Innovation Fellow (PIF) the other day about possible solutions for making sure Personally Identifiable Information (PII) doesn't get exposed via government APIs. Afterwards, I got to thinking about possible API options, and I don't think it would be that difficult to get started with a basic solution. My thoughts are, that you could provide a simple API proxy, that would terminate requests from any Swagger defined APIs and easily iterate through each value and apply a series of regular expressions against it to look for common PII or other data that shouldn't be exposed. The proxy could automatically replace with template values like John or Jane Doe for names, 1234 Street for addresses, etc. API providers could set a list of areas they are concerned about exposing with the API proxy configuration, and it would enforce all filtering required. The proxy could also look for other common patterns, and make recommendations of other areas that could be masked, scrubbed or anonymized that the API provider didn't consider. Technically it sounds like a pretty simple solution, that could get smarter and faster over time at identifying sensitive information, to better serve API providers. This type of proxy could be default in healthcare, education and...[<a href="/2013/09/13/a-masking-scrubbing-anonymizing-api/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/09/09/the-spreadsheet-will-play-a-central-role-in-the-api-space/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/spreadsheet-basic.gif" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/09/09/the-spreadsheet-will-play-a-central-role-in-the-api-space/">The Spreadsheet Will Play A Central Role In The API Space</a></h3>
			<p><em>09 Sep 2013</em></p>
			<p>
The more I immerse myself in government, I'm reminded of the central role that the spreadsheet plays in our business and government operations--primarily Microsoft Excel, but also in some circles, the Google Docs Spreadsheet.
While it is government that is bringing the spreadsheet front and center for me again, I'm reminded of days while working on SAP events and working on budgets, sessions and registrations lists that were past around in complex series of spreadsheets. After this I go further back in time, to the early 2000s when I worked in the non-profit sector, where database management was completely done in a myriad of group and individual spreadsheets.
Beyond the spreadsheet being the central villain in global operations, I'm seeing it emerge as a character across the API landscape with Octobpart Electronics providing bill of materials management in Microsoft Excel that is driven from their API, CrunchBase adding 13,689 Companies and 1,462 venture rounds as an Excel download, and Twilio allowing users to make calls and send SMSs from spreadsheets.
As much as us API geeks would love for people to deploy clean, sensibly designed APIs, that meet our visions of the future of APIs--the reality is that much of the worlds data is managed via the spreadsheet.  If we are truly going to deliver on the API economy, we have to consider the spreadsheet.
This spreadsheet bridge is not just about allowing users to publish data via APIs from spreadsheets, but also enabling every day users to cosume valuable API driven data and resources from their native spreadsheet. It has to be a two way street.
Whether we like it or not, the spreadsheet will continue to play a central role in the API space, and represents the future of acessing valuable corporate, non-profit and government resources for everyone.
[<a href="/2013/09/09/the-spreadsheet-will-play-a-central-role-in-the-api-space/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/09/07/loosely-coupled-services/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/bw-gears.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/09/07/loosely-coupled-services/">Loosely Coupled Services</a></h3>
			<p><em>07 Sep 2013</em></p>
			<p>Building off a similar topic this week, I was asked to dumb down or explain what I meant by "Loosely Coupled Services", alongside a "Library of Modular Services". In this case, loosely couple means independent technical and data services, in the same way you would access services that people are familar with in the mainstream business world. Think of the services you would access and put to use around your home. Common household services like electrician, plumber, tile layer and sheet rocker. These each represent independent services you would access to tackle a home improvement project. While there is some overlap in these services, generally each service technician specializes in one area, doing one thing and doing it well. The slight overlap between an electrician and plumber would be considered the "loosely coupled" part, where there are dependencies between each specialized service, ie. the plumber needs an electrician to wire the dishwasher after he /she plumbs it. The concept of loosely coupled services works well when it comes to APIs. The goal is to define APIs to do one thing and do it well, establishing a library of modular services that can be used across a company and organization, its partners as well as provide public access to the most commonly requested resources. A simple example might be product catalog. You can deliver a web service that allows for accessing, searching and pulling details of products a company offers. All the web service knows how to do is find, list and provide info on products, nothing else. This product catalog will have loosely coupled dependencies with other inventory, shopping cart and coupon services, but in the end its very specialized. Any organization or company will have a wide variety of potential services that can be defined. It is best to define these in as granular of a way as possible, keeping them entirely independent of other services, except for slightly coupling that allow them to...[<a href="/2013/09/07/loosely-coupled-services/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/09/07/library-of-modular-services/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/universal-library-sign.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/09/07/library-of-modular-services/">Library of Modular Services</a></h3>
			<p><em>07 Sep 2013</em></p>
			<p>I'm always looking for simpler and more concise language to describe API, while writing stories and white papers for my audience. I recently used the phrase "library of modular web services", in a presentation outline at the Department of Veterans Affairs (VA). This white paper was intended for a non-technical, state government audience, and my collaborator on the presentation asked if I could dumb this phrase down a little for the audience, providing a simpler explanation. In this case, I think certain phrases get co-opted by the developer and IT crowd, borrowing from the physical world, resulting in them having a perceived technical meaning, but when in reality they are still very rooted in their past, and can be easily explained by taking users back to their previous meanings. One perfect example of this is the phrase, a "Library of Modular Services". Think of each book, in a physical library as an analogy of a single API service. Much like when building an application on top of API services, when you are developing a research paper in a library, you need a multitude of resources to bring your paper together. When you visit the library to conduct your research you can browse the library directory, find a wide variety of books you will need. Early on you will be testing out many of these books, then setting aside the books that do not deliver the value and information you are looking for. When you find the specific resources you need, this is when the modular approach comes into play. For example, if you need a book on a specific artist from history, you aren't required to check-out the entire art history section, or even check-out all impressionists artists, you can go for a very specific artist like Monet or pick and choose from the impressionist resources you need. Using this library analogy for API services works very well. As a company or organization, instead of...[<a href="/2013/09/07/library-of-modular-services/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/09/05/i-am-always-amazed-at-how-little-people-understand-about-github/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/bw-github.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/09/05/i-am-always-amazed-at-how-little-people-understand-about-github/">I Am Always Amazed At How Little People Understand About Github</a></h3>
			<p><em>05 Sep 2013</em></p>
			<p>I work with some seriously smart people on a day to day basis, virtually across the web, and in person on some of the projects I'm working on in federal government. Much like APIs, Github is fast becoming a ubiquitous technology that people are using to manage their community, code, documents and much more. Several times each week I encounter situations where Github is referenced as a potential platform for managing a new project, or cited wen talking about how to solicit feedback, engagement and participation across existing projects. I'm always amazed that in about 75% of these Github conversations, someone chimes in about how Github wouldn't be appropriate because of the barrier to entry for many users. I find this barrier to entry perspective very interesting. Many of the uses of Github require no knowledge of, or the need to touch code. One meeting in particular, was about providing feedback on the next steps of data.gov, when a participant referenced that for users who weren't technical, but wanted to provide feedback, they should use a separate forum to submit feedback. To understand this I pulled up the data.gov site, clicked on link to Github repository behind the project, clicked on issues tab, then submit new issue. A text box came up much like it would on Facebook or the proposed forum. In reality there are no technical hurdles for these users, except their own perception that Github is a social coding site for programming. This type of perception is a holdover from the last 30 years of IT and developers making sure they were keepers of the knowledge and instilling fear in users, that treading in this realm is only for the brave, often male world of developers, database and IT folk. In the world of software as a service (SaaS) and APIs, this is no longer a reality, but the perception is still there. As I work hard to evangelize API tools and...[<a href="/2013/09/05/i-am-always-amazed-at-how-little-people-understand-about-github/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/09/05/building-internet-of-things-products-you-better-secure-it-says-the-ftc/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/trendnet-camera.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/09/05/building-internet-of-things-products-you-better-secure-it-says-the-ftc/">Building Internet of Things Products? You Better Secure It, Says the FTC</a></h3>
			<p><em>05 Sep 2013</em></p>
			<p>
The Federal Trade Commission(FTC) just settled a case with web-enabled camera maker TRENDnet, signaling the government agency's first action against an Internet of Thing's company.
The FTC's complaint alleges that TRENDnet was labeling their cameras as secure, when in reality the camera had faulty software that left them open to online viewing and audio access to anyone who had the Internet address of the camera.
The FTC / TRENDnet case is the first, in what I predict is a future filled with security and privacy violations by Internet of Things products and companies.  As we blindly race forward with the exciting Internet of Things, many companies will disregard the security of their hardware and software, just like TRENDnet did.
Hopefully as an industry we can help make sure this doesn't get out of hand, and don't require the federal government to police the situation. As technology providers, we need to make sure the software, hardware and APIs that drive the Internet of Things is properly secured, protecting our customers and the industry.
[<a href="/2013/09/05/building-internet-of-things-products-you-better-secure-it-says-the-ftc/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/09/05/api-of-api-keyword-searches/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/bw-magnifying-glass.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/09/05/api-of-api-keyword-searches/">API of API Keyword Searches</a></h3>
			<p><em>05 Sep 2013</em></p>
			<p>
I was working on series of API endpoints this week, each of them had a basic search parameter, allowing you pass a keyword to filter your API request.  Pretty standard stuff.
After deploying the APIs I wanted to make sure I tracked what people were searching for, so I could use in reporting and other tools. Then I got to thinking, that it would make sense to go ahead and launch an API of API search queries, allowing other users to be able to discover and benefit from insights derived from other API users searches.
Just a random thought as I'm playing around more with APIs in government. I definitely like the stimulation I get from designing, deploying and evolving APIs at my new gig, in addition to my existing monitoring of the API space.
[<a href="/2013/09/05/api-of-api-keyword-searches/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/09/04/am-i-going-to-see-you-nordicapis-in-sweden-september-18th-amp-19th/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/nordic-apis-logo.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/09/04/am-i-going-to-see-you-nordicapis-in-sweden-september-18th-amp-19th/">Am I Going to See You @NordicAPIs in Sweden, September 18th &amp; 19th?</a></h3>
			<p><em>04 Sep 2013</em></p>
			<p>There is a growing number of API conferences going on this year in the US, but the hunger for API knowledge isn't just something going on in this country, we are seeing a demand for API information and conversation growing internationally. One place that is exploding is in Europe and specifically in the Scandinavian region, and there is one must-go-to event that is driving the API conversation--the Nordic API Conference, September 18th and 19th in Stockholm, Sweden. I will be heading out for the conference and giving a talk I'm calling "The Politics of APIs is the Future", my current abstract is: We have found the right balance of technology for APIs, using simple lightweight protocols, built on HTTP. The business of APIs around good documentation, marketing and support to developers and monetization strategies are being proven. The next challenge we face in the API space will be around terms of use, privacy, deprecation and security. In addition to my talk, I will be moderating a panel on the Internet of Things, but specifically on business models, with Ronnie Mitra, Bradford Stephens, David Henricson Briggs and Ellen Sundh: As we just begin getting a hold on monetization strategies and business models for APIs delivering data and resources for mobile development. How will we begin to understand how to apply what we have learned for the Internet of Things across our homes, vehicles, sensors and other Internet enabled objects that are being integrating with our lives. The Nordic APIs is exactly two weeks away, so its not too late to buy a plane ticket and engage in API conversations with global thought leaders fromt the space, in beautiful Stockholm. I've never been to Sweden and looking forward to going. I get really pumped by the passion and energy for APIs, interoperability and opening up government businesses outside the United States. If you can make time, and afford the trip, I look forward to seeing you in...[<a href="/2013/09/04/am-i-going-to-see-you-nordicapis-in-sweden-september-18th-amp-19th/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/09/02/private-sector-sharing-the-load-through-government-apis/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/bw-irs-logo.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/09/02/private-sector-sharing-the-load-through-government-apis/">Private Sector Sharing The Load Through Government APis</a></h3>
			<p><em>02 Sep 2013</em></p>
			<p>When it comes to APIs, people respond to stories about real world examples, even more than solid technological implementations. If you can demonstrate how APIs are actually providing a solution, you can reach more people than just talking about the technological nuts and bolts. With this in mind I'm working through telling stories around how the IRS leveraged web services to incentivize private sector to develop applications that would provide tax solutions for the every day tax payer. In my short year and half working for government I've heard the example of "TurboTax" used to describe an example of how the federal government can leverage technology to deliver partner driven solutions, and better serve the public. Obviously this is an example that resonates with leaders in government, but one that I think needs a lot more work to actually flush out the model more deeply, while keeping it as something that anyone can understand and is able to repeat in their own circles. The story of the IRS e-File program for developers is a important blueprint for how a forms driven federal government system, can deploy APIs and share the burden of delivering important civic services with the private sector. Describing this as a "Turbo Tax Solution", is an extremely simplified analogy, whereTurbo Tax is just one application within an ecosystem of private sector, trusted IRS partners. As with every other federal agency, the IRS faced the problem of modernizing its systems to keep up with current technologies, while also continuing to improve the US tax process, so that it would better serve americans, and make the massive federal agency more efficient, which resulted in the design of an e-File system, where tax professionals could submit electronic tax form filings via IRS systems. While a web-based approach to modernizing the IRS tax process is a large part of the evolution of the US tax process, it wasn't enough. The IRS isn't in the business of...[<a href="/2013/09/02/private-sector-sharing-the-load-through-government-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/09/02/baseline-for-federal-government-open-data-and-api-portals/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/bw-portal.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/09/02/baseline-for-federal-government-open-data-and-api-portals/">Baseline for Federal Government Open Data and API Portals</a></h3>
			<p><em>02 Sep 2013</em></p>
			<p>I have a whole list of projects around open data and APIs at the Department of Veterans Affairs (VA). Additionally I have numerous other open data and API projects I'd like to tackle across other federal agencies. As I do with other areas of my work, I needed a standardized way to stabilize the datasets and APis I will need for my projects, in the same way any open data and API provider should do for their consumers. To help support my work, and hopefully the work of others I wanted to create a baseline portal that I could use at the VA, for showing what is possible when hanging open datasets and APIs, in a full featured portal. The success of any open data and / or API portal starts with the technical building blocks, like data and APIs, but have a set of business and political building blocks that are essential to their adoption and growth. I've spent the last three years studying the business and politics of APIs. During these three years I've looked at almost 10,000 API developer portals, and I've established a base set of what I consider the building blocks of successful API portals, with a handful in which I consider essential to success. I've always wanted a simple API portal template that would reflect this research, and my new Developer @ VA&nbsp;portal&nbsp;is the first step towards achieving this. Developer @ VA is an early stage prototype, whcih I've built to satisfy this need of mine, specifically for my VA projects. I will be polishing this portal and replicating it as a single template that can be used for any API and / or open data portal. This portal exists purely as a Github repository and runs on Github Pages, using a Jekyll for managing its pages and blog. Everything else is HTML, CSS, Javascript and JSON, allowing it to be able to run on any server, including other...[<a href="/2013/09/02/baseline-for-federal-government-open-data-and-api-portals/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/08/28/pick-your-head-up-regularly-heads-down-is-good-but-being-aware-cannot-be-ignored/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/y-u-no-guy-why-u-no-pay-attention.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/08/28/pick-your-head-up-regularly-heads-down-is-good-but-being-aware-cannot-be-ignored/">Pick Your Head Up Regularly, Heads Down is Good, But Being Aware Cannot Be Ignored</a></h3>
			<p><em>28 Aug 2013</em></p>
			<p>One important thing I've learned while running API Evangelist, is the importance of picking your head up from your work on a regular basis, and tuning into the world around me. When you are running your API initiative it can be also be easy to go heads down coding, addressing technical issues, managing support channels and dealing with the general day-to-day, internal activity of running a company. Don't get me wrong, I'm big on going radio silent, closing the Gmail tab, shutting down TweetDeck, LinkedIn, Facebook, Google+, Skype and my other communication channels. Since I stopped using Google Reader to monitor feeds, and setup my own internal curation, I can easily tune out my API industry monitoring and curation for days sometimes. This is all intended to get shit done and reduce distractions. Even with my regular tuning out of the world and focusing on work, I make sure and pick my head up, turn on communication channels, read and curate blog posts and generally take a good look at the world around me. I've worked too hard, building up momentum with my content creation, search engine optimization and social media presence to let it all slide. I can coast for days, or even weeks, but if I drop the ball for too long, I will not only stop any forward motion and growth--I risk losing traction and quickly becoming irrelevant. My number one mission with the API Evangelist Network is to educate myself, then secondarily educate the masses about the API space. If I don't pick my head up regularly, tune into the API space and understand the latest trends, technologies and players--I'm doing myself a disservice, as well as the greater interest of the API industry, and whoever I work for. When running your company, make sure you find time to go heads down, focusing on your work, but make sure you pick your head up regularly and tune into your community, your...[<a href="/2013/08/28/pick-your-head-up-regularly-heads-down-is-good-but-being-aware-cannot-be-ignored/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/08/28/kicking-the-api-strategy-amp-practice-conference-into-full-gear/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/api-strategy-and-practice-san-francisco-october-23-24-25-half.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/08/28/kicking-the-api-strategy-amp-practice-conference-into-full-gear/">Kicking The API Strategy &amp; Practice Conference Into Full Gear</a></h3>
			<p><em>28 Aug 2013</em></p>
			<p>
While we officially launched API Strategy &amp; Practice, San Francisco edition back in May, we've been pretty quiet during the summer months. Well, now summer is coming to a close, and we are now less than 60 days away from the API community conversation that is #APIStrat.
To start ramping things up, I'm going to start showcasing the amazing line-up of speakers we have for the event, and giving the kick-ass sponsors who have stepped up to support the event, the "love" they deserve.
Early bird pricing has ended, but you have less than a month to get in on the mid range pricing. Don't miss out like so many did in February when #APIStrat New York City sold out--buy your tickets now.
Even with large number of speakers we have lined up, we still have some slots left open, and will be making some announcements of other big names to the lineup-so stay tuned.
I will be exploring the wide range of topics and tracks we have planned here on API Evangelist as well as the #APIStrat blog, so subscribe to our RSS feeds and tune in on Twitter for more details.
[<a href="/2013/08/28/kicking-the-api-strategy-amp-practice-conference-into-full-gear/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/08/27/the-api-space-often-seems-to-more-about-money-intellectual-property-and-competition-than-interoperability-sometimes/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/bw-greed.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/08/27/the-api-space-often-seems-to-more-about-money-intellectual-property-and-competition-than-interoperability-sometimes/">The API Space Often Seems To More About Money, Intellectual Property and Competition, Than Interoperability Sometimes</a></h3>
			<p><em>27 Aug 2013</em></p>
			<p>I used to think that the API space is resistant to defining standards around REST, data formats, webhooks, hypermedia, api definitions and other key areas of the space, because after the top down, strict structure of SOA, the community just wanted to let the space organically define the best approaches. The API world just seemed like a wild west of strong minded individuals, who had a sort of "markets will work it out" approach, and the best approach will win in the end. You know, kind of like the Amazon cloud API battle? By 2013, the only thing we've come to agreement on is around oAuth, and by many accounts that was a failure. I used to think that many of the bitter battles by the RESTafarians about API design, RESTfulness and Hypermedia were because these were very smart, stubborn folks trying to craft the best approach possible. After many years of advocating for open source tooling, open events in the space and sharing of common API design patterns, I don't think there is much goodwill for any of it, because companies are more interested in their intellectual property(IP), seeming competitive and ultimately making the most money and pleasing their VCs. Now don't get me wrong, there are some very fine companies, do good in the space. I'm not saying the entire sector has lots its way. However the majority of the vibe from major players is, we don't want to share design patterns, open tooling, work together to support industry events and gatherings, we will just do it all ourselves, keeping the IP and value for themselves. I understand I'm less interested in the whole business and VC aspect of this than many of you are, but I think APIs got their start in openness, collaboration and sharing in the spirit of transparency and interoperability. It seems like like after 10 years and finally getting some traction in the space, we are starting to...[<a href="/2013/08/27/the-api-space-often-seems-to-more-about-money-intellectual-property-and-competition-than-interoperability-sometimes/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/08/27/sitemap-for-apis/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/bw-telescope.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/08/27/sitemap-for-apis/">Sitemap for APIs</a></h3>
			<p><em>27 Aug 2013</em></p>
			<p>
When it comes to API discovery, as an industry we haven't been able to find a satisfactory technological solution yet. While I often feel the right approach hasn't emerged yet, I think we are just overlooking "good enough" solutions, because we are waiting for the holy grail of API discovery.
I can't imagine that indexing, search and discovery of the myriad of web APIs out there is that much harder than indexing, search and discovery of the billions of HTML documents available online.  Sure, when you are talking about programmatic interfaces, you need a little more precision, but I think us technologists are caught up our own beliefs that APIs should be perfect.
It would make sense that we adopt some evolution of the common sitemaps format, retrofit it to be JSON, accommodate open data catalogs, and allow for various API definitions in Swagger, I/O Docs or even API blueprint.  Sure these formats won't have the precision of an evolution of the precious WSDL, or some actually agreed upon standard, but it will get us over the hump we are in.
ProgrammableWeb is 8 years old now, and in 2013, we still don't have any next step, let lone an actual usable solution for API discovery? I just have a hard time believing this is a technological problem, that it is more the stubbornness of the leaders in the space to just take any meaningful step towards API discovery, and lead.
There isn't going to be any money in API discovery, so this isn't something a single startup can emerge to solve. It is something we will all have to discuss and play with until we can find something will get us to the next step, together.
[<a href="/2013/08/27/sitemap-for-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/08/27/oauth-101/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/OAuth2.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/08/27/oauth-101/">OAuth 101</a></h3>
			<p><em>27 Aug 2013</em></p>
			<p>With APIs beginning to enter the mainstream consciousness, it is time to spend more time educating the masses about OAuth. We've had plenty of conversations between two of the OAuth legs, provider and developer, but we now need to bring the third leg into the conversation--the user. First, what is OAuth? - An open protocol to allow secure authorization in a simple and standard method from web, mobile and desktop applications. Whether you like it or not, OAuth has become the industry standard for accessing resources, being served up via APIs, that are being consumed through desktop, web and the fast growing mobile space. OAuth Platforms &amp; Data Providers If you are an online platform, OAuth is something you need to understand. At a minimum, if you require users to establish an account, you need to consider allowing users to create their accounts and login in the future using other popular OAuth providers like Facebook, Twitter and Google. Next if you want to provide access to your platform user's data via an API, you need to take a deeper dive into OAuth, and consider establishing yourself as an OAuth provider. OAuth for Desktop, Web and Mobile Developers In 2013, if you are a developer, you are probably using APIs. OAuth has been very intimidating for developers for quite some time, but with the increased availability of quality OAuth clients, better implementations and educational materials from API providers, and standardized approaches by startups like OAuth.io--OAuth is something you shouldn't fear anymore. You need OAuth as a default tool in your developer toolbox. Everyday Online User Like the term API, OAuth is something that should be added to the vocabulary of every tech savvy user. You should understand that OAuth exists, and that it gives you the ability to create accounts and login to your favorite platforms without filling out endless new forms and sharing your passwords unnecessarily. The platforms you use daily, like Facebook, Twitter, LinkedIn...[<a href="/2013/08/27/oauth-101/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/08/25/api-testing-and-monitoring-finding-a-home-in-your-companies-existing-qa-process/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/bw-qa.jpeg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/08/25/api-testing-and-monitoring-finding-a-home-in-your-companies-existing-qa-process/">API Testing and Monitoring Finding A Home In Your Companies Existing QA Process</a></h3>
			<p><em>25 Aug 2013</em></p>
			<p>I've been doing API Evangelist for three years now, a world where selling APIs to existing companies outside of Silicon Valley, and often venture capital firms is a serious challenge. While APis have been around for a while in many different forms, this new, more open and collaborative approach to APis seems very foreign, new and scary for some companies and investors--resulting in them often very resistant to it. As part of my storytelling process, I'm always looking for ways to dovetail API tools and services into existing business needs and operations, making them much more palatable to companies across many business sectors. Once part of the API space I'm just getting a handle on is the area&nbsp;API integration, which includes testing, monitoring, debugging, scheduling, authentication and other key challenges developers face when building applications that depend on APIs. I was having a great conversation with Roger Guess of TheRightAPI the other day, which I try to do regularly. We are always brainstorming ideas on where the space is going and the best way to tell stories around API integration, that will resonate with existing companies. Roger was talking about the success they are finding dovetailing their testing, monitoring and other web API integration services with a company's existing QA process--something that I can see will resonate with many companies. Hopefully your company already has a full developed QA cycle for your development team(s), including, but not limited to, automated, unit and regression testing--something where API tests, monitoring, scheduling and other emerging API integration building blocks will fit in nicely. This new breed of APi integration tools don't have to be some entirely new approach to development, chances are you are already using APIs in your development and API testing and monitoring can just be added to your existing QA toolbox. I will spend more time looking for stories that help relate some of these new approaches to your existing QA processes, hopefully finding news...[<a href="/2013/08/25/api-testing-and-monitoring-finding-a-home-in-your-companies-existing-qa-process/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/08/24/with-apis-in-your-company-start-small-and-read-api-evangelist/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/bw-start.jpeg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/08/24/with-apis-in-your-company-start-small-and-read-api-evangelist/">With APIs In Your Company, Start Small And Read API Evangelist</a></h3>
			<p><em>24 Aug 2013</em></p>
			<p>I thoroughly enjoy the assortment of emails, LinkedIn messages and phone calls I get from people in the SMB and enterprise, letting me know the role my blog plays in them starting, cultivating and evolving their own API initiatives. I received once such call this week, from an unnamed individual, at an unnamed company, letting me know the role API Evangelist played in providing the information they needed to find success. Like many other companies who reach out to me, their efforts aren't to the point where they feel comfortable telling stories publicly, so I'm happy to keep anonymous, until they are ready. The stories that come out of these companies are all very similar. The API initiatives were started by single person, or small group of passionate individuals who start small, find safe and sensible wins, while keeping risk and failures to a minimum. They start with data and resources that are not mission critical, but still offer value to either internal, partner or public developers. These innovators usually start with a handful of trusted partners, keeping the experimentation very controlled in a safe environment, before opening up to a wider base of partners, and then when ready, to a self-service public audience. This approach allows API innovators to find small successes and report these wins to business leaders and stakeholders, before moving forward with other efforts. Taking this approach in small, iterative cycles, providing decision makers with the necessary reporting and education, allows for you to slowly change internal culture. API change does not happen overnight, and it is easy to fail if you try to go big in companies who aren't quite ready. I can't get enough of these stories, I can't wait until these program mature, where I can tell them publicly on the blog. Until then, remember that when you are starting with a brand new API initiative within your company, start small, find success, minimize risk, repeat and tell...[<a href="/2013/08/24/with-apis-in-your-company-start-small-and-read-api-evangelist/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/08/22/view-csv-and-tsv-data-files-in-table-views-directly-on-github/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/github-csv-table-view.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/08/22/view-csv-and-tsv-data-files-in-table-views-directly-on-github/">View CSV and TSV Data Files In Table Views Directly On Github</a></h3>
			<p><em>22 Aug 2013</em></p>
			<p>
Github is really doing some cool stuff to help open data folks manage and share their data.
They just launched the ability to render data from .csv (comma-separated) and .tsv (tab-separated) files as an interactive table, including headers and row numbering.  They even let you link to a specific row for sharing specific data from the file.
As I'm working on opening up government data, I'm pushing for agencies to use Github when publishing and sharing CSV, TSV, XML and JSON files. These kind of features really go a long way in helping me achieve my goals.
Make sure and also check out what Github has done around 3D models and geographic data, pretty cool stuff.
[<a href="/2013/08/22/view-csv-and-tsv-data-files-in-table-views-directly-on-github/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/08/22/to-the-audrey-watters-haters/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/audrey-kin-paris.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/08/22/to-the-audrey-watters-haters/">To The Audrey Watters Haters</a></h3>
			<p><em>22 Aug 2013</em></p>
			<p>I've had the joy of watching a lot of you bash on my girlfriend, from the misogynistic douche bags telling her to get back in the kitchen because she questions their technology startup, to the recent @FakeAudreyWatters Twitter account spending a good portion of their day mocking her. Audrey and I are very different personalities when it comes to expressing ourselves in an online environment, but we share one common thing--a passion for helping encourage meaningful dialogue about where we are going with this whole technology roller coaster. Audrey is extremely passionate about education and where we are going with the education of our kids, and how we are applying technology in the classroom. If she is critical of your startup, idea or otherwise, you may not like it, but there might actually be a reason behind it--why don't you engage her in dialogue about it? She spends at least 12 hours a day, 7 days a week, researching, writing and stressing over her work(unpaid). I spend every moment with her and I see how much thought she puts into all of this. She is a very positive person, and extremely intellectually stimulating to be around, which is why I'm with her. Together, as a team we have achieved some amazing things in the last three years. I strongly believe Audrey and I have positively impacted the online world by helping folks think critically about education, and across numerous other industries through analysis of APis. I depend on Audrey to bounce ideas off, ranging from oAuth to API terms of use. API Evangelist would not exist without her. When I was first with Audrey she often frustrated me with her confrontational approach, but over the course of four years, I have found it to be essential to what I do. She battles me on ideas, sometimes to the point where we both stomp off, but in every case, I've been able to apply her critical...[<a href="/2013/08/22/to-the-audrey-watters-haters/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/08/22/delivering-value-for-developers-is-first-when-it-comes-to-the-census-bureau-apis/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/census.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/08/22/delivering-value-for-developers-is-first-when-it-comes-to-the-census-bureau-apis/">Delivering Value For Developers Is First When It Comes To The Census Bureau APIs</a></h3>
			<p><em>22 Aug 2013</em></p>
			<p>I wrote a piece about providing a full download vs. API last month, where I used the Census Bureau API as an example. The post got the attention of the folks at the Census, and they invited me out for a discussion yesterday about their API strategy. The Census Bureau API team asked me what I thought of their API developer area, and while I have lots of suggestions of where they could do, I first focused on what they have already delivered. I don't know if you understand the size of the census, but it is a massive undertaking, resulting in data at a scope that we are only seeing matched in the last few years, with the Google's and Twitters of the world--the only difference is the census has been going on since 1790. it gives you an ideas of the serious big data potential behind the Census Bureau API. Faced with data at this scope, I understand that delivering a simple, web API is not easy. I was impressed with the teams efforts before I came to D.C., but now I'm really impressed that such a simple, web API could be delivered out of such a large government entity. Many other agencies are still trying to even learn what an API is, and even if they do attempt at delivering APIs, the result is often the much more technical cousin of web APIs, SOAP web services. I totally respect the simple start to the Census Bureau API. The current API landing gives you brief introduction to the API, shows you how to access the data via the URL endpoints, gives you example responses, error codes and addresses what you need to use the APIs in JavaScript. They also give you quick access to getting API keys, a developer forum, application gallery and of course you still get full access to Census downloads. What a great start. So simple. Giving developers exactly what...[<a href="/2013/08/22/delivering-value-for-developers-is-first-when-it-comes-to-the-census-bureau-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/08/21/time-tracking-platform-harvest-moves-api-docs-and-app-showcase-to-github/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/harvest-logo.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/08/21/time-tracking-platform-harvest-moves-api-docs-and-app-showcase-to-github/">Time Tracking Platform Harvest Moves API Docs and App Showcase to Github</a></h3>
			<p><em>21 Aug 2013</em></p>
			<p>
Time Tracking API platform Harvest has embraced Github as part of their API ecosystem. I'm always on the hunt for examples of API providers using Github, so I figured I'd showcase Harvest's creative use of the social coding platform.
Starting with their documentation, the Harvest team has moved the API documentation to a Github repository, allowing developers to "watch" the API, get updates when changes are made, asks questions or even contribute to the API docs by submitting a pull request.
Harvest is also using the wiki portion of their Github repo for a developer application gallery they are calling Community Creations and Hacks, where they showcase innovative uses of the Harvest API--currently displaying 20 integrations by Harvest users.
I'm currently tracking on 11 separate uses of Github for API management, and always on the hunt for new ways to use Github to support API ecosystems. Nice move Harvest!
[<a href="/2013/08/21/time-tracking-platform-harvest-moves-api-docs-and-app-showcase-to-github/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/08/21/api-skills-alongside-web-in-developers-toolbox/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/bw-toolbox.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/08/21/api-skills-alongside-web-in-developers-toolbox/">API Skills Alongside Web In Developers Toolbox</a></h3>
			<p><em>21 Aug 2013</em></p>
			<p>As I immerse myself in the federal government, I have left my private sector world where web APIs have become commonplace. Sure I still worked hard to get outside of Silicon Valley and reach out further into land of "normals", helping spread the API gospel, but in Washington D.C. I seriously have my work cut out for me. I have a great support system within the Office of Science and Technology Policy (OSTP) at the White House, but as I go deeper within specific agencies I see fewer web APIs, and fewer people who understand them. When I do come across a web service, it makes me hopeful, but still these SOAP driven services may get the job done for programmers, but lack the simplicity needed to get wider adoption. This is only my second week in DC, I'm spending a lot of time going through websites, getting to know the Department of Veterans Affairs and other agencies, and recognize there is a lot of web talent, even though much is probably contracted, within the Federal Government. I can't help but think how CMS platforms like Wordpress, Drupal and others have helped our government publish valuable information and resources via the web, but we still are lacking a complimentary web API movement. The value of websites has been accepted across federal government, what can we do to get web APIs to the same level? Web services are embraced, but they are still a very black box, developer centric tool, something out of reach of the common gov worker. But web APIs aren't much different than the websites being produced, they just trade their HTML output for data formats like XML and JSON--I'm looking to change this. In 2013 and 2014 I want to pose the question in within government, why aren't open data and API skills part of the federal government's web developer toolbox, alongside the skills you already posses. You can increase the productivity...[<a href="/2013/08/21/api-skills-alongside-web-in-developers-toolbox/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/08/16/what-api-documentation-do-you-suggest/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/Swagger-Screenshot-1.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/08/16/what-api-documentation-do-you-suggest/">What API Documentation Do You Suggest?</a></h3>
			<p><em>16 Aug 2013</em></p>
			<p>As I spend time in Washington DC, I get a lot of questions regarding API design, deployment and management. It is quite likely my writing will evolve here at API Evangelist during the next year. You will see me quickly scrub answers that I'm giving to questions that I receive from any number of federal agencies. One question I received today was a classic one: what are some good examples of API docs? But in this particular case it wasn't just for an API, there is also a full download of data available as well. First, regardless of whether or not it is data download (CSV, XML, JSON) or API you need to provide a wrapper area, or portal, that will onboard users and helps them understand what you are delivering, enabling them to go from 0-60 with as little friction as possible. This is what I have studied for the last 3 years. After looking at thousands of APIs areas, you start to see patterns. You will find&nbsp;my research in the form of "building blocks" on a section of my site. Even though most of my research is focused on APIs, these patterns can apply universally to data download or API delivery. But specifically to question of what API documentation I like? I also recommend looking at: Stripe Twilio Parse Full Contact Box Dwolla When looking through these make sure and take notice of how&nbsp;Dwolla separates their intro page, between non-devs and devs. This is a very significant concept for delivering onboarding materials for users where not everyone will be a developer. Beyond those suggestions for API docs, here are&nbsp;Thirty APIs To Look At When Planning Your API, if you are looking for more examples of quality API areas + documentation. Another thing to consider when actually deploying specifically an API, is making your API documentation "interactive". There are several solutions for doing this right now, but the leading solution (in my opinion) is...[<a href="/2013/08/16/what-api-documentation-do-you-suggest/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/08/16/api-craft-soa-vs-api/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/api-craft-logo.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/08/16/api-craft-soa-vs-api/">API Craft - SOA vs API?</a></h3>
			<p><em>16 Aug 2013</em></p>
			<p>
This is from a question I answered on the API Craft Forum tonight titled: SOA vs API?
I happened to look at the slide and also related video but unfortunately still do not have&nbsp;&nbsp;a crystal clear view.Is my understanding correct?

SOA and API are complementary paradigms/technologies. APIs are a facade to SOA to expose them to the outside world?
SOA was aimed to provide an integration mechanism/guidelines for enterprise while APIs are generally aimed to make the backend systems public? Also, APIs can be internal to the organization.

My response:
Your understanding is in the ballpark.&nbsp;&nbsp;APIs were one tool in the SOA toolbox. Except you are seeing APIs as just technology.  APIs have jumped out of the enterprise toolbox, and found success in the richer oxygen environment of the Internet, escaping from the claustrophobic environment of the restrictive enterprise network in which strict governance was imposed, and technologists decided everything.  After going outside the firewall, APIs became about the simplicity of REST + JSON over HTTP, putting these resources closer to actual problem owners--flipping the governance of SOA on its head, making APIs more about partnering, collaboration, transparency and openness, and not just about control. After escaping the governance and the bottleneck of traditional IT, this new breed of APIs allowed for new types of innovation, business models and opportunities amongst not just open developers, but actual business owners. A new world emerged that the governance overlords of SOA could never achieve or even see.  Allowing the&nbsp;humans to win over the machines!&nbsp;&nbsp;Making for a new formula for success that can be applied in public, partner or internal environments.
[<a href="/2013/08/16/api-craft-soa-vs-api/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2013/08/15/moving-beyond-the-constraints-of-commercial-api-design-with-the-public-media-platform/"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/public-media-logo.jpeg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2013/08/15/moving-beyond-the-constraints-of-commercial-api-design-with-the-public-media-platform/">Moving Beyond the Constraints of Commercial API Design With The Public Media Platform</a></h3>
			<p><em>15 Aug 2013</em></p>
			<p>There are just a handful of API platforms that I feel have greatly impacted the world of APIs and were significant in leading the space in important ways. These platforms include, but are not limited to Amazon Web Services, EBay, Salesforce, Google Maps and Twitter. All of these companies have changed the way we build applications and conduct business, by using APIs. In 2013, as we watch 50-100 public APIs launch each week, it can be difficult to see any sign of meaningful impementations in each wave of new API deployments. Just as I'm getting completely depressed about this lack of true API innovation, I was introduced to a new Public Media Platform that is pushing forward the tech, business and politics of APIs. The Public Media Platform (PMP) is a non-profit organization formed by public media's leading organizations, APM, NPR, PBS, PRI and PRX, to establish digital content repository and distribution system that will enable users to easily discover and interact with the news, information, cultural and educational content that is produced across the public media landscape. PMP has come together to develop a completely API driven platform, that will empower producers of public media to store and share text, digital video, audio, images and related meta data. This approach to media delivery will increase the distribution and reach, lower operating costs, while also handling the business rules, rights management necessary for media delivery in an online and mobile world. By lowering these barriers of entry, and simplifying operations and distribution, PMP will open up opportunities for these leading players to get their work in front of the large public media audience. However, this isn't just about benefiting these existing players, who are investing in the platform, once deployed, the platform will be opened up to any media producer. With this newly developed ecosystem, any developer will be able to build tools and applications that will help public media stations and producers deliver content...[<a href="/2013/08/15/moving-beyond-the-constraints-of-commercial-api-design-with-the-public-media-platform/">Read More</a>]</p>
			<p><hr /></p>
	  

		<hr />
		<ul class="pagination" style="text-align: center;">
			
				<li style="text-align:left;"><a href="/blog/page27" class="button"><< Prev</a></li>
			
				<li style="width: 75%"><span></span></li>
			
				<li style="text-align:right;"><a href="/blog/page29" class="button">Next >></a></li>
			
		</ul>

  </div>
</section>

              <footer>
	<hr>
	<div class="features">
		<article>
			<div class="content">
				<p align="center"><a href="https://www.postman.com" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/partners/postman-logo.png" width="60%" style="padding: 15px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
		<article>
			<div class="content">
				<p align="center"><a href="https://github.com/postmanlabs/newman" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/postman/newman-logo.png" width="60%" style="padding: 15px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
	</div>
</footer>


            </div>
          </div>

          <div id="sidebar">
            <div class="inner">

              <nav id="menu">
  <header class="major">
    <h2>Menu</h2>
  </header>
  <ul>
    <li><a href="/">Home Page</a></li>
    <li><a href="/blog/">The Blog</a></li>
    <li><a href="https://101.apievangelist.com/">API 101</a></li>
    <li><a href="http://history.apievangelist.com">History of APIs</a></li>
    <li><a href="https://women-in-tech.apievangelist.com/">Women in Technology</a></li>    
  </ul>
</nav>

              <section>
	<div class="mini-posts">
		<header>
			<h2 style="text-align: center;"><i>API Evangelist Sponsors</i></h2>
		</header>
		<article>
			<div class="content">
				<p align="center"><a href="https://www.postman.com" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/partners/postman-logo.png" width="75%" style="padding: 5px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
		<article>
			<div class="content">
				<p align="center"><a href="https://tyk.io/" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/tyk/tyk-logo.png" width="75%" style="padding: 5px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
		<article>
			<div class="content">
				<p align="center"><a href="https://www.openapis.org/" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/specifications/openapi.png" width="75%" style="padding: 5px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
		<article>
			<div class="content">
				<p align="center"><a href="https://www.asyncapi.com/" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/asyncapi/asyncapi-horiozontal.png" width="75%" style="padding: 5px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
		<article>
			<div class="content">
				<p align="center"><a href="https://json-schema.org/" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/specifications/json-schema.png" width="75%" style="padding: 5px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
		<article>
			<div class="content">
				<p align="center"><a href="https://github.com/postmanlabs/newman" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/postman/newman-logo.png" width="75%" style="padding: 5px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
	</div>
</section>


            </div>
          </div>

      </div>

<script src="/assets/js/skel.min.js"></script>
<script src="/assets/js/util.js"></script>
<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
<script src="/assets/js/main.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-1119465-51"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-1119465-51');
</script>


</body>
</html>
