<!DOCTYPE html>
<html xmlns="https://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
  <html>
  <title>API Evangelist </title>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
  <!--[if lte IE 8]><script src="/assets/js/ie/html5shiv.js"></script><![endif]-->
  <link rel="stylesheet" href="/assets/css/main.css" />
  <link rel="stylesheet" href="/assets/css/bootstrap.min.css" />
  <!--[if lte IE 9]><link rel="stylesheet" href="/assets/css/ie9.css" /><![endif]-->
  <!--[if lte IE 8]><link rel="stylesheet" href="/assets/css/ie8.css" /><![endif]-->

  <!-- Icons -->
  <link rel="shortcut icon" type="image/x-icon" href="https://apievangelist.com/favicon.ico">
	<link rel="icon" type="image/x-icon" href="https://apievangelist.com/favicon.ico">

  <link rel="alternate" type="application/rss+xml" title="API Evangelist Blog - RSS 2.0" href="https://apievangelist.com/blog.xml" />
  <link rel="alternate" type="application/atom+xml" title="API Evangelist Blog - Atom" href="https://apievangelist.com/atom.xml">

  <!-- JQuery -->
  <script src="/js/jquery-latest.min.js" type="text/javascript" charset="utf-8"></script>
  <script src="/js/bootstrap.min.js" type="text/javascript" charset="utf-8"></script>
  <script src="/js/utility.js" type="text/javascript" charset="utf-8"></script>

  <!-- Github.js - http://github.com/michael/github -->
  <script src="/js/github.js" type="text/javascript" charset="utf-8"></script>

  <!-- Cookies.js - http://github.com/ScottHamper/Cookies -->
  <script src="/js/cookies.js"></script>

  <!-- D3.js http://github.com/d3/d3 -->
  <script src="/js/d3.v3.min.js"></script>

  <!-- js-yaml - http://github.com/nodeca/js-yaml -->
  <script src="/js/js-yaml.min.js"></script>

  <script src="/js/subway-map-1.js" type="text/javascript"></script>

  <style type="text/css">

    .gist {width:100% !important;}
    .gist-file
    .gist-data {max-height: 500px;}

    /* The main DIV for the map */
    .subway-map
    {
        margin: 0;
        width: 110px;
        height: 5000px;
        background-color: white;
    }

    /* Text labels */
    .text
    {
        text-decoration: none;
        color: black;
    }

    #legend
    {
    	border: 1px solid #000;
        float: left;
        width: 250px;
        height:400px;
    }

    #legend div
    {
        height: 25px;
    }

    #legend span
    {
        margin: 5px 5px 5px 0;
    }
    .subway-map span
    {
        margin: 5px 5px 5px 0;
    }

    </style>

    <meta property="og:url" content="">
    <meta property="og:type" content="website">
    <meta property="og:title" content="API Evangelist">
    <meta property="og:site_name" content="API Evangelist">
    <meta property="og:description" content="A network of research sites dedicated to the technology, business, and politics of APIs.">
    <meta property="og:image" content="http://s3.amazonaws.com/kinlane-productions/api-evangelist/t-shirts/KL_InApiWeTrust-1000.png">

    <meta name="twitter:url" content="">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="API Evangelist">
    <meta name="twitter:site" content="API Evangelist">
    <meta name="twitter:description" content="A network of research sites dedicated to the technology, business, and politics of APIs.">
    
      <meta name="twitter:creator" content="@apievangelist">
    
    <meta property="twitter:image" content="http://s3.amazonaws.com/kinlane-productions/api-evangelist/t-shirts/KL_InApiWeTrust-1000.png">


</head>

  <body>

			<div id="wrapper">
					<div id="main">
						<div class="inner">

              <header id="header">
  <a href="http://apievangelist.com" class="logo"><img src="https://kinlane-productions.s3.amazonaws.com/api-evangelist/api-evangelist-logo-400.png" width="75%" /></a>
  <ul class="icons">
    <li><a href="https://twitter.com/apievangelist" class="icon fa-twitter"><span class="label">Twitter</span></a></li>
    <li><a href="https://github.com/api-evangelist" class="icon fa-github"><span class="label">Github</span></a></li>
    <li><a href="https://www.linkedin.com/organization/1500316/" class="icon fa-linkedin"><span class="label">LinkedIn</span></a></li>
    <li><a href="http://apievangelist.com/atom.xml" class="icon fa-rss"><span class="label">RSS</span></a></li>
  </ul>
</header>

    	        <section>
	<div class="content">

	<h3>The API Evangelist Blog</h3>
	<p>This blog is dedicated to understanding the world of APIs, exploring a wide range of topics from design to deprecation, and spanning the technology, business, and politics of APIs. <a href="https://github.com/kinlane/api-evangelist" target="_blank">All of this runs on Github, so if you see a mistake, you can either fix by submitting a pull request, or let us know by submitting a Github issue for the repository</a>.</p>
	<center><hr style="width: 75%;" /></center>
	
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/12/05/what-is-more-important-having-an-api-or-having-a-well-designed-api/">What Is More Important? Having An API? Or Having A Well-Designed API?</a></h3>
        <span class="post-date">05 Dec 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algo-rotoscope/stories-new/16_38_600_500_0_avg_1_1_1.jpg" align="right" width="45%" style="padding: 15px;" /></p>
<p>I  got some expected flack this week for some stories on database to API deployments, and allowing folks to just auto-generate APIs from database structures. This approach is notorious for producing very badly designed APIs, which is something that just reflects whatever legacy infrastructure you have as a backend. It is something that drives many of API design, architects, and pundits crazy. Just do things properly!!! Follow good design practices! Put some thought into your API, and have some pride in this interface you are putting out there. All of this is easy for us to declare from our vantage point, but when your entrenched within an existing organization, battling for every movement forward, and often times just to not go backwards, this isn’t always the reality.</p>

<p>As technologists we are always looking forward, and have a really hard time empathizing with folks who are stuck in positions that aren’t as forward leaning as ours. I know we have a well of experience we want everyone to see eye to eye with, but that isn’t always the reality. You can’t convince someone who is just trying to stay afloat within an organization that they should be investing in all of these possibilities in a future they aren’t tuned into. Not everyone holds the privileged position that many of us enjoy in the technology space, and I feel we can do a better job empathizing with some of them. I’m not saying we should give up on leading, and telling stories of a better future, but we need to work to build bridges to many who are less fortunate than we are.</p>

<p>You know what is worse than being in an organization where you are battling for every bit of budget, resources, skills, and other things that help you stay afloat? Having people in more privileged positions making you feel stupid for what you do not understand, or have the time to learn. I wish folks at startups, and bigcos would spend more time investing in the knowledge transfer to smaller, more underserved organizations. Not teaching them to use their software, but actually investing in their staff becoming more web, and API literate. Instead, of making people feel like they don’t have the knowledge, skills, and resources to do things right. In my experience, most of these folks are well aware of this, and they don’t need to be reminded on it.</p>

<p>I’m investing in organizations just doing APIs. Sure, I would like them to do it as well as possible, but I’m more invested in people just doing them. Making their data, content, and other resources more accessible so they can be just a little bit more successful in what they are doing. There will be some pain to go along with this approach, but I feel like it will ultimately be worth it. I can’t shield data stewards, and other would-be API providers from all the pain of doing APIs. I feel it is more important to me that folks have an API, and be on their journey, than having a perfectly designed API. This is where the learning comes, and hopefully I can convince more technologists, startups, and bigcos to invest in this journey, rather than shame people for not being well-equipped when it comes to doing APIs, and quite possibly never even doing them at all. That is much worse, than a poorly designed API in my book.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/12/05/what-is-more-important-having-an-api-or-having-a-well-designed-api/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/12/05/the-picture-we-pain-with-each-api-release/">The Picture We Paint With The Stories We Tell Around Each API Version Release</a></h3>
        <span class="post-date">05 Dec 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/facebook/facebook-version-211-release.png" align="right" width="45%" style="padding: 15px;" /></p>
<p>I fell down the rabbit hole of the latest Facebook version release, trying to understand the deprecation of their User Insights API. The story of the deprecation of the API isn’t told accurately as part of the the regular release process, so I found myself thinking more deeply about how we tell stories (or don’t) around each step forward of our APIs. I have dedicated areas of my API research for the <a href="http://road-map.apievangelist.com/">road map</a>, <a href="http://issues.apievangelist.com/">issues</a>, and <a href="http://change-log.apievangelist.com/">change log</a> for API operations, because their presence tell a lot about the character of an API, and their usage I feel paints and accurate painting of each moment in time for an API.</p>

<p><a href="https://developers.facebook.com/docs/graph-api/changelog">Facebook has a dedicated change log for their API platform</a>, as well as an <a href="https://developers.facebook.com/status/dashboard/">active status</a> and <a href="https://developers.facebook.com/status/issues/">issues</a> pages, but they do not share much about what their road map looks like. They provide a handful of elements with each releases change log:</p>

<ul>
  <li><strong>New Features</strong> — New products or services, including new nodes, edges, and fields.</li>
  <li><strong>Changes</strong> — Changes to existing products or services (not including Deprecations).</li>
  <li><strong>Deprecations</strong> — Existing products or services that are being removed.</li>
  <li><strong>90-Day Breaking Changes</strong> — Changes and deprecations that will take effect 90 days after the version release date.</li>
</ul>

<p>The presence, or lack of presence, of a road map, change log, status and issue pages for an API paints a particular picture of a platform in my mind. Also, the stories they tell, or do not tell with each release paint an evolving picture of where a platform is headed, and whether or not we want to participating in the journey. Facebook does better than most platforms I track on when it comes to storytelling, by also releasing a blog post telling the story of each release, providing separate posts for <a href="https://developers.facebook.com/blog/post/2017/11/07/graphapi-v2.11/">the Graph API</a>, as well as <a href="https://developers.facebook.com/ads/blog/post/2017/11/07/marketing-api-v211/">the Marketing API</a>. It is too bad that <a href="https://developers.facebook.com/ads/blog/post/2017/11/07/marketing-api-v211/">they omitted the deprecation of the Audience Insight API</a>, which occurred at the time of this story.</p>

<p>While I consider the presence of building blocks like a change log, road map, issues and status page a positive sign for platforms. It still always requires reading between the lines, and staying in tune with each release to really get a feel for how well a platform puts these building blocks to work for the platform. Regardless, I think these building blocks do adequately paint a picture of the current state of a platform, it just usually happens to be the picture that platform wants you to see, not necessary the picture the platform consumers would like to see.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/12/05/the-picture-we-pain-with-each-api-release/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/12/05/api-deployment-templates-as-part-of-a-wider-api-governance-strategy/">API Deployment Templates As Part Of A Wider API Governance Strategy</a></h3>
        <span class="post-date">05 Dec 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algo-rotoscope/stories/server-cloud1_internet_numbers.jpg" align="right" width="45%" style="padding: 15px;" /></p>
<p>People have been asking me for more stories on API governance. Examples of how it is working, or not working at the companies, organizations, institutions, and government agencies I’m talking with. Some folks are looking for top down ways of controlling large teams of developers when it comes to delivering APIs consistently across large disparate organizations, while others are looking for bottom ways to educate and incentivize developers to operate APIs in sync, working together as a large, distributed engine.</p>

<p>I’m approach my research into API governance as I would any other area, not from the bottom up, or top down. I’m just assembling all the building blocks I come across, then began to assemble them into a coherent picture of what is working, and what is not. One example I’ve found of an approach to helping API providers across the federal government better implement consistent API patterns is out of the General Services Administration (GSA), with <a href="https://gsa.github.io/prototype-city-pairs-api-documentation/api-docs/">the Prototype City Pairs API</a>. The Github repository is a working API prototype, documentation and developer portal that is in alignment with the GSA API design guidelines, providing a working example that other API developers can reverse engineer.</p>

<p>The <a href="https://gsa.github.io/prototype-city-pairs-api-documentation/api-docs/">Prototype City Pairs API</a> is a forkable example of what you want developers to emulate in their work. It is a tool in the GSA’s API governance toolbox. It demonstrates what developers should be working towards in not just their API design, but also the supporting portal and documentation. The GSA leads by example. Providing a pretty compelling approach to model, and a building block any API provider could add to their toolbox. I would consider a working prototype to be both a bottom up approach because it is forkable, and usable, but also top down because it can reflect wider organizational API governance objectives.</p>

<p>I could see mature API governance operations having multiple API design and deployment templates like the GSA has done, providing a suite of forkable, reusable API templates that developers can put to use. While not all developers would use, in my experience many teams are actually made up of reverse engineers, who tend to emulate what they know. If they are exposed to bad API design, they tend to just emulate that, but if they are given robust, well-defined examples, they will just emulate healthy patterns. I’m adding API deployment templates to my API governance research, and will keep rounding off strategies for successful API governance, that can work at a wide variety of organizations, and platforms. As it stands, there are not very many examples out there, and I’m hoping to pull together any of the pieces I can find into a coherent set of approaches folks can choose from when crafting their own approach.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/12/05/api-deployment-templates-as-part-of-a-wider-api-governance-strategy/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/12/04/narrowing-in-on-my-api-governance-using-api-transit-to-map-out-psd2/">Narrowing In On My API Governance Strategy Using API Transit To Map Out PSD2</a></h3>
        <span class="post-date">04 Dec 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/talks/november-2015/subway-map-15.png" align="right" width="45%" style="padding: 15px;" /></p>
<p><a href="https://apievangelist.com/2017/08/17/testing-out-the-concept-of-api-transit-instead-of-api-lifecycle/">I’m still kicking around my API Transit strategy in my head</a>, trying to find a path forward with applying to API governance. <a href="https://apievangelist.com/2015/11/29/the-api-lifecycle-my-talk-from-defrag-and-apistrat/">I started moving it forward a couple years ago as a way to map out the API lifecycle</a>, but in my experience, managing APIs are rarely a linear lifecycle. I have been captivated by the potential of the subway map to help us map out, understand, and navigate complex infrastructure since I learned about <a href="https://en.wikipedia.org/wiki/Tube_map">Harry Beck’s approach to the London Tube map which has become the standard for quantifying transit around the globe</a>.</p>

<p>I am borrowing from Beck’s work, but augmenting for a digital world to try and map out the API practices I study in my research of the space in a way that allow them to be explored, but also implemented, measured, and reported upon by all stakeholders involved with API operations. While I’m still pushing forward this concept in the safe space of my own API projects, I’m beginning to dabble with applying at the industry level, by applying to PSD2 banking, and seeing if I can’t provide an interactive map that helps folks see, understand, and navigate what is going on when it comes to banking APIs.</p>

<p>An API Transit map for PSD2 would build upon the framework I have derived from my API research, applied specifically for quantifying the PSD2 world. Each of the areas of my research broken down into separate subway lines, that can be plotted along the map with relative stops along they way:</p>

<ul>
  <li><strong>Definition</strong> - Which definitions are used? Where are the OpenAPI, schema, and other relevant patterns.</li>
  <li><strong>Design</strong> - What design patterns are in play across the API definitions, and what is the meaning behind the design of all APIs.</li>
  <li><strong>Deployment</strong> - What does deployment look like on-premise, in the cloud, and from region to region.</li>
  <li><strong>Portals</strong> - What is the minimum viable standard for an API portal presence with any building blocks.</li>
  <li><strong>Management</strong> - Quantify the standard approaches to managing APIs from on-boarding to analysis and reporting.</li>
  <li><strong>Plans</strong> - How are access tiers and plans defined, providing 3rd party access to APIs, including that of aggregators and application developers.</li>
  <li><strong>Monitoring</strong> - What does monitoring of web APIs look like, and how is data aggregated and shared.</li>
  <li><strong>Testing</strong> - What does testing of web APIs look like, and how is data aggregated and shared.</li>
  <li><strong>Performance</strong> - What does performance evaluation of web APIs look like, and how is data aggregated and shared.</li>
  <li><strong>Security</strong> - What are the security practices in place for the entire API stack?</li>
  <li><strong>Breaches</strong> - When there is a breach, what is the protocol, and practices surrounding what should happen–where is the historical data as well.</li>
  <li><strong>Terms of Service</strong> - What does terms of service across many APIs look like?</li>
  <li><strong>Privacy Policy</strong> - How is privacy protected across API operations?</li>
  <li><strong>Support</strong> - What are all the expected support channels, and where are they located?</li>
  <li>Road Map - What is expected, and where do we find the road map and change log for the platform?</li>
</ul>

<p>These are just a handful of the lines I will be laying out as part of my subway map. I have others I want to add, but this provides a nice version of what I”d like to see as an API Transit map of the PSD2 universe. Each line would have numerous stops that would provide resources and potentially tooling to help educate, quantify, and walk people through each of these areas in detail, but in the context of PSD2, and the banking industry. This where I’m beginning to push the subway map context further to help make work in a virtualized world, and augmenting with some concepts I hope will add new dimensions to how we understand, and navigate our digital worlds, but using the subway map as a skeuomorph.</p>

<p>To help make the PSD2 landscape I’m mapping out more valuable I am playing with adding a “tour” layer, which allows me to craft tours that cover specific lines, hitting only the stops that matter, bridges multiple lines, and creates a meaningful tour for a specific audience. Here are a handful of the tours I’m planning for PSD2:</p>

<ul>
  <li><strong>Introduction</strong> - A simple introduction to the concepts at play when it comes to the PSD2 landscape.</li>
  <li><strong>Provider Training</strong> - A detailed training walk-through for anyone looking to provide a PSD2 compliant platform.</li>
  <li><strong>Provider Certification</strong> - A detailed walkthrough that gathers information and detail to map out, quantity, and assess a specific PSD2 API / platform.</li>
  <li><strong>Executive</strong> - A robust walk-through of the concepts at play for an executive from the 100K view, as well as those of their own companies PSD2 certified API, and possibly those of competitors.</li>
  <li><strong>Regulator</strong> - A comprehensive walk through the entire landscape, including what is required, as well as the certification of individual PSD2 API platforms, with real-time control dashboard.</li>
</ul>

<p>These are just a few of the areas I’m looking to provide tours through this quantified PSD2 API Transit landscape. I am using Github to deploy, and evolve my maps, which leverages Jekyll as a Hypermedia client to deliver the API Transit experience. While each line of the API Transit map has it’s own hypermedia flow for storing and experiencing each stop along the line, the tours also have its own hypermedia flows which can augment existing lines and stops, as well as inject their own text, images, audio, video, links and tooling along the way.</p>

<p>The result will be a single URL which anyone can land on for the PSD2 API Transit platform. You can choose from any of the pre-crafted tours, or just begin exploring each line, getting off at only the stops that interest you. Some stops will be destinations, while others will provide transfers to other lines. I’m going to be investing some cycles into my PSD2 API Transit platform over the holidays. If you have any questions, comments, input, or would like to invest in my work, please let me know. I’m always looking for feedback, as well as interested parties to help fund my work and ensure I can carve out the time to make them happen.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/12/04/narrowing-in-on-my-api-governance-using-api-transit-to-map-out-psd2/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/12/04/being-able-to-see-your-database-in-xml-json-and-csv/">Being Able To See Your Database In XML, JSON, and CSV</a></h3>
        <span class="post-date">04 Dec 2017</span>
        <p><a href="https://www.slashdb.com/documentation/api-documentation/"><img src="https://s3.amazonaws.com/kinlane-productions/slashdb/slashdb-content-negotiation.png" align="right" width="45%" style="padding: 15px;" /></a></p>
<p><em>This is a sponsored post by my friends over at <a href="https://www.slashdb.com/">SlashDB</a>. The topic is chosen by me, but the work is funded by SlasDB, making sure I keep doing what I do here at API Evangelist. Thank you <a href="https://www.slashdb.com/">SlashDB</a> for your support, and helping me educate my readers about what is going on in the API space.</em></p>

<p>I remember making the migration from XML to JSON. It was hard for me to understand that difference between the formats, and that you accomplish pretty much the same things in JSON that you could in XML. I’ve been seeing similarities in my migration to YAML from JSON. The parallels in each of these formats isn’t 100%, but this story is more about our perception of data formats, than it is about the technical details. CSV has long been a tool in my toolbox, but it was until this recent migration from JSON to YAML that I really started seeing the importance of CSV when it comes to helping onboard business users with the API possibilities.</p>

<p>In my experience API design plays a significant role in helping us understand our data. Half of this equation is understanding our schema, and what the dimensions, field names, and data types of the data we are moving around using APIs. As I was working through some stories on how my friends over at SlashDB are turning databases into APIs, I saw that they were translating database, tables, and field names into API design, and that <a href="https://www.slashdb.com/documentation/api-documentation/">they also help you handle content negotiation between JSON, XML, CSV</a>. Which I interpret as an excellent opportunity for learning more about the data we have in our databases, and getting to know the design aspects of the data schema.</p>

<p>In an earlier post about what SlashDB does I mentioned that many API designers cringe at translating database directly into a web API. While I agree that people should be investing into API design to get to know their data resources, the more time I spend with SlashDB’s approach to deploying APIs from a variety of databases, the more I see the potential for teaching API design skills along the way. I know many API developers who understand API design, but do not understand content negotiation between XML, JSON, and CSV. I see an opportunity for helping publish web APIs from a database, while having a conversation about what the API design should be, and also getting to know the underlying schema, then being able to actively negotiate between the different formats–all using an existing service.</p>

<p>While I want everyone to be as advanced as they possibly can with their API implementations, I also understand the reality on the ground at many organizations. I’m looking for any possible way to just get people doing APIs, and begin their journey, and I am not going to be to heavy handed when it comes to people being up to speed on modern API design concepts. The API journey is the perfect way to learn, and going from database to API, and kicking of the journey is more important than expecting everyone to be skilled from day one. This is why I’m partnering with companies like SlashDB, to help highlight tools that can help organizations take their existing legacy databases and translate them into web APIs, even if those APIs are just auto-translations of their database schema.</p>

<p>Being able to see your database as XML, JSON, and CSV is an important API literacy exercise for companies, organizations, institutions, and government agencies who are looking to make their data resources available to partners using the web. It is another important step in understanding what we have, and the naming and dimensions of what we are making available. I think the XML to JSON holds one particular set of lessons, but then CSV possesses a set of lessons all its own, helping keep the bar low for the average business user when it comes to making data available over the web. I’m feeling like there are a number of important lessons for companies looking to make their databases available via web APIs over at SlashDB, with automated XML, JSON, and CSV translation being just a notable one.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/12/04/being-able-to-see-your-database-in-xml-json-and-csv/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/12/04/facebook-quietly-deprecates-the-audience-insight-api-used-to-automate-targeting-during-the-election/">Facebook Quietly Deprecates The Audience Insight API Used To Automate Targeting During The Election</a></h3>
        <span class="post-date">04 Dec 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/facebook/audience-insights/facebook-audience-insights-api-affinity.png" align="right" width="45%" style="padding: 15px;" /></p>
<p><a href="http://www.adweek.com/digital/facebook-is-shutting-down-its-api-that-marketers-lean-on-for-research/#/">According to AdWeek, Facebook is quietly shutting down its Audience Insights API by the end of the year</a>. They have a statement from Facebook stating, “We have decided to focus marketers on our more broadly available Audience Insights tool, so we are winding down the Audience Insights API by end of year. We’ll continue testing different ways to provide valuable insights to advertisers and agencies through the tool and across other destinations on Facebook.” which I assume they got directly from Facebook, because I can find no other communication regarding the deprecation of the API through normal <a href="https://newsroom.fb.com/">newsroom</a>, or <a href="https://developers.facebook.com/docs/graph-api/changelog">API change log</a> channels. It could be that I’m missing it, but it is clear they are trying to minimize chatter around this.</p>

<p>According to <a href="https://www.facebook.com/business/help/304781119678235">the Facebook help page</a>, Audience Insights, “shows you data about your target audiences so that you can create more relevant advertisements for them”. The platform uses native Facebook data to show you audience features such as: Age and gender, Relationship status, Education level, Job role, Top categories, Page likes, Top cities, Top countries, Top languages, Frequency of activities, and Device users. Then using third-party data (data come from sources like Acxiom, Datalogix and Epsilon) they show you audience features such as: Lifestyle, Household income, Home ownership, Household size, Home market value, Spending methods, Retail spending, Online purchases, Purchase behavior, and whether they are in market for a vehicle. You can still get at this via <a href="https://www.facebook.com/ads/audience-insights/">the Facebook Audience Insights web interface</a>, but the APIs for automating this aspect of Facebook has mostly disappeared, or is in the process of disappearing.</p>

<p>There are three layers to the Faceook Audience Insights API deprecation. You can still access some insights for ads, pages, and other objects, as well as one audience insight still available:</p>

<ul>
  <li><a href="https://developers.facebook.com/docs/graph-api/reference/v2.11/insights"><strong>/{object-id}/insights</strong></a>  - Facebook Insights is a product available to all Pages and Apps on Facebook using the Insights dashboard.</li>
  <li><a href="https://developers.facebook.com/docs/graph-api/reference/audience-insights-rule/"><strong>Audience Insights Rule</strong></a> - Definition of an audience insight rule.</li>
</ul>

<p>Then there are a handful of API paths related to Audience Insights that are still there, but not listed off the main navigation:</p>

<ul>
  <li><a href="https://developers.facebook.com/docs/graph-api/reference/audience-insights-rule-component/"><strong>Audience Insights Rule Component</strong></a> - Rule component of a study rule.</li>
  <li><a href="https://developers.facebook.com/docs/graph-api/reference/audience-insights-post/"><strong>Audience Insights Post</strong></a> - Represents a sample post.</li>
  <li><a href="https://developers.facebook.com/docs/graph-api/reference/audience-insights-group-by-summary/"><strong>Audience Insights Group By Summary</strong></a> - Overall summary for audience insights query insights.</li>
  <li><a href="https://developers.facebook.com/docs/graph-api/reference/insights-value/"><strong>Insights Value</strong></a> - The value for one insights metric given a timestamp.</li>
  <li><a href="https://developers.facebook.com/docs/graph-api/reference/insights-result/"><strong>Insights Result</strong></a> - The result of an Insights query.</li>
</ul>

<p>Then there are the core Audince Insights APIs that are completely gone, with all documentation removed:</p>

<ul>
  <li><strong>Audience Insights Lifestyles</strong> (<a href="https://developers.facebook.com/docs/graph-api/reference/audience-insights-lifestyles/">URL</a>) (<a href="https://webcache.googleusercontent.com/search?q=cache:zcVvTrCjRTYJ:https://developers.facebook.com/docs/graph-api/reference/audience-insights-lifestyles/+&amp;cd=1&amp;hl=en&amp;ct=clnk&amp;gl=us">Cached URL</a>) - Insights about lifestyles for you audience.</li>
  <li><strong>Audience Insight Education Level</strong> (<a href="https://developers.facebook.com/docs/graph-api/reference/audience-insights-education-level/">URL</a> (<a href="https://webcache.googleusercontent.com/search?q=cache:AxUtpiQ0vuIJ:https://developers.facebook.com/docs/graph-api/reference/audience-insights-education-level/+&amp;cd=1&amp;hl=en&amp;ct=clnk&amp;gl=us">Cached URL</a>) - Information about the education level of your audience</li>
  <li><strong>Audience Insights Home Owners</strong> (<a href="https://developers.facebook.com/docs/graph-api/reference/audience-insights-home-owners/">URL</a> (<a href="https://webcache.googleusercontent.com/search?q=cache:8KLILtYG3KYJ:https://developers.facebook.com/docs/graph-api/reference/audience-insights-home-owners/+&amp;cd=1&amp;hl=en&amp;ct=clnk&amp;gl=us">Cached URL</a>) - Information about home ownership.</li>
  <li><strong>Audience Insights Household Income</strong> (<a href="https://developers.facebook.com/docs/graph-api/reference/audience-insights-household-income/">URL</a> (<a href="https://webcache.googleusercontent.com/search?q=cache:um_yOLJk-lYJ:https://developers.facebook.com/docs/graph-api/reference/audience-insights-household-incomes/+&amp;cd=1&amp;hl=en&amp;ct=clnk&amp;gl=us">Cached URL</a>) - Household incomes information about your audience.</li>
  <li><strong>Audience Insights Purchase Behaviors</strong> (<a href="https://developers.facebook.com/docs/graph-api/reference/audience-insights-purchase-behaviors/">URL</a> (<a href="https://webcache.googleusercontent.com/search?q=cache:7GPqnSgOYVIJ:https://developers.facebook.com/docs/graph-api/reference/audience-insights-purchase-behaviors/+&amp;cd=1&amp;hl=en&amp;ct=clnk&amp;gl=us">Cached URL</a>) - Purchase behaviors information for your audience.</li>
  <li><strong>Audience Insights Affinity</strong> (<a href="https://developers.facebook.com/docs/graph-api/reference/audience-insights">URL</a> (<a href="https://webcache.googleusercontent.com/search?q=cache:rhIkcFkbT7YJ:https://developers.facebook.com/docs/graph-api/reference/audience-insights-affinity/+&amp;cd=1&amp;hl=en&amp;ct=clnk&amp;gl=us">Cached URL</a>) - Information about the affinity for a given page.</li>
</ul>

<p>These are the six API paths that you would use to scale and automate any information, or disinformation campaign. This is how you develop, evolve, and act upon your models when it comes to publishing Facebook Pages, buying advertising and spreading video, photos, news, and other (dis)information that you are targeting your users with. I see hints of these insight API going away on <a href="https://developers.facebook.com/docs/graph-api/changelog/version2.11">the most recent November 7th update</a>, but there are <a href="https://developers.facebook.com/docs/graph-api/changelog/version2.10#mapi-deprecate">no marketing API deprecations in the last one in July that changed how you are able share links via the API</a>–something that was a response to the election backlash. The last cache of the missing documentation pages was on November 9th, showing they’ve been actively working in November to clean things up, and by the looks of things they are still working on this.</p>

<p>Ok, many might say that this is a good thing. Facebook is removing the tools that allow you to automate these types of campaigns. Limiting who has access to them. Sure. However, it doesn’t stop them from still providing access to partners, and other folks behind the scenes, further reducing any observability into the process, after <a href="https://newsroom.fb.com/news/2017/10/update-on-our-advertising-transparency-and-authenticity-efforts/">they’ve promised to be more transparent about all of this</a>. Also, the sneaky nature of the API deprecation, which isn’t unusual for Facebook reveals their true motivation. The deprecation is only published in AdWeek, and clearly is something other outlets are either unaware of, or unwilling to talk about due to retribution by Facebook, which might limit your exposure on the network. Facebook has many news outlets by the balls when it comes to platform exposure these days, potentially limiting who will be critical of the platform.</p>

<p>The Facebook Audience Insights API represents the conundrum of APIs for me. If APIs don’t exist we can’t see into the algorithms that are increasingly governing our lives. If they do exist then people with ill intentions get access to them, and can use them for shady things like we’ve been seeing as part of the election. The answer? They should exist, but then provide access by auditors, regulators, researchers, and journalists to see what is possible via platforms. Then, EVERYONE who has access to the tools should be observable and accountable. Not just the APIs, but also the web interface. If you are developing models that target a demographic, that demographic should know about it, and auditors, researchers, and journalists should have API access to all of this, so that they can assess and report on what is going on. The watchers should also be accountable. This is why I do APIs, not because I believe they are always good, but because they provide us with secure, managed, accountable observability into how platforms and algorithms work (or don’t).</p>

<p>Ideally, tools like this do not exist in the first place. My feeling is that we burn it down. However, I know this isn’t a reality. My next recommendation is that ALL advertising platforms possess APIs for ALL aspects of operations, with access tiers for auditors, regulators, researchers, and journalists. Observability into how these platforms are operating is the only way we can move this conversation forward in a way that protects the end-users of platforms from harm. It is clear that Facebook is not interested in true observability, and are playing the usual transparency games by acting like they are self-regulating, but then just pulling the curtains on what they are up to. In coming years, we’ll see more APIs be deprecated because of this, as the platforms realizing what is possible, and just commence more secretive about what they do. The cat is out of the bag. The technology exists to give us visibility into what is going on, the trick is going to be all about keeping the APIs that exist operational, and delivering 100% coverage of platform operations, and regulating that APIs be introduced where they do not exist already. Sorry platforms, you had plenty of time to be straight up about this stuff, and you chose not to.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/12/04/facebook-quietly-deprecates-the-audience-insight-api-used-to-automate-targeting-during-the-election/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/12/01/the-conversational-interface-appetite-for-data-via-apis/">The Conversational Interface Appetite For Data Via APIs</a></h3>
        <span class="post-date">01 Dec 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algo-rotoscope/stories-new/16_77_800_500_0_max_0_1_-1.jpg" align="right" width="45%" style="padding: 15px" /></p>
<p><em>This is a sponsored post by my friends over at <a href="https://www.slashdb.com/">SlashDB</a>. The topic is chosen by me, but the work is funded by SlasDB, making sure I keep doing what I do here at API Evangelist. Thank you <a href="https://www.slashdb.com/">SlashDB</a> for your support, and helping me educate my readers about what is going on in the API space.</em></p>

<p>I spend a lot of time studying what is going on around bots on Twitter, Facebook, and Slack, as well as voice enablement like we see with Alexa, Google, and Siri. I lump these all under a research category called conversational interfaces. Conversational interfaces represent the next generation of API clients, with AWS Alexa being the most sophisticated example at how it will all work(eventually). While there are some interesting examples of conversational interfaces in action, for the most part they are still pretty simple, silly, and not providing much value. I’d say that any of the bots or voice implementations I’ve come across which are useful, are also pretty corporate, demonstrating the amount of resources you need to invest when crafting conversational interfaces.</p>

<p>From my vantage point I’m seeing three main areas slowing the growth of true usability of conversational interfaces, 1) desire, and people not wanting or caring to engage, 2) availability of data via APIs in format that is usable, and 3) the performance of APIs that do have relevant data, and their ability to deliver it as an answer to a question in reasonable amount of time. You can put me squarely into the first category of not really wanting to use conversational interfaces, but I do understand that there are people who are into doing it, which gets me somewhat involved when it comes to thinking about the 2nd, and 3rd challenge. APIs are what delivers answers in conversational interfaces, and since APIs are my jam, I’m tuning in.</p>

<p>One of the biggest challenges the conversational interface space will face in coming years is having the access to the answers or data they need to function as expected. It’s not that the data isn’t out there, it is that it isn’t available in accessible, usable API interfaces that developers can quickly wire up via platforms like Slack and Alexa. There is a wealth of sports data out there, but to make it available via bots and voice platforms you have to be able to get at via APIs. There is a wealth of movie data out there, but you have to be able to get at it via simple APIs. I can go on and on about the types of data we need, and even point out where you can find it, the problem is that it isn’t available via a simple web API so that a developer can quickly build a conversational interface on top of it.</p>

<p>This is why you’ll find me doing more research into data, and database to API implementations, partnering with folks like <a href="https://www.slashdb.com/">SlashDB</a>, who help make deploying web APIs from databases dead simple. We need more APIs, not thousands more, but millions more. We need the APIs to be simple, and authentication standardized, so that developers can quickly get their hands on what they need to develop valuable conversational interfaces. We don’t need API providers publishing APIs trying to be the next Twilio or SendGrid. We need API providers making ALL their valuable data available via APIs, and removing the friction for conversational interface developers to find what they need, so they can wire up the answers demanded by bots, voice, and other applications. If you want your valuable data available in conversational interfaces you need to be exposing it via web APIs.</p>

<p>Personally, I do not get excited by bot or voice enabled applications. I enjoy automation, but I’m more of a fan of the intimacy between my brain, my fingers, and the keyboard. However, like most of the tech space I understand that conversational interfaces will keep evolving, and want to contribute where I can to make them more usable. Another aspect of why I am getting on board with conversational interfaces, as with all the other API driven applications, is when it comes to surveillance and privacy. I want to play a role in helping define the backend layers of conversational interfaces, make them usable, valuable, while also protecting the privacy, security, and data ownership of individuals who are putting them to work. This is why you’ll find me chiming in more on the subject, not because I’m pro-conversational interface, it is because they are happening, and I want to make sure it works as well as possible for everyone involved.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/12/01/the-conversational-interface-appetite-for-data-via-apis/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/12/01/how-do-you-ask-questions-of-data-using-apis/">How Do You Ask Questions Of Data Using APIs?</a></h3>
        <span class="post-date">01 Dec 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algo-rotoscope/stories-new/27_93_800_500_0_max_0_-5_-5.jpg" align="right" width="45%" style="padding: 15px;" /></p>
<p>I’m preparing to publish a bunch of transit related data as APIs, for us across a number of applications from visualizations to conversation interfaces like bots and voice-enablement. As I’m learning about the data, publishing it as unsophisticated CRUD APIs, I’m thinking deeply about how I would enable others to ask questions of this data using web APIs. I’m thinking about the hard work of deriving visual meaning from specific questions, all the way to how would you respond to an Alexa query regarding transit data in less than a second. Going well beyond what CRUD gives us when we publish our APIs and taking things to the next level.</p>

<p>Knowing the technology sector, the first response I’ll get is machine learning! You take all your data, and you train up some machine learning models, put some natural language process to work, and voila, you have your answer to how you provide answers. I think this is a sensible approach to many data sets, and for organizations who have the machine learning skills and resources at their disposal. There are also a growing number of SaaS solutions for helping put machine learning work to answer complex questions that might be asked of large databases. Machine learning is definitely part of the equation for me, but I’m not convinced it is the answer in all situations, and it might not always yield the correct answers we are always looking for.</p>

<p>After machine learning, and first on my list of solutions to this challenge is API design. How can I enable a domain expert to pull out the meaningful questions that will be asked of data, and expose as simple API paths, allowing consumers to easily get at the answers to questions. I’m a big fan of this approach because I feel like the chance we will get right answers to questions will be greater, and the APIs will help consumers understand what questions they might want to be asking, even when they are not domain experts. This approach might be more labor intensive than the magic of machine learning, but I feel like it will produce much higher quality results, and better serve the objectives I have for making data available for querying. Plus, this is a lower impact solution, allowing more people to implement, who might not have the machine learning skills or resources at their disposal. API design using low-cost web technology, makes for very accessible solutions.</p>

<p>Whether you go the machine learning or artisanal domain expert API design route, there has to be a feedback loop in place to help improve the questions being asked, as well as the answers being given. If there is no feedback loop, the process will never be improved. This is what APIs excel at when you do them properly. The savvy API platform providers have established feedback loops for API consumers, and their users to correct answers when they are wrong, learn how to ask new types of questions, and improve upon the entire question and answer life cycle. I don’t care whether you are going the machine learning route, or the API design route, you have to have a feedback loop in place to make this work as expected. Otherwise it is a closed loop system, and unlikely to give the answers people are looking for.</p>

<p>For now, I’m leaning heavily on the API design route to allow for my consumers to ask questions of the data I’m publishing as APIs. I’m convinced of my ability to ask some sensible questions of the data, and expose as simple URLs that anyone can query, and then evolve forward and improve upon as time passes. I just don’t have the time and resources to invest in the machine learning route at this point. As the leading machine learning platforms evolve, or as I generate more revenue to be able to invest in these solutions I may change my tune. However, for now I’ll just keep publishing data as simple web APIs, and crafting meaningful paths that allow people to ask questions of some of the data I’m coming across locked up in zip files, spreadsheets, and databases.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/12/01/how-do-you-ask-questions-of-data-using-apis/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/12/01/how-to-say-you-might-charge-for-api-access-in-the-future-without-being-a-dick/">How To Say You Might Charge For API Access In The Future Without Being A Jerk</a></h3>
        <span class="post-date">01 Dec 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algo-rotoscope/stories/statue-face-open-mouth_copper_circuit.png" align="right" width="45%" style="padding: 15px;" /></p>
<p>I get it. It takes money to operate APIs. I’m a big advocate for making sure API providers, even public data API providers can sensibly charge for access to their valuable resources. I’m also painfully aware at how unrealistic a libertarian driven view of the web being open and free makes it very difficult to begin charging for data that has been historically free. However, I’m also a fan of helping API providers understand how they can communicate that they might / will be charging for access to data at some point in the future without being complete jerks about it.</p>

<p>I see API providers regularly make the statement that they will begin charging for API access at some point in the future, but this particular story is driven from hearing it out of the <a href="https://technical.ly/dc/2017/11/22/developers-upset-wmatas-new-data-terms-use/">Washington Metropolitan Area Transit Authority (WMATA) making changes to their terms of service</a>, where one of the bullet points was that they would begin charging for access at some point. Making the announcement that you intend to begin charging for something that has been free is challenging in any API ecosystem, but especially so within public data API ecosystems like WMATA. In any of these environments you can’t just shoot across your community’s bow with a statement like this, and expect a positive response. Doing so, just shows how out of touch with your community you are.</p>

<p>First rule of communicating around the business side of your road map is don’t just say you’ll be charging at some point and leave things there. Give details of what this means. Demonstrate your knowledge around how API management and service composition works. Will ALL developers be charged? Will it just be commercial developers? Will it be developers over a certain level of consumption? Do not leave it to the communities imagination regarding what will happen, because this is where the powers of Internet speculation will take hold, and begin working against your API efforts. This is where your entire community will begin talking about how these changes will impact their business, and begin to prepare for the worst, even if the changes won’t even impact them. Creating a ripple effect across your API platform, and potentially hurting business beyond what will actually be reality.</p>

<p>Next, share some thoughts behind the reasoning behind these changes. Craft a blog post. Hold some office hours. Talk to your API consumers about why you will need to start charging for access to ALL or some of your API resources. Back up the details you provied with some actual insight into what went into the decision making process. Prove to your API consumers that you have their best interest in mind, and aren’t just looking to screw everyone over. A lack of visibility into the decision making process will only push your API consumers to assume the worst. Ideally, this isn’t just a one time event, and you publish a series of blog posts sharing the story behind the process of needing to generate more revenue, to cover rising costs, or whatever else might be the reason behind the need to charge for access at some point in the future. Don’t make this just a sudden thing, build up to it, and ease your community into the concept that APIs will move from free to paid.</p>

<p>After providing details on the API monetization strategy and plan, and sharing the story behind this shift in platform operations, lean on your API feedback loop as part of your shift in strategy. You have a strong feedback loop in place directly with your strongest API consumers, and at scale across the rest of your API consumers, right? You actively understand what your strongest platform consumers are thinking, and how the introduction of fees might impact their operations, right? I’m guessing if you are making vague statements about charging for access in the future and just walking away, that there is NO feedback loop, or the feedback loop is pernicious to say the least. You don’t really have much interest in what your API consumers are thinking, and how the shifts in a fee structure and monetization strategy will impact them. Otherwise, you’d fully understand the impacts of making statements about charging for API consumption at some date down the road.</p>

<p>Being an API provider isn’t easy. Balancing your platform concerns with those of your API consumers isn’t easy. Time and time again I see providers enter into the game without having put much thought into a monetization strategy, and have no coherent plan in place. Making changes down the road painful for everyone. Do yourself a favor, and spend the time learning about modern API management practices, and how API service composition works. Visit the API portals of leading API providers to see how they have structured their plans, and composed their service access tiers. Talk to people like me who study this stuff for a living, before you ever go public with your API. However, once you do, know that communication is essential, and that you won’t get away with being a jerk on this stuff, and just randomly telling people that at some point in the future you will be charging for access doesn’t fly in API-land, things don’t work like that.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/12/01/how-to-say-you-might-charge-for-api-access-in-the-future-without-being-a-dick/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/30/sql-statement-pass-through-using-web-apis/">SQL Statement Pass-Through Using Web APIs</a></h3>
        <span class="post-date">30 Nov 2017</span>
        <p><em>This is a sponsored post by my friends over at <a href="https://www.slashdb.com/">SlashDB</a>. The topic is chosen by me, but the work is funded by SlasDB, making sure I keep doing what I do here at API Evangelist. Thank you <a href="https://www.slashdb.com/">SlashDB</a> for your support, and helping me educate my readers about what is going on in the API space.</em></p>

<p><a href="https://www.slashdb.com/how-it-works/#sql-pass-thru"><img src="https://s3.amazonaws.com/kinlane-productions/slashdb/slashdb-sql-pass-through-mode.png" align="right" width="45%" style="padding: 15px;" /></a></p>
<p>I’m closely following the approach of GraphQL when it comes to making data resources more accessible by API consumers when developing applications. I think there is some serious value introduced when it comes empowering front-end developers with the ability to get exactly the data they need using a variety of querying structures. I enjoy studying up on different approaches to making different dimensions of a database to consumers and end-users, and found a pretty scrappy one from my friends over at SlashDB, with <a href="https://www.slashdb.com/how-it-works/#sql-pass-thru">their SQL statement pass through</a>. It’s not the most formal approach to query a database, but I think it’s scrappy and simple enough, that it might work for a wide variety of technical, as well as non-technical users.</p>

<p>Using the SlashDB mode, an administrator, or an application backend developer can define arbitrary SQL queries which once defined, can be executed as a smple URL. The example query they provide returns customers from London: http://demo.slashdb.com/query/customers-in-city/city/London.html. It is something that will make RESTafarians pull their hair (dreads?) out, but for business users looking to get their hands on some data to populate a spreadsheet, or share with a partner when developing an application–it will be a lifesaver. As the GraphQL folks like trumpet, REST isn’t the only way to get things done, and while I think we should be thinking critical about the long term impact of our API design choices, getting business done efficiently is an important aspect of doing APIs as well.</p>

<p>What I like about the SlashDB approach is it makes for an intuitive URL. Something business users can understand. I could see crafting these in bulk, and some becoming permanent, while others maybe being more of a temporary thing. Depending on the application you may want to standardize how you publish your URLs, using common patterns, and making sure queries aren’t changing, if they are being baked into applications. I think that simple URLs that retrieve data from a database will always trump a more complex, technical solution that developers often want. Developers are always going to want more robust solutions that they can tweak and play with, but business users just want what they need, and are looking for the quickest way to solve their business problem–SQL statement pass-through is this.</p>

<p>I’ve worked at companies that have an HTML Textarea on the dashboard of the internal portal where you can hand type SQL statements, or use from a pre-configured set of statements. Allowing business users to quickly query a database and dump to spreadsheet, CSV, and import into other applications. I can see SQL pass-through being a quick and dirty solution that reflects these other approaches I’ve seen in the past. I could see bookmarks, quick links, and other scrappy ways of using the web to query backend databases like this. When you couple this with some sort of API key or other identifier, you can also begin to develop an awareness of who is making these types of queries, and what types of applications they are putting them to use in. Taking SQL query pass-through to the next level and going beyond just API deployment, and moving into the realms of API management.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/30/sql-statement-pass-through-using-web-apis/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/30/the-average-person-will-never-care-about-apis-until-it-does-something-meaningful/">The Average Person Will Never Care About APIs Until It Does Something Meaningful</a></h3>
        <span class="post-date">30 Nov 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algo-rotoscope/stories-new/17_88_800_500_0_max_0_-5_-5.jpg" align="right" width="45%" style="padding: 15px;" /></p>
<p>I am always looking for ways to introduce people to the concept of APIs, and that they are right below everything digital you do in your daily life. Even with my prolific writing, and sharing on social media, the number of new converts to API awareness are relatively low. I’m alright with what I do not scaling. I’m in this for the long haul, not to sell products or services. I’m looking to help turn on the API light for people not because I want them building the next API, I want to help enlighten folks so that they can take more control over their digital presence, and push back on the platforms and algorithms that are increasingly dominating our lives.</p>

<p>One thing I’ve learned about normal folks in my journey as the API Evangelist is that nobody will ever care about APIs until they do something meaningful in their lives. Technologists learn about APIs for other reasons, but normal people aren’t motivated in the same ways, and need to have some meaning before they’ll wade into this more technical world of unknown, unknowns. When talking to technologists about APIs I focus on the API lifecycle, and the agility that APIs bring. With normal folks I tend to focus on platforms they already use, and algorithms that directly impact their lives, or impact people they know. As an API storyteller it is important for me to develop meaningful stories, that make APIs accessible in everyday scenarios to average people I encounter.</p>

<p>If someone is a photographer I will tell stories of the Flickr or Instagram API. If someone is an accountant, I will work through how the Intuit API is rapidly being used by small businesses. If someone is a genealogist I will talk about how the Family Search API drives Ancestry.com. If someone is a music professional I will focus on Spotify, or maybe the Bandcamp API. This is why I play with as many APIs as I can, so that I’m familiar with them, and can tell meaningful stories around the impact they make (good or bad). I tell these stories, so that I can share them with average people who may not be aware that APIs exist right below the surface of their world. Once I show them in a meaningful way, they’ll almost always continue their journey on their own, poking, scratching, and learning about what APIs can do in their world.</p>

<p>Technologists often take for granted why people understand APIs. They don’t think about the why of it. You either are a technologist and know, or you aren’t in this class of tech wizards and have no business knowing. I do not see the world like that. I’m regularly thinking about how I can produce new converts, and open up the average person’s eyes to what APIs are. I do not believe in a technologist class, and that some people should know this, and others should not. I believe that EVERYONE should be aware of how their data, and other bits and bytes are moving around beneath the websites they use, the mobile applications they depend on, and the devices they are putting into their homes, automobiles, and other aspects of our lives. Even with this belief, I fully understand I will never convert normal folks into being an API aware individual until they do something meaningful in their life.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/30/the-average-person-will-never-care-about-apis-until-it-does-something-meaningful/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/30/licensing-over-dc-transit-data/">Troubling Terms of Service Changes From Washington Metropolitan Area Transit Authority (WMATA) Data APIs</a></h3>
        <span class="post-date">30 Nov 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/transit/wmata-transit-terms-of-service.png" align="right" width="45%" style="padding: 15px;" /></p>
<p><a href="https://technical.ly/dc/2017/11/22/developers-upset-wmatas-new-data-terms-use/">I was turned onto a developing problem within the Washington Metropolitan Area Transit Authority (WMATA) around a recent terms of service change made around the transit data API by Technically DC</a>. While the transit authority is saying the changes are business as usual and make sense for the platform, some of the developers, specifically one of the biggest API users <a href="https://dcmetrohero.com/">MetroHero</a> says the changes are targeting them specifically.</p>

<p>MetroHero presented what they feel are the unreasonable changes to the WMATA API terms of service in a WMATA Board Meeting recently, focusing on four main areas:</p>

<ul>
  <li>That no user or developer can mention “WMATA” in press releases without letting WMATA first review it.</li>
  <li>That WMATA can gain access to any user’s applications that use the data, can audit personnel information for anyone working on those applications, and WMATA can also create their own version at any time.</li>
  <li>That WMATA forbids users from claiming their data is accurate, complete or timely, or claiming it is more so than WMATA’s data.</li>
  <li>That the transit agency may now charge users in the future for using their data.</li>
</ul>

<p>These are all common changes I’ve seen made to API terms of service before, and are usually signs that a platform operator that is pretty out of touch with what it is like to be an API consumer, and with their own API community. It is a sign of a broken or pernicious feedback loop which leads to API providers making decisions that do lasting damage to their communities like this. These types of changes <a href="https://www.wired.com/2012/09/twitters-new-rules-of-the-road-means-some-apps-are-roadkill/">reflects the “rules of road” terms of service changes Twitter made to back in 2012</a>. Which didn’t fully kill off the Twitter API, but set such a bad tone in the community, the company is still working to dig out of it five years later. I know platform operators feel they need to assert this level of control, but in an API community you need to learn to let go a little, communicate, and work with your community, not against them.</p>

<p>I’m going to work through all of these bullet points as separate stories, and try to help other API providers, as well as the WMATA understand how they might be able to handle these types of requests better. Doing it in a way that doesn’t cause irreparable damage to their communities, and still achieves their objectives. However, I will emphasize that I think if WMATA spent more time actually communicating with their developers, especially the leading ones like MetroHero, you’d probably see how ridiculous your requests area in the first place. APIs are not just about you opening up access to your data, it is about opening up access to your processes, and feedback loops, and collaborating with your community. It isn’t about command and control, and broadcasting the rules of the road for you platform–Twitter showed us this does not work well in todays environment.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/30/licensing-over-dc-transit-data/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/29/sorry-your-api-effort-falls-a-little-short-of-the-apis-I-cover/">Sorry Your API Effort Falls A Little Short For The APIs I Cover</a></h3>
        <span class="post-date">29 Nov 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algo-rotoscope/stories/supreme-court-judgement.jpg" align="right" width="45%" style="padding: 15px;" /></p>
<p>I get a lot of emails from companies asking me to look at their APIs. Too many for a one person operation like me to consider. I have to be picky about the APIs I’m taking a look at, and over time I’ve developed a set of criteria for determining how much energy I will invest in an API. Usually within about 2-3 minutes I can tell if it is an API I will be diving in deeper, or I will just be walking away and moving on with my work.</p>

<p>The first thing that turns me off of an API is that it just isn’t interesting. I’ll land on the page and I can tell what it does, but it just doesn’t interest me. It doesn’t offer any value, or it is in a category that I’m just not eager to be thinking about and showcasing in my work. If an API doesn’t deliver value, and stand out as being interesting beyond the hundreds of other APIs I see each week, I’m just not going to stop and take notice. Sorry, it might be to others–don’t just take my opinion.</p>

<p>The next thing that keeps me from going deeper is I can’t tell what an API does. I’m always amazed at how much head scratching, clicking and reading I will do before I ever figure out what an API does. I’m pretty hard headed, so sometimes its me, but other times I’m just stuck at figuring out what is going on under the hood. Usually after about 3-5 minutes of struggling to understand what is happening, I will just walk away. It is unlikely that other folks will be investing more time than that, and the API will not last long in my experience.</p>

<p>After that, the biggest crime I see companies and organizations make is that they just do not invest enough into a dedicated portal, and the other supporting resources for their API. If someone sends me a link to their API and it is in the help or knowledge base section of their website, I know that they don’t really care about it, and won’t be investing much more into it. APIs shouldn’t be a side project for companies in 2017, they should be front and center, in their own dedicated portal, with a prominent link off the website navigation.</p>

<p>I try to always respond to emails I get from folks letting them know their API efforts fall short of what I’m expecting to see. I feel bad raining on their parade, but the bar is pretty high in 2017. Your API needs to stand out, deliver value, and be something you are investing in. Maybe my response will light the fire under your API operations, and at least get you reading my blog some more, and learning about what other API providers are doing. Then you can take some of what you’ve learned back to your organization and get to work building a first class API operation.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/29/sorry-your-api-effort-falls-a-little-short-of-the-apis-I-cover/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/29/asyncapi-is-a-specification-format-for-message-driven-apis/">AsyncAPI Is A Specification Format For Message-Driven APIs</a></h3>
        <span class="post-date">29 Nov 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/asyncapi/asyncapi-editor-sample.png" align="right" width="45%" style="padding: 15px;" /></p>
<p>I’ve been learning about a new API definition format called AsyncAPI that allows you to define message-driven APIs in a machine-readable format. It is protocol-agnostic, which means you can use it for APIs that work over MQTT, AMQP, WebSockets, STOMP, and other real-time, and Internet of Things focused APIs. The specification format mirrors OpenAPI, making it pretty easy to get up to speed understanding what is going on.</p>

<p>There are two primary concepts at play with the AsyncAPI:</p>

<ol>
  <li>Messages - Consumer(s) communicate with your API via messages. A message is a piece of information two or more programs exchange. Most of the times to notify the other end(s) that, either an event has occurred or you want to trigger a command. Technically speaking the events and actions will always be sent in the same way. These are just messages, and their content can be anything. So when we talk about the difference between events and actions, this is only a semantic differentiation of message’s content. We do not enforce you to make any difference between them, although we encourage you to do it. A message can contain headers and a payload. However, both are optional. The specification allows you to define any header, to remain as much protocol-agnostic as possible.</li>
  <li>Topics -  Message-driven protocols usually contain something called topic (MQTT), routing key (AMQP), destination (STOMP), etc. To some extent, they can compare to URLs in HTTP APIs. So, when you send a message to your API, it will be routed depending on the topic you published on. This feature allows you to create APIs that subscribe to specific topics and publish to other ones.
There’s no standard way of naming topics, so we recommend you to have a look at our proposal here.</li>
</ol>

<p>I don’t have any APIs I can apply AsyncAPI to, so I have to just learn from the examples and any other work I come across. It makes me happy to see folks developing API specifications like this, going beyond what OpenAPI is doing, but also keeping so closely in alignment with the existing work out of the OAI. I’m always hearing folks say that the OpenAPI specification doesn’t do what they want it to do, yet they don’t invest in vendor extensions, or even augment the work that is going on with a complimentary set of specifications. Good to see people just make it happen!</p>

<p>I’m adding AsyncAPI to <a href="http://definitions.apievangelist.com/">my API definition research</a> so I can keep in tune with where it goes. I’m talking with some folks regarding how it should viewed by the OAI. In my opinion, the OAI is going to have to begin considering how it will embrace specs that go beyond what it can do, as well as <a href="http://apievangelist.com/2017/09/25/considering-the-future-of-the-openapi-initiative/">begin to adopt industry specific OAI implementations that may require acknwoledging some vendor extensions that may never get brought into the core specification</a>. Anyways, it’s good to see movement in this area. Nice work <a href="https://twitter.com/fmvilas">Fran</a>, <a href="https://twitter.com/bpedro">Bruno</a>, and <a href="https://twitter.com/PermittedSoc">Mike</a>–you guys are rocking it.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/29/asyncapi-is-a-specification-format-for-message-driven-apis/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/29/api-deployment-is-about-publishing-them-wherever-they-are-needed/">API Deployment Is About Publishing Them Wherever They Are Needed</a></h3>
        <span class="post-date">29 Nov 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/slashdb/slashdb-database-deployment.png" align="right" width="45%" style="padding: 15px;" /></p>
<p><em>This is a sponsored post by my friends over at <a href="https://www.slashdb.com/">SlashDB</a>. The topic is chosen by me, but the work is funded by SlasDB, making sure I keep doing what I do here at API Evangelist. Thank you <a href="https://www.slashdb.com/">SlashDB</a> for your support, and helping me educate my readers about what is going on in the API space.</em></p>

<p>I spun out a separate research area for <a href="http://deployment.apievangelist.com">API deployment</a>, from my core <a href="http://deployment.apievangelist.com">API management research</a> back in 2012 when companies were regularly asking me which of the API management providers they should be using to publish new APIs. At the time, none of them would help you actually publish your APIs, and there just wasn’t enough conversations going on around the subject. When I give talks which include my section on API deployment, some people still scratch their heads thinking there really isn’t that many options on the table–they deploy APIs wherever they’ve been deploying their APIs. However, in a cloud-driven world, the opportunities for how and where we can deploy our APIs are increasing, and the savvy teams are getting more versatile in how they get things done.</p>

<p>Supporting multi-cloud is something all API service providers should be supporting. <a href="https://www.slashdb.com/pricing/">I was reviewing the approach to pricing from my friends and partners over at SlashDB</a>, and I noticed as part of their pricing tier that they have “deployment” as one of the options. Allowing for deployment of their database to API solution on Debian, RedHat, VMWare, VirtualBox, Docker, Vagrant, Amazon, Azure, as well as custom solutions at the enterprise tiers. Focusing on the needs of a diverse range of enterprise customers, while also paying attention to where the API deployment conversation has been shifting for some time with Amazon, Docker, and the other platforms that are dominating the IT landscape.</p>

<p>API service providers should be supporting multiple cloud platforms like SlashDB does, but API providers should also be looking at their own API deployment in the context of multi-cloud as well. You may have your primary way of doing APIs now, but I’m guessing that once you begin doing APIs at scale, your approaches to deploying APIs will begin to shift. When I talk with companies, organizations, institutions, and government agencies about their API deploy practices, it is increasingly common to see different groups using different platforms, as well as multiple API gateways in operation. This is usually not due to some grand plan in place, and has happened in a more organic, and often disorganized way. Sometimes there are good reasons for using different platforms, services, and tools, and other times there is not–it is up to your API governance, and leadership teams to decide which is which.</p>

<p>API deployment should be about publishing APIs wherever you need them. It could because different teams prefer different platforms, tools, and services, or maybe it is a project or partner requirement that you deploy an API somewhere out of the norm. Regardless of the reasons the most seasoned teams I come across are able to roll with the punches, deploy their APIs where they need them, while still keeping in sync with overall API governance and standards practices. In my opinion, both API providers, as well as the API service providers should be multi-platform, and multi-cloud prepared. You may not be fluent, but be ready for the possibility that at some point you may need to get out of your comfort zone. Even if you aren’t actively playing with alternate platforms, services, and tools, I recommend reading and staying in tune with other approaches.</p>

<p>I’ve been pretty content with my hand-crafted approach to deploying APIs using Linux, Apache, MySQL, and Slim PHP API framework. It’s standardized, clean, and something that many of my clients can support. However, I’m rapidly shifting my approach to support AWS API Gateway, as well as beginning to play with different flavors my APIs that are deployable on Google and Azure. I’m looking to keep my toolbox focused, with my primary ways of reliably deploying APIs in as little time as possible. However, I’m fully aware that API deployment has become about being able to publish them wherever they are needed, whether it is one of my clients requesting it, or maybe it is just because I’m looking to deploy a specific API prototype, and tell a specific story on a platform I may not be 100% fluent in–pushing my API deployment skills beyond where they are today.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/29/api-deployment-is-about-publishing-them-wherever-they-are-needed/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/28/making-your-api-pricing-page-accessible-to-everyone/">Making Your API Pricing Page Accessible To Everyone</a></h3>
        <span class="post-date">28 Nov 2017</span>
        <p>I’ve been talking with <a href="https://bitscoop.com/">the folks over at Bitscoop about their integration platform as a service (iPaaS) offering</a>. I would API mapping as a service, but that is another story. After talking with them, and going through their website, I wanted to focus on <a href="https://bitscoop.com/pricing/">Bitscoop’s pricing page</a>, which I feel reflects where API service pricing and plans are headed. There are three main areas of their pricing that I think are worth highlighting for accessing APIs at scale.</p>

<p>Bitscoop is really priced for EVERYONE, with a simple free tier to get started using the platform.</p>

<p align="center"><a href="https://bitscoop.com/pricing/"><img src="https://s3.amazonaws.com/kinlane-productions/bitscoop/bitscoop-pricing-free.png" align="center" width="40%" /></a></p>

<p>Next there are three tiers of access: developer, organization, and enterprise. It’s not as “ascendable” as I’d like it (smoother hop from tier to tier), but because Bitscoop clearly articulates how much additional calls are for each tier, the jump from tier to tier isn’t as painful.</p>

<p align="center"><a href="https://bitscoop.com/pricing/"><img src="https://s3.amazonaws.com/kinlane-productions/bitscoop/bitscoop-pricing-tiers.png" align="center" width="75%" /></a></p>

<p>Closing out the Bitscoop pricing page they have a custom solutions section letting you know they’ll deploy your API service to Google, Amazon, or Azure. Reflecting where API deployment, and API service deployment is headed.</p>

<p align="center"><a href="https://bitscoop.com/pricing/"><img src="https://s3.amazonaws.com/kinlane-productions/bitscoop/bitscoop-pricing-custom.png" align="center" width="75%" /></a></p>

<p>Thats it. That is the story. Make your services accessible. Don’t price people out. Make your solutions available to everyone, with the opportunity to grow. I’m always fascinated by how many differing opinions there are out there regarding how you craft your SaaS and API plans. I think Bitscoop pricing reflects the reality of when you are integrating with hundreds or thousands of APIs. To be able to compete at this scale you are going to have to be plug and play with your tech, as well as the business of your APIs.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/28/making-your-api-pricing-page-accessible-to-everyone/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/28/the-openapi-driven-mock-api-server-from-stripe/">The OpenAPI-Powered Mock API Server From Stripe</a></h3>
        <span class="post-date">28 Nov 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/stripe/stripe-mock-api-server.png" align="right" width="45%" style="padding: 15px;" /></p>
<p>I showcased Stripe’s OpenAPI definition the other week, so I wanted to also highlight a side effect of Stripe deciding to be OpenAPI-Driven. <a href="https://github.com/stripe/stripe-mock#development">Stripe recently published an OpenAPI-powered mock server</a>, allowing Stripe API consumers to test drive, and play with the Stripe API in a simulated environment. “It operates statelessly (i.e. it won’t remember new resources that are created with it) and responds with sample data that’s generated using a similar scheme to the one found in the API reference.”</p>

<p>The Stripe Mock Server is written in Go, and <a href="https://github.com/stripe/stripe-mock">is available on Github</a>. You can rebuild the Stripe API mock server from an updated OpenAPI anytime. It is a pretty dead simple mock server that seems like should be standard practice for any API. Providing a simple, safe, and portable way to play with an API. I’m going to fork the Stripe Mock API and play with it, see what is possible with the tool.</p>

<p>I will be keeping an eye out for any other OpenAPI-powered tools out of Stripe, now they are actively working with it. Adoption of OpenAPI at this level of API provider is helpful to the rest of the community, by providing an example of how you can bake OpenAPI into your operations, but also the open source tooling these companies produce. It’s an important community effect that makes this whole API thing work so well.</p>

<p>Ideally, the leading API providers, with the most resources, could coordinate their efforts and deliver a suite of open source tooling. However, I’m patient, I’m just happy that big companies like Stripe, Slack, Box, New York Times are doing OpenAPI at all. I can wait for all the cool tooling to happen next. I’ll keep an eye on Stripe’s Github organization to see what pops up.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/28/the-openapi-driven-mock-api-server-from-stripe/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/28/getting-a-handle-on-our-database-schema-using-apis/">Getting A Handle On Our Database Schema Using APIs</a></h3>
        <span class="post-date">28 Nov 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algo-rotoscope/stories/server-cloud1_internet_numbers.jpg" align="right" width="45%" style="padding: 15px;" /></p>
<p><em>This is a sponsored post by my friends over at <a href="https://www.slashdb.com/">SlashDB</a>. The topic is chosen by me, but the work is funded by SlasDB, making sure I keep doing what I do here at API Evangelist. Thank you <a href="https://www.slashdb.com/">SlashDB</a> for your support, and helping me educate my readers about what is going on in the API space.</em></p>

<p>When I take money from my partners, I am always looking for characteristics in their products and services that allow me to write honest stories about the solutions they provide. I can’t do this for all API companies that approach me, but the ones that are doing useful things, make it pretty easy for me. <a href="https://www.slashdb.com/">SlashDB</a> helps me out on this front because they aren’t the shiny new startup doing APIs–they are the real world business helping other companies, organizations, institutions, and government agencies get a handle on their databases using APIs. One huge benefit of this process in my opinion is how it helps us get a handle on the schema we use, by letting a little light in on the process.</p>

<p>One of the main reasons our databases are such a mess is because they are hidden away behind a dark technical or organizational curtain, and there really isn’t much accountability regarding how we define, name, organize, and store our data. Of course there are exceptions to this, but a messy, bloated, unwieldy database is a hallmark of about 75% of the organizations I’ve worked with over my 30 year career. Central databases are often a mashup of years, even decades of creating databases, tables, and adding columns, often times occurring over generations of database teams. The result is often an incoherent mess regarding how things are named, with layers of cryptic field names, and irrelevant table names, which might seem normal until you go and try to expose these data resources to 3rd party and partner developers.</p>

<p>Many of the data APIs I come across in my research lack any API design investment. Meaning they didn’t take any consideration when it came to exposing backend databases as coherent paths, parameters, and other elements. Many API providers just spit out the database as a web API, and called it good enough. This can be very frustrating for many Restafarians, and API designers. I agree, and I would love to see more efforts from API providers when it comes to making their APIs more intuitive, and doing the hard work of understand what resources they have, and how to best present their resources to their consumers. However, I feel like just exposing your database as endpoints can be an important first step in the API journey, and one that isn’t always 100% dialed in on day one–that is ok. Just publishing APIs, even if they reflect exactly the table and fields structures behind, is still an important first step for many companies. Not everybody is API design ready, and having APIs can prove to be more important than good design practices.</p>

<p>As I was looking through SlashDB’s site looking for potential story ideas, I thought their approach to exposing database and tables as paths, and helping take the first step of evolving any database towards being an API was worth telling a story about. I know this is the stuff that drives API obsessed folks crazy, and feel I shouldn’t be encouraging people, but I think it is more important that folks are doing APIs, and have embarked on their API journey, over doing things perfectly. API providers like SlashDB aren’t the bleeding edge of API design technology, they are the industrial grade API deployment solutions folks need to go from database to API. So go ahead and publish APIs that look exactly like your database structure. I’m not going to shame you. I think letting the sunlight in a bit is way more healthier than waiting until you have the perfect design, or worse, never doing it at all.</p>

<p>Tools like SlashDB allow us to begin the long process of unwinding our legacy database schema, and start being more consistent in the vocabulary we use. Even though the first version might not be as coherent, and plain language as we’d like, publishing a web API from your backend database like SlashDB provides, at least gets things out on the workbench–allowing you to begin having a conversation with external partners about what the future of your schema should look like. You are never going to learn API design by keeping everything behind closed doors, and even though you are going to have to support your first version out of the box for a significant amount of time–at least you are pushing your schema forward, making it more usable by external partners, and (hopefully) open to discussions about why your database schema might not work 100% at the moment.</p>

<p>Database to API is something ALL companies, organizations, institutions, and government agencies should be doing in 2017. ALL your databases should have web APIs available, even if you are still using ODBC/JDBC and other connectivity options. If you have the time and resources to inject some healthy API design practices into the mix you should, however don’t let it hold back your API deployments if you can’t. You should be eliminating any obstacles between your backend databases and the applications that need access to this data. Even if you did have the time to think through your API design, there is good chance you will need to shift the design of your API down the road based upon the feedback of consumers. So, just get your APIs published today, and begin the hard work of getting a handle on your database schema–it is too important to put off until you have everything just right.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/28/getting-a-handle-on-our-database-schema-using-apis/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/27/multi-region-apis-using-aws-api-gateway/">Multi-Region APIs Using AWS API Gateway</a></h3>
        <span class="post-date">27 Nov 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/amazon/amazon-api-gateway-regions.png" align="right" width="45%" style="padding: 15px;" /></p>
<p>I’ve been deploying two project using AWS API Gateway, Lambda, and Amazon RDS lately. I’ve become so sold on this approach to deploying APIs as part of this work, that I am evolving my own internal API process to use the same approach. The technical aspect of serverless plus the gateway definitely convinced me of the potential, but it was also the usage of AWS IAM which sealed the deal for me. I’m all too aware of how much my API security lacks as a one person shop, something that I also see reflected in my client operations, and I’d rather be offloading security to AWS than ending up taking the hit on it down the road.</p>

<p>While deploying my project using AWS API Gateway, and Lambda, I was faced with the question regarding which zone I should be deploying the APIs in. It is the first time I’ve been faced with the opportunity to deploy my APIs into multiple zones. Sure, I could have deployed my servers into any AWS zone before, but for some reason now that I’m doing with AWS API Gateway, and Lambda, the opportunity seemed more of a possibility. I’ve pitched it to my client to consider an east as well as a west coast API deployment, so that we can give developers the choice in the documentation to choose which availability zone they’d like to use in their application. Before I make the proposal I’m going to deploy some prototypes, and do some benchmark testing, and see what the benefits are.</p>

<p>Even if I end up publishing APIs into separate regions, I still have the backend database to content with. Where do I put the database, and how to I replicate between zones. Amazon RDS gives me the tools to tackle this, but historically I would only do this just for backup, not for actual redundancy, as well as performance gains. Amazon zones have been a staple of the cloud since early days, but I still have many clients who only operate in the east coast region. I’m thinking I will begin to push for a multi-region approach, and see if I can’t convince some of them to start thinking bigger. Getting to know where their customers are, and delivering infrastructure closer where the resources are needed.</p>

<p>I’m rolling out some new APIs as part of my own infrastructure. Most of my APIs are retail, as well as wholesale APIs. Meaning you can use the APIs I’ve published, or I’ll deploy them specifically for you, in your own AWS account. I think I’m going to make east / west an option for my retail APIs, and ALL the AWS regions an option for the wholesale APIs. I’m seeing geographical region as another consideration when I’m thinking about how I should be breaking down my APIs, into smaller more bite-size chunks. I see geographical region as a variable in the host for my APIs, just like I’d add any other variable in the path. Opening up a whole new set of possibilities when it comes to not just API deployment, but also API reliability and performance.</p>

<p>As I continue to drink the AWS Kool-Aid I’m questioning my increased dependence on the platform. However, it gets harder to deny when they bring security to the table, and increased performance, availability, and reliability to my API stack, and the APIs I’m delivering for my clients. There is no way I could afford to do APIs at scale, across multiple regions without AWS. I think back to the day when I would secure my own T1s, colo-facility, and servers. Even with the threat of vendor lock-in, I do not want to ever go back to that world. I enjoy the benefits of AWS. I’m just going to try and keep things as well defined as simple, microservice APIs, so that I can migrate to Google, Azure, or if necessary my own infrastructure. As much as I’d like to reduce my dependencies on major cloud providers, in the current online environment I just can’t. Being able to operate in any region around the globe is a pretty significant benefit to doing business online.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/27/multi-region-apis-using-aws-api-gateway/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/27/hints-of-banking-api-regulations-from-cfpb-with-consumer-authorized-financial-data-sharing-and-aggregation-rules/">Hints of Banking API Regulations From CFPB With Consumer Authorized Financial Data Sharing And Aggregation Rules</a></h3>
        <span class="post-date">27 Nov 2017</span>
        <p><a href="https://www.consumerfinance.gov/about-us/newsroom/cfpb-outlines-principles-consumer-authorized-financial-data-sharing-and-aggregation/"><img src="https://s3.amazonaws.com/kinlane-productions/cfpb/cfpb-outlines-principles-for-consumer-authorized-financial-data-sharing-and-aggregation.png" align="right" width="45%" style="padding: 15px;" /></a></p>
<p><a href="https://www.consumerfinance.gov/about-us/newsroom/cfpb-outlines-principles-consumer-authorized-financial-data-sharing-and-aggregation/">The Consumer Finance Protection Bureau (CFPB) has started laying out some consumer-authorized data sharing and aggregation rules to begin moving forward the banking data scraping conversation in (hopefully) a more production way</a>. It is common knowledge that many financial focused (Fintech) companies regularly access consumers account data using their credentials, so that they scrape relevant account information from their bank, for use in a wide variety of 3rd party tools. This is a common practice that everyone in the industry knows about, understands is a potential security and privacy risk, but everyone looks the other way because it adds value to the consumer ecosystem.</p>

<p>In a perfect world each bank would have a public API portal where Fintech aggregators could come and sign up for application keys, and get the authorization of users via OAuth, and obtain access to their banking data in a secure, and accountable way. However, as we are well aware, we do not live in a perfect world, and banks are pretty resistant to change, so the scraping continues. At some point we are going to see the landscape begin to shift, and I’m guessing it will be at the regulatory level where we finally begin to see this behavior changed–making the CFPB’s rules announcement a reflection of what is coming down the pipes when it comes to banking API regulation.</p>

<p><a href="http://files.consumerfinance.gov/f/documents/cfpb_consumer-protection-principles_data-aggregation.pdf">The consumer protection principles for consumer-authorized financial data sharing and aggregation</a> announcement focuses on:</p>

<ul>
  <li><strong>Access</strong> - Consumers are able, upon request, to obtain information about their ownership or use of a financial product or service from their product or service provider. Such information is made available in a timely manner. Consumers are generally able to authorize trusted third parties to obtain such information from account providers to use on behalf of consumers, for consumer benefit, and in a safe manner. Financial account agreements and terms support safe, consumer-authorized access, promote consumer interests, and do not seek to deter consumers from accessing or granting access to their account information. Access does not require consumers to share
their account credentials with third parties.</li>
  <li><strong>Data Scope and Usability</strong> - Financial data subject to consumer and consumer-authorized access may include any transaction, series of transactions, or other aspect of consumer usage; the terms of any account, such as a fee schedule; realized consumer costs, such as fees or interest paid;
and realized consumer benefits, such as interest earned or rewards. Information is made available in forms that are readily usable by consumers and consumer-authorized third parties. Third parties with authorized access only access the data necessary to provide the product(s) or service(s) selected by the consumer and only maintain such data as long as necessary.</li>
  <li><strong>Control and Informed Consent</strong> - Consumers can enhance their financial lives when they control information regarding their accounts or use of financial services. Authorized terms of access, storage, use, and disposal are fully and effectively disclosed to the consumer, understood by the consumer, not overly broad, and consistent with the consumer’s reasonable expectations in light of the product(s) or service(s) selected by the consumer. Terms of data access include access frequency, data scope, and retention period. Consumers are not coerced into granting third-party access. Consumers understand data sharing revocation terms and can readily and simply revoke authorizations to access, use, or store data. Revocations are implemented by providers in a timely and effective manner, and at the discretion of the consumer, provide for third parties to delete personally identifiable information.</li>
  <li><strong>Authorizing Payments</strong> - Authorized data access, in and of itself, is not payment authorization. Product or service providers that access information and initiate payments obtain separate and distinct consumer authorizations for these separate activities. Providers that access information and initiate payments may reasonably require consumers to supply both forms of authorization to obtain services.</li>
  <li><strong>Security</strong> - Consumer data are accessed, stored, used, and distributed securely. Consumer data are maintained in a manner and in formats that deter and protect against security breaches and prevent harm to consumers. Access credentials are similarly secured. All parties that access, store, transmit, or dispose of data use strong protections and effective processes to mitigate the risks of, detect, promptly respond to, and resolve and remedy data breaches, transmission errors, unauthorized access, and fraud, and transmit data only to third parties that also have such protections and processes. Security practices adapt effectively to new threats.</li>
  <li><strong>Access Transparency</strong>  - Consumers are informed of, or can readily ascertain, which third parties that they have authorized are accessing or using information regarding the consumers’ accounts or other consumer use of financial services. The identity and security of each such party, the data they access, their use of such data, and the frequency at which they access the data is reasonably ascertainable to the consumer throughout the period that the data are accessed, used, or stored.</li>
  <li><strong>Accuracy</strong> - Consumers can expect the data they access or authorize others to access or use to be
accurate and current. Consumers have reasonable means to dispute and resolve data inaccuracies, regardless of how or where inaccuracies arise.</li>
  <li><strong>Ability to Dispute and Resolve Unauthorized Access</strong> - Consumers have reasonable and practical means to dispute and resolve instances of unauthorized access and data sharing, unauthorized payments conducted in connection with or as a result of either authorized or unauthorized data sharing access, and failures to comply with other obligations, including the terms of consumer authorizations. Consumers are not required to identify the party or parties who gained or enabled
unauthorized access to receive appropriate remediation. Parties responsible for unauthorized access are held accountable for the consequences of such access.</li>
  <li><strong>Efficient and Effective Accountability Mechanisms</strong> -  The goals and incentives of parties that grant access to, access, use, store, redistribute, and dispose of consumer data align to enable safe consumer access and deter misuse. Commercial participants are accountable for the risks, harms, and costs they introduce to consumers. Commercial participants are likewise incentivized and empowered effectively to prevent, detect, and resolve unauthorized access and data sharing, unauthorized payments conducted in connection with or as a result of either authorized or unauthorized data sharing access, data inaccuracies, insecurity of data, and failures to comply with other obligations, including the terms of consumer authorizations.</li>
</ul>

<p>Smells like a PSD2-esque set of API standards are on the horizon for the U.S. Ideally this is something the banks would see as an opportunity, rather than a regulatory thing, but I understand how hard-headed they are. I’m spending some time over the next month or two getting up to speed more on where we stand with the PSD2 rollout, as well as the GDPR rollout in the EU. Both of these efforts provide us with a blueprint to follow here in the US. Obviously it is a much different regulatory and banking environment here, but there are still plenty of lessons to consider, and think about as agencies like the CFPB get to work on this topic.</p>

<p>All nine aspects of this latest announcement from the CFPB reflect what APIs are all about. We have the blueprint for tackling this problem head on in use across the tech sector already. This isn’t a technology problem, this is a business and politics problem. It would make sense for a savvy bank (cough, cough Capital One) to get ahead of this one and be the Amazon Web Services of the banking space and set the standard for how data aggregation and sharing occurs. Define the open blueprint for how consumer data is accessed and put to work in the banking ecosystem, gain teh competitive advantage when it comes to Fintech tooling servicing the space, and make all the other banks play catch up. As usual, I’ll keep an eye on what the banks are up to (not much), and look out for more movement from the federal government on this issue, and report back anything I find.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/27/hints-of-banking-api-regulations-from-cfpb-with-consumer-authorized-financial-data-sharing-and-aggregation-rules/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/27/making-sure-you-operate-in-the-cloud-marketplaces-as-an-api-service-provider/">Making Sure You Operate In The Cloud Marketplaces As An API Service Provider</a></h3>
        <span class="post-date">27 Nov 2017</span>
        <p><em>This is a sponsored post by my friends over at <a href="https://www.slashdb.com/">SlashDB</a>. The topic is chosen by me, but the work is funded by SlasDB, making sure I keep doing what I do here at API Evangelist. Thank you <a href="https://www.slashdb.com/">SlashDB</a> for your support, and helping me educate my readers about what is going on in the API space.</em></p>

<p><img src="https://s3.amazonaws.com/kinlane-productions/slashdb/slashdb-automatic-rest-api-for-databases-in-aws-marketplaces.png" align="right" width="45%" style="padding: 15px;" /></p>
<p>As the cloud giants like AWS, Microsoft, and Google continue to assert their dominance of the digital world, one aspect of their operations I’m watching closely has to do with their marketplaces. Google’s marketplaces are still very Android focused, but Amazon and Microsoft have shifted their recent editions of their marketplaces to be more cloud oriented, and accommodating a wide variety of applications, machine learning models, as well as APIs and API-focused services. While these marketplaces are still growing, and asserting their role in the digital economy, they are something I advise API providers, and service providers to be keeping a close eye on, and begin considering how they will want to operate within these environments.</p>

<p>If you are an API service provider, and you are selling services to API providers anywhere along the API lifecycle, I recommend you follow the example of friends over at SlashDB, who have their database to API offerings in two of the leading marketplaces:</p>

<ul>
  <li><a href="https://aws.amazon.com/marketplace/pp/B01MU8W71L"><strong>AWS</strong></a> - Automatically constructing a REST API to databases for reading and writing on the AWS platform.</li>
  <li><a href="https://azuremarketplace.microsoft.com/en-us/marketplace/apps/vte.slashdb"><strong>Azure Marketplace</strong></a> - SlashDB enables you to do more with traditional databases and Microsoft Azure.</li>
</ul>

<p>As more companies, organizations, institutions, and government agencies move their databases into the cloud, SlashDB sees the opportunity to help them quickly turn databases and tables into web interfaces for querying data. Having your API service ready to go, in the environments where your potential customers are already operating is how much of this API stuff will go down in the future. Amazon has set the stage for how we’ll be delivering IT infrastructure over the last decade with the introduction of the cloud, and Google and Microsoft are quickly playing catch up. The savvy API service providers understand their role in this cloud evolution and make sure their services are available as retail solutions, but also as plug and play wholesale solutions in these cloud marketplaces.</p>

<p>SlashDB is clearly serving the deployment and management aspects of the API lifecycle, but I’m tracking on virtualization, testing, monitoring, security, and other aspects of doing business with APIs who are also deploying using these cloud marketplaces. I’m also seeing an uptick in the growth of machine learning models being made available via AWS, Azure, and Google, demonstrating that the algorithmic evolution of the API sector will occur in these environments. The algorithmic wave of APIs is just getting started, but publishing APIs from your databases on the leading cloud platforms is standard operating procedure for businesses of all shapes and sizes in 2017. Are your API services available in the AWS or Azure marketplaces?</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/27/making-sure-you-operate-in-the-cloud-marketplaces-as-an-api-service-provider/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/21/the-defensive-database-administrator-and-the-eager-blockchain-believer/">The Defensive Database Administrator And The Eager Blockchain Believer</a></h3>
        <span class="post-date">21 Nov 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algo-rotoscope/stories/adam-smith_dali_three.jpg" align="right" width="45%" style="padding: 15px;" /></p>
<p>Think about the power that database administrators have in your organizations world? I’ve been working with databases since my first job in 1987. I’ve seen the power bestowed upon database administrators in organization after organization. They are fully aware of the power they control, and most other people in an organization are regularly reminded of this power. The defensive database administrator is always the biggest obstacle in the way of API teams who are often seen as a threat to the power and budgets that database groups command. This power is why databases are often centralized, scaled vertically, and are the backends to so many web, mobile, desktop, and server applications.</p>

<p>I spend a significant amount time thinking about the power that database administrators wield, and how we can work to find more constructive, secure, and sensible approaches to shifting legacy database behaviors. Lately, I also find myself thinking a lot more about Blockchain. Not because I’m a believer, but because so many believers are pushing it onto my radar. Blockchain will continue to be a thing, not because it is a thing, but because so many people believe it is a thing. Most blockchains will not withstand the test of time, they are vapor, but the blockchains that remain will because people have convinced other people to put something meaningful into their blockchain. Much like we have convinced so many companies, organizations, institutions, and government agencies to put data into databases. Yes we. I’m complicit.</p>

<p>A definition of the blockchain is, “a continuously growing list of records, called blocks, which are linked and secured using cryptography”. It’s a database, linked and secured using cryptography. The reason you hear about the blockchain so much, and how it can revolutionize almost every business sector, is the blockchain believers want to convince you to put your digital assets into their blockchain, which will eventually make it something real. I can setup a blockchain today, call it anything I want, but it is nothing more than an empty distributed database. It doesn’t become anything until there is something of value stored in it, which is why there are so many eager folks right now trying to convince that blockchain is something, so you’ll put your valuable things in there, and it will become something.</p>

<p>Think of blockchain believers as the frontend version of the defensive database administrator. After a blockchain has been up for 20 years, and has a bunch of valuable things stored in it, the blockchain believers will become more like the database administrators. They’ll grow beards (even the women), and become more defensive of their precious data stores from whatever the next threat to their power is, and do whatever it takes to defend their power. Blockchain believers are young energetic, and looking to build their empires, and database administrators are usually older and motivated to defend their empires. When you are down in the trenches trapped within the tractor beam of a database it is hard to see beyond it. When you are basking in glow of Internet technology, and everything is new and exciting, it can also be hard to see beyond it. With everything, give it 20 years, and things often times become whatever they’ve replaced.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/21/the-defensive-database-administrator-and-the-eager-blockchain-believer/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/21/when-you-believe-everything-in-tech-is-new-and-nothing-repeats-itself/">When You Believe Everything In Tech Is New And Nothing Repeats Itself</a></h3>
        <span class="post-date">21 Nov 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algo-rotoscope/stories/beach-rocks-currents_blue_circuit_4.jpg" align="right" width="45%" style="padding: 15px;" /></p>
<p>I get regular waves of commenters and tweeters who like to point out the API patterns I’m covering in the API space, have all been done before. We tried discovery docs before they are called WSDL! That API discovery thing is called UDDI! RPC is nothing new! That isn’t new. We tried that before, and it didn’t work. I rarely ever engage with these folks, as this behavior is one pattern in behavior I actually do believe we SHOULDN’t be repeating and showcasing.</p>

<p>I’m fascinated by the reasons someone would feel so strongly they need to respond. That something happened in the past, and because it didn’t work we shouldn’t try again today. That somehow the world of compute isn’t built upon, and remixed upon previous ideas that worked, and many that didn’t work until just the right conditions existed. This kind of behavior is really fascinating for me in the world of APIs where reuse, aggregation, facades, and so many patterns of reworking what already exists is core to the entire concept. Where do folks get such strange believes in the past, and what can and cannot be re-interpreted in the future?</p>

<p>Hey you, electric car manufacturers, the electric car was done in early 20th century and it didn’t work! Hey musician, that baseline was originally present in the big band era and didn’t go over well, it won’t work now! Those pants were first tried in the 1950s and were a flop. Someone already wrote a book on Abraham Lincoln, why would you want to write another? Where do people get the idea that something that existed in the past shouldn’t be tried again, when it comes to the world of technology? Not only have the thought, but so many feel so strongly that they have to reach out and tell me what I’m writing about is dumb because it’s already been done?</p>

<p>What is it about web technology that makes people think something can’t be tried again? That conditions aren’t different now? That they need to condemn people? It’s a fascinating phenomena that surrounds Internet technology. It’s one of the reasons it whispers so strongly to young men, who usually do not have a strong understanding of the past, let alone how the future is built on the past. They feel so strongly in their beliefs, and in technology, that they feel compelled to tell people regularly how wrong they are. This behavior manifests itself in strange ways, it feels oddly like bot behavior, meaning that they operate within a certain set of Internet age rules, and do not understand the real world. They work kind of like antibody against anything that it feels questions its reality that everything is new, everything is awesome, and nothing from the past is important or should be used again.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/21/when-you-believe-everything-in-tech-is-new-and-nothing-repeats-itself/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/21/day-2638-apis-are-dumb/">Day 2,638: APIs Are Dumb</a></h3>
        <span class="post-date">21 Nov 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algo-rotoscope/stories/christianity-under-construction_atari_asteroids.jpg" align="right" width="45%" style="padding: 15px;" /></p>
<p>It is one of those weeks where writing API stories, and doing my API work is completely uninteresting, and my three year old self is throwing a temper tantrum when it comes to doing anything. APIs are dumb. Why the hell would I care about this aspect of technology? Most people don’t understand what the fuck I’m talking about, and people keep doing really dumb shit with them, instead of working on the problems that really matter. Why do I keep doing what I’m doing? Why don’t I just go get a real job, make some real money, and give a shit less? Great question!</p>

<p>Most weeks I can just turn the API Evangelist persona on, and with a notebook full of ideas, and inbox full of questions, I begin writing the API blah blah blah. It just flows. This week it all seems dumb, and I have to fabricate any ounce of caring about APIs. Beyond APIs and Internet technology in general feeling like a pretty bad idea, I feel complicit in helping bring about this technological beast that is wreaking havoc on our world right now. Why the hell should I continue doing API Evangelist, when so many of my ideas can be used for exploitation, and just keep making rich white people richer? It just seems like a bad idea, so why shouldn’t I just shut things down and go find a meaningful job (does that exist)?</p>

<p>First, I always start with the basic API Evangelist mission: helping non-techies understand what APIs are, and how they are right under the hood of everything we are using that is digital. What I do will never receive venture capital, be profitable, and return measurable ROI. Few other companies, let alone individual care about a digitally literate world, they just want consumers, and refuse to see the correlation. I’m the one showcasing API stories consistently regardless of the latest trends, and focus on understanding what is happening outside the current popular areas of investment. I’m the one person that isn’t changing my tune based upon what my investors are telling me, and my storytelling doesn’t reflect where I am at in my runway.</p>

<p>Second, I’m working on important projects. I pushing forward the human services data API (HSDA), and if I get the bandwidth I’ll help lend a hand on Open 311, and work to standardize how we also report issues in cities around the glob. I’m studying how city, state, and federal governments can use common API management practices to generate the next generation of tax base and revenue from the valuable data, and content resources they are stewards of. I’m thinking about how we take back  control from the big tech companies when it our personal data, and content. I’m also thinking about how Twitter, Facebook, and other API platforms are allowing their APIs to be abused by bots because it supports their bottom line, and strengthens their numbers–despite what it is doing to our democracy, our communities, and society. Who else is doing this?</p>

<p>Third, I just don’t want the greedy fucking people to win. I just want to keep being a monkey wrench in the works. I don’t think I’m going to win at this game. I don’t think I’m convince everyone of the right way of doing technology (is there one), but god dam I’m going to make it harder for the people with the money to always win. I’m going to make them spend more money. I’m going work to educate people about how the technology works, and show how we can all resist. On the days that I find it hard to care about educating people about APIs, or even the good APIs projects I’m on, being a wrench in the gears always brightens my day and puts a smile on my face. If nothing else, I’m going to just screw with your grand plans for world domination, and getting rich on our backs. On our data. On our personal lives. I’m going to make you work harder to exploit all of us.</p>

<p>Ok. I’m getting closer to being back on track. Just needed a little reminder of why I’m doing this. APIs are dumb. I’m pretty sure we shouldn’t be fucking doing them in the first place, however with all this technology, algorithms, and artificial stupidity in place, we need some way of making it all a little more observable, and APIs is the best we got. They are the best example I have of making black box algorithms a little more transparent, and how we can take back a little of that data exhaust we generate each day on our mobile phones and laptops. If nothing else, I just need to keep studying this API bullshit so I understand what they are doing, and how they are moving the bits and bytes around in this surveillance capitalism reality we’ve allowed to be constructed. So that when the time is right, I can throw myself against the machine and make it come to a halt, even for a brief moment.</p>

<p>Looking in the mirror: Ok, asshole. Go get em! You can do this. Stop being such a whiney bitch and keep writing stories and doing the research.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/21/day-2638-apis-are-dumb/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/20/generating-operational-revenue-from-public-data-access-using-api-management/">Generating Operational Revenue From Public Data Access Using API Management</a></h3>
        <span class="post-date">20 Nov 2017</span>
        <p><i>This is part of some research I'm doing with <a href="http://apis.how/streamdata">Streamdata.io</a>. We share a common interest around the accessibility of public data, so we thought it would be a good way for us to partner, and Streamdata.io to underwrite some of my work, while also getting the occasional lead from you, my reader. Thanks for supporting my work <a href="http://apis.how/streamdata">Streamdata.io</a>, and thanks for support them readers!</i></p>
<p><img src="https://s3.amazonaws.com/kinlane-productions/public-data-api-management/parks-prohibit-commercial-use.png" align="right" width="45%" style="padding: 15px;" /></p>
<p>A concept I have been championing over the years involves helping government agencies and other non-profit organizations generate revenue from public data. It is a quickly charged topic whenever brought up, as many open data and internet activists feel public data should remain freely accessible. Something I don’t entirely disagree with, but this is a conversation, that when approached right can actually help achieve the vision of open data, while also generating much needed revenue to ensure the data remains available, and even has the opportunity to improve in quality and impact over time.</p>

<p><strong>Leveraging API Management</strong>
I’d like to argue that APIs, and specifically API management has been well established in the private sector, and increasingly in the public sector, for making valuable data and content available online in a secure and measurable way. Companies like Amazon, Google, and even Twitter are using APIs to make data freely available, but through API management are limiting how much any single consumer can access, and even charging per API call to generate revenue from 3rd party developers and partners. This proven technique for making data and content accessible online using low-cost web technology, requiring all consumers to sign up for a unique set of keys, then rate limiting access, and establishing different levels of access tiers to identify and organize different types of consumers, can and should be applied in government agencies and non-profit organizations to make data accessible, while also asserting more control over how it is used.</p>

<p><strong>Commercial Use of Public Data</strong>
While this concept can apply to almost any type of data, for the purposes of this example, I am going to focus on 211 data, or the organizations, locations, and services offered by municipalities and non-profit organizations to hep increase access and awareness of health and human services. With 211 data it is obvious that you want this information to be freely available, and accessible by those who need it. However, there are plenty of commercial interests who are interested in this same data, and are using it to sell advertising against, or enrich other datasets, and products or services. There is not reason why cash strapped cities, and non-profit organizations carry the load to maintain, and serve up data for free, when the consumers are using it for commercial purposes. We do not freely give away physical public resources to commercial interests (well, ok, sometimes), without expecting something in return, why would we behave differently with our virtual public resources?</p>

<p><strong>It Costs Money To Serve Public Data</strong>
Providing access to public data online costs money. It takes money to run the database, servers, bandwidth, and websites and applicatiosn being used to serve up data. It takes money to clean the data, validate phone numbers, email addresses, and ensure the data is of a certain quality and brings value to end-users. Yes this data should be made freely available to those who need it. However, the non-profit organizations and government agencies who are stewards of the data shouldn’t be carrying the financial burden of this data remaining freely available to commercial entities who are looking to enrich their products and services, or simply generate advertising revenue from public data. As modern API providers have learned there are always a variety of API consumers, and I’m recommending that public data stewards begin leverage APIs, and API management to better understand who is accessing their data, and begin to put them into separate buckets, and understand who should be sharing the financial burden of providing public data.</p>

<p><strong>Public Data Should Be Free To The Public</strong>
If it is public data, it should be freely available to the public. One the web, and through the API. The average citizen should be able to come use human service websites to find services, as well as us the API to help them in their efforts to help others find services. As soon as any application of the public data moves into the commercial realm, and the storage, server, and bandwidth costs increase, they shouldn’t be able to offload the risk and costs to the platform, and be forced to help carry load when it comes to covering platform costs. API management is a great way to measure each application consumption, and then meter and quantify their role and impact, and either allow them to remain freely accessing information, or be forced to pay a fee for API access and consumption.</p>

<p><strong>Ensuring Commercial Usage Helps Carry The Load</strong>
Commercial API usage will have a distinctly different usage fingerprint than the average citizen, or smaller non-commercial application. API consumers can be asked to declare they application upon signing up for API access, as well as be identified throughout their consumption and traffic patterns. API management excels at metering and analyzing API traffic to understand where it is being applied, either on the web or in mobile, as well as in system to system, and other machine learning or big data analysis scenarios. Public data stewards should be in the business of requiring ALL API consumers sign up for a key which they include with each call, allowing the platform to identify and measure consumption in real-time, and on recurring basis.</p>

<p><strong>API Plans &amp; Access Tiers For Public Data</strong>
Modern approaches to API management lean on the concept of plans or access tiers to segment out consumers of valuable resources. You see this present in software as a service (SaaS) offerings who often have starter, professional, and enterprise levels of access. Lower levels of the access plan might be free, or low cost, but as you ascend up the ladder, and engage with platforms at different levels, you pay different monthly, as well as usage costs. While also enjoying different levels of access, and loosened rate limits, depending on the plan you operate within. API plans allows platforms to target different types of consumers with different types of resources, and revenue levels. Something that should be adopted by public data stewards, helping establish common access levels that reflect their objectives, as well as is in alignment with a variety of API consumers.</p>

<p><strong>Quantifying, Invoicing, And Understanding Consumption</strong>
The private sector focuses on API management as a revenue generator. Each API call is identified and measured, grouping each API consumers usage by plan, and attaching a value to their access. It is common to charge API consumers for each API call they make, but there are a number of other ways to meter and charge for consumption. There is also the possibility of paying for usage on some APIs, where specific behavior is being encouraged. API calls, both reading and writing, can be operated like a credit system, accumulating credits, as well as the spending of credits, or translation of credits into currency, and back again. API management allows for the value generated, and extracted from public data resources is measured, quantified, and invoiced for even if money is never actually transacted. API management is often used to show the exchange of value between internal groups, partners, as well as with 3rd party public developers as we see commonly across the Internet today.</p>

<p><strong>Sponsoring, Grants, And Continued Investment in Public Data</strong>
Turning the open data conversation around using APIs, will open up direct revenue opportunities for agencies and organizations from charging for volume and commercial levels of access. It will also open up the discussion around other types of investment that can be made. Revenue generated from commercial use can go back into the platform itself, as well as funding different applications of the data–further benefitting the overall ecosystem. Platform partners can also be leveraged to join at specific sponsorship tiers where they aren’t necessarily metered for usage, but putting money on the table to fund access, research, and innovative uses of public data–going well beyond just “making money from public data”, as many open data advocates point out.</p>

<p><strong>Alternative Types of API Consumers</strong>
Discovering new applications, data sources, and partners is increasingly why companies, organizations, institutions, and government agencies are doing APIs in 2017. API portals are becoming external R&amp;D labs for research, innovation, and development on top of digital resources being made available via APIs. Think of social science research that occurs on Twitter or Facebook, or entrepreneurs developing new machine learning tools for healthcare, or finance. Once data is available, identified as quality source of data, it will often be picked up by commercial interests building interesting things, but also university researchers, other government agencies, and potentially data journalists and scientists. This type of consumption can contribute directly to new revenue opportunities for organization around their valuable public data, but it can also provide more insight, tooling, and other contributions to a cities or organizations overall operations.</p>

<p><strong>Helping Public Data Stewards Do What They Do Best</strong>
I’m not proposing that all public data should be generating revenue using API management. I’m proposing that there is a lot of value in these public data assets being available, and a lot of this value is being extracted by commercial entities who might not be as invested in public data stewards long term viability. In an age where many businesses of all shapes and sizes are realizing the value of data, we should be helping our government agencies, and the not for profit organizations that serve the public good realize this as well. We should be helping them properly manage their digital data assets using APIs, and develop an awareness of who is consuming these resources, then develop partnerships, and new revenue opportunities along the way. I’m not proposing this happens behind closed doors, and I’m interested in things following an open API approach to providing observable, transparent access to public resources.</p>

<p>I want to see public data stewards be successful in what they do. The availability, quality, and access of public data across many business sectors is important to how the economy and our society works (or doesn’t). I’m suggesting that we leverage APIs, and API management to work better for everyone involved, not just generate more money. I’m looking to help government agencies, and non-profit organizations who work with public data understand the potential of APIs when it comes to access to public data. I’m also looking to help them understand modern API management practices so they can get better at identifying public data consumers, understanding how they are putting their valuable data to work, and develop ways in which they can partner, and invest together in the road map of public data resources. This isn’t a new concept, it is just one that the public sector needs to become more aware of, and begin to establish more models for how this can work across government and the public sector.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/20/generating-operational-revenue-from-public-data-access-using-api-management/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/17/the-many-meanings-of-do-not-make-the-same-mistake-as-twitter-did-with-their-api/">The Many Meanings Of "Do Not Make The Same Mistake As Twitter Did With Their API"</a></h3>
        <span class="post-date">17 Nov 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algo-rotoscope/stories/kinlane-white-board-twitter_copper_circuit.png" align="right" width="45%" style="padding: 15px;" /></p>
<p>I remember the first time I heard someone say that they didn’t want to make the same mistake as Twitter did with their API. It was from Pinterest. After that I heard the phrase uttered by many companies, with almost an entirely different meaning behind what the mistake was. Twitter is a darling of the API community when it comes to being the poster child for what not to do in the API space. I consider Twitter to be in the top 10 most important APIs out there, as well as being in the top ten APIs I wouldn’t want to be responsible for, and is a platform full of endless examples of how to do APIs right, and how to do them wrong.</p>

<p>When some companies say this phrase, they mean they don’t want to make the mistake Twitter did by having an API at all–usually heard from executives. Other times, it is said in response to anti competitive behavior in their API ecosystem, and treating startups badly. When you hear from developers, it is usually about their rate limits, and their rules of the road they published a few years back. It coming years I predict we’ll be saying it about automation, and using Twitter as case study for how not to assert control of bots on your API platform. You’ll find me leveraging this statement regularly to talk about making sure you have a real API monetization strategy, and don’t wait a decade to start offering premium access to your APIs that are accessible to EVERYONE.</p>

<p><a href="https://apievangelist.com/2012/06/29/twitter-continues-to-restrict-access-to-our-tweets/">I’ve been complaining about access to the Twitter API for over five years now</a>. API plans are the heart of every API I keep an eye on. They set the tone for ALL conversations that go on around an API. The lack of a coherent, equitable, API access plan at Twitter has set into motion almost every other illness on the platform from harassment to bots. Many of the reasons I would utter the phrase “you don’t want to make the same mistake as Twitter” all stem from the lack of a coherent API plan for the platform. Not having a dedicated page, with a coherent plan for access to your API is the number one mistake you can make operating your APIs in 2017.</p>

<p>When I say this, I am not making any assumptions around what you should be charging, or how you should be limiting access. I’m simply saying that you should have to have a plan, and your community needs a URI to be able to become aware of your plan before ever consuming an API. There are may ways you can make your plan too restrictive, and inject other problems into your API plan, but having one is a good start, and really helps distinguish the APIs who have their act together and those who do not. An API plan demonstrates that you, well, have a plan. Having it publicly available in your developer portal, demonstrates some transparency of your plan, and that you are somewhat willing to include your API community in this plan–always a good idea, but you’d be surprised who doesn’t quite understand this.</p>

<p>Twitter’s biggest crime in my book is not having an API plan over the years. There are many ways we can beat up on Twitter for their shortcomings over the years. I’ve done my fair share. However, I do try and understand the scope of their challenges, and showcase the good that comes from the ecosystem as well. I’m hopeful that their move in offering premium APIs is more about defining a coherent plan for the API, and not simply about chasing a new revenue stream. The release of the APIs, and the structure of the plans and pricing seem to reflect they’ve done some deep thinking from the consumer perspective, so I am optimistic they are moving towards having a plan over just squeezing more money out of our information.</p>

<p>The moral of today’s story kids, is that if you don’t want to make the same mistake as Twitter, do not wait a decade to have a plan in place for your API. Make sure all your APIs have a clear monetization strategy, with a coherent plan in place regaring how you’ll manage your APIs in a way that delivers on your monetization strategy, but also provides a shared plan that includes your partners, and regular API consumers. Without a solid plan in place for your API, your community will never truly be in sync with your organization, and you’ll be incentivizing the worst behavior amongst your consumers. Don’t be like Twitter, and have a plan in place from day one.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/17/the-many-meanings-of-do-not-make-the-same-mistake-as-twitter-did-with-their-api/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/17/api-management-is-about-awareness-and-control-over-our-digital-resources/">API Management Is About Awareness And Control Over Our Digital Resources</a></h3>
        <span class="post-date">17 Nov 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algo-rotoscope/stories/adam-smith_blue_circuit.jpg" align="right" width="45%" style="padding: 15px;" /></p>
<p>I’ve been diving into the fundamentals of API management as part of several projects I am working on. I am setting up API management for a single API project, as well as thinking through API management practices across many API implementations in a single industry. I also just had lunch with a friend at an API startup I work with who is looking to invest in me doing some further research and storytelling when it comes to API management. All of this is providing me with a great opportunity to step back and think about API management from the small detailed moving parts, all the way up to the industry, regulatory, and macro levels of managing digital resources online.</p>

<p><a href="http://management.apievangelist.com/">API management</a> is the oldest aspect of my research, and one I still think is one of the most critical aspects of doing APIs in my opinion. While there are many features modern API management brings to the table, the core of it is all about allowing consumers to sign up to access some data, content, media, or algorithm. Each consumer receives a set of keys that will identify and allow for their access to be measured, which then allows the owners or stewards of digital resources to develop awareness around who is accessing a resource, and what they are doing with it. Some call it security, others analytics, but I see it about developing an awareness and asserting control over our digital resources.</p>

<p>If you are focused on monetization, API management is about generating revenue. If you are worried about who has access to your digital assets, API management is about security. If you are doing API management right you realize it is about being aware of the digital resources you have, working to make sure they are well defined, and are tuned into your API management dashboard to understand how they are being used (or not used). I feel like this has been one of the shortcomings of an VC led world of API management, is that it became heavily focused on restricting and controlling access, and fixated on generating revenue, leaving a significant amount of opportunity on the table for making sense of the digital resources we all depend on, and maximizing their access, usage, and yes, revenue.</p>

<p>I see more investment in APIs when it comes to startups getting access to resources. I also see heavy investment when it comes to APIs generating new data points (home, auto, wearables, sensors, etc.) However, when it comes to understanding and quantifying the data, content, and algorithms already in use, there just isn’t much investment. Not there isn’t value there. There just isn’t enough value there to attract VC level interest. I feel like the tech sector wants APIs for all the wrong reasons. The reasons that benefit them. The pervasiveness nature of this way of thinking has stagnated companies, organizations, institutions, and government agencies from establishing control over their vital digital resources, developing awareness, and establishing control, using API management.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/17/api-management-is-about-awareness-and-control-over-our-digital-resources/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/17/we-love-what-you-do-in-the-api-space-now-do-it-our-way/">We Love What You Do In The API Space But Could You Do It Our Way</a></h3>
        <span class="post-date">17 Nov 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/api-evangelist-logos/api-evangelist-butterfly-vertical.png" align="right" width="45%" style="padding: 15px;" /></p>
<p>I hear it daily in my inbox, on Twitter, and via LinkedIn. We love what you do! We’ve followed your work for a while, and love your unique voice, and the way you tell stories on your blog. I’m not very good at accepting praise on my work, especially when I know that much of it isn’t sincere and genuine. Saying it casually to me is weird, and I am not sure why people feel like they should be saying it, but it is the folk who go the distance to say it, but then also try to change the way I am, after acknowledging over and over, that they like what I do.</p>

<p>From running a major conference, to my everyday storytelling, I get waves of people who like what I’ve done historically, want to support and be part of it, but once engaged actively try to change the conversation, and change the tone of what I do. The community has really seemed to rally around your conference, and clearly you’ve built a loyal group by making your event about ideas–we’d like to sponsor, but we really need a main stage talk where we can talk about our products. We love the tone of your storytelling on the blog and how you educated people people about the real world aspects of doing APIs–we’d love to sponsor, but we need you to talk about our products, and shift the focus to what we are doing. There are so many ways people acknowledge the value of what I do, but then want me to do the same old tired thing they’ve been doing.</p>

<p>I get why you do it. It is easy. It is going from zero to what you want in as little time as possible. However, you seem to be all too willing to completely ignore why my thing is working and why your old tired thing isn’t, and why you are even attracted to my thing in the first place. It is because your approach isn’t creative. It is’t genuine. Nobody cares. It takes work to actually care about something, and find the way to share it in a way that folks will actually care about it. You can’t just do this with any technology, product, or service. If I just do your thing, then I’d be just like you, and people like you wouldn’t even notice me. I wouldn’t have any audience, or people who trust me. Maybe that is just want you want though? Maybe I make you look bad, and it would be easier if I just went away.</p>

<p>Honestly, I just can’t get into the heads of why folks are attracted to what I do, approach me, then want to change what I do. Why 1000 lb gorillas are so used to getting their way sponsoring conferences, and getting the tech blogosphere to be their mouthpiece? I guess the ROI on it is still greater than the work of having to do anything meaningful. They can use up small bloggers like me, and move along without any meaningful consequences. I guess many haven’t really stopped to evaluate why I’ve managed to build and maintain an audience of 7 years of doing this, they just hear people talking about what I do, and think “I need some of that!”. Well, I guess you’ll keep doing your version, and I’ll keep doing mine, and we’ll keep meeting like oil and water until one of us gets our way. I’m guessing your type of approach will ultimately win out, but as long as I’m alive I’m going to keep doing my way, just so I can be a monkey wrench in your way of doing things.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/17/we-love-what-you-do-in-the-api-space-now-do-it-our-way/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/17/my-base-yaml-for-starter-api-plans/">My Basic YAML For Starter API Plans</a></h3>
        <span class="post-date">17 Nov 2017</span>
        <p><img src="http://kinlane-productions.s3.amazonaws.com/api_evangelist_site/blog/api_plans_pricing_tiers.png" align="right" width="45%" style="padding: 15px;" /></p>
<p><a href="http://plans.apievangelist.com/">I started developing a machine readable format for describing the API plans and pricing for leading API providers a few years back</a>. Eventually I’d like to see the format live alongside OpenAPI, Postman, and other machine readable API specifications within a single APIs.json index. I am looking to adequately describe the plans and pricing for APIs, which are often just as important as the technical details, in the same way we’ve describe the technical surface area of an API using OpenAPI for some years now. People love to tell me that I will never be able to do it, which only makes me want to do it more.</p>

<p>I’m revisiting my work as part of work I’m doing on a clients project, which I’m also using to push forward my API portal and management toolbox. The project I’m working on has two API plans:</p>

<p>1) Starter - The free level of access everyone gets when signing up for access to an API.
2) Verified - A verified level of pay as you go usage once you have credit card on file.</p>

<p>I’ve taken the common elements across these plans and described them in a YAML format which allows me to remix the elements into the two plans I currently have, while also allowing me to reuse them for possible future plans, helping keep my approach consistent.</p>

<script src="https://gist.github.com/kinlane/e1bbbabe8f24c0aced4d41b45f2295d8.js"></script>

<p>I’m using the plan elements in this YAML file to generate the plans and pricing page for each API. Generating two separate plan boxes, with the details, and elements of each plan. I keep all the moving parts of each plan defined as separate fields and collections so that I can reuse in any new plans. I also make use of the individual elements in comparison charts, and other pricing and plan related resources through an APIs portal. The specification isn’t perfect, but it provides me a starting point for considering how I make my API plans and pricing machine readable, and indexed as part of the <a href="http://apisjson.org/">APIs.json</a> for each of my projects.</p>

<p>Next, I am taking API plan templates and auto-generating plans using AWS API Gateway. I’m going to play around with recreating some of the common plans we see for leading API providers out there using an existing gateway solution. Similar to generating the technical surface area of an API using AWS API Gateway, I’m looking to generate the business surface area of each API using the API Gateway in the same way. Definitely still a lot of work ahead of me when it comes to polishing my API plan specification format, but I feel like it is pretty good start, and after publishing a version for leading API providers, as well as some of the custom projects I’m working on, I think it will be a little more ready for prime time.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/17/my-base-yaml-for-starter-api-plans/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/16/the-three-stripe-openapi-vendor-extensions/">Three Stripe OpenAPI Vendor Extensions</a></h3>
        <span class="post-date">16 Nov 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/stripe/stripes-openapi-vendor-extension.png" align="right" width="45%" style="padding: 15px;" /></p>
<p>As part of my work on <a href="http://openapi.toolbox.apievangelist.com/">my OpenAPI toolbox</a> I am keeping an eye out for how leading API providers are using OpenAPI. One layer of this part of my research is understanding how teams are extending the OpenAPI specification, while also encouraging other companies to understand that they can extend the specification in the first place. I’m always surprised how many people I come across that say they do not use the specification because it doesn’t do everything they need. I alternatively feel like it is my responsibility to understand what the spec can do, and then bend it to do what I need it to using vendor extensions.</p>

<p>I have been studying how <a href="https://github.com/stripe/openapi">payment provider Stripe has been crafting their OpenAPI</a> throughout the week, while also understanding how they are applying it across their platform operations. As part of their Github repository for managing the Stripe OpenAPI they share three vendor extensions they are using to evolve what is possible with OpenAPI:</p>

<ul>
  <li><strong>x-expandableFields</strong> - Resources include an x-expandableFields that contains a list of fields that are expandable by making an API request with an expand parameter. See expanding objects.</li>
  <li><strong>x-polymorphicResources</strong> - Some API responses are “polymorphic” in that they might return multiple types of resources which is a case that OpenAPI can’t handle. In these cases the spec will reference a “synthetic” resource which is an aggregate of the properties common to all the possible resources. It will also include the field x-polymorphicResources which references those resources more precisely.</li>
  <li><strong>x-resourceId</strong> - Resources include x-resourceId which is a canonical name for each resource. It can be used in conjunction with openapi/fixtures{2,3}.{json,yaml} to look up a sample representation (otherwise known as a “fixture”) of the resource.</li>
</ul>

<p>Some interesting extensions. The expandable fields, and resource id is pretty straight forward, but the polymorphic resources opens up some interesting questions when it comes to API design. It makes me want to learn more about the how and why Stripe does this with their API. Maybe it is just me, but I find OpenAPI a very useful tool for quantifying the design decisions that go into an API. I’m eager to learn more about how consistent providers are, as well as understanding where they deviated, and I find vendor extension are useful in revealing clues behind the decisions to deviate from common API design patterns.</p>

<p>I am going to be spending a lot of time studying Stripe’s usage of OpenAPI. It is significant that top tier providers to share their OpenAPI on Github like Stripe does. It helps us learn more about the Stripe API, and the design and documentation decisions that have gone into the payment API. I wish more API providers would share their OpenAPI definition(s) via Github, and share any vendor extensions they have defined. A machine readable API definition on Github, with easy to find vendor extensions, across many API providers sounds like the beginning of a new generation of API discovery. One that can help drive the future of the OpenAPI Initiative (OAI) through real world usage, and shaping the OpenAPI specification road map through actively defining and sharing vendor extensions.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/16/the-three-stripe-openapi-vendor-extensions/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/16/the-information-you-get-when-allowing-developers-to-sing-up-for-api-using-github/">The Information You Get When Allowing Developers To Sign Up For An API Using Github</a></h3>
        <span class="post-date">16 Nov 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/github/github-authentication-screenshot.png" align="right" width="45%" style="padding: 15px;" /></p>
<p>I’m a big Github user. I depend on Github for managing all my projects, and Github Pages for the presentation layer around all my research. When anything requires authentication, whether for accessing an API, or gaining access to any of my micro apps, I depend on Github authentication. <a href="https://gist.github.com/kinlane/00db3d871b615c8b1c43dbc60ae41f86">I have a basic script that I deploy regularly after setting up a Github OAuth application</a>, which I use to enable authentication for my API portals and applications, handling the OAuth dance, and returning me the information I need for my system.</p>

<p>After a user authenticates I am left with access to the following fields: id, avatar_url, gravatar_id, url, html_url, followers_url, following_url, gists_url, starred_url, subscriptions_url, organizations_url, repos_url, events_url, received_events_url, type, site_admin, name, company, blog, location, email, hireable, bio, public_repos, public_gists, followers, following, created_at, updated_at, private_gists, total_private_repos, owned_private_repos, disk_usage, collaborators, two_factor_authentication, and plan. Not all these fields are filled out, and honestly I don’t care about most of them for my purposes, but it does provide an interesting look at what you get from Github, over a basic email and password approach to authentication.</p>

<p>I’m just looking for any baseline information to validate someone is a human being when signing up. Usually a valid email is this baseline. However, I prefer some sort of active profile for a human being, and have chosen Github as the baseline. When anyone signs up I also quickly calculate some other considerations regarding how long they’ve had a Github account, how active it is, and some numbers regarding this history and activity. I don’t expect everyone to have a full blown public Github profile like I do, but if you are looking to use on of my APIs, or API-driven micro tools I’m looking for something more than just a valid email–I want some sign of life. I will be evolving this algorithm, and enforcing it in different ways at different times.</p>

<p>I always hesitate using Github as the default login for my API portals and applications, but honestly I think it is a pretty low bar to expect folks to have a Github account. I feel like we should be raising the bar a little when it comes to who is accessing our resources online. The APIs and tooling I’m making available are mine, and I just want to make sure you are human, and are verifiable on some level, and I find that the links available as part of your Github profile provide me with more reliable and verifiable aspects of being human in the tech space. Making the fields returned as part of Github authentication pretty valuable for verifying humans in my self-service, and increasingly automated world.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/16/the-information-you-get-when-allowing-developers-to-sing-up-for-api-using-github/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/16/you-thinking-i-mean-rest-when-say-apis-is-about-your-limited-views-not-mine/">You Thinking I Mean REST When I Say API Is About Your Limited Views, Not Mine</a></h3>
        <span class="post-date">16 Nov 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algo-rotoscope/stories/kin-chesapeake-sun_light_dali.jpg" align="right" width="45%" style="padding: 15px;" /></p>
<p>I’m fascinated by the baggage people bring to the table when engaging in discussions around technology with me. A common opener for many conversations with season technologists centers around REST not penciling out as everyone thought, failing to be the catch-all solution, and will quickly move to how I feel about some new technology (GraphQL, gRPC, Kafka, other) making my work irrelevant. I wish I had some quick phrase to help folks understand how this line of questioning demonstrates their extremely limiting views of the tech sector, as well as my work with APIs, but alas I find silence usually does the job in these situations–allowing everyone to quickly move.</p>

<p>For me, application programming interface, or API, is all about finding the right interface for programming against for a specific application. I’d say the closest things that anchors my belief system to REST, is that I tend to focus on leveraging the web when it comes to defining the web because it is low coast, usually well known, and avoids reinventing the wheel. I’m not a RESTafarian, and you will not find me online arguing the finer details of REST over other approaches. It just isn’t my style, and I leave it to ya’ll to work out these finer details, and share the stories about what is working, and what is not working in your operations.</p>

<p>Your assumptions around what APIs means to me demonstrates your limited views, only partially because of the technological underpinnings. The technical details of API is only 1/3 of the equation for me, and the majority of my research and storytelling focuses on the business and politics of doing APIs, but I’m guessing you aren’t aware of this. I find that the technology definitely sets the tone for API implementations and conversations, but the ones that actually make a significant impact always transcend the technology, and help acknowledge, and understand the other aspects of operating online which is making doing APIs a good or bad thing. From your opening statements, I’m guessing our conversation won’t be transcending anything.</p>

<p>I appreciate you taking a moment to share your limited view of APIs and what I do. You’ll have to excuse me for not having much to say, but after doing this for seven years I know that I will have little effect to shifting your limited views of what is API, and what it is that I do as the API Evangelist. I know that you feel pretty strongly REST APIs didn’t deliver, but I’m pretty busy helping folks understand how they can effectively manage their digital resources on the web, and securely share and provide access to their data, content, and algorithms using web technology. I don’t see the need for managing and moving our these digital bits going away anytime soon, and I find my time is better spent avoiding the political eddies that swirl at the edges of the API mainstream.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/16/you-thinking-i-mean-rest-when-say-apis-is-about-your-limited-views-not-mine/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/16/stripe-elements-and-how-we-organize-our-api-embeddables/">Stripe Elements And How We Organize Our API Embeddables</a></h3>
        <span class="post-date">16 Nov 2017</span>
        <p><a href="https://stripe.github.io/elements-examples/"><img src="https://s3.amazonaws.com/kinlane-productions/stripe/stripe-elements-grey-embeddable.png" align="right" width="45%" style="padding: 15px;" /></a></p>
<p>I am setting up Stripe for a client, and I found myself browsing through Stripe Elements, and <a href="https://stripe.github.io/elements-examples/">the examples they have published to Github</a>. If you aren’t familiar, “Stripe Elements are pre-built rich UI components that help you build your own pixel-perfect checkout flows across desktop and mobile.” I put Stripe Elements into my bucket of <a href="http://embeddable.apievangelist.com/">API embeddables</a>, which overlaps with <a href="http://sdk.apievangelist.com/">my API SDK research</a>, but because they are JavaScript open up a whole new world of possibilities for developers and non-developers, I keep separate.</p>

<p><a href="https://stripe.com/docs/stripe-js">Stripe.js and supporting elements</a> provides a robust set of solutions for integrating the Stripe API into your website, web or mobile application. You can choose the pre-made element, customize as you see fit, or custom build your own using the Stripe.js SDK. It provides a great place to start when learning about Stripe, reverse engineering some existing solutions, and figuring out what integration will ultimately look like. In my scenario, the default Stripe element in their documentation works just fine for me, but I couldn’t help but playing with some of the others just to see what is possible.</p>

<p>You can tell Stripe has invest A LOT into their Sripe.js SDK, and the overall user experience around it. It provides a great example of how far you can go with embeddable API solutions. I like that they have the Stripe Elements published to Github, and available in six different languages. As I was learning and Googling, I came across other examples of Stripe.js deployment on other 3rd party sites, making me think it would be nice if Stripe had a user generated elements gallery as part of their offering, accepting pull requests from developers in the Stripe community. It wouldn’t be that hard to come up with a template markdown page that developers could fill out and submit, sharing their unique approach to publishing Stripe Elements.</p>

<p>Having a Github repository to display example embeddable API tooling makes sense, and is something I’ll add to my embeddable research. While not all SDKs warrant having their own Github repository, I’d say that embeddable JavaScript SDKs rise to the occasion, and when they are as robust as Stripe Elements might benefit from their own landing page, and forkable, continuously integratable elements. Actually, on second thought, in a CI/CD world I’m feeling like ALL API SDKs should have their own repository, opening up the possibility for them to have their own landing page, issues, and code in a separate repo, for easier integration. I’m going to do a round-up of Stripe’s embeddable efforts, as well as the other SDKs they support, and see what other examples I can extract for other API providers to consider as they pull together their approach to supporting the intersection of embeddable and SDK.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/16/stripe-elements-and-how-we-organize-our-api-embeddables/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/15/form-posts-as-gateway-for-showing-people-they-can-program-the-web-using-apis/">Form Posts As Gateway For Showing People They Can Program The Web Using APIs</a></h3>
        <span class="post-date">15 Nov 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/forms/contact-form.png" align="right" width="45%" style="padding: 15px;" /></p>
<p>I am always looking for new avenues to help on-board folks with APIs. <a href="http://apievangelist.com/2017/11/10/are-people-ready-for-an-online-api-driven-world-that-is-progammable/">I’m concerned that folks aren’t quite ready for the responsibility that comes with a programmable web</a>, and I’m looking for ways to help show them how the web is already programmable, and that APIs can help them take more control over their data and content online. A significant portion of <a href="https://apievangelist.com/2016/04/13/formalizing-my-approach-to-identifying-the-low-hanging-api-fruit/">my low hanging fruit API work</a> centers around the forms already in use across websites, and how these forms are a doorway for data, and content that should also be available via an API. If information is already available on your website, and being gathered or displayed in response to a form on your website, it is a great place to start a conversation around providing an API that delivers the same functionality.</p>

<p>Sometimes forms drive website searches, and act as a way to gather some data before presenting results–providing a good example of a GET API. In other situations forms act as an input for data, such as a contact form, or survey response. In these scenarios, forms provide a good example of a writable, or POST API path–allowing data and content to be added into a system. I’m always pointing out that if data is displayed in tables, or accessible through a form submission on a website, this is where you should start with readable APIs. The same holds true for form submissions that gather data, being where folks should bet starting with writable APIs.</p>

<p>I feel like contact, messaging, and survey forms are all good examples of how companies, organizations, institutions, and government agencies can begin with write APIs. Business users get the concept of a form, and even its submission via a POST on the web. It is a great place to start the conversation with folks about having APIs that don’t just deliver information, but also accept new information using the web. I’m thinking about how I can use Google Forms in conjunction with the work I’ve been doing around managing data using Google Sheets, and exposing it publicly using the Google Sheets API. Demonstrating how simple it is to make data reusable across many applications using Google Sheets, but then also open up access to submit data using Google Forms.</p>

<p>Forms are nothing new in my work as the API Evangelist. I see regular waves of starts emerge to try and crack open the intersection of forms and APIs. I feel like it is one of those areas where we need a lot more training and educational materials, as well as simple prototypes and open source tooling to help folks understand how forms and APIs work together before the next waves of form based startups can get the traction they desire. I feel like there is a significant opportunity to open up the mind of the average business user regarding the programmatically of the web using APIs, but it isn’t just a business opportunity, its an educational opportunity. Which the API space isn’t always good at delivering in because we tend to be so distracted with the building and selling of startups. Hopefully, someone comes along and can use forms as a way to onboard the next wave of API savvy folks, which eventually will pencil out in the success of one or more form centered API startups.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/15/form-posts-as-gateway-for-showing-people-they-can-program-the-web-using-apis/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/15/deploy-low-hanging-fruit-rogue-api-portals-for-those-who-are-behind-the-curve/">Deploy Low Hanging Fruit Rogue API Portals For Those Who Are Behind The Curve</a></h3>
        <span class="post-date">15 Nov 2017</span>
        <p>&lt;p<img src="https://s3.amazonaws.com/kinlane-productions/low-hanging-fruit/api-evangelist-low-hanging-fruit-story-screenshot.png" align="right" width="40%" style="padding: 15px;" />&lt;/p&gt;The concept of rogue APIs isn’t anything new. Instagram started out as a rogue API, and many leading platforms who are less than open with their platforms have rogue APIs. They are usually APIs that have been reverse engineered from mobile applications, and published to Github for other developers to use. I’m looking to marry this concept with <a href="https://apievangelist.com/2016/04/13/formalizing-my-approach-to-identifying-the-low-hanging-api-fruit/">my low hanging fruit API work</a>, where I help organizes start their API journey using data and content that is already on their website. Meaning, if it is already available on the web as table, form, or as CSV, spreadsheet, or other machine readable fie, it should be available via an API. As APIs are just the next step in the evolution, this is the logical place for the API journey to begin for many companies, organizations, institutions, and government agencies.</p>

<p>I’ve spidered the entire web site of organizations to extract lists of data sources they should be turning into APIs. I’ve done this at the request of the website owner, as well as without the permission. Honestly, it provides a pretty compelling look at the digital presence for an organization when you harvest raw data like this and publish to a Github repository. It isn’t a view that every organization is ready for, or has thought about. Making it an even more important place for organizations to start their API journey. APIs aren’t just about providing access to your data and content for your partners and 3rd party developers, it is about getting a handle on your digital assets, and how you present and provide access to this digital representation of your organization–something many suck at profoundly.</p>

<p>I’d like to invest more cycles into <a href="https://apievangelist.com/2016/04/13/formalizing-my-approach-to-identifying-the-low-hanging-api-fruit/">my low hanging fruit API research</a>. I’d love to take some government agencies and not just identify the low hanging fruit, but actually deploy a rogue API portal, and hang some of the APIs there. I’d like to do this to a couple of companies, institutions, as well as government agencies. I know that I’d get in trouble doing this with some companies, and even other entities, but I think it is a good way to instigate the API conversation, and I am willing to take the chance. I<a href="http://university-of-oklahoma-api.apievangelist.com/">had the University of Oklahoma contact me after I scraped their web site</a>, and I think I could recreate the effect with other groups. The trick is doing it in a transparent and observable way, with everything on Github, and communicated in a clear way. So, that someone knows who is behind it, and can reach out to do things in a more formal way–moving from a rogue API, to an official API.</p>

<p>To move this forward I am going to target a single government agency, scrape their website, and any other open daa I can find, and then public an official rogue API portal, and begin hanging some of the APIs there. I’m even going to open up read and write capabilities via the API for any developer who wants to register, and pay for access to the API. I’ll make sure things are clearly marked as being a unofficial rogue API, and provide contact information for anyone looking to communicate with me. I see low hanging fruit rogue APIs as being a way I can get the attention of companies, organizations, institutions, and government agencies when it comes to APIs. Even begin to build awarness and critical mass within a community around the digital assets shared on the website, and now via an API portal. A kind of activist API deployment, and beginning the public API journey.</p>

<p>This goes well beyond the concept of scraping for me. Which I’ve seen a number of startups come and go trying to accomplish. This is about helping show organizations the importance having a website as well as APIs to help counter scraping efforts, and get a better handle on their digital presence. It is meant to start the conversation with some very entrenched folks around the digital resources they are making public, and how APIs can help them better quantify their digital presence, and take control over that presence beyond just their website. If there is an agency, institution, or organization you’d like to see target, or even would be willing to invest some money in deploying a low hanging fruit rogue API portal for, feel free to let me know. I’ll be investing some cycles into this area of my research, just to make sure my content is fresh, while also seeing what new conversations I might be able jumpstart, so its a good time to get involved and fund what I’m doing.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/15/deploy-low-hanging-fruit-rogue-api-portals-for-those-who-are-behind-the-curve/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/15/headless-cms-and-api-evolution-beyond-wordpress/">Headless CMS And The API Evolution Beyond WordPress</a></h3>
        <span class="post-date">15 Nov 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/headless/headless-cms-brackets.png" align="right" width="40%" style="padding: 15px;" /></p>
<p>I am a fan of what WordPress has done for the online world. I feel like it has enabled a lot of folks to take some control over their web presence, and in some situations even made programmers out of business people who never thought that is what they’d end up doing. Even with all the positive benefits of WordPress, it has had some significant negative side effects which I think warrant us to begin looking beyond the existing ecosystem–something I’m hoping the headless CMS, and static website movement can help fuel. I’m not anti-WordPress, but I think the movement has run its course, and we can do better when it comes to helping folks take control over their web presence, as well as avoid much of the security challenges we experience as a result of WordPress.</p>

<p>If you aren’t familiar with the concept of headless, it is just about doing APIs, but centered around the end deliverable–the application. Headless focuses on decoupling content for use in apps, websites, or any other data-driven projects, allowing content to be created and managed independently from where it’s used. To us API-aware folks this is how All applications should behave, but I feel like the headless CMS concept is an important API gateway for business users who have drank the WordPress kool-aid, and are looking to do more with their CMS, and break free of some of the challenges of operating exclusively in a WordPress state of mind.</p>

<p>The most damaging aspect of WordPress I have felt is it’s emphasis on the blog. Everything is centered around the blog with WordPress installs, which isn’t the reason many folks should be doing a website in the first place, but because of their platform they feel compelled to. Headless CMS can be about managing ANY content, and crafting an API backend, that can deliver exactly the content you need in any website, web or mobile backend, bypassing the concept of the blog entirely. Which may not seem like much, but I’ve seen the blog become a pretty big obstacle for some individuals and companies looking to get a handle on their digital content.</p>

<p>The second most challenging aspect of operating WordPress is security. Managing a dynamically driven CMS that is so ubiquitous, and ultimately a huge target by bad actors is daunting for any seasoned IT people, but can be damaging for any unaware individual just trying to manage their website. I stopped running API Evangelist on WordPress because I couldn’t keep up with the security concerns, and operating my public presence as a series of statically published websites has done wonders to the security of my platform. I just do not feel that WordPress is sustainable as a CMS for individuals and companies who do not have the resources to properly manage and secure. There are many flavors of headless CMS, I’m looking to push the more static flavor I’be been seeing on the landscape.</p>

<p>I’m hopeful that the concept of headless coupled with a static CMS can be a proper gateway for individuals, companies, organizations, institutions, and government agencies who want to get a handle on a specific layer of managing their data and content, to learn about APIs. I find that most people aren’t interested in learning about APIs, they are interested in delivering API-driven solutions. Once they get a taste of this, they want to learn more. I feel like the WordPress API is going to be a complicated introduction to the world of APIs for many, but a simple, static, website implementation with a robust API backend provides a much more approachable view of what APIs can do. I’m going to keep an eye on everything headless, and keep scratching out stories to tel my audience about what they can do. I feel like they are key to helping us evolve beyond the Web 2.0 world WordPress set into motion, and begins to give us more control over our backends using APIs, but in a way that help us manage many different front-end applications, with CMS being the first stop for many individuals.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/15/headless-cms-and-api-evolution-beyond-wordpress/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/15/twitter-finally-begins-to-monetize-their-apis/">Twitter Finally Begins To Monetize Their APIs</a></h3>
        <span class="post-date">15 Nov 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/twitter/TwitterPremiumAPIs.gif" align="right" width="45%" style="padding: 15px;" /></p>
<p>It has been a long time coming, but T<a href="https://blog.twitter.com/developer/en_us/topics/tools/2017/introducing-twitter-premium-apis.html">witter has finally started charging for premium access to their APIs</a>. Until now, you could only access data via the free Twitter API with limitations, or pay to use Gnip at the enterprise level–nothing in between. <a href="http://apievangelist.com/2012/06/29/twitter-continues-to-restrict-access-to-our-tweets/">I’ve long complained about how Twitter restricts access to our tweets</a>, as well as <a href="http://apievangelist.com/2015/10/22/if-twitter-can-deliver-transparency-around-api-access-and-business-model-they-might-be-able-to-find-their-way-again/">the lack of transparency and honesty around their business model</a>. I’ve complained so much about it, I eventually stopped writing about it, and I never thought I’d see the day where Twitter starts charging for access to their platform.</p>

<p>While I have concerns about Twitter further limiting access to our data by charging for API access, their initial release has some positive signs that give me hope that they are monetizing things in a sensible way. They seem to be focused on monetizing some of the key paint points around Twitter API consumption, like being able to get more access to historical data, offer more Tweets per request, higher rate limits, a counts endpoint that returns time-series counts of Tweets, more complex queries and metadata enrichments, such as expanded URLs and improved profile geo information. Twitter seems to be thinking about the primary pain we all experience at the lower rungs of Twitter access, and focusing on making the platform more scalable for companies of all shapes and sizes–which has been core to my complaints.</p>

<p>Twitter even provides a quote from a client which highlights what I’ve been complaining about for some time about the inequity in Twitter API access:</p>

<blockquote>
  <p>I wish these premium APIs were available during our first few years. As we grew, we quickly ran into data limitations that prevented expansion. Ultimately, we raised a round of funding in order to accelerate our growth with the enterprise APIs. With the premium APIs, we could have bootstrapped our business longer and scaled more efficiently. - Madeline Parra, CEO and Co-Founder, Twizoo (now part of Skyscanner) @TwizooSocial</p>
</blockquote>

<p><img src="https://s3.amazonaws.com/kinlane-productions/twitter/twitter-plans.png" align="right" width="45%" style="padding: 15px;" /></p>
<p>This demonstrates for me how venture capital, and the way the belief systems around it railroad folks down a specific path, and is blind to those of us who do not choose the path of venture capital. Twitter’s new pricing page starts things off at $149.00 / month, after the current free public tier of access, and climbs up five tiers to $2,499.00 / month. Giving you more access with each access tier you climb. While not a perfect spacing of pricing tiers, something that sill might be difficult for some startups to climb, it is much better than what was there before, or should I say, what wasn’t there. At least you can scale your access now, in a sensible, above the board vertical way, and not horizontally with separate accounts. Incentivizing the more positive behavior Twitter should want to see via their API.</p>

<p>Twitter should have started doing this back in 2008 and 2009 to help throttle bad behavior on their platform. The platform would look very different today if there had been a level playing field in the API ecosystem, and developers weren’t forced to scale horizontally. API monetization and planning isn’t just about generating revenue to keep a platform up and running serving everyone. Sensible API monetization is about being aware of, and intimately understanding platform behavior and charging to restrict, shape, and incentivize the behavior you want to see on your platform. Twitter has missed out on a huge opportunity to truly understand the API community at this level, as well as generate much needed revenue over the years. Shutting out many good actors, incentivizing bad actors, and really only recognizing trusted partners, while being blind to everything else.</p>

<p>After a decade of complaining about Twitter’s practices in their ecosystem, and their clear lack of a business model around their API. I am happy to see movement in this area. While there is a HUGE amount of work ahead of them, I feel like monetization of the API ecosystem, and crafting of a sensible API plan framework is essential to the health and viability of the platform. It is how they will begin to get a hold on the automation that plagues the platform, and begin de-platforming the illness that has become synonymous with Twitter during the 2016 election, while also leveling the playing field for many of us bootstrapped startups who are trying to do interesting things with the Twitter API. I’ll keep an eye on the Twitter premium APIs, and see where things head, but for now I’m cautiously optimistic.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/15/twitter-finally-begins-to-monetize-their-apis/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/14/the-seo-benefits-of-publishing-your-api-operations-to-github/">The SEO Benefits Of Publishing Your API Operations To Github</a></h3>
        <span class="post-date">14 Nov 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/github/github-api-evangelist.png" align="right" width="45%" style="padding: 15px;" /></p>
<p><a href="http://kinlane.com/2013/01/02/all-side-projects-are-now-hosted-on-github/">I’ve been operating 100% of my public presence for API Evangelist on Github for almost five years now</a>. I really like the public layer of my world being static, but I also like the modularity that using Github repos for my projects have injected into my workflow. API Evangelist runs as almost 100 separate Github repositories, all using a common Jekyll template for the UI, making it look like you are always on the same API Evangelist website. Any website, application, data, or API begins as a Github repository in my world, and grows from there depending on how much energy I give a project during my daily work.</p>

<p>When I first started doing all of this, I worried a little bit about the search engine optimization of my public websites. From what I could tell in 2013, my sites ranked lower after the switch, but since I’m not in this for the numbers game, I shrugged it off. However, in 2017 the numbers look different, and some of the projects I’ve been cultivating on Github actually rank pretty high, even with minimal optimization on my part. This isn’t just the web front-end for my projects–I am also seeing the Github repositories themselves showing up pretty prominently in search engine results.</p>

<p>All of this is anecdotal. I haven’t done any official measurements or testing on the topic, I just don’t care enough to invest that amount of work in it all. I just have to note that in the last year I am seeing significant benefit for my SEO by running things on Github. When you bundle this with the search and discovery opportunities via Github, the benefits to running an API project on Github as much as possible makes sense. It is something I encourage all of my clients who are operating public APIs consider as part of their overall marketing, communications, and evangelism strategy.</p>

<p>I’ve been profiling all the possible ways that an API provider can use Github as part of operations for a number of years, but I think I will be reassessing all of this in light of the SEO benefits. Exploring the ways that you can increase the exposure of your public API operations using Github. I don’t think my usage of Github is the only reason behind my SEO domination when it comes to the world of APIs, but I am beginning to think it is playing a bigger role than I had expected. I’m publishing a new API for a client right now, where they have given me full control over publishing to the Github ecosystem, which is a perfect opportunity to rethink all of this, and begin to think a little more constructively about the SEO benefits of using Github for API operations.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/14/the-seo-benefits-of-publishing-your-api-operations-to-github/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/14/glitch-is-where-you-will-learn-the-essential-human-side-of-operating-your-api/">Glitch Is Where You Will Learn The Essential Human Side Of Operating Your API</a></h3>
        <span class="post-date">14 Nov 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/glitch/1_-GNpo5PEhPm-1Ns4F76t9w.png" align="right" width="45%" style="padding: 15px;" /></p>
<p>The biggest deficiency I see in the world of APIs is an ability to understand the human side of what we are all doing. The space is dominated by men, and people who have an understanding of, and deep belief in technology, over that of humans. The biggest problems APIs face across their life cycle is humans, and increasingly one of the biggest threats to humans is an API (ie. Twitter API automation &amp; harassment, IoT device exploitation, Facebook advertising, etc.) APIs encounter human friction because their creators didn’t anticipate the human portion of the equation, and APIs often get used against humans because their creators again didn’t anticipate human nature, and how people might use their technology for doing harmful things.</p>

<p>I rarely see folks in the API sector focusing on the human side of the equation, but I am pleasantly surprised to see a constant drumbeat coming out of <a href="https://glitch.com">Glitch</a>, “the friendly community where you’ll build the app of your dreams.” Glitch is a platform where API consumers can remix apps that use APIs, and API providers can engage with API consumers who are building and remixing interesting things. Glitch has been on my list to write about more, and is something I’ll be using, and focusing more time on in future posts, but I wanted to just highlight how much focus is spent on the human side of the API world over at Glitch.</p>

<p>Take a look at the articles coming out of the Glitch blog, <a href="https://medium.com/glitch/dev-rel-success-requires-an-ongoing-connection-to-a-community-of-peers-ed660b40b62">Dev Rel success requires an ongoing connection to a community of peers</a>, and <a href="https://medium.com/glitch/dev-rel-must-be-supported-with-ongoing-investment-in-professional-development-19ba90326b7a">Dev Rel must be supported with ongoing investment in professional development</a>–all part of the ongoing stories around <a href="https://medium.com/glitch/a-developer-relations-bill-of-rights-21381920e273">a Developer Bill of Rights</a>, which Glitch has been very vocal about, emphasizing the importance of the human aspects of doing APIs and building applications. Which is the first startup I’ve seen come along that is investing so much energy into discussing what really makes all of this actually work.</p>

<p>The core of Glitch is all about building apps. Which is the same core objective of API providers. However, as you begin to spend time there, you begin to learn a lot more about developer relations (dev rel), and the focus on applications just becomes part of the conversation. They do a great job to identify the human elements of building applications, and delivering meaningful things for not just humans, but humans at large organizations. There is talk of working with marketing and sales, and helping developers and API providers not forget about the little meaningful details that can make or break your API efforts. I’m going to spend some time building an app on Glitch, and remix using some of what is already there. I found I’ve learned a lot on their blog, and I am interested in learning more about what they are bringing to the community.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/14/glitch-is-where-you-will-learn-the-essential-human-side-of-operating-your-api/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/14/provide-me-with-api-discovery-using-an-openapi-diff/">Could I Please Get An API Discovery Tool That Evaluates An OpenAPI Diff</a></h3>
        <span class="post-date">14 Nov 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/openapi/openapi-logo.png" align="right" width="30%" style="padding: 25px;" /></p>
<p>I am increasingly tracking on OpenAPI definitions published to Github by leading API providers I track on. Platforms like <a href="http://apievangelist.com/2017/11/12/stripes-openapi-is-available-on-github-in-version-30/">Stripe</a>, <a href="http://apievangelist.com/2017/05/22/box-goes-all-in-on-openapi/">Box</a>, <a href="http://apievangelist.com/2017/03/01/new-york-times-manages-their-openapi-using-github/">New York Times</a> are actively managing their OpenAPI definitions using Github, making them well suited for integration into their platform operations, API consumer scenarios, and even within analyst systems like what I have going on as the API Evangelist.</p>

<p>Once I have an authoritative source of an OpenAPI, meaning a public URI for an OpenAPI that is actively being maintained by the API provider, I have a pretty valuable feed into the roadmap, as well as change log for an API. I feel like we are getting to the point where there are enough authoritative OpenAPIs that we can start using as a machine readable notification and narrative tool for helping us stay in tune with one or many APIs across the landscape. Helping us stay in tune with APIs in real-time, and giving APIs an effective tool for communicating out changes to the platform–we just need more OpenAPIs, and some new tooling to emerge.</p>

<p>I’m envisioning an OpenAPI client that regularly polls OpenAPIs and caches them. Anytime there is a change it does a diff, and isolated anything new. Think of an RSS reader, but for OpenAPIs, and going well beyond new entries, and actually creates a narrative based upon the additions and changes. Tell me about the new paths added, and any new headers, parameters, or maybe how the schema has grown. Provide me insights on what has changed, and possibly what has been removed, or will be removed in future editions. As an API analyst, I’d like to be able to have an OpenAPI-enabled approach to receiving push notifications when an API changes, with a short, concise summary about what has change in my inbox, via Twitter, or Github notification.</p>

<p>OpenAPI already provides API discovery features through the documentation it generates, and I’m increasingly using Github to find new APIs after they publish their OpenAPIs to Github, but this type of API discovery and notification at the granular level would be something new. If there was such tooling out there, it would provide yet another incentive for API provides to publish and maintain an active, up to date OpenAPI definition. This is a concept I’d like to also see expanded to the API operational level using <a href="http://apisjson.org/">APIs.json</a>, where we can receive notifications about changes to documentation, pricing, SDKs, and other critical aspects of API integration, beyond just the surface area of the API. All of this stuff will take many years to unfold, as it has taken over five years for us to reach a critical mass of OpenAPI definitions to emerge, I suspect it will take another five to ten years for robust tooling to emerge at this level, which also depends on many API definitions to be available.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/14/provide-me-with-api-discovery-using-an-openapi-diff/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/14/added-a-simple-bulk-api-for-my-human-services-data-api/">I Added A Simple Bulk API For My Human Services Data API</a></h3>
        <span class="post-date">14 Nov 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/open-referral/human-services-data-bulk-api.png" align="right" width="45%" style="padding: 15px;" /></p>
<p>The core Human Services Data API allows for adding of organizations, locations, services, and contacts one by one using a single POST on the core API paths for each available resource. However, if you want to add thousands, or even hundreds of records, it can quickly become cumbersome to submit each of the calls, so I wanted to introduce a simple Human Services Bulk API for helping handle the adding of large quantity of data, on a one-time, or recurring basis. I know there job queuing solutions available out there, but my goal with this project is to focus on the API definition, as well as the backend system(s). For this round, I just want to get a simple baseline definition in place, with a simple API backend for orchestrating. I’ll update to support AWS, and other queuing solutions as part of the road-map–further hammering out a consistent <a href="http://developer.open.referral.adopta.agency/#HSDA Bulk">HSDA Bulk API</a>.</p>

<p>The first dimension of this new HSDA Bulk API focuses on providing paths for POSTing large quantities of data across the core human service resources:</p>

<ul>
  <li>organizations/ - POST complete organizations JSON records as array.</li>
  <li>locations/ - POST complete locations JSON records as array.</li>
  <li>services/ - POST complete services JSON records as array.</li>
  <li>contacts/ - POST complete contacts JSON records as array.</li>
</ul>

<p>You can submit as many records to each of these paths (well, within reason), including the sub-resources for each object like physical address, phones, etc. When POSTed each record doesn’t immediately go into the main HSDA database. Each entry is entered into a jobs system, which can be run on a schedule, based upon events, or maybe just wait until the middle of the night. The goal is to offload the bulk insert to a job system, which can spread things out over time, and minimize negative impact on resources strapped human services database. HSDA Bulk API runs as a separate microservice which can be run side by side with the core HSDA implementation, or possibly scaled on separate infrastructure to allow for handling of expected loads.</p>

<p>The next dimension of this new HSDA Bulk API allows for importing of <a href="https://openreferral.readthedocs.io/en/latest/hsds/reference/">HSDS datapackage.json files</a>, bringing things back to basics with the Human Services Data Specification(HSDS). <a href="https://s3.amazonaws.com/kinlane-productions/open-referral/sample-datapackage/datapackage.json">The JSON file contains a list of paths to individual HSDS CSV files</a>, which are then processed as individual resources, with each record inserted as a job, for running on schedule, event, or other approach. Adding a more comprehensive approach to loading up large datasets into any human services system using an HSDA API, while also continuing to smooth out the impact of the core system using jobs.</p>

<p>With both of these dimension, you can perform bulk uploads of data using the individual organizations, locations, services, and contacts page, as well as a complete datapackage.json file. Next I will be hammering on the demo API I have a bunch more, to harden the code, and see if I’m missing any details. After that I’ll started looking at switching out the custom backend I have with an AWS API Gateway managed, and possibly AWS SQS or other jobs solution. I’m trying to keep <a href="https://github.com/human-services/portal/blob/master/_data/api-commons/openapi-hsda-bulk.yaml">the HSDA Bulk API definition</a> simple, but also allow for scaling up with other more robust backend system. For now, I’d call this edition of <a href="http://developer.open.referral.adopta.agency/#HSDA Bulk">the HSDA Bulk API</a> to be a decent v1.0 start for this new HDSA microservice.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/14/added-a-simple-bulk-api-for-my-human-services-data-api/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/13/i-added-a-taxonomy-api-to-support-the-human-services-data-api-hsda/">I Added A Taxonomy API To Support The Human Services Data API (HSDA)</a></h3>
        <span class="post-date">13 Nov 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/open-referral/human-services-taxonomy-api.png" align="right" width="45%" style="padding: 15px" /></p>
<p>I have been organizing <a href="http://org.open.referral.adopta.agency/">my Human Services Data API (HSDA) specification work</a> into separate microservices as part of version 1.0 for the API definition that cities and other organizations running 211 operations can pick and choose which aspects they want to run. One service I carved off of the move from version 1.0 to 1.1 of the specification was taxonomy, and how the human services are categories and organized. I saw there was more research to be done around 211 taxonomy, and I felt it had the potential to be a separate but supporting service to augment what Open Referral is already trying to do with <a href="http://org.open.referral.adopta.agency/#Specification">the Human Services Data API (HSDA) specification</a>.</p>

<p><a href="http://developer.open.referral.adopta.agency/#HSDA Taxonomy">The HSDA Taxonomy API specification provides a handful of API paths for creating, reading, updating, and deleting taxonomy used in any HSDA implementation</a>. I have populated my demo API with <a href="https://github.com/auntbertha/openeligibility">the Open Elegibility taxonomy</a> to help jumpstart folks, but any HSDA provider can populate with their own custom taxonomy, or other existing format. Then you can apply any taxonomy to any of the services stored within an HSDA database, and there is an API path for querying services by taxonomy. Next I’ll make sure you can search by taxonomy, and see the taxonomy as part of the response body for all services returned across HSDA, HSDA Search, and HSDA Taxonomy.</p>

<p>HSDA Taxonomy API is a simple service, but it is one that I want to get up and running, and maturing quickly. I feel like there is a lot of opportunity around 211 taxonomy aggregation, an further standardizing and evolving on top of Open Eligibility, or establishing a separate Open Referral taxonomy that can be open source. The current 211 taxonomy dominating the landscape is the AIRS 211 format, which is a proprietary taxonomy, something that I’ll address in a separate post. Have a shared vocabulary around human services is almost as important as the data itself–if you can’t find meaningful services, in a consistent way across providers, the data itself becomes much less valuable.</p>

<p><a href="http://developer.open.referral.adopta.agency/#HSDA Taxonomy">I have launched a demo copy of the API at my Human Services Demo API</a>, and next I am working on a handful of UI elements for managing, browsing, and searching for services using the HSDA Taxonomy API. My goal is to get v1.0 of the HSDA Taxonomy specification being discussed as part of the overall HSDA governance process, while I’m also hardening the API, and UI tooling via a couple of HSDA implementations I’m working on. Then I’ll circle back in a couple months and see where things are, learn more about some other taxonomies, and hopefully pull together more of a strategy around how to get people sharing 211 taxonomies, and speaking a common language about how they categorize human services, as well as store and provide access to human service organizations, locations, and services.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/13/i-added-a-taxonomy-api-to-support-the-human-services-data-api-hsda/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/12/stripes-openapi-is-available-on-github-in-version-30/">Stripes OpenAPI Is Available On Github In Version 3.0</a></h3>
        <span class="post-date">12 Nov 2017</span>
        <p><a href="https://github.com/stripe/openapi"><img src="https://s3.amazonaws.com/kinlane-productions/stripe/stripes-openapi-specification-on-github.png" align="right" width="45%" style="padding: 15px;" /></a></p>
<p>I can’t write about every API provider who publishes their OpenAPI to Github, there are just too many. But, I can write about the rockstar API providers who do though, and showcase what they are doing, so I can help influence the API providers who have not started publishing their OpenAPIs in this way. If you are looking for a solid example of a leading API provider publishing their OpenAPI to Github, <a href="https://github.com/stripe/openapi">I recommend taking a look at the payment provider Stripe</a>.</p>

<p><a href="https://github.com/stripe/openapi">Their repository contains OpenAPI specifications for Stripe’s API</a>, with multiple files available in the in the openapi/ directory:</p>

<ul>
  <li><strong>spec3.{json,yaml}</strong> - OpenAPI 3.0 spec.</li>
  <li><strong>spec2.{json,yaml}</strong> - OpenAPI 2.0 spec. We’re continuing to generate this for now, but it will be deprecated in favor of spec3.</li>
  <li><strong>fixtures3.{json,yaml}</strong> - Test fixtures for resources in spec3. See below for more information.</li>
  <li><strong>fixtures2.{json,yaml}</strong> - Test fixtures for resources in spec2.</li>
</ul>

<p>It is pretty exciting to see them already embracing version 3.0. They even provide a listing of the OpenAPI vendor extensions they are using, which are specific to their API. <a href="http://openapi.toolbox.apievangelist.com/">I’ll be adding these to my OpenAPI toolbox</a> when I have the time, adding to the number of vendor extensions I have indexed. Stripe provides another pretty solid example of an API provider taking ownership of their OpenAPI spec, publishing to Github for their consumers to put tow rok, but clearly they are also using as part of their own internal workflows as well.</p>

<p>Every API provider should have a Github repository with an up to date OpenAPI <a href="https://github.com/stripe/openapi">like Stripe does</a>. I know many API architects envision a hypermedia API discovery landscape, where APIs are defined and discoverable by default, but I think an OpenAPI on Github is the best we can hope for at this stage in the evolution of the space. With the momentum I’m seeing in the number API providers publishing their OpenAPIs to Github, I’m feeling like Github is going to become the continuous integration, API discovery engine we’ve all been looking for over the last decade. Allowing us to discover, integrate and orchestrate with our APIs across the API life cycle–we just need everyone to follow Stripe’s lead. ;-)</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/12/stripes-openapi-is-available-on-github-in-version-30/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/12/locking-up-any-taxonomy-is-short-sighted-in-todays-online-environment/">Locking Up Any Open Data Taxonomy Is Short Sighted In Todays Online Environment</a></h3>
        <span class="post-date">12 Nov 2017</span>
        <p><a href="https://211taxonomy.org/"><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/open-referral/211tax.png" align="right" width="40%" style="padding: 15px;" /></a></p>
<p>I published a taxonomy API as part of my Human Services Data API (HSDA) work recently, and as part of the work I wanted it to support a handful of the human services taxonomies available currently. The most supported taxonomy available out there is <a href="https://211taxonomy.org/">the AIRS/211 LA County Taxonomy</a>. It is a taxonomy in use by 211 of LA County, as well as owned and licensed by them. From what I gather, it is the most common format in use, and <a href="http://211wny.org/index.php/airs-license">you can find licensing pages for it from other municipal 211 providers</a>. Before you can download a copy of the taxonomy you have to agree to the license I’ve posted at the bottom of this post, something I was unwilling to do.</p>

<p>Taxonomies shouldn’t be locked up this way. Let alone taxonomies for use in open data, helping citizens at the municipal level. I understand that 211 LA will argue that they’ve put a bunch of work into the schema, and therefore they want to protect what they view their intellectual property, but in 2017 this is wrong. This isn’t the way things should be done, sorry. The AIRS taxonomy should be openly available, and reusable in a machine readable format, and evolved by an open governance process. There is no reason for this valuable taxonomy, that has the potential to make our cities better, should be locked up like this–it needs to be widely used, and adopted without any legal friction along the way.</p>

<p>I understand that it takes work, and resources to keep a taxonomy meaningful, and usable, but we should not stand in the way of people finding human services, and restricting 211 providers from using the same vocabulary. There are other was to generate revenue, and evolve forward a taxonomy in an online, collaborative environment, much like we are currently doing with open source software. This kind of stuff drives me nuts, and the licensing around this important technology is something I’ll keep an eye on, and contributing whatever I can to help stimulate the discussion in favor of open sourcing. In the absence of AIRS, I have adopted <a href="https://github.com/auntbertha/openeligibility">an open source 211 taxonomy called Open Eligibility</a>, but alas it seems like an effort that has gone dormant. <a href="https://github.com/human-services/openeligibility">I have forked the specification</a>, added more simpler JSON, CSV, and JSON formats which I will be working with it alongside the rest of <a href="http://developer.open.referral.adopta.agency/#HSDA Taxonomy">my Human Services Data API (HSDA) taxonomy work</a>.</p>

<p>Taxonomy licensing is another area of consideration I’ll add to <a href="http://licensing.apievangelist.com/">my API licensing research</a>, as well as for guidance around my HSDA work. I wish this type of stuff didn’t still happen in 2017. It is a relic of another time, and in a digital age, taxonomies for any aspect of public infrastructure should be openly licensed, and reusable by everyone. I would like to see <a href="http://openreferral.org/">Open Referral</a> expand its portfolio to push forward one or more taxonomies for not just human services, but also organizations, locations, and potentially other relevant schema we are pushing forward. I see Open Referral as an incubator for schema, OpenAPI definitions, as well as datasets like 211 taxonomy, helping provide a commons where 211 organizations can find what they need.</p>

<hr />

<p>TAXONOMY SUBSCRIPTION AGREEMENT</p>

<p>CAREFULLY READ THIS TAXONOMY SUBSCRIPTION AGREEMENT BEFORE DOWNLOADING, INSTALLING OR USING THE TAXONOMY (DEFINED BELOW). TAKING ANY STEP TO DOWNLOAD, INSTALL OR USE THE TAXONOMY IN ANY WAY CONSTITUTES YOUR ASSENT TO AND ACCEPTANCE OF THIS AGREEMENT AND IS A REPRESENTATION BY YOU THAT YOU HAVE THE AUTHORITY TO ASSENT TO AND ACCEPT THIS AGREEMENT. IF YOU DO NOT AGREE WITH THE TERMS AND CONDITIONS OF THIS AGREEMENT, YOU MUST NOT DOWNLOAD, INSTALL OR USE THE TAXONOMY AND YOU MUST IMMEDIATELY RETURN THE TAXONOMY (AND NOT KEEP ANY COPIES) TO 211 LA AND SO NOTIFY 211 LA OF SUCH FAILURE TO AGREE.</p>

<p>Taxonomy Subscription Agreement (“Agreement”) contains the terms and conditions by which Information and Referral Federation of Los Angeles, Inc., doing business as 211 of LA County (“211 LA”) provides a subscription license to use the Taxonomy. This Agreement is a binding legal contract between you (both the individual downloading, installing and/or using the Taxonomy and, if applicable, the legal entity on behalf of which such individual is acting) (“Subscriber”) and 211 LA.</p>

<p>1.Definitions</p>

<p>Subscriber Database means a database of health and human services information and resources that is created and maintained by Subscriber.</p>

<p>Subscriber Directory means a printed directory or electronic read-only directory of health and human services that is created and maintained by Subscriber using a Subscriber Database. As used in this definition, “read-only” means an electronic version of a directory in which the information in such directory, including the Taxonomy, cannot be modified or altered in any way.</p>

<p>Subscription Order Form means the form(s) used by 211 LA for allowing subscribers to purchase or renew subscription licenses of the Taxonomy.</p>

<p>Taxonomy means the Taxonomy of Human Services maintained and made generally available by 211 LA for purposes of indexing health and human services information and resources, including its terms, definitions, codes and references and any and all updates, upgrades, enhancements or other modifications that may be made available by 211 LA to Subscriber from time to time.</p>

<p>Taxonomy Website means a website hosted by 211 LA through which subscription licenses for the Taxonomy can be purchased and the Taxonomy can be downloaded.</p>

<p>2.Taxonomy License.</p>

<p>Limited License. Subject to Subscriber’s compliance with the terms and conditions of this Agreement (including, without limitation, Sections 2.2, 2.3, 3 and 4), 211 LA hereby grants to Subscriber a limited, non-exclusive, non-transferable, non-sublicensable license to:</p>

<p>access portions of the Taxonomy Website designated by 211 LA for subscribers and download the Taxonomy as made generally available thereon;</p>

<p>use the Taxonomy, including its codes, terms, definitions, and references, as a classification structure for indexing health and human services information and resources in a Subscriber Database;</p>

<p>include Taxonomy terms in a survey instrument prepared by Subscriber as reasonably necessary to collect information from third party organizations regarding health and human services, provided that such survey instrument may only include the Taxonomy terms that Subscriber has used to index health and human services information and resources in the Subscriber Database;</p>

<p>include Taxonomy terms as an index in a Subscriber Directory distributed or otherwise made available to third parties (including over the Internet), provided that (i) the proceeds of any monetary or other consideration provided in connection with such distribution are provided to a non-profit, charitable organization and (ii) any such Subscriber Directory may only include the Taxonomy terms that Subscriber has used to index health and human services information and resources in the Subscriber Database, along with any higher level terms on the same branch that are needed to display the hierarchical structure; and</p>

<p>include the Taxonomy definitions in the Subscriber Directory referenced in Section 2.1(d) above, provided that such Subscriber Directory may include only those definitions for terms that Subscriber has used to index health and human services information and resources in the Subscriber Database.</p>

<p>License Restrictions. Nothing contained in this Agreement will be construed as conferring upon Subscriber, by implication, operation of law or otherwise, any license or other rights except as expressly set forth in Section 2.1. Subscriber shall not, and shall not allow any third party to: (i) copy, display or otherwise use all or any portion of the Taxonomy except as incorporated into a Subscriber Directory as permitted in Section 2.1; (ii)  transmit or otherwise distribute the Taxonomy (or any portion of the Taxonomy) as a separate product, module or material to any end user or other third party, or make the Taxonomy (or any portion of the Taxonomy) available to any end user or other third party as a downloadable file separate from a Subscriber Directory; (iii) transmit or otherwise distribute any portion of the Taxonomy for commercial purposes or otherwise for profit or other monetary gain; (iv) incorporate the Taxonomy (or any portion of the Taxonomy) into any database or software through which the Taxonomy (or any portion of the Taxonomy) can be printed, downloaded or modified; or (v) loan, lease, resell, sell, offer for sale, sublicense, adapt, translate, create derivative works of or otherwise modify or alter all or any part of the Taxonomy. Further, Subscriber acknowledges and agrees that use of the Taxonomy Website is also subject to 211 LA’s Terms of Use, as made available thereon and updated from time to time.</p>

<p>Notice.</p>

<p>If the Taxonomy, or any potion of the Taxonomy (including its terms, codes, definitions or references), are utilized in a Subscriber Directory that is published, transmitted, distributed or otherwise made available to third parties, by any means or medium, the Subscriber shall prominently display the following notice in such directory:</p>

<p>Copyright © 1983-2007, Information and Referral Federal of Los Angeles County, Inc. All rights reserved. The index, codes and definitions of the terms contained herein are the intellectual property of Information and Referral Federal of Los Angeles, Inc. and are protected by copyright and other intellectual property laws. No part of this listing of human services terms and definitions may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electrical, mechanical, photocopying, recording or otherwise without the prior written permission of the Information and Referral Federal of Los Angeles County, Inc.</p>

<p>If the Taxonomy is displayed or otherwise made available in a Subscriber Directory via the Internet, Subscriber shall prominently include a link to a copyright acknowledgement statement that 211 LA maintains online, currently located at: http://www.211la.org/Content.asp?Content=Taxonomy&amp;SubContent=Copyright.</p>

<p>3.Intellectual Property Ownership.</p>

<p>Ownership of the Taxonomy. As between 211 LA and Subscriber, 211 LA retains and shall own all right, title and interest in and to the Taxonomy and any derivative works or other modifications thereof, including, without limitation, all copyright, trademark, trade secret and other intellectual rights, subject only to the limited license set forth herein. Subscriber does not acquire any other rights, express or implied, in the Taxonomy. Subscriber hereby assigns, and agrees to assign, to 211 LA all right, title and interest (including all intellectual property rights) throughout the world that Subscriber has or may have in the Taxonomy (including with respect to any modifications suggested by, or other contributions made by, Subscriber), which assignment shall be deemed effective as to any future modifications or contributions immediately upon the creation thereof. Subscriber further irrevocably waives any “moral rights” or other rights with respect to attribution of authorship or integrity of any modifications suggested by, or other contributions made by, Subscriber under any applicable law under any legal theory.</p>

<p>Access and Security.</p>

<p>Subscriber is solely responsible for providing, installing and maintaining at Subscriber’s own expense all equipment, facilities and services necessary to access and use the Taxonomy, including, without limitation, all computer hardware and software, modems, telephone service and Internet access.</p>

<p>Subscriber may be issued or otherwise assigned a user identification and/or password (collectively, “User Identifications “) to access the Taxonomy and/or Taxonomy Website as permitted hereunder. Subscriber is solely responsible for tracking all use of the User Identifications and for ensuring the security and confidentiality of all User Identifications. Subscriber acknowledges that Subscriber is fully responsible for all liabilities incurred through the use of any User Identification and that any download, transmission or transaction under a User Identification will be deemed to have been performed by Subscriber.</p>

<p>Subscriber shall ensure that each of its employees complies with this Agreement, including, without limitation, the license restrictions in Section 2.2 and shall protect the Taxonomy from any use that is not permitted under this Agreement. Subscriber shall promptly notify 211 LA of any unauthorized copying, display, modification, transmission, distribution, or use of the Taxonomy of which it becomes aware.</p>

<p>211 LA reserves the right at any time and without prior notice to Subscriber to change the hours of operation of the Taxonomy Website or to limit Subscriber’s access to the Taxonomy (i) in order to perform repairs or to make updates, upgrades, enhancements or other modifications or (ii) in response to unforeseen circumstances or circumstances beyond 211 LA’s reasonable control. 211 LA may add or withdraw elements of to or from the Taxonomy and/or Taxonomy Website from time to time in its sole discretion, although Subscriber acknowledges and agrees that 211 LA has no obligation to maintain or provide any updates, upgrades, enhancements, or other modifications to the Taxonomy or Taxonomy Website.</p>

<p>Verification. 211 LA may, during the term of this Agreement and with seven (7) days prior notice, request and gain access to Subscriber’s premises for the limited purpose of conducting an inspection to determine and verify that Subscriber is in compliance with the terms and conditions hereof. Subscriber shall promptly grant such access and cooperate with 211 LA in the inspection; provided, however, the inspection shall be conducted in a manner not intended to disrupt unreasonably Subscriber’s business and shall be restricted in scope, manner and duration to that reasonably necessary to achieve its purpose.</p>

<p>4.Payment</p>

<p>Payment. In consideration for the subscription license granted under Section 2.1, Subscriber shall pay the applicable fees as set forth in the Subscription Order Form and/or Taxonomy Website. All fees are nonrefundable. Any information that you may provide in connection with obtaining the subscription (including any nonprofit and/or AIRS membership information) may be verified and your subscription license may be placed on hold or terminated in the event of inaccuracies or discrepancies.</p>

<p>Taxes. In addition to all applicable fees, Subscriber shall pay all sales, use, personal property and other taxes resulting from this Agreement or any activities under this Agreement, excluding taxes based on 211 LA’s net income, unless Subscriber furnishes proof of exemption from payment of such taxes in a form reasonably acceptable to 211 LA. Further, If Subscriber is required by law to deduct or withhold any taxes, levies, imposts, fees, assessments, deductions or charges from or in respect of any amounts payable hereunder, (a) Subscriber shall pay the relevant taxation authority the minimum amounts necessary to comply with the applicable law, (b) Subscriber shall make such payment prior to the date on which interest or penalty is attached thereto, and (c) the amounts payable hereunder shall be increased as may be necessary so that after Subscriber makes all required deductions or withholdings, 211 LA shall receive amounts equal to the amounts it would have received had no such deductions or withholdings been required.</p>

<p>Discounts. From time to time, and in 211 LA’s sole discretion, 211 LA may offer discounts to particular organizations (such as nonprofits, government agencies and members of the Alliance of Information and Referral Systems (AIRS)). If such a discount is offered to Subscriber, Subscriber may be required to submit proof of nonprofit status (such as a federal EIN number), a valid AIRS membership number and/or additional information in order to receive such discounts.</p>

<p>Delivery. The Taxonomy is only made available electronically via download from the Taxonomy Website and, unless otherwise agreed by 211 LA in writing on a case-by-case basis, will not be delivered in any other form or via in any other method.</p>

<p>5.Term and Termination</p>

<p>Term. Subscriber’s rights with respect to the Taxonomy will commence on the date full payment of license fees are received and approved by 211 LA and will continue for an initial period of one (1) year, at which point Subscriber’s rights and this Agreement shall expire. If available, Subscriber may renew its subscription license via the Taxonomy Website, which renewal will be subject to and governed by 211 LA’s then-current fees and then-current terms and conditions (which may include a new or updated Taxonomy Subscription Agreement).</p>

<p>Termination of Agreement. Subscriber may terminate this Agreement at any time by sending an email message addressed to taxonomy@infoline la.org, with the subject “Subscription Cancellation.” Further, if Subscriber commits any breach of any provision of this Agreement, 211 LA will have the right to terminate this Agreement (including the rights granted to Subscriber under 2.1) by written notice, unless Subscriber remedies such breach to 211 LA’s reasonable satisfaction within thirty (30) calendar days after receiving written notice from 211 LA.</p>

<p>Effect of Termination.</p>

<p>Upon termination or expiration, and except as expressly provided in Section 5.3(b), the rights and license granted to Subscriber hereunder shall immediately cease and Subscriber will immediately cease all use of the Taxonomy, will destroy all copies of the Taxonomy and will promptly certify such action to 211 LA in writing. Without limitation of the foregoing, 211 LA may immediately terminate Subscriber’s account and ability to access the Taxonomy via the Taxonomy Website upon any expiration or termination of this Agreement. Expiration or termination of this Agreement will not limit either party from pursuing other remedies available to it, including injunctive relief.</p>

<p>The parties’ rights and obligations under Sections 2.2, 3, 4, 5.3, 6, and 7 will survive expiration or termination of this Agreement. Further, unless this Agreement has been terminated by 211 LA for breach, the rights granted to Subscriber under Sections 2.1(b) through (e), as well as the rights and obligations set forth in Section 2.3, shall survive and continue following any expiration or termination of this Agreement, but only with respect to the most recent version of the Taxonomy downloaded by Subscriber from the Taxonomy Website as of the date of expiration or termination and provided that Subscriber’s rights shall continue to be subject to termination by 211 LA under Section 5.2.</p>

<p>6.Disclaimer of Warranty and Limitation of Liability.</p>

<p>Disclaimer of Warranty. 211 LA does not represent that the Taxonomy will meet any expectations or specifications of Subscriber. THE TAXONOMY AND ANY OTHER INFORMATION, PRODUCTS OR SERVICES PROVIDED BY 211 LA TO SUBSCRIBER ARE PROVIDED “AS IS,” WITHOUT WARRANTY OF ANY KIND. 211 LA HEREBY DISCLAIMS ANY AND ALL WARRANTIES OF ANY KIND, WHETHER EXPRESS, IMPLIED OR STATUTORY, INCLUDING, WITHOUT LIMITATION, THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, SATISFACTORY QUALITY, ACCURACY, TITLE AND NONINFRINGEMENT, AND ALL WARRANTIES THAT MAY ARISE FROM COURSE OF PERFORMANCE, COURSE OF DEALING OR USAGE OF TRADE.</p>

<p>Limitation of Liability. TO THE EXTENT PERMITTED BY APPLICABLE LAW: (I) IN NO EVENT WILL 211 LA BE LIABLE FOR ANY INDIRECT, INCIDENTAL, SPECIAL, CONSEQUENTIAL OR PUNITIVE DAMAGES, OR DAMAGES FOR LOSS OF PROFITS, REVENUE, BUSINESS, SAVINGS, DATA, USE OR COST OF SUBSTITUTE PROCUREMENT, INCURRED BY SUBSCRIBER OR ANY THIRD PARTY, WHETHER IN AN ACTION IN CONTRACT OR TORT, EVEN IF THE SUBSCRIBER OR THE OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES OR SUCH DAMAGES ARE FORESEEABLE AND (II) 211 LA’S LIABILITY FOR DAMAGES HEREUNDER WILL IN NO EVENT EXCEED THE FEES RECEIVED BY 211 LA HEREUNDER. SUBSCRIBER ACKNOWLEDGES THAT THE LIMITATIONS OF LIABILITY IN THIS SECTION 6.2 AND IN THE OTHER PROVISIONS OF THIS AGREEMENT, AND THE ALLOCATION OF RISK HEREIN, ARE AN ESSENTIAL ELEMENT OF THE BARGAIN BETWEEN THE PARTIES, WITHOUT WHICH 211 LA WOULD NOT ENTER INTO THIS AGREEMENT.</p>

<p>7.Miscellaneous Provisions</p>

<p>No Assignment. Subscriber may not assign, sell, transfer, delegate or otherwise dispose of, whether voluntarily or involuntarily, by operation of law or otherwise, this Agreement, or any rights or obligations under this Agreement. Any purported assignment, transfer, or delegation by Subscriber will be null and void. Subject to the foregoing, this Agreement will be binding on the parties and their respective successors and assigns.</p>

<p>Relationship Between the Parties. The parties shall at all times be and remain independent contractors. Nothing in this Agreement creates a partnership, joint venture or agency relationship between the parties.</p>

<p>Governing Law. This Agreement is to be construed in accordance with and governed by the internal laws of the State of California (as permitted by Section 1646.5 of the California Civil Code (or any similar successor provision)) without giving effect to any choice of law rule that would cause the application of the laws of any jurisdiction other than the internal laws of the State of California to the rights and duties of the parties. In the event of any controversy, claim or dispute between the parties arising out of or relating to this agreement, such controversy, claim or dispute may be tried solely in a state or federal court located within the County of Los Angeles, California and the parties hereby irrevocably consent to the jurisdiction and venue of such courts.</p>

<p>Severability and Waiver. If any provision of this Agreement is held to be illegal, invalid, or otherwise unenforceable, such provision will be enforced to the extent possible consistent with the stated intention of the parties, or, if incapable of such enforcement, will be deemed to be severed and deleted from this Agreement, while the remainder of this Agreement will continue in full force and effect. The waiver by either party of any default or breach of this Agreement will not constitute a waiver of any other or subsequent default or breach.</p>

<p>Headings. The headings used in this Agreement are for convenience only and shall not be considered in construing or interpreting this Agreement.</p>

<p>No Third Party Beneficiaries. This Agreement is made and entered into for the sole protection and benefit of the parties hereto, and is not intended to convey any rights or benefits to any third Party, nor will this Agreement be interpreted to convey any rights or benefits to any person except the parties hereto.</p>

<p>Entire Agreement. This Agreement, along with the Terms of Use made available on the Taxonomy Website, constitutes the complete agreement between the parties and supersedes any prior or contemporaneous agreements or representations, whether written or oral, concerning the subject matter of this Agreement. This Agreement may be changed by 211LA from time to time immediately upon notice to Subscriber (which may be achieved by posting an updated copy of this Agreement on the Taxonomy Website) or by written agreement of the parties. Continued use of the subscriber portions of the Taxonomy Website following any change constitutes acceptance of the change.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/12/locking-up-any-taxonomy-is-short-sighted-in-todays-online-environment/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/12/i-finally-have-a-weekly-email-newsletter-roundup-of-api-evangelist-posts/">I Finally Have A Weekly Email Newsletter Roundup Of API Evangelist Posts</a></h3>
        <span class="post-date">12 Nov 2017</span>
        <p><a href="http://apievangelist.com/#Newsletter"><img src="https://s3.amazonaws.com/kinlane-productions/api-evangelist/api-evangelist-newsletter.png" align="right" width="35%" style="padding: 15px;" /></a></p>
<p>I’ve had people asking me for an email newsletter containing everything I’ve done over the week for quite a while now, and I finally got around to do doing it. I’m now using MailChimp to pull in the last 20 API Evangelist blog posts and send out as a digest each Monday morning. Providing a summary of everything I wrote for the previous week.</p>

<p>I’m thankful for services like MailChimp which help me get up and running with things like a newsletter quickly. Then  can scale it over time, and even use their API if I want. Without service providers like this I’d never have things like a newsletter. Here is the email newsletter sign up form from MailChimp, and you can always find <a href="http://apievangelist.com/#Newsletter">on the bottom of the home page for API Evangelist</a>:</p>

<!-- Begin MailChimp Signup Form -->
<link href="//cdn-images.mailchimp.com/embedcode/horizontal-slim-10_7.css" rel="stylesheet" type="text/css" />

<style type="text/css">
	#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; width:100%;}
</style>

<div id="mc_embed_signup">
<form action="https://apievangelist.us17.list-manage.com/subscribe/post?u=36a583d2f353a9d31387227ea&amp;id=0593412b68" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate="">
    <div id="mc_embed_signup_scroll">
	<input type="email" value="" name="EMAIL" class="email" id="mce-EMAIL" placeholder="email address" required="" />
    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_36a583d2f353a9d31387227ea_0593412b68" tabindex="-1" value="" /></div>
    <div class="clear"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button" /></div>
    </div>
</form>
</div>

<!--End mc_embed_signup-->

<p>I am not a big email person, as many of you know. However, I understand that many of you are, and I’m seeing a resurgence of readership via email newsletter over using RSS. While I still love me some RSS, I understand that many folks have moved on, often filling the void with their inboxes. After some high profile folks asked me for an email digest, because they were too busy to always remember to tune in, I had to make it happen.</p>

<p>Thanks for tuning in. If there is anything else you’d like to see in the weekly round up–let me know. I’m trying to keep basic for now, but I am thinking about adding some additional thoughts, or other aspects of my API industry research in there–like links to my guides, tools, and services. Right now, I’m giving a shout out to all my sponsors in the footer, but as the list grows it might be another place I entertain sponsorship of this crazy train I call API Evangelist. Thanks for all your support.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/12/i-finally-have-a-weekly-email-newsletter-roundup-of-api-evangelist-posts/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/10/i-can-keep-evangelizing-the-same-api-stories-for-the-next-decade/">I Can Keep Evangelizing The Same API Stories For The Next Decade In Government</a></h3>
        <span class="post-date">10 Nov 2017</span>
        <p><img src="http://kinlane-productions.s3.amazonaws.com/algorotoscope/builder/filtered/34_33_700_500_0_max_0_1_1.jpg" align="right" width="45%" style="padding: 15px;" /></p>
<p><a href="https://www.fedscoop.com/events/redhatgov/2017/agenda/">I spoke on a panel at the Red Hat, Fed Scoop Government Symposium in Washington D.C. yesterday</a>. I had some great conversations with technology vendors, as well as government agencies about everything API. I enjoy being outside the Silicon Valley echo chamber when it comes to technology because I enjoy helping folks understand the basics of what is going on with the basics of APIs, over getting too excited over the latest wave of new technology, and a constant need to be moving forward before ever getting a handle on the problems on the table.</p>

<p>It can be hard to to repeat some of the same stories I’ve been telling for the last seven years while in these circles, but honestly the process helps me refine what I’m saying, and continue to actively think through the sustained relevancy of the stories I’ve been telling. After this round of discussions in D.C. I feel there are a some themes in my work, I can keep refining, and crafting stories for sharing in the government space.</p>

<ul>
  <li><strong>Open</strong> - I know its a tired term, but learning to be more open with other agencies, partners, and the public is an essential component of doing APIs in the federal government.</li>
  <li><strong>Documentation</strong> - Do not reinvent the wheel with documentation, and leverage OpenAPI to help you keep documentation usable, up to date, and valuable to developers using existing open source API documentation solution.</li>
  <li><strong>Support</strong> - Provide email, office hours, Twitter, ticketing, Github issues, and other common support building blocks for API consumers, making sure people know they can get help when they need.</li>
  <li><strong>Communication</strong> - Talk to your consumers. Have a blog, Twitter account, and other social channels for communicating internally, with partners, and publicly with API consumers.</li>
  <li><strong>Experiment</strong> - See your APIs as an R&amp;D extension of an agency, and allow for experimentation with APIs, as well as the consumption of the APIs. Think about sandboxes, data virtualization, and other ways of minimizing agency risk.</li>
  <li><strong>Education</strong> - Make sure you are reaching out, educating, and providing training for all API stakeholders, ensuring that everyone is up to speed, and making no assumptions about what people know, or do not know.</li>
</ul>

<p>None of this is technical. This is all basic API knowledge that any business or technical API stakeholder can take ownership of. These are all things that I see kill API efforts in the public, as well as private sector. These are all things that IT and developer folks scoff at and feel are unnecessary, and business users do not always see as an essential part of technical implementations. <a href="http://apievangelist.com/2017/07/27/state-of-apis-in-the-federal-government/">These are all deficient elements present across the 100 developer portals, and the 500 APIs I keep an eye on across the federal government</a>. They are common building blocks of API operations that I’ll keep beating a drum about on my blog, and in person at events I attend in D.C.</p>

<p>The API environment in D.C. would frustrate your average API developer, architect, and evangelist. I get frustrated at the speed of things, and having to say the same things over and over. However, I also understand the scope of what the federal government does, and the number of people we have to get up to speed on things. The number of APIs available is actively growing, but the consistency, usability, and effectiveness of APIs isn’t keeping pace. To keep things in balance we are going to need even more evangelism around operating government in an online environment, and how APIs can help provide access to data, content, and even algorithms across all branches of government in a safe and secure ways.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/10/i-can-keep-evangelizing-the-same-api-stories-for-the-next-decade/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/10/admitting-there-is-so-much-i-do-not-know-makes-me-better-at-apis/">Admitting There Is So Much I Do Not Understand Makes Be Better At APIs</a></h3>
        <span class="post-date">10 Nov 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algo-rotoscope/stories/server-racks-clouds_copper_circuit.jpg" align="right" width="45%" style="padding: 15px;" /></p>
<p>One of the reasons I’m so good at APIs is because I embrace how little I know. This rolling realization keeps my appetite wet when it comes to learning to things, and working hard to discover, and realize sensible API practices. I am comfortable with the fact that I do not know something. I enjoy coming up against things I do not understand, eager to learn more. However, I think there is one big difference in the way I approach technology from other developers, is that I’m not confident that I will ever be able to fully understand a particular domain, let alone think that technology, or specifically APIs are a solution to a specific set of problems within every domain.</p>

<p>Many developers are overly confident in what they know. They are also overly confident in their ability to learn new things. They are also overly confident that they can hammer out a technological solution that will solve all problems within a domain. I feel like many technologists aren’t in the game to learn, they are in the game to prove they have the chops to solve problems, and when they can’t they just walk away. When you approach APIs in this way you are leaving a lot of opportunity for learning and growth on the table. APIs shouldn’t be seen as simply a solution. APIs are just a tool (like the web) in a business toolbox, that should be applied when appropriate, and not applied when it doesn’t make sense.</p>

<p>Beyond developers, I feel like many business users are scared off by the uncertainty in the world of APIs. They don’t thrive in an environment where there are so many possibilities, configurations, and ways to do things right and wrong. APIs give you more control over your data, content, and algorithms, allowing you to provide access to them in many ways, and reach across many client channels like the web, mobile, and other device or network implementations. I feel like many business users want this amount of control, but aren’t willing to invest the time to be able to make decisions in this environment, and own the responsibility surrounding so much uncertainty. Unlike developers, they may have the domain expertise, but aren’t willing to experiment, play around with, and bang their head on the different ways APIs can help deliver solutions.</p>

<p>I feel like developers tend to suck at admitting they don’t understand things, and have to much belief in our technological toolbox when it comes to filling in the gaps. I feel like business users just aren’t confident enough with technology to thrive in environments where you perpetually do not know everything. I feel like my ability to admit I do not know, and maybe never fully understand a specific domain–coupled with my insatiable appetite for learning, puts me in a good position to be studying APIs. I can dive into new domains without thinking I’m going to save or disrupt the world. I can develop API prototypes, and help define API specifications, fully aware that I may not get it right on the first release. I know this is ok. I know that APIs are a journey, and not a destination. I know that APIs shouldn’t always be done. I know that sometimes they are a bad idea. I respect that there are domain experts in specific industries that I should be learning from. Admitting there is so much I do not know, helps me be better at what I do with APIs.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/10/admitting-there-is-so-much-i-do-not-know-makes-me-better-at-apis/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/10/are-people-ready-for-an-online-api-driven-world-that-is-progammable/">Are People Ready For An Online API-Driven World That Is Programmable?</a></h3>
        <span class="post-date">10 Nov 2017</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/algo-rotoscope/stories-new/van-gogh-starry-night-container-bridge-2.jpg" align="right" width="45%" style="padding: 15px;" /></p>
<p>I am struggling with helping some folks get beyond their API being just readable, and helping them understand the potential of having POST, PUT, and other writable aspects to their resources, making things much more programmable. My client has a firm grasp on the ability to GET data from their API and publish on websites. They also have the concept that they can GET other data from other 3rd party APIs, and display on their website alongside their data. Where they are struggling is that they can also add new data to their API, and update existing data they are making available via their API, and ultimately their website as well.</p>

<p>This hurdle isn’t limited to any single project I’m working on. I find a number of people who seem to have a decent grasp on APIs in general, struggling with or completely avoiding conversations around making the data writeable. They are able to make the transition from web to API when it comes to retrieving data, but making the same jump when it comes to adding and updating data is proving to be more difficult. I think there will always be a cognitive load with jumping from read to write, as you have to think more about security, data quality, and other common concerns. However, beyond that, I’m trying to explore what might be the challenges people are facing. Many of the folks I’m working with are a bit shaky on their grasp of APIs, and aren’t too confident in sharing what they don’t understand.</p>

<p>As I do, I’ll put it out to the universe and ask my audience what they’ve seen. On the surface, I’d say that adding or updating data into a database online is tougher to wrap your head around without some context, and some of the affordances we enjoy in the browser. Adding a Tweet through mobile application or website? No problem. POST a tweet through API, is a little tougher to envision. Updating a contact record in your administrative system? No problem. PUT via API to the /contact/ path doesn’t compute as quickly. API developers can quickly see these interfaces as programmable, but for the average business user, there is more dependence on the affordances provided in the browser, and us developers are taking the importance of these affordances for granted.</p>

<p>Beyond that, I’m guessing there is a perceived lack of control. Anyone can add or update? How do we address quality control? IDK, just spitball’n here. The majority of APIs I come across are GET only, so I have to believe there are issues around control, and beliefs around ownership. I can’t believe all of these API providers don’t grasp the technical aspects of writeable APIs. It is the same in the federal government. ALL the web APIs are read only. We’ve started to see this ice break a little in recent years, but federal agencies are rightfully wary of the responsibility of letting the public write data to their databases. I almost feel like the Facebook and Twitters of the world are almost too open to allowing folks to write, without being thoughtful around privacy, security, and data ownership or stewardship–just to get their hands on the data.</p>

<p>I wondering if POST, PUT, and DELETE should be 101 concepts that I’m teaching to folks. Should I be starting out with just the safer, more straightforward reading of data, content, and algorithmic resources. Then down the road introduce the ability to add, update, and delete information. I know the concept of DELETE freaks people out pretty quickly. IDK. I’m just doing my job, and questioning things at all levels, and wondering if people are even ready for a programmable online world. I think SaaS has delivered a programmable world with a wealth of affordances that help onboard people with all of this, and us API people are failing at translating the significance of an API-driven world that is programmable to our business users.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/10/are-people-ready-for-an-online-api-driven-world-that-is-progammable/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/10/you-can-lead-a-horse-to-water-but-you-cannot-make-them-drink-the-api-edition/">You Can Lead A Horse To Water But You Cannot Make Them Drink--The API Edition</a></h3>
        <span class="post-date">10 Nov 2017</span>
        <p><img src="http://kinlane-productions.s3.amazonaws.com/algorotoscope/bluelake/clean_view/file-00_00_38_67.jpg" align="right" width="45%" style="padding: 15px;" /></p>
<p>I have seven years of API research available at apievangelist.com. I regularly publish short form, and long form versions of this information on my blogs on a weekly basis. I publish prototypes, demo websites and portals, and develop API training curriculum for use across a wide variety of industries. I regularly take versions of my API research, and rework, rebrand, and dial in to speak to a specific company, organizations, institution, agency, or industry. In many cases I make this information freely available, helping make sure it is available to those who need it. Despite all this work, many folks who are already doing APIs refuse to read, listen, and learn from what is already going on in the API space, and doomed to repeat the mistakes many of us have already made and learned from in our API journeys.</p>

<p>Many folks don’t really understand my motivations and think I have some sort of agenda to sell them something, disrupt their current reality, or other uninformed perspective. Ultimately, not trusting what I’m putting out there. I guess viewing that the water is poised in some way. Others don’t feel they need it, either because they feel like they have all the answers, or the problems haven’t become a reality in their worlds yet, so my solutions seem irrelevant. I find it tough to argue with someone about preventative care when it comes to their API operations, when they spend their days triaging bugs, problems, and legacy technology challenges. They are fire fighters, water isn’t for drinking!</p>

<p>A long standing example of this can be found in the hypermedia realm. No matter how much some very smart people, with a wealth of experience deploying and managing APIs warn about challenges with maintaining API SDKs and clients, some folks will never see it as a problem until they actually face it themselves. I can showcase endless numbers of healthy practices extract from companies like AWS, Twitter, and Twilio for people to learn from, but many folks will never see their relevance until they directly experience the problem. Most people have trouble looking forward, as well as stepping outside their own API operations and looking at them side by side with other leading API pioneers. They are different. Special. Often times, people never even engage in these thought exercises at all. There just isn’t the room in their operations for thinking proactively.</p>

<p>I regularly get frustrated when my clients, or people I’m asked to speak with about healthy API practices actively ignore, criticize, and dismiss what I’m sharing. I shouldn’t. I can’t force people to trust me. I can’t force people to drink from the water I’m providing. All I can do is plant the seed in their minds that there is water over here when you get thirsty. It seems to be a chronic condition across many industries, that folks only drink when they are super thirsty, after they get dehydrated, rather than proactively drinking water regularly throughout the day. In the end, my energy is better spend doing what I do best–researching, then openly sharing what I’m learning across the API space from other people doing APIs well. My job will often involves leading a horse to water, but does not ever involve forcing anyone to drink. I considered creating a blog called API Water Boarding, but it just didn’t seem like a good idea. ;-)</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/10/you-can-lead-a-horse-to-water-but-you-cannot-make-them-drink-the-api-edition/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2017/11/09/the-impact-of-api-management-on-api-security/">The Impact Of API Management On API Security</a></h3>
        <span class="post-date">09 Nov 2017</span>
        <p><a href="http://apis.how/security/"><img src="https://s3.amazonaws.com/kinlane-productions/guides/security/api-security-guide-api-management.png" align="right" width="45%" style="padding: 15px;" /></a></p>
<p><em>This is a story from my latest <a href="http://security.apievangelist.com/#Guide">API Evangelist API security industry guide</a>. My partner <a href="http://apis.how/elasticbeam">ElasticBeam</a> has underwritten my API security research, allowing me to publish a formal PDF of my guide, providing business and technical users with a walk-through of the moving parts, tools, and companies doing interesting things with API security. When I publish each guide, I publish each story here on the blog, helping build awareness around my research–this is a short one on API management.</em></p>

<p>API management has done an amazing job in helping companies, organizations, institutions, and government agencies make their digital resources more available on-line in a secure way. Allowing API providers to require developers to sign up, obtain keys, and tokens which need to accompany all API calls. This, along with encryption by default has gone a long way towards making data, content, and algorithms more accessible, while also being secure. However, many API providers have stopped here, and think their resources are secure, when in reality there is so much more work to be done.</p>

<p>Requiring all developers obtain keys to access resources, and encryption data in transit is an important part of API security, but it is just one tool in the API security toolbox. Out of API management you also receive an enhanced set of logging, analysis, and reporting tools for how developers are putting API resources to work. When done well, this pushes the API security conversation forward, allowing API providers to balance access with security, and be proactive when it comes to limiting access, or even shutting off access when their is abuse. The problem is not all API providers are investing here, let alone going beyond what API management providers offer.</p>

<p>The awareness brought to the table my API management is valuable, but there are so many aspects of API operations at the web server, DNS, and other levels that are often left out of the API management conversation. I’ll be pushing API providers to look beyond just the API management layer, and expanding API security awareness to every other stop along the API life beyond just management.</p>

<p><em>You can <a href="http://security.apievangelist.com/#Guide">download or purchase my API Evangelist API security industry guide over at my API security research</a>, and if you want to point out any corrections, and share your thoughts on what is missing, feel free to submit a Github issue on the research project’s Github repository. I appreciate your support of my work, and depend on folks like you, and <a href="http://apis.how/elasticbeam">ElasticBeam</a> to make this all work.</em></p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2017/11/09/the-impact-of-api-management-on-api-security/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  

	<table width="100%" border="1" style="background-color:#FFF; border: 0px #FFF;">
		<tr style="background-color:#FFF; border: 0px #FFF;">
			<td align="left">
				<a href="/blog/page7" class="button"><< Prev</a></li>
			</td>
			<td></td>
			<td align="right">
				<a href="/blog/page9" class="button">Next >></a>
			</td>
		</tr>
	</table>

  </div>
</section>

              
<footer>
  <hr>
  <div class="features">
    
    
      
      <article>
        <div class="content">
          <p align="center"><a href="https://www.getpostman.com/" target="_blank"><img src="https://apievangelist.com/images/postman-logo.png" width="75%" style="padding: 15px; border: 1px solid #000;" /></a></p>
        </div>
      </article>
      
    
      
      <article>
        <div class="content">
          <p align="center"><a href="https://tyk.io/" target="_blank"><img src="https://apievangelist.com/images/tyk-logo.png" width="75%" style="padding: 15px; border: 1px solid #000;" /></a></p>
        </div>
      </article>
      
    
  </div>
  <hr>
  <p align="center">
    relevant work:
    <a href="http://apievangelist.com">apievangelist.com</a> |
    <a href="http://adopta.agency">adopta.agency</a>
  </p>
</footer>


            </div>
          </div>

          <div id="sidebar">
            <div class="inner">

              <nav id="menu">
  <header class="major">
    <h2>Menu</h2>
  </header>
  <ul>
    <li><a href="/">Homepage</a></li>
    <li><a href="http://101.apievangelist.com/">101</a></li>
    <li><a href="/blog/">Blog</a></li>
    <li><a href="http://history.apievangelist.com/">History of APIs</a></li>
    <li><a href="/#api-lifecycle">API Lifecycle</a></li>
    <li><a href="/search/">Search</a></li>
    <li><a href="/newsletters/">Newsletters</a></li>
    <li><a href="/images/">Images</a></li>
    <li><a href="/archive/">Archive</a></li>
  </ul>
</nav>

              <section>
  <div class="mini-posts">
    <header>
			<h2 style="text-align: center;"><i>API Evangelist Sponsors</i></h2>
		</header>
    
    
      
        <article style="display: inline;">
          <a href="https://www.getpostman.com/" class="image"><img src="https://apievangelist.com/images/postman-logo.png" alt="" width="50%" style="padding: 15px; border: 1px solid #000;" /></a>
        </article>
      
    
      
        <article style="display: inline;">
          <a href="https://tyk.io/" class="image"><img src="https://apievangelist.com/images/tyk-logo.png" alt="" width="50%" style="padding: 15px; border: 1px solid #000;" /></a>
        </article>
      
    
  </div>
</section>


            </div>
          </div>

      </div>

<script src="/assets/js/skel.min.js"></script>
<script src="/assets/js/util.js"></script>
<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
<script src="/assets/js/main.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-1119465-51"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-1119465-51');
</script>


</body>
</html>
