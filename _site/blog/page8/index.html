<!DOCTYPE html>
<html xmlns="https://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
  <html>
  <title>API Evangelist </title>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
  <!--[if lte IE 8]><script src="/assets/js/ie/html5shiv.js"></script><![endif]-->
  <link rel="stylesheet" href="/assets/css/main.css" />
  <link rel="stylesheet" href="/assets/css/bootstrap.min.css" />
  <!--[if lte IE 9]><link rel="stylesheet" href="/assets/css/ie9.css" /><![endif]-->
  <!--[if lte IE 8]><link rel="stylesheet" href="/assets/css/ie8.css" /><![endif]-->

  <!-- Icons -->
  <link rel="shortcut icon" type="image/x-icon" href="https://apievangelist.com/favicon.ico">
	<link rel="icon" type="image/x-icon" href="https://apievangelist.com/favicon.ico">

  <link rel="alternate" type="application/rss+xml" title="API Evangelist Blog - RSS 2.0" href="https://apievangelist.com/blog.xml" />
  <link rel="alternate" type="application/atom+xml" title="API Evangelist Blog - Atom" href="https://apievangelist.com/atom.xml">

  <!-- JQuery -->
  <script src="/js/jquery-latest.min.js" type="text/javascript" charset="utf-8"></script>
  <script src="/js/bootstrap.min.js" type="text/javascript" charset="utf-8"></script>
  <script src="/js/utility.js" type="text/javascript" charset="utf-8"></script>

  <!-- Github.js - http://github.com/michael/github -->
  <script src="/js/github.js" type="text/javascript" charset="utf-8"></script>

  <!-- Cookies.js - http://github.com/ScottHamper/Cookies -->
  <script src="/js/cookies.js"></script>

  <!-- D3.js http://github.com/d3/d3 -->
  <script src="/js/d3.v3.min.js"></script>

  <!-- js-yaml - http://github.com/nodeca/js-yaml -->
  <script src="/js/js-yaml.min.js"></script>

  <script src="/js/subway-map-1.js" type="text/javascript"></script>

  <style type="text/css">

    .gist {width:100% !important;}
    .gist-file
    .gist-data {max-height: 500px;}

    /* The main DIV for the map */
    .subway-map
    {
        margin: 0;
        width: 110px;
        height: 5000px;
        background-color: white;
    }

    /* Text labels */
    .text
    {
        text-decoration: none;
        color: black;
    }

    #legend
    {
    	border: 1px solid #000;
        float: left;
        width: 250px;
        height:400px;
    }

    #legend div
    {
        height: 25px;
    }

    #legend span
    {
        margin: 5px 5px 5px 0;
    }
    .subway-map span
    {
        margin: 5px 5px 5px 0;
    }

    </style>

    <meta property="og:url" content="">
    <meta property="og:type" content="website">
    <meta property="og:title" content="API Evangelist">
    <meta property="og:site_name" content="API Evangelist">
    <meta property="og:description" content="A network of research sites dedicated to the technology, business, and politics of APIs.">
    <meta property="og:image" content="http://s3.amazonaws.com/kinlane-productions/api-evangelist/t-shirts/KL_InApiWeTrust-1000.png">

    <meta name="twitter:url" content="">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="API Evangelist">
    <meta name="twitter:site" content="API Evangelist">
    <meta name="twitter:description" content="A network of research sites dedicated to the technology, business, and politics of APIs.">
    
      <meta name="twitter:creator" content="@apievangelist">
    
    <meta property="twitter:image" content="http://s3.amazonaws.com/kinlane-productions/api-evangelist/t-shirts/KL_InApiWeTrust-1000.png">


</head>

  <body>

			<div id="wrapper">
					<div id="main">
						<div class="inner">

              <header id="header">
	<a href="http://apievangelist.com" class="logo"><img src="https://kinlane-productions2.s3.amazonaws.com/api-evangelist/api-evangelist-logo-400.png" width="75%" /></a>
	<ul class="icons">
		<li><a href="https://twitter.com/apievangelist" class="icon fa-twitter"><span class="label">Twitter</span></a></li>
		<li><a href="https://github.com/api-evangelist" class="icon fa-github"><span class="label">Github</span></a></li>
		<li><a href="https://www.linkedin.com/company/api-evangelist/" class="icon fa-linkedin"><span class="label">LinkedIn</span></a></li>
		<li><a href="http://apievangelist.com/atom.xml" class="icon fa-rss"><span class="label">RSS</span></a></li>
	</ul>
</header>

    	        <section>
	<div class="content">

		<h3>The API Evangelist Blog</h3>

	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/12/06/the-shifting-api-landscape/"><img src="http://kinlane-productions2.s3.amazonaws.com/algorotoscope/canyon/yellow_collage/file-00_02_34_62.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/12/06/the-shifting-api-landscape/">The Shifting API Landscape</a></h3>
			<p><em>06 Dec 2017</em></p>
			<p>I’ve been watching, and trying to move forward the API conversation across all business sectors for seven years now. I’m not a startup. I’m not an API service provider. I’m not steering an enterprise group. I’m not an investor. I’m a software architect and storyteller who saw the potential for leveraging web infrastructure to deliver data, content, media, and algorithms across the web, to our mobile phones, as well as the seemingly endless number of devices we are connecting to the Internet in our personal, professional, and industrial worlds. I’m not studying the landscape so I sell to it. I am studying the landscape so I can understand it. While most of my readers will not grasp that difference, it gives me a fundamentally different view of what is going on across the space. In the last seven years I’ve had a focus on helping individuals at SMB, SME, enterprise, organizations, institutions, and government agencies understand what APIs are, and why they should be doing them. In 2017, I feel that mission becoming irrelevant based upon the shifting API landscape. As I work on my third API-first strategy for a top level federal agency in response to an RFI in recent months, prepare for an all week API workshop at Mutual of Omaha in Nebraska, and bookmark the job postings for API architect at almost every major bank in the US and UK, my cute little mission to help understand people understand what APIs are clearly needs to be retired. While there are plenty of people who still need to be educated what APIs are, and that they should be doing them, I’m going to leave it to the waves of other pundits, advocates, evangelists, and analysts to help onboard them. I’ve done my time. There are many changes on the horizon for API Evangelist which I’ll cover in future posts, but one significant one for me will be to lose “the mission”. As much...[<a href="/2017/12/06/the-shifting-api-landscape/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/12/05/what-is-more-important-having-an-api-or-having-a-welldesigned-api/"><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories-new/16_38_600_500_0_avg_1_1_1.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/12/05/what-is-more-important-having-an-api-or-having-a-welldesigned-api/">What Is More Important? Having An API? Or Having A Well-Designed API?</a></h3>
			<p><em>05 Dec 2017</em></p>
			<p>I got some expected flack this week for some stories on database to API deployments, and allowing folks to just auto-generate APIs from database structures. This approach is notorious for producing very badly designed APIs, which is something that just reflects whatever legacy infrastructure you have as a backend. It is something that drives many of API design, architects, and pundits crazy. Just do things properly!!! Follow good design practices! Put some thought into your API, and have some pride in this interface you are putting out there. All of this is easy for us to declare from our vantage point, but when your entrenched within an existing organization, battling for every movement forward, and often times just to not go backwards, this isn’t always the reality. As technologists we are always looking forward, and have a really hard time empathizing with folks who are stuck in positions that aren’t as forward leaning as ours. I know we have a well of experience we want everyone to see eye to eye with, but that isn’t always the reality. You can’t convince someone who is just trying to stay afloat within an organization that they should be investing in all of these possibilities in a future they aren’t tuned into. Not everyone holds the privileged position that many of us enjoy in the technology space, and I feel we can do a better job empathizing with some of them. I’m not saying we should give up on leading, and telling stories of a better future, but we need to work to build bridges to many who are less fortunate than we are. You know what is worse than being in an organization where you are battling for every bit of budget, resources, skills, and other things that help you stay afloat? Having people in more privileged positions making you feel stupid for what you do not understand, or have the time to learn. I wish folks...[<a href="/2017/12/05/what-is-more-important-having-an-api-or-having-a-welldesigned-api/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/12/05/the-picture-we-paint-with-the-stories-we-tell-around-each-api-version-release/"><img src="https://s3.amazonaws.com/kinlane-productions2/facebook/facebook-version-211-release.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/12/05/the-picture-we-paint-with-the-stories-we-tell-around-each-api-version-release/">The Picture We Paint With The Stories We Tell Around Each API Version Release</a></h3>
			<p><em>05 Dec 2017</em></p>
			<p>I fell down the rabbit hole of the latest Facebook version release, trying to understand the deprecation of their User Insights API. The story of the deprecation of the API isn’t told accurately as part of the the regular release process, so I found myself thinking more deeply about how we tell stories (or don’t) around each step forward of our APIs. I have dedicated areas of my API research for the road map, issues, and change log for API operations, because their presence tell a lot about the character of an API, and their usage I feel paints and accurate painting of each moment in time for an API. Facebook has a dedicated change log for their API platform, as well as an active status and issues pages, but they do not share much about what their road map looks like. They provide a handful of elements with each releases change log: New Features — New products or services, including new nodes, edges, and fields. Changes — Changes to existing products or services (not including Deprecations). Deprecations — Existing products or services that are being removed. 90-Day Breaking Changes — Changes and deprecations that will take effect 90 days after the version release date. The presence, or lack of presence, of a road map, change log, status and issue pages for an API paints a particular picture of a platform in my mind. Also, the stories they tell, or do not tell with each release paint an evolving picture of where a platform is headed, and whether or not we want to participating in the journey. Facebook does better than most platforms I track on when it comes to storytelling, by also releasing a blog post telling the story of each release, providing separate posts for the Graph API, as well as the Marketing API. It is too bad that they omitted the deprecation of the Audience Insight API, which occurred at the time...[<a href="/2017/12/05/the-picture-we-paint-with-the-stories-we-tell-around-each-api-version-release/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/12/05/api-deployment-templates-as-part-of-a-wider-api-governance-strategy/"><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories/server-cloud1_internet_numbers.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/12/05/api-deployment-templates-as-part-of-a-wider-api-governance-strategy/">API Deployment Templates As Part Of A Wider API Governance Strategy</a></h3>
			<p><em>05 Dec 2017</em></p>
			<p>People have been asking me for more stories on API governance. Examples of how it is working, or not working at the companies, organizations, institutions, and government agencies I’m talking with. Some folks are looking for top down ways of controlling large teams of developers when it comes to delivering APIs consistently across large disparate organizations, while others are looking for bottom ways to educate and incentivize developers to operate APIs in sync, working together as a large, distributed engine. I’m approach my research into API governance as I would any other area, not from the bottom up, or top down. I’m just assembling all the building blocks I come across, then began to assemble them into a coherent picture of what is working, and what is not. One example I’ve found of an approach to helping API providers across the federal government better implement consistent API patterns is out of the General Services Administration (GSA), with the Prototype City Pairs API. The Github repository is a working API prototype, documentation and developer portal that is in alignment with the GSA API design guidelines, providing a working example that other API developers can reverse engineer. The Prototype City Pairs API is a forkable example of what you want developers to emulate in their work. It is a tool in the GSA’s API governance toolbox. It demonstrates what developers should be working towards in not just their API design, but also the supporting portal and documentation. The GSA leads by example. Providing a pretty compelling approach to model, and a building block any API provider could add to their toolbox. I would consider a working prototype to be both a bottom up approach because it is forkable, and usable, but also top down because it can reflect wider organizational API governance objectives. I could see mature API governance operations having multiple API design and deployment templates like the GSA has done, providing a suite of forkable,...[<a href="/2017/12/05/api-deployment-templates-as-part-of-a-wider-api-governance-strategy/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/12/04/narrowing-in-on-my-api-governance-strategy-using-api-transit-to-map-out-psd2/"><img src="https://s3.amazonaws.com/kinlane-productions2/talks/november-2015/subway-map-15.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/12/04/narrowing-in-on-my-api-governance-strategy-using-api-transit-to-map-out-psd2/">Narrowing In On My API Governance Strategy Using API Transit To Map Out PSD2</a></h3>
			<p><em>04 Dec 2017</em></p>
			<p>I’m still kicking around my API Transit strategy in my head, trying to find a path forward with applying to API governance. I started moving it forward a couple years ago as a way to map out the API lifecycle, but in my experience, managing APIs are rarely a linear lifecycle. I have been captivated by the potential of the subway map to help us map out, understand, and navigate complex infrastructure since I learned about Harry Beck’s approach to the London Tube map which has become the standard for quantifying transit around the globe. I am borrowing from Beck’s work, but augmenting for a digital world to try and map out the API practices I study in my research of the space in a way that allow them to be explored, but also implemented, measured, and reported upon by all stakeholders involved with API operations. While I’m still pushing forward this concept in the safe space of my own API projects, I’m beginning to dabble with applying at the industry level, by applying to PSD2 banking, and seeing if I can’t provide an interactive map that helps folks see, understand, and navigate what is going on when it comes to banking APIs. An API Transit map for PSD2 would build upon the framework I have derived from my API research, applied specifically for quantifying the PSD2 world. Each of the areas of my research broken down into separate subway lines, that can be plotted along the map with relative stops along they way: Definition - Which definitions are used? Where are the OpenAPI, schema, and other relevant patterns. Design - What design patterns are in play across the API definitions, and what is the meaning behind the design of all APIs. Deployment - What does deployment look like on-premise, in the cloud, and from region to region. Portals - What is the minimum viable standard for an API portal presence with any building blocks....[<a href="/2017/12/04/narrowing-in-on-my-api-governance-strategy-using-api-transit-to-map-out-psd2/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/12/04/facebook-quietly-deprecates-the-audience-insight-api-used-to-automate/"><img src="https://s3.amazonaws.com/kinlane-productions2/api-evangelist-logos/api-evangelist-red-seal.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/12/04/facebook-quietly-deprecates-the-audience-insight-api-used-to-automate/">Facebook Quietly Deprecates The Audience Insight API Used To Automate</a></h3>
			<p><em>04 Dec 2017</em></p>
			<p>According to AdWeek, Facebook is quietly shutting down its Audience Insights API by the end of the year. They have a statement from Facebook stating, “We have decided to focus marketers on our more broadly available Audience Insights tool, so we are winding down the Audience Insights API by end of year. We’ll continue testing different ways to provide valuable insights to advertisers and agencies through the tool and across other destinations on Facebook.” which I assume they got directly from Facebook, because I can find no other communication regarding the deprecation of the API through normal newsroom, or API change log channels. It could be that I’m missing it, but it is clear they are trying to minimize chatter around this. According to the Facebook help page, Audience Insights, “shows you data about your target audiences so that you can create more relevant advertisements for them”. The platform uses native Facebook data to show you audience features such as: Age and gender, Relationship status, Education level, Job role, Top categories, Page likes, Top cities, Top countries, Top languages, Frequency of activities, and Device users. Then using third-party data (data come from sources like Acxiom, Datalogix and Epsilon) they show you audience features such as: Lifestyle, Household income, Home ownership, Household size, Home market value, Spending methods, Retail spending, Online purchases, Purchase behavior, and whether they are in market for a vehicle. You can still get at this via the Facebook Audience Insights web interface, but the APIs for automating this aspect of Facebook has mostly disappeared, or is in the process of disappearing. There are three layers to the Faceook Audience Insights API deprecation. You can still access some insights for ads, pages, and other objects, as well as one audience insight still available: /{object-id}/insights - Facebook Insights is a product available to all Pages and Apps on Facebook using the Insights dashboard. Audience Insights Rule - Definition of an audience insight rule. Then...[<a href="/2017/12/04/facebook-quietly-deprecates-the-audience-insight-api-used-to-automate/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/12/04/being-able-to-see-your-database-in-xml-json-and-csv/"><img src="https://s3.amazonaws.com/kinlane-productions2/slashdb/slashdb-content-negotiation.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/12/04/being-able-to-see-your-database-in-xml-json-and-csv/">Being Able To See Your Database In XML, JSON, and CSV</a></h3>
			<p><em>04 Dec 2017</em></p>
			<p>This is a sponsored post by my friends over at SlashDB. The topic is chosen by me, but the work is funded by SlasDB, making sure I keep doing what I do here at API Evangelist. Thank you SlashDB for your support, and helping me educate my readers about what is going on in the API space. I remember making the migration from XML to JSON. It was hard for me to understand that difference between the formats, and that you accomplish pretty much the same things in JSON that you could in XML. I’ve been seeing similarities in my migration to YAML from JSON. The parallels in each of these formats isn’t 100%, but this story is more about our perception of data formats, than it is about the technical details. CSV has long been a tool in my toolbox, but it was until this recent migration from JSON to YAML that I really started seeing the importance of CSV when it comes to helping onboard business users with the API possibilities. In my experience API design plays a significant role in helping us understand our data. Half of this equation is understanding our schema, and what the dimensions, field names, and data types of the data we are moving around using APIs. As I was working through some stories on how my friends over at SlashDB are turning databases into APIs, I saw that they were translating database, tables, and field names into API design, and that they also help you handle content negotiation between JSON, XML, CSV. Which I interpret as an excellent opportunity for learning more about the data we have in our databases, and getting to know the design aspects of the data schema. In an earlier post about what SlashDB does I mentioned that many API designers cringe at translating database directly into a web API. While I agree that people should be investing into API design to get...[<a href="/2017/12/04/being-able-to-see-your-database-in-xml-json-and-csv/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/12/01/the-conversational-interface-appetite-for-data-via-apis/"><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories-new/16_77_800_500_0_max_0_1_-1.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/12/01/the-conversational-interface-appetite-for-data-via-apis/">The Conversational Interface Appetite For Data Via APIs</a></h3>
			<p><em>01 Dec 2017</em></p>
			<p>This is a sponsored post by my friends over at SlashDB. The topic is chosen by me, but the work is funded by SlasDB, making sure I keep doing what I do here at API Evangelist. Thank you SlashDB for your support, and helping me educate my readers about what is going on in the API space. I spend a lot of time studying what is going on around bots on Twitter, Facebook, and Slack, as well as voice enablement like we see with Alexa, Google, and Siri. I lump these all under a research category called conversational interfaces. Conversational interfaces represent the next generation of API clients, with AWS Alexa being the most sophisticated example at how it will all work(eventually). While there are some interesting examples of conversational interfaces in action, for the most part they are still pretty simple, silly, and not providing much value. I’d say that any of the bots or voice implementations I’ve come across which are useful, are also pretty corporate, demonstrating the amount of resources you need to invest when crafting conversational interfaces. From my vantage point I’m seeing three main areas slowing the growth of true usability of conversational interfaces, 1) desire, and people not wanting or caring to engage, 2) availability of data via APIs in format that is usable, and 3) the performance of APIs that do have relevant data, and their ability to deliver it as an answer to a question in reasonable amount of time. You can put me squarely into the first category of not really wanting to use conversational interfaces, but I do understand that there are people who are into doing it, which gets me somewhat involved when it comes to thinking about the 2nd, and 3rd challenge. APIs are what delivers answers in conversational interfaces, and since APIs are my jam, I’m tuning in. One of the biggest challenges the conversational interface space will face in coming years...[<a href="/2017/12/01/the-conversational-interface-appetite-for-data-via-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/12/01/how-to-say-you-might-charge-for-api-access-in-the-future-without-being-a-jerk/"><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories/statue-face-open-mouth_copper_circuit.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/12/01/how-to-say-you-might-charge-for-api-access-in-the-future-without-being-a-jerk/">How To Say You Might Charge For API Access In The Future Without Being A Jerk</a></h3>
			<p><em>01 Dec 2017</em></p>
			<p>I get it. It takes money to operate APIs. I’m a big advocate for making sure API providers, even public data API providers can sensibly charge for access to their valuable resources. I’m also painfully aware at how unrealistic a libertarian driven view of the web being open and free makes it very difficult to begin charging for data that has been historically free. However, I’m also a fan of helping API providers understand how they can communicate that they might / will be charging for access to data at some point in the future without being complete jerks about it. I see API providers regularly make the statement that they will begin charging for API access at some point in the future, but this particular story is driven from hearing it out of the Washington Metropolitan Area Transit Authority (WMATA) making changes to their terms of service, where one of the bullet points was that they would begin charging for access at some point. Making the announcement that you intend to begin charging for something that has been free is challenging in any API ecosystem, but especially so within public data API ecosystems like WMATA. In any of these environments you can’t just shoot across your community’s bow with a statement like this, and expect a positive response. Doing so, just shows how out of touch with your community you are. First rule of communicating around the business side of your road map is don’t just say you’ll be charging at some point and leave things there. Give details of what this means. Demonstrate your knowledge around how API management and service composition works. Will ALL developers be charged? Will it just be commercial developers? Will it be developers over a certain level of consumption? Do not leave it to the communities imagination regarding what will happen, because this is where the powers of Internet speculation will take hold, and begin working against your...[<a href="/2017/12/01/how-to-say-you-might-charge-for-api-access-in-the-future-without-being-a-jerk/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/12/01/how-do-you-ask-questions-of-data-using-apis/"><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories-new/27_93_800_500_0_max_0_-5_-5.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/12/01/how-do-you-ask-questions-of-data-using-apis/">How Do You Ask Questions Of Data Using APIs?</a></h3>
			<p><em>01 Dec 2017</em></p>
			<p>I’m preparing to publish a bunch of transit related data as APIs, for us across a number of applications from visualizations to conversation interfaces like bots and voice-enablement. As I’m learning about the data, publishing it as unsophisticated CRUD APIs, I’m thinking deeply about how I would enable others to ask questions of this data using web APIs. I’m thinking about the hard work of deriving visual meaning from specific questions, all the way to how would you respond to an Alexa query regarding transit data in less than a second. Going well beyond what CRUD gives us when we publish our APIs and taking things to the next level. Knowing the technology sector, the first response I’ll get is machine learning! You take all your data, and you train up some machine learning models, put some natural language process to work, and voila, you have your answer to how you provide answers. I think this is a sensible approach to many data sets, and for organizations who have the machine learning skills and resources at their disposal. There are also a growing number of SaaS solutions for helping put machine learning work to answer complex questions that might be asked of large databases. Machine learning is definitely part of the equation for me, but I’m not convinced it is the answer in all situations, and it might not always yield the correct answers we are always looking for. After machine learning, and first on my list of solutions to this challenge is API design. How can I enable a domain expert to pull out the meaningful questions that will be asked of data, and expose as simple API paths, allowing consumers to easily get at the answers to questions. I’m a big fan of this approach because I feel like the chance we will get right answers to questions will be greater, and the APIs will help consumers understand what questions they might want...[<a href="/2017/12/01/how-do-you-ask-questions-of-data-using-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/30/troubling-terms-of-service-changes-from-washington-metropolitan-area-transit/"><img src="https://s3.amazonaws.com/kinlane-productions2/transit/wmata-transit-terms-of-service.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/30/troubling-terms-of-service-changes-from-washington-metropolitan-area-transit/">Troubling Terms of Service Changes From Washington Metropolitan Area Transit</a></h3>
			<p><em>30 Nov 2017</em></p>
			<p>I was turned onto a developing problem within the Washington Metropolitan Area Transit Authority (WMATA) around a recent terms of service change made around the transit data API by Technically DC. While the transit authority is saying the changes are business as usual and make sense for the platform, some of the developers, specifically one of the biggest API users MetroHero says the changes are targeting them specifically. MetroHero presented what they feel are the unreasonable changes to the WMATA API terms of service in a WMATA Board Meeting recently, focusing on four main areas: That no user or developer can mention “WMATA” in press releases without letting WMATA first review it. That WMATA can gain access to any user’s applications that use the data, can audit personnel information for anyone working on those applications, and WMATA can also create their own version at any time. That WMATA forbids users from claiming their data is accurate, complete or timely, or claiming it is more so than WMATA’s data. That the transit agency may now charge users in the future for using their data. These are all common changes I’ve seen made to API terms of service before, and are usually signs that a platform operator that is pretty out of touch with what it is like to be an API consumer, and with their own API community. It is a sign of a broken or pernicious feedback loop which leads to API providers making decisions that do lasting damage to their communities like this. These types of changes reflects the “rules of road” terms of service changes Twitter made to back in 2012. Which didn’t fully kill off the Twitter API, but set such a bad tone in the community, the company is still working to dig out of it five years later. I know platform operators feel they need to assert this level of control, but in an API community you need to learn...[<a href="/2017/11/30/troubling-terms-of-service-changes-from-washington-metropolitan-area-transit/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/30/the-average-person-will-never-care-about-apis-until-it-does-something/"><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories-new/17_88_800_500_0_max_0_-5_-5.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/30/the-average-person-will-never-care-about-apis-until-it-does-something/">The Average Person Will Never Care About APIs Until It Does Something</a></h3>
			<p><em>30 Nov 2017</em></p>
			<p>I am always looking for ways to introduce people to the concept of APIs, and that they are right below everything digital you do in your daily life. Even with my prolific writing, and sharing on social media, the number of new converts to API awareness are relatively low. I’m alright with what I do not scaling. I’m in this for the long haul, not to sell products or services. I’m looking to help turn on the API light for people not because I want them building the next API, I want to help enlighten folks so that they can take more control over their digital presence, and push back on the platforms and algorithms that are increasingly dominating our lives. One thing I’ve learned about normal folks in my journey as the API Evangelist is that nobody will ever care about APIs until they do something meaningful in their lives. Technologists learn about APIs for other reasons, but normal people aren’t motivated in the same ways, and need to have some meaning before they’ll wade into this more technical world of unknown, unknowns. When talking to technologists about APIs I focus on the API lifecycle, and the agility that APIs bring. With normal folks I tend to focus on platforms they already use, and algorithms that directly impact their lives, or impact people they know. As an API storyteller it is important for me to develop meaningful stories, that make APIs accessible in everyday scenarios to average people I encounter. If someone is a photographer I will tell stories of the Flickr or Instagram API. If someone is an accountant, I will work through how the Intuit API is rapidly being used by small businesses. If someone is a genealogist I will talk about how the Family Search API drives Ancestry.com. If someone is a music professional I will focus on Spotify, or maybe the Bandcamp API. This is why I play with as...[<a href="/2017/11/30/the-average-person-will-never-care-about-apis-until-it-does-something/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/30/sql-statement-passthrough-using-web-apis/"><img src="https://s3.amazonaws.com/kinlane-productions2/slashdb/slashdb-sql-pass-through-mode.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/30/sql-statement-passthrough-using-web-apis/">SQL Statement Pass-Through Using Web APIs</a></h3>
			<p><em>30 Nov 2017</em></p>
			<p>This is a sponsored post by my friends over at SlashDB. The topic is chosen by me, but the work is funded by SlasDB, making sure I keep doing what I do here at API Evangelist. Thank you SlashDB for your support, and helping me educate my readers about what is going on in the API space. I’m closely following the approach of GraphQL when it comes to making data resources more accessible by API consumers when developing applications. I think there is some serious value introduced when it comes empowering front-end developers with the ability to get exactly the data they need using a variety of querying structures. I enjoy studying up on different approaches to making different dimensions of a database to consumers and end-users, and found a pretty scrappy one from my friends over at SlashDB, with their SQL statement pass through. It’s not the most formal approach to query a database, but I think it’s scrappy and simple enough, that it might work for a wide variety of technical, as well as non-technical users. Using the SlashDB mode, an administrator, or an application backend developer can define arbitrary SQL queries which once defined, can be executed as a smple URL. The example query they provide returns customers from London: http://demo.slashdb.com/query/customers-in-city/city/London.html. It is something that will make RESTafarians pull their hair (dreads?) out, but for business users looking to get their hands on some data to populate a spreadsheet, or share with a partner when developing an application–it will be a lifesaver. As the GraphQL folks like trumpet, REST isn’t the only way to get things done, and while I think we should be thinking critical about the long term impact of our API design choices, getting business done efficiently is an important aspect of doing APIs as well. What I like about the SlashDB approach is it makes for an intuitive URL. Something business users can understand. I could see crafting...[<a href="/2017/11/30/sql-statement-passthrough-using-web-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/29/sorry-your-api-effort-falls-a-little-short-for-the-apis-i-cover/"><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories/supreme-court-judgement.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/29/sorry-your-api-effort-falls-a-little-short-for-the-apis-i-cover/">Sorry Your API Effort Falls A Little Short For The APIs I Cover</a></h3>
			<p><em>29 Nov 2017</em></p>
			<p>I get a lot of emails from companies asking me to look at their APIs. Too many for a one person operation like me to consider. I have to be picky about the APIs I’m taking a look at, and over time I’ve developed a set of criteria for determining how much energy I will invest in an API. Usually within about 2-3 minutes I can tell if it is an API I will be diving in deeper, or I will just be walking away and moving on with my work. The first thing that turns me off of an API is that it just isn’t interesting. I’ll land on the page and I can tell what it does, but it just doesn’t interest me. It doesn’t offer any value, or it is in a category that I’m just not eager to be thinking about and showcasing in my work. If an API doesn’t deliver value, and stand out as being interesting beyond the hundreds of other APIs I see each week, I’m just not going to stop and take notice. Sorry, it might be to others–don’t just take my opinion. The next thing that keeps me from going deeper is I can’t tell what an API does. I’m always amazed at how much head scratching, clicking and reading I will do before I ever figure out what an API does. I’m pretty hard headed, so sometimes its me, but other times I’m just stuck at figuring out what is going on under the hood. Usually after about 3-5 minutes of struggling to understand what is happening, I will just walk away. It is unlikely that other folks will be investing more time than that, and the API will not last long in my experience. After that, the biggest crime I see companies and organizations make is that they just do not invest enough into a dedicated portal, and the other supporting resources for their...[<a href="/2017/11/29/sorry-your-api-effort-falls-a-little-short-for-the-apis-i-cover/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/29/asyncapi-is-a-specification-format-for-messagedriven-apis/"><img src="https://s3.amazonaws.com/kinlane-productions2/asyncapi/asyncapi-editor-sample.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/29/asyncapi-is-a-specification-format-for-messagedriven-apis/">AsyncAPI Is A Specification Format For Message-Driven APIs</a></h3>
			<p><em>29 Nov 2017</em></p>
			<p>I’ve been learning about a new API definition format called AsyncAPI that allows you to define message-driven APIs in a machine-readable format. It is protocol-agnostic, which means you can use it for APIs that work over MQTT, AMQP, WebSockets, STOMP, and other real-time, and Internet of Things focused APIs. The specification format mirrors OpenAPI, making it pretty easy to get up to speed understanding what is going on. There are two primary concepts at play with the AsyncAPI: Messages - Consumer(s) communicate with your API via messages. A message is a piece of information two or more programs exchange. Most of the times to notify the other end(s) that, either an event has occurred or you want to trigger a command. Technically speaking the events and actions will always be sent in the same way. These are just messages, and their content can be anything. So when we talk about the difference between events and actions, this is only a semantic differentiation of message’s content. We do not enforce you to make any difference between them, although we encourage you to do it. A message can contain headers and a payload. However, both are optional. The specification allows you to define any header, to remain as much protocol-agnostic as possible. Topics - Message-driven protocols usually contain something called topic (MQTT), routing key (AMQP), destination (STOMP), etc. To some extent, they can compare to URLs in HTTP APIs. So, when you send a message to your API, it will be routed depending on the topic you published on. This feature allows you to create APIs that subscribe to specific topics and publish to other ones. There’s no standard way of naming topics, so we recommend you to have a look at our proposal here. I don’t have any APIs I can apply AsyncAPI to, so I have to just learn from the examples and any other work I come across. It makes me happy to see...[<a href="/2017/11/29/asyncapi-is-a-specification-format-for-messagedriven-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/29/api-deployment-is-about-publishing-them-wherever-they-are-needed/"><img src="https://s3.amazonaws.com/kinlane-productions2/slashdb/slashdb-database-deployment.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/29/api-deployment-is-about-publishing-them-wherever-they-are-needed/">API Deployment Is About Publishing Them Wherever They Are Needed</a></h3>
			<p><em>29 Nov 2017</em></p>
			<p>This is a sponsored post by my friends over at SlashDB. The topic is chosen by me, but the work is funded by SlasDB, making sure I keep doing what I do here at API Evangelist. Thank you SlashDB for your support, and helping me educate my readers about what is going on in the API space. I spun out a separate research area for API deployment, from my core API management research back in 2012 when companies were regularly asking me which of the API management providers they should be using to publish new APIs. At the time, none of them would help you actually publish your APIs, and there just wasn’t enough conversations going on around the subject. When I give talks which include my section on API deployment, some people still scratch their heads thinking there really isn’t that many options on the table–they deploy APIs wherever they’ve been deploying their APIs. However, in a cloud-driven world, the opportunities for how and where we can deploy our APIs are increasing, and the savvy teams are getting more versatile in how they get things done. Supporting multi-cloud is something all API service providers should be supporting. I was reviewing the approach to pricing from my friends and partners over at SlashDB, and I noticed as part of their pricing tier that they have “deployment” as one of the options. Allowing for deployment of their database to API solution on Debian, RedHat, VMWare, VirtualBox, Docker, Vagrant, Amazon, Azure, as well as custom solutions at the enterprise tiers. Focusing on the needs of a diverse range of enterprise customers, while also paying attention to where the API deployment conversation has been shifting for some time with Amazon, Docker, and the other platforms that are dominating the IT landscape. API service providers should be supporting multiple cloud platforms like SlashDB does, but API providers should also be looking at their own API deployment in the context...[<a href="/2017/11/29/api-deployment-is-about-publishing-them-wherever-they-are-needed/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/28/the-openapipowered-mock-api-server-from-stripe/"><img src="https://s3.amazonaws.com/kinlane-productions2/stripe/stripe-mock-api-server.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/28/the-openapipowered-mock-api-server-from-stripe/">The OpenAPI-Powered Mock API Server From Stripe</a></h3>
			<p><em>28 Nov 2017</em></p>
			<p>
I showcased Stripe’s OpenAPI definition the other week, so I wanted to also highlight a side effect of Stripe deciding to be OpenAPI-Driven. Stripe recently published an OpenAPI-powered mock server, allowing Stripe API consumers to test drive, and play with the Stripe API in a simulated environment. “It operates statelessly (i.e. it won’t remember new resources that are created with it) and responds with sample data that’s generated using a similar scheme to the one found in the API reference.”

The Stripe Mock Server is written in Go, and is available on Github. You can rebuild the Stripe API mock server from an updated OpenAPI anytime. It is a pretty dead simple mock server that seems like should be standard practice for any API. Providing a simple, safe, and portable way to play with an API. I’m going to fork the Stripe Mock API and play with it, see what is possible with the tool.

I will be keeping an eye out for any other OpenAPI-powered tools out of Stripe, now they are actively working with it. Adoption of OpenAPI at this level of API provider is helpful to the rest of the community, by providing an example of how you can bake OpenAPI into your operations, but also the open source tooling these companies produce. It’s an important community effect that makes this whole API thing work so well.

Ideally, the leading API providers, with the most resources, could coordinate their efforts and deliver a suite of open source tooling. However, I’m patient, I’m just happy that big companies like Stripe, Slack, Box, New York Times are doing OpenAPI at all. I can wait for all the cool tooling to happen next. I’ll keep an eye on Stripe’s Github organization to see what pops up.

[<a href="/2017/11/28/the-openapipowered-mock-api-server-from-stripe/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/28/making-your-api-pricing-page-accessible-to-everyone/"><img src="https://s3.amazonaws.com/kinlane-productions2/bitscoop/bitscoop-pricing-free.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/28/making-your-api-pricing-page-accessible-to-everyone/">Making Your API Pricing Page Accessible To Everyone</a></h3>
			<p><em>28 Nov 2017</em></p>
			<p>I’ve been talking with the folks over at Bitscoop about their integration platform as a service (iPaaS) offering. I would API mapping as a service, but that is another story. After talking with them, and going through their website, I wanted to focus on Bitscoop’s pricing page, which I feel reflects where API service pricing and plans are headed. There are three main areas of their pricing that I think are worth highlighting for accessing APIs at scale.

Bitscoop is really priced for EVERYONE, with a simple free tier to get started using the platform.



Next there are three tiers of access: developer, organization, and enterprise. It’s not as “ascendable” as I’d like it (smoother hop from tier to tier), but because Bitscoop clearly articulates how much additional calls are for each tier, the jump from tier to tier isn’t as painful.



Closing out the Bitscoop pricing page they have a custom solutions section letting you know they’ll deploy your API service to Google, Amazon, or Azure. Reflecting where API deployment, and API service deployment is headed.



Thats it. That is the story. Make your services accessible. Don’t price people out. Make your solutions available to everyone, with the opportunity to grow. I’m always fascinated by how many differing opinions there are out there regarding how you craft your SaaS and API plans. I think Bitscoop pricing reflects the reality of when you are integrating with hundreds or thousands of APIs. To be able to compete at this scale you are going to have to be plug and play with your tech, as well as the business of your APIs.

[<a href="/2017/11/28/making-your-api-pricing-page-accessible-to-everyone/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/28/getting-a-handle-on-our-database-schema-using-apis/"><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories/server-cloud1_internet_numbers.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/28/getting-a-handle-on-our-database-schema-using-apis/">Getting A Handle On Our Database Schema Using APIs</a></h3>
			<p><em>28 Nov 2017</em></p>
			<p>This is a sponsored post by my friends over at SlashDB. The topic is chosen by me, but the work is funded by SlasDB, making sure I keep doing what I do here at API Evangelist. Thank you SlashDB for your support, and helping me educate my readers about what is going on in the API space. When I take money from my partners, I am always looking for characteristics in their products and services that allow me to write honest stories about the solutions they provide. I can’t do this for all API companies that approach me, but the ones that are doing useful things, make it pretty easy for me. SlashDB helps me out on this front because they aren’t the shiny new startup doing APIs–they are the real world business helping other companies, organizations, institutions, and government agencies get a handle on their databases using APIs. One huge benefit of this process in my opinion is how it helps us get a handle on the schema we use, by letting a little light in on the process. One of the main reasons our databases are such a mess is because they are hidden away behind a dark technical or organizational curtain, and there really isn’t much accountability regarding how we define, name, organize, and store our data. Of course there are exceptions to this, but a messy, bloated, unwieldy database is a hallmark of about 75% of the organizations I’ve worked with over my 30 year career. Central databases are often a mashup of years, even decades of creating databases, tables, and adding columns, often times occurring over generations of database teams. The result is often an incoherent mess regarding how things are named, with layers of cryptic field names, and irrelevant table names, which might seem normal until you go and try to expose these data resources to 3rd party and partner developers. Many of the data APIs I come across...[<a href="/2017/11/28/getting-a-handle-on-our-database-schema-using-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/27/multiregion-apis-using-aws-api-gateway/"><img src="https://s3.amazonaws.com/kinlane-productions2/amazon/amazon-api-gateway-regions.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/27/multiregion-apis-using-aws-api-gateway/">Multi-Region APIs Using AWS API Gateway</a></h3>
			<p><em>27 Nov 2017</em></p>
			<p>I’ve been deploying two project using AWS API Gateway, Lambda, and Amazon RDS lately. I’ve become so sold on this approach to deploying APIs as part of this work, that I am evolving my own internal API process to use the same approach. The technical aspect of serverless plus the gateway definitely convinced me of the potential, but it was also the usage of AWS IAM which sealed the deal for me. I’m all too aware of how much my API security lacks as a one person shop, something that I also see reflected in my client operations, and I’d rather be offloading security to AWS than ending up taking the hit on it down the road. While deploying my project using AWS API Gateway, and Lambda, I was faced with the question regarding which zone I should be deploying the APIs in. It is the first time I’ve been faced with the opportunity to deploy my APIs into multiple zones. Sure, I could have deployed my servers into any AWS zone before, but for some reason now that I’m doing with AWS API Gateway, and Lambda, the opportunity seemed more of a possibility. I’ve pitched it to my client to consider an east as well as a west coast API deployment, so that we can give developers the choice in the documentation to choose which availability zone they’d like to use in their application. Before I make the proposal I’m going to deploy some prototypes, and do some benchmark testing, and see what the benefits are. Even if I end up publishing APIs into separate regions, I still have the backend database to content with. Where do I put the database, and how to I replicate between zones. Amazon RDS gives me the tools to tackle this, but historically I would only do this just for backup, not for actual redundancy, as well as performance gains. Amazon zones have been a staple of the...[<a href="/2017/11/27/multiregion-apis-using-aws-api-gateway/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/27/making-sure-you-operate-in-the-cloud-marketplaces-as-an-api-service-provider/"><img src="https://s3.amazonaws.com/kinlane-productions2/slashdb/slashdb-automatic-rest-api-for-databases-in-aws-marketplaces.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/27/making-sure-you-operate-in-the-cloud-marketplaces-as-an-api-service-provider/">Making Sure You Operate In The Cloud Marketplaces As An API Service Provider</a></h3>
			<p><em>27 Nov 2017</em></p>
			<p>This is a sponsored post by my friends over at SlashDB. The topic is chosen by me, but the work is funded by SlasDB, making sure I keep doing what I do here at API Evangelist. Thank you SlashDB for your support, and helping me educate my readers about what is going on in the API space. As the cloud giants like AWS, Microsoft, and Google continue to assert their dominance of the digital world, one aspect of their operations I’m watching closely has to do with their marketplaces. Google’s marketplaces are still very Android focused, but Amazon and Microsoft have shifted their recent editions of their marketplaces to be more cloud oriented, and accommodating a wide variety of applications, machine learning models, as well as APIs and API-focused services. While these marketplaces are still growing, and asserting their role in the digital economy, they are something I advise API providers, and service providers to be keeping a close eye on, and begin considering how they will want to operate within these environments. If you are an API service provider, and you are selling services to API providers anywhere along the API lifecycle, I recommend you follow the example of friends over at SlashDB, who have their database to API offerings in two of the leading marketplaces: AWS - Automatically constructing a REST API to databases for reading and writing on the AWS platform. Azure Marketplace - SlashDB enables you to do more with traditional databases and Microsoft Azure. As more companies, organizations, institutions, and government agencies move their databases into the cloud, SlashDB sees the opportunity to help them quickly turn databases and tables into web interfaces for querying data. Having your API service ready to go, in the environments where your potential customers are already operating is how much of this API stuff will go down in the future. Amazon has set the stage for how we’ll be delivering IT infrastructure over the...[<a href="/2017/11/27/making-sure-you-operate-in-the-cloud-marketplaces-as-an-api-service-provider/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/27/hints-of-banking-api-regulations-from-cfpb-with-consumer-authorized-financial-data-sharing-and-aggregation-rules/"><img src="https://s3.amazonaws.com/kinlane-productions2/cfpb/cfpb-outlines-principles-for-consumer-authorized-financial-data-sharing-and-aggregation.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/27/hints-of-banking-api-regulations-from-cfpb-with-consumer-authorized-financial-data-sharing-and-aggregation-rules/">Hints of Banking API Regulations From CFPB With Consumer Authorized Financial Data Sharing And Aggregation Rules</a></h3>
			<p><em>27 Nov 2017</em></p>
			<p>The Consumer Finance Protection Bureau (CFPB) has started laying out some consumer-authorized data sharing and aggregation rules to begin moving forward the banking data scraping conversation in (hopefully) a more production way. It is common knowledge that many financial focused (Fintech) companies regularly access consumers account data using their credentials, so that they scrape relevant account information from their bank, for use in a wide variety of 3rd party tools. This is a common practice that everyone in the industry knows about, understands is a potential security and privacy risk, but everyone looks the other way because it adds value to the consumer ecosystem. In a perfect world each bank would have a public API portal where Fintech aggregators could come and sign up for application keys, and get the authorization of users via OAuth, and obtain access to their banking data in a secure, and accountable way. However, as we are well aware, we do not live in a perfect world, and banks are pretty resistant to change, so the scraping continues. At some point we are going to see the landscape begin to shift, and I’m guessing it will be at the regulatory level where we finally begin to see this behavior changed–making the CFPB’s rules announcement a reflection of what is coming down the pipes when it comes to banking API regulation. The consumer protection principles for consumer-authorized financial data sharing and aggregation announcement focuses on: Access - Consumers are able, upon request, to obtain information about their ownership or use of a financial product or service from their product or service provider. Such information is made available in a timely manner. Consumers are generally able to authorize trusted third parties to obtain such information from account providers to use on behalf of consumers, for consumer benefit, and in a safe manner. Financial account agreements and terms support safe, consumer-authorized access, promote consumer interests, and do not seek to deter consumers from...[<a href="/2017/11/27/hints-of-banking-api-regulations-from-cfpb-with-consumer-authorized-financial-data-sharing-and-aggregation-rules/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/21/when-you-believe-everything-in-tech-is-new-and-nothing-repeats-itself/"><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories/beach-rocks-currents_blue_circuit_4.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/21/when-you-believe-everything-in-tech-is-new-and-nothing-repeats-itself/">When You Believe Everything In Tech Is New And Nothing Repeats Itself</a></h3>
			<p><em>21 Nov 2017</em></p>
			<p>I get regular waves of commenters and tweeters who like to point out the API patterns I’m covering in the API space, have all been done before. We tried discovery docs before they are called WSDL! That API discovery thing is called UDDI! RPC is nothing new! That isn’t new. We tried that before, and it didn’t work. I rarely ever engage with these folks, as this behavior is one pattern in behavior I actually do believe we SHOULDN’t be repeating and showcasing. I’m fascinated by the reasons someone would feel so strongly they need to respond. That something happened in the past, and because it didn’t work we shouldn’t try again today. That somehow the world of compute isn’t built upon, and remixed upon previous ideas that worked, and many that didn’t work until just the right conditions existed. This kind of behavior is really fascinating for me in the world of APIs where reuse, aggregation, facades, and so many patterns of reworking what already exists is core to the entire concept. Where do folks get such strange believes in the past, and what can and cannot be re-interpreted in the future? Hey you, electric car manufacturers, the electric car was done in early 20th century and it didn’t work! Hey musician, that baseline was originally present in the big band era and didn’t go over well, it won’t work now! Those pants were first tried in the 1950s and were a flop. Someone already wrote a book on Abraham Lincoln, why would you want to write another? Where do people get the idea that something that existed in the past shouldn’t be tried again, when it comes to the world of technology? Not only have the thought, but so many feel so strongly that they have to reach out and tell me what I’m writing about is dumb because it’s already been done? What is it about web technology that makes people think...[<a href="/2017/11/21/when-you-believe-everything-in-tech-is-new-and-nothing-repeats-itself/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/21/the-defensive-database-administrator-and-the-eager-blockchain-believer/"><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories/adam-smith_dali_three.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/21/the-defensive-database-administrator-and-the-eager-blockchain-believer/">The Defensive Database Administrator And The Eager Blockchain Believer</a></h3>
			<p><em>21 Nov 2017</em></p>
			<p>Think about the power that database administrators have in your organizations world? I’ve been working with databases since my first job in 1987. I’ve seen the power bestowed upon database administrators in organization after organization. They are fully aware of the power they control, and most other people in an organization are regularly reminded of this power. The defensive database administrator is always the biggest obstacle in the way of API teams who are often seen as a threat to the power and budgets that database groups command. This power is why databases are often centralized, scaled vertically, and are the backends to so many web, mobile, desktop, and server applications. I spend a significant amount time thinking about the power that database administrators wield, and how we can work to find more constructive, secure, and sensible approaches to shifting legacy database behaviors. Lately, I also find myself thinking a lot more about Blockchain. Not because I’m a believer, but because so many believers are pushing it onto my radar. Blockchain will continue to be a thing, not because it is a thing, but because so many people believe it is a thing. Most blockchains will not withstand the test of time, they are vapor, but the blockchains that remain will because people have convinced other people to put something meaningful into their blockchain. Much like we have convinced so many companies, organizations, institutions, and government agencies to put data into databases. Yes we. I’m complicit. A definition of the blockchain is, “a continuously growing list of records, called blocks, which are linked and secured using cryptography”. It’s a database, linked and secured using cryptography. The reason you hear about the blockchain so much, and how it can revolutionize almost every business sector, is the blockchain believers want to convince you to put your digital assets into their blockchain, which will eventually make it something real. I can setup a blockchain today, call it anything...[<a href="/2017/11/21/the-defensive-database-administrator-and-the-eager-blockchain-believer/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/21/day-2638-apis-are-dumb/"><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories/christianity-under-construction_atari_asteroids.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/21/day-2638-apis-are-dumb/">Day 2,638: APIs Are Dumb</a></h3>
			<p><em>21 Nov 2017</em></p>
			<p>It is one of those weeks where writing API stories, and doing my API work is completely uninteresting, and my three year old self is throwing a temper tantrum when it comes to doing anything. APIs are dumb. Why the hell would I care about this aspect of technology? Most people don’t understand what the fuck I’m talking about, and people keep doing really dumb shit with them, instead of working on the problems that really matter. Why do I keep doing what I’m doing? Why don’t I just go get a real job, make some real money, and give a shit less? Great question! Most weeks I can just turn the API Evangelist persona on, and with a notebook full of ideas, and inbox full of questions, I begin writing the API blah blah blah. It just flows. This week it all seems dumb, and I have to fabricate any ounce of caring about APIs. Beyond APIs and Internet technology in general feeling like a pretty bad idea, I feel complicit in helping bring about this technological beast that is wreaking havoc on our world right now. Why the hell should I continue doing API Evangelist, when so many of my ideas can be used for exploitation, and just keep making rich white people richer? It just seems like a bad idea, so why shouldn’t I just shut things down and go find a meaningful job (does that exist)? First, I always start with the basic API Evangelist mission: helping non-techies understand what APIs are, and how they are right under the hood of everything we are using that is digital. What I do will never receive venture capital, be profitable, and return measurable ROI. Few other companies, let alone individual care about a digitally literate world, they just want consumers, and refuse to see the correlation. I’m the one showcasing API stories consistently regardless of the latest trends, and focus on understanding what...[<a href="/2017/11/21/day-2638-apis-are-dumb/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/20/generating-operational-revenue-from-public-data-access-using-api-management/"><img src="https://s3.amazonaws.com/kinlane-productions2/public-data-api-management/parks-prohibit-commercial-use.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/20/generating-operational-revenue-from-public-data-access-using-api-management/">Generating Operational Revenue From Public Data Access Using API Management</a></h3>
			<p><em>20 Nov 2017</em></p>
			<p>This is part of some research I'm doing with Streamdata.io. We share a common interest around the accessibility of public data, so we thought it would be a good way for us to partner, and Streamdata.io to underwrite some of my work, while also getting the occasional lead from you, my reader. Thanks for supporting my work Streamdata.io, and thanks for support them readers! A concept I have been championing over the years involves helping government agencies and other non-profit organizations generate revenue from public data. It is a quickly charged topic whenever brought up, as many open data and internet activists feel public data should remain freely accessible. Something I don’t entirely disagree with, but this is a conversation, that when approached right can actually help achieve the vision of open data, while also generating much needed revenue to ensure the data remains available, and even has the opportunity to improve in quality and impact over time. Leveraging API Management I’d like to argue that APIs, and specifically API management has been well established in the private sector, and increasingly in the public sector, for making valuable data and content available online in a secure and measurable way. Companies like Amazon, Google, and even Twitter are using APIs to make data freely available, but through API management are limiting how much any single consumer can access, and even charging per API call to generate revenue from 3rd party developers and partners. This proven technique for making data and content accessible online using low-cost web technology, requiring all consumers to sign up for a unique set of keys, then rate limiting access, and establishing different levels of access tiers to identify and organize different types of consumers, can and should be applied in government agencies and non-profit organizations to make data accessible, while also asserting more control over how it is used. Commercial Use of Public Data While this concept can apply to almost any...[<a href="/2017/11/20/generating-operational-revenue-from-public-data-access-using-api-management/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/17/we-love-what-you-do-in-the-api-space-but-could-you-do-it-our-way/"><img src="https://s3.amazonaws.com/kinlane-productions2/api-evangelist-logos/api-evangelist-butterfly-vertical.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/17/we-love-what-you-do-in-the-api-space-but-could-you-do-it-our-way/">We Love What You Do In The API Space But Could You Do It Our Way</a></h3>
			<p><em>17 Nov 2017</em></p>
			<p>I hear it daily in my inbox, on Twitter, and via LinkedIn. We love what you do! We’ve followed your work for a while, and love your unique voice, and the way you tell stories on your blog. I’m not very good at accepting praise on my work, especially when I know that much of it isn’t sincere and genuine. Saying it casually to me is weird, and I am not sure why people feel like they should be saying it, but it is the folk who go the distance to say it, but then also try to change the way I am, after acknowledging over and over, that they like what I do. From running a major conference, to my everyday storytelling, I get waves of people who like what I’ve done historically, want to support and be part of it, but once engaged actively try to change the conversation, and change the tone of what I do. The community has really seemed to rally around your conference, and clearly you’ve built a loyal group by making your event about ideas–we’d like to sponsor, but we really need a main stage talk where we can talk about our products. We love the tone of your storytelling on the blog and how you educated people people about the real world aspects of doing APIs–we’d love to sponsor, but we need you to talk about our products, and shift the focus to what we are doing. There are so many ways people acknowledge the value of what I do, but then want me to do the same old tired thing they’ve been doing. I get why you do it. It is easy. It is going from zero to what you want in as little time as possible. However, you seem to be all too willing to completely ignore why my thing is working and why your old tired thing isn’t, and why you are even attracted...[<a href="/2017/11/17/we-love-what-you-do-in-the-api-space-but-could-you-do-it-our-way/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/17/the-many-meanings-of-do-not-make-the-same-mistake-as-twitter-did-with-their/"><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories/kinlane-white-board-twitter_copper_circuit.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/17/the-many-meanings-of-do-not-make-the-same-mistake-as-twitter-did-with-their/">The Many Meanings Of "Do Not Make The Same Mistake As Twitter Did With Their</a></h3>
			<p><em>17 Nov 2017</em></p>
			<p>I remember the first time I heard someone say that they didn’t want to make the same mistake as Twitter did with their API. It was from Pinterest. After that I heard the phrase uttered by many companies, with almost an entirely different meaning behind what the mistake was. Twitter is a darling of the API community when it comes to being the poster child for what not to do in the API space. I consider Twitter to be in the top 10 most important APIs out there, as well as being in the top ten APIs I wouldn’t want to be responsible for, and is a platform full of endless examples of how to do APIs right, and how to do them wrong. When some companies say this phrase, they mean they don’t want to make the mistake Twitter did by having an API at all–usually heard from executives. Other times, it is said in response to anti competitive behavior in their API ecosystem, and treating startups badly. When you hear from developers, it is usually about their rate limits, and their rules of the road they published a few years back. It coming years I predict we’ll be saying it about automation, and using Twitter as case study for how not to assert control of bots on your API platform. You’ll find me leveraging this statement regularly to talk about making sure you have a real API monetization strategy, and don’t wait a decade to start offering premium access to your APIs that are accessible to EVERYONE. I’ve been complaining about access to the Twitter API for over five years now. API plans are the heart of every API I keep an eye on. They set the tone for ALL conversations that go on around an API. The lack of a coherent, equitable, API access plan at Twitter has set into motion almost every other illness on the platform from harassment to bots....[<a href="/2017/11/17/the-many-meanings-of-do-not-make-the-same-mistake-as-twitter-did-with-their/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/17/my-basic-yaml-for-starter-api-plans/"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/api_plans_pricing_tiers.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/17/my-basic-yaml-for-starter-api-plans/">My Basic YAML For Starter API Plans</a></h3>
			<p><em>17 Nov 2017</em></p>
			<p>I started developing a machine readable format for describing the API plans and pricing for leading API providers a few years back. Eventually I’d like to see the format live alongside OpenAPI, Postman, and other machine readable API specifications within a single APIs.json index. I am looking to adequately describe the plans and pricing for APIs, which are often just as important as the technical details, in the same way we’ve describe the technical surface area of an API using OpenAPI for some years now. People love to tell me that I will never be able to do it, which only makes me want to do it more. I’m revisiting my work as part of work I’m doing on a clients project, which I’m also using to push forward my API portal and management toolbox. The project I’m working on has two API plans: 1) Starter - The free level of access everyone gets when signing up for access to an API. 2) Verified - A verified level of pay as you go usage once you have credit card on file. I’ve taken the common elements across these plans and described them in a YAML format which allows me to remix the elements into the two plans I currently have, while also allowing me to reuse them for possible future plans, helping keep my approach consistent. I’m using the plan elements in this YAML file to generate the plans and pricing page for each API. Generating two separate plan boxes, with the details, and elements of each plan. I keep all the moving parts of each plan defined as separate fields and collections so that I can reuse in any new plans. I also make use of the individual elements in comparison charts, and other pricing and plan related resources through an APIs portal. The specification isn’t perfect, but it provides me a starting point for considering how I make my API plans and pricing...[<a href="/2017/11/17/my-basic-yaml-for-starter-api-plans/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/17/api-management-is-about-awareness-and-control-over-our-digital-resources/"><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories/adam-smith_blue_circuit.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/17/api-management-is-about-awareness-and-control-over-our-digital-resources/">API Management Is About Awareness And Control Over Our Digital Resources</a></h3>
			<p><em>17 Nov 2017</em></p>
			<p>I’ve been diving into the fundamentals of API management as part of several projects I am working on. I am setting up API management for a single API project, as well as thinking through API management practices across many API implementations in a single industry. I also just had lunch with a friend at an API startup I work with who is looking to invest in me doing some further research and storytelling when it comes to API management. All of this is providing me with a great opportunity to step back and think about API management from the small detailed moving parts, all the way up to the industry, regulatory, and macro levels of managing digital resources online. API management is the oldest aspect of my research, and one I still think is one of the most critical aspects of doing APIs in my opinion. While there are many features modern API management brings to the table, the core of it is all about allowing consumers to sign up to access some data, content, media, or algorithm. Each consumer receives a set of keys that will identify and allow for their access to be measured, which then allows the owners or stewards of digital resources to develop awareness around who is accessing a resource, and what they are doing with it. Some call it security, others analytics, but I see it about developing an awareness and asserting control over our digital resources. If you are focused on monetization, API management is about generating revenue. If you are worried about who has access to your digital assets, API management is about security. If you are doing API management right you realize it is about being aware of the digital resources you have, working to make sure they are well defined, and are tuned into your API management dashboard to understand how they are being used (or not used). I feel like this has been one...[<a href="/2017/11/17/api-management-is-about-awareness-and-control-over-our-digital-resources/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/16/you-thinking-i-mean-rest-when-i-say-api-is-about-your-limited-views-not-mine/"><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories/kin-chesapeake-sun_light_dali.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/16/you-thinking-i-mean-rest-when-i-say-api-is-about-your-limited-views-not-mine/">You Thinking I Mean REST When I Say API Is About Your Limited Views, Not Mine</a></h3>
			<p><em>16 Nov 2017</em></p>
			<p>I’m fascinated by the baggage people bring to the table when engaging in discussions around technology with me. A common opener for many conversations with season technologists centers around REST not penciling out as everyone thought, failing to be the catch-all solution, and will quickly move to how I feel about some new technology (GraphQL, gRPC, Kafka, other) making my work irrelevant. I wish I had some quick phrase to help folks understand how this line of questioning demonstrates their extremely limiting views of the tech sector, as well as my work with APIs, but alas I find silence usually does the job in these situations–allowing everyone to quickly move. For me, application programming interface, or API, is all about finding the right interface for programming against for a specific application. I’d say the closest things that anchors my belief system to REST, is that I tend to focus on leveraging the web when it comes to defining the web because it is low coast, usually well known, and avoids reinventing the wheel. I’m not a RESTafarian, and you will not find me online arguing the finer details of REST over other approaches. It just isn’t my style, and I leave it to ya’ll to work out these finer details, and share the stories about what is working, and what is not working in your operations. Your assumptions around what APIs means to me demonstrates your limited views, only partially because of the technological underpinnings. The technical details of API is only 1/3 of the equation for me, and the majority of my research and storytelling focuses on the business and politics of doing APIs, but I’m guessing you aren’t aware of this. I find that the technology definitely sets the tone for API implementations and conversations, but the ones that actually make a significant impact always transcend the technology, and help acknowledge, and understand the other aspects of operating online which is making doing...[<a href="/2017/11/16/you-thinking-i-mean-rest-when-i-say-api-is-about-your-limited-views-not-mine/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/16/three-stripe-openapi-vendor-extensions/"><img src="https://s3.amazonaws.com/kinlane-productions2/stripe/stripes-openapi-vendor-extension.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/16/three-stripe-openapi-vendor-extensions/">Three Stripe OpenAPI Vendor Extensions</a></h3>
			<p><em>16 Nov 2017</em></p>
			<p>As part of my work on my OpenAPI toolbox I am keeping an eye out for how leading API providers are using OpenAPI. One layer of this part of my research is understanding how teams are extending the OpenAPI specification, while also encouraging other companies to understand that they can extend the specification in the first place. I’m always surprised how many people I come across that say they do not use the specification because it doesn’t do everything they need. I alternatively feel like it is my responsibility to understand what the spec can do, and then bend it to do what I need it to using vendor extensions. I have been studying how payment provider Stripe has been crafting their OpenAPI throughout the week, while also understanding how they are applying it across their platform operations. As part of their Github repository for managing the Stripe OpenAPI they share three vendor extensions they are using to evolve what is possible with OpenAPI: x-expandableFields - Resources include an x-expandableFields that contains a list of fields that are expandable by making an API request with an expand parameter. See expanding objects. x-polymorphicResources - Some API responses are “polymorphic” in that they might return multiple types of resources which is a case that OpenAPI can’t handle. In these cases the spec will reference a “synthetic” resource which is an aggregate of the properties common to all the possible resources. It will also include the field x-polymorphicResources which references those resources more precisely. x-resourceId - Resources include x-resourceId which is a canonical name for each resource. It can be used in conjunction with openapi/fixtures{2,3}.{json,yaml} to look up a sample representation (otherwise known as a “fixture”) of the resource. Some interesting extensions. The expandable fields, and resource id is pretty straight forward, but the polymorphic resources opens up some interesting questions when it comes to API design. It makes me want to learn more about the how and...[<a href="/2017/11/16/three-stripe-openapi-vendor-extensions/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/16/the-information-you-get-when-allowing-developers-to-sign-up-for-an-api-using/"><img src="https://s3.amazonaws.com/kinlane-productions2/github/github-authentication-screenshot.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/16/the-information-you-get-when-allowing-developers-to-sign-up-for-an-api-using/">The Information You Get When Allowing Developers To Sign Up For An API Using</a></h3>
			<p><em>16 Nov 2017</em></p>
			<p>I’m a big Github user. I depend on Github for managing all my projects, and Github Pages for the presentation layer around all my research. When anything requires authentication, whether for accessing an API, or gaining access to any of my micro apps, I depend on Github authentication. I have a basic script that I deploy regularly after setting up a Github OAuth application, which I use to enable authentication for my API portals and applications, handling the OAuth dance, and returning me the information I need for my system. After a user authenticates I am left with access to the following fields: id, avatar_url, gravatar_id, url, html_url, followers_url, following_url, gists_url, starred_url, subscriptions_url, organizations_url, repos_url, events_url, received_events_url, type, site_admin, name, company, blog, location, email, hireable, bio, public_repos, public_gists, followers, following, created_at, updated_at, private_gists, total_private_repos, owned_private_repos, disk_usage, collaborators, two_factor_authentication, and plan. Not all these fields are filled out, and honestly I don’t care about most of them for my purposes, but it does provide an interesting look at what you get from Github, over a basic email and password approach to authentication. I’m just looking for any baseline information to validate someone is a human being when signing up. Usually a valid email is this baseline. However, I prefer some sort of active profile for a human being, and have chosen Github as the baseline. When anyone signs up I also quickly calculate some other considerations regarding how long they’ve had a Github account, how active it is, and some numbers regarding this history and activity. I don’t expect everyone to have a full blown public Github profile like I do, but if you are looking to use on of my APIs, or API-driven micro tools I’m looking for something more than just a valid email–I want some sign of life. I will be evolving this algorithm, and enforcing it in different ways at different times. I always hesitate using Github as the default login for...[<a href="/2017/11/16/the-information-you-get-when-allowing-developers-to-sign-up-for-an-api-using/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/16/stripe-elements-and-how-we-organize-our-api-embeddables/"><img src="https://s3.amazonaws.com/kinlane-productions2/stripe/stripe-elements-grey-embeddable.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/16/stripe-elements-and-how-we-organize-our-api-embeddables/">Stripe Elements And How We Organize Our API Embeddables</a></h3>
			<p><em>16 Nov 2017</em></p>
			<p>I am setting up Stripe for a client, and I found myself browsing through Stripe Elements, and the examples they have published to Github. If you aren’t familiar, “Stripe Elements are pre-built rich UI components that help you build your own pixel-perfect checkout flows across desktop and mobile.” I put Stripe Elements into my bucket of API embeddables, which overlaps with my API SDK research, but because they are JavaScript open up a whole new world of possibilities for developers and non-developers, I keep separate. Stripe.js and supporting elements provides a robust set of solutions for integrating the Stripe API into your website, web or mobile application. You can choose the pre-made element, customize as you see fit, or custom build your own using the Stripe.js SDK. It provides a great place to start when learning about Stripe, reverse engineering some existing solutions, and figuring out what integration will ultimately look like. In my scenario, the default Stripe element in their documentation works just fine for me, but I couldn’t help but playing with some of the others just to see what is possible. You can tell Stripe has invest A LOT into their Sripe.js SDK, and the overall user experience around it. It provides a great example of how far you can go with embeddable API solutions. I like that they have the Stripe Elements published to Github, and available in six different languages. As I was learning and Googling, I came across other examples of Stripe.js deployment on other 3rd party sites, making me think it would be nice if Stripe had a user generated elements gallery as part of their offering, accepting pull requests from developers in the Stripe community. It wouldn’t be that hard to come up with a template markdown page that developers could fill out and submit, sharing their unique approach to publishing Stripe Elements. Having a Github repository to display example embeddable API tooling makes sense, and is...[<a href="/2017/11/16/stripe-elements-and-how-we-organize-our-api-embeddables/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/15/twitter-finally-begins-to-monetize-their-apis/"><img src="https://s3.amazonaws.com/kinlane-productions2/twitter/TwitterPremiumAPIs.gif" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/15/twitter-finally-begins-to-monetize-their-apis/">Twitter Finally Begins To Monetize Their APIs</a></h3>
			<p><em>15 Nov 2017</em></p>
			<p>It has been a long time coming, but Twitter has finally started charging for premium access to their APIs. Until now, you could only access data via the free Twitter API with limitations, or pay to use Gnip at the enterprise level–nothing in between. I’ve long complained about how Twitter restricts access to our tweets, as well as the lack of transparency and honesty around their business model. I’ve complained so much about it, I eventually stopped writing about it, and I never thought I’d see the day where Twitter starts charging for access to their platform. While I have concerns about Twitter further limiting access to our data by charging for API access, their initial release has some positive signs that give me hope that they are monetizing things in a sensible way. They seem to be focused on monetizing some of the key paint points around Twitter API consumption, like being able to get more access to historical data, offer more Tweets per request, higher rate limits, a counts endpoint that returns time-series counts of Tweets, more complex queries and metadata enrichments, such as expanded URLs and improved profile geo information. Twitter seems to be thinking about the primary pain we all experience at the lower rungs of Twitter access, and focusing on making the platform more scalable for companies of all shapes and sizes–which has been core to my complaints. Twitter even provides a quote from a client which highlights what I’ve been complaining about for some time about the inequity in Twitter API access: I wish these premium APIs were available during our first few years. As we grew, we quickly ran into data limitations that prevented expansion. Ultimately, we raised a round of funding in order to accelerate our growth with the enterprise APIs. With the premium APIs, we could have bootstrapped our business longer and scaled more efficiently. - Madeline Parra, CEO and Co-Founder, Twizoo (now part of Skyscanner)...[<a href="/2017/11/15/twitter-finally-begins-to-monetize-their-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/15/headless-cms-and-the-api-evolution-beyond-wordpress/"><img src="https://s3.amazonaws.com/kinlane-productions2/headless/headless-cms-brackets.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/15/headless-cms-and-the-api-evolution-beyond-wordpress/">Headless CMS And The API Evolution Beyond WordPress</a></h3>
			<p><em>15 Nov 2017</em></p>
			<p>I am a fan of what WordPress has done for the online world. I feel like it has enabled a lot of folks to take some control over their web presence, and in some situations even made programmers out of business people who never thought that is what they’d end up doing. Even with all the positive benefits of WordPress, it has had some significant negative side effects which I think warrant us to begin looking beyond the existing ecosystem–something I’m hoping the headless CMS, and static website movement can help fuel. I’m not anti-WordPress, but I think the movement has run its course, and we can do better when it comes to helping folks take control over their web presence, as well as avoid much of the security challenges we experience as a result of WordPress. If you aren’t familiar with the concept of headless, it is just about doing APIs, but centered around the end deliverable–the application. Headless focuses on decoupling content for use in apps, websites, or any other data-driven projects, allowing content to be created and managed independently from where it’s used. To us API-aware folks this is how All applications should behave, but I feel like the headless CMS concept is an important API gateway for business users who have drank the WordPress kool-aid, and are looking to do more with their CMS, and break free of some of the challenges of operating exclusively in a WordPress state of mind. The most damaging aspect of WordPress I have felt is it’s emphasis on the blog. Everything is centered around the blog with WordPress installs, which isn’t the reason many folks should be doing a website in the first place, but because of their platform they feel compelled to. Headless CMS can be about managing ANY content, and crafting an API backend, that can deliver exactly the content you need in any website, web or mobile backend, bypassing the concept of...[<a href="/2017/11/15/headless-cms-and-the-api-evolution-beyond-wordpress/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/15/form-posts-as-gateway-for-showing-people-they-can-program-the-web-using-apis/"><img src="https://s3.amazonaws.com/kinlane-productions2/forms/contact-form.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/15/form-posts-as-gateway-for-showing-people-they-can-program-the-web-using-apis/">Form Posts As Gateway For Showing People They Can Program The Web Using APIs</a></h3>
			<p><em>15 Nov 2017</em></p>
			<p>I am always looking for new avenues to help on-board folks with APIs. I’m concerned that folks aren’t quite ready for the responsibility that comes with a programmable web, and I’m looking for ways to help show them how the web is already programmable, and that APIs can help them take more control over their data and content online. A significant portion of my low hanging fruit API work centers around the forms already in use across websites, and how these forms are a doorway for data, and content that should also be available via an API. If information is already available on your website, and being gathered or displayed in response to a form on your website, it is a great place to start a conversation around providing an API that delivers the same functionality. Sometimes forms drive website searches, and act as a way to gather some data before presenting results–providing a good example of a GET API. In other situations forms act as an input for data, such as a contact form, or survey response. In these scenarios, forms provide a good example of a writable, or POST API path–allowing data and content to be added into a system. I’m always pointing out that if data is displayed in tables, or accessible through a form submission on a website, this is where you should start with readable APIs. The same holds true for form submissions that gather data, being where folks should bet starting with writable APIs. I feel like contact, messaging, and survey forms are all good examples of how companies, organizations, institutions, and government agencies can begin with write APIs. Business users get the concept of a form, and even its submission via a POST on the web. It is a great place to start the conversation with folks about having APIs that don’t just deliver information, but also accept new information using the web. I’m thinking about how I...[<a href="/2017/11/15/form-posts-as-gateway-for-showing-people-they-can-program-the-web-using-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/15/deploy-low-hanging-fruit-rogue-api-portals-for-those-who-are-behind-the-curve/"><img src="https://s3.amazonaws.com/kinlane-productions2/low-hanging-fruit/api-evangelist-low-hanging-fruit-story-screenshot.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/15/deploy-low-hanging-fruit-rogue-api-portals-for-those-who-are-behind-the-curve/">Deploy Low Hanging Fruit Rogue API Portals For Those Who Are Behind The Curve</a></h3>
			<p><em>15 Nov 2017</em></p>
			<p>&lt;p&lt;/p&gt;The concept of rogue APIs isn’t anything new. Instagram started out as a rogue API, and many leading platforms who are less than open with their platforms have rogue APIs. They are usually APIs that have been reverse engineered from mobile applications, and published to Github for other developers to use. I’m looking to marry this concept with my low hanging fruit API work, where I help organizes start their API journey using data and content that is already on their website. Meaning, if it is already available on the web as table, form, or as CSV, spreadsheet, or other machine readable fie, it should be available via an API. As APIs are just the next step in the evolution, this is the logical place for the API journey to begin for many companies, organizations, institutions, and government agencies. I’ve spidered the entire web site of organizations to extract lists of data sources they should be turning into APIs. I’ve done this at the request of the website owner, as well as without the permission. Honestly, it provides a pretty compelling look at the digital presence for an organization when you harvest raw data like this and publish to a Github repository. It isn’t a view that every organization is ready for, or has thought about. Making it an even more important place for organizations to start their API journey. APIs aren’t just about providing access to your data and content for your partners and 3rd party developers, it is about getting a handle on your digital assets, and how you present and provide access to this digital representation of your organization–something many suck at profoundly. I’d like to invest more cycles into my low hanging fruit API research. I’d love to take some government agencies and not just identify the low hanging fruit, but actually deploy a rogue API portal, and hang some of the APIs there. I’d like to do this to a...[<a href="/2017/11/15/deploy-low-hanging-fruit-rogue-api-portals-for-those-who-are-behind-the-curve/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/14/the-seo-benefits-of-publishing-your-api-operations-to-github/"><img src="https://s3.amazonaws.com/kinlane-productions2/github/github-api-evangelist.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/14/the-seo-benefits-of-publishing-your-api-operations-to-github/">The SEO Benefits Of Publishing Your API Operations To Github</a></h3>
			<p><em>14 Nov 2017</em></p>
			<p>I’ve been operating 100% of my public presence for API Evangelist on Github for almost five years now. I really like the public layer of my world being static, but I also like the modularity that using Github repos for my projects have injected into my workflow. API Evangelist runs as almost 100 separate Github repositories, all using a common Jekyll template for the UI, making it look like you are always on the same API Evangelist website. Any website, application, data, or API begins as a Github repository in my world, and grows from there depending on how much energy I give a project during my daily work. When I first started doing all of this, I worried a little bit about the search engine optimization of my public websites. From what I could tell in 2013, my sites ranked lower after the switch, but since I’m not in this for the numbers game, I shrugged it off. However, in 2017 the numbers look different, and some of the projects I’ve been cultivating on Github actually rank pretty high, even with minimal optimization on my part. This isn’t just the web front-end for my projects–I am also seeing the Github repositories themselves showing up pretty prominently in search engine results. All of this is anecdotal. I haven’t done any official measurements or testing on the topic, I just don’t care enough to invest that amount of work in it all. I just have to note that in the last year I am seeing significant benefit for my SEO by running things on Github. When you bundle this with the search and discovery opportunities via Github, the benefits to running an API project on Github as much as possible makes sense. It is something I encourage all of my clients who are operating public APIs consider as part of their overall marketing, communications, and evangelism strategy. I’ve been profiling all the possible ways that an...[<a href="/2017/11/14/the-seo-benefits-of-publishing-your-api-operations-to-github/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/14/i-added-a-simple-bulk-api-for-my-human-services-data-api/"><img src="https://s3.amazonaws.com/kinlane-productions2/open-referral/human-services-data-bulk-api.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/14/i-added-a-simple-bulk-api-for-my-human-services-data-api/">I Added A Simple Bulk API For My Human Services Data API</a></h3>
			<p><em>14 Nov 2017</em></p>
			<p>The core Human Services Data API allows for adding of organizations, locations, services, and contacts one by one using a single POST on the core API paths for each available resource. However, if you want to add thousands, or even hundreds of records, it can quickly become cumbersome to submit each of the calls, so I wanted to introduce a simple Human Services Bulk API for helping handle the adding of large quantity of data, on a one-time, or recurring basis. I know there job queuing solutions available out there, but my goal with this project is to focus on the API definition, as well as the backend system(s). For this round, I just want to get a simple baseline definition in place, with a simple API backend for orchestrating. I’ll update to support AWS, and other queuing solutions as part of the road-map–further hammering out a consistent HSDA Bulk API. The first dimension of this new HSDA Bulk API focuses on providing paths for POSTing large quantities of data across the core human service resources: organizations/ - POST complete organizations JSON records as array. locations/ - POST complete locations JSON records as array. services/ - POST complete services JSON records as array. contacts/ - POST complete contacts JSON records as array. You can submit as many records to each of these paths (well, within reason), including the sub-resources for each object like physical address, phones, etc. When POSTed each record doesn’t immediately go into the main HSDA database. Each entry is entered into a jobs system, which can be run on a schedule, based upon events, or maybe just wait until the middle of the night. The goal is to offload the bulk insert to a job system, which can spread things out over time, and minimize negative impact on resources strapped human services database. HSDA Bulk API runs as a separate microservice which can be run side by side with the core HSDA...[<a href="/2017/11/14/i-added-a-simple-bulk-api-for-my-human-services-data-api/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/14/glitch-is-where-you-will-learn-the-essential-human-side-of-operating-your-api/"><img src="https://s3.amazonaws.com/kinlane-productions2/glitch/1_-GNpo5PEhPm-1Ns4F76t9w.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/14/glitch-is-where-you-will-learn-the-essential-human-side-of-operating-your-api/">Glitch Is Where You Will Learn The Essential Human Side Of Operating Your API</a></h3>
			<p><em>14 Nov 2017</em></p>
			<p>The biggest deficiency I see in the world of APIs is an ability to understand the human side of what we are all doing. The space is dominated by men, and people who have an understanding of, and deep belief in technology, over that of humans. The biggest problems APIs face across their life cycle is humans, and increasingly one of the biggest threats to humans is an API (ie. Twitter API automation &amp; harassment, IoT device exploitation, Facebook advertising, etc.) APIs encounter human friction because their creators didn’t anticipate the human portion of the equation, and APIs often get used against humans because their creators again didn’t anticipate human nature, and how people might use their technology for doing harmful things. I rarely see folks in the API sector focusing on the human side of the equation, but I am pleasantly surprised to see a constant drumbeat coming out of Glitch, “the friendly community where you’ll build the app of your dreams.” Glitch is a platform where API consumers can remix apps that use APIs, and API providers can engage with API consumers who are building and remixing interesting things. Glitch has been on my list to write about more, and is something I’ll be using, and focusing more time on in future posts, but I wanted to just highlight how much focus is spent on the human side of the API world over at Glitch. Take a look at the articles coming out of the Glitch blog, Dev Rel success requires an ongoing connection to a community of peers, and Dev Rel must be supported with ongoing investment in professional development–all part of the ongoing stories around a Developer Bill of Rights, which Glitch has been very vocal about, emphasizing the importance of the human aspects of doing APIs and building applications. Which is the first startup I’ve seen come along that is investing so much energy into discussing what really makes all...[<a href="/2017/11/14/glitch-is-where-you-will-learn-the-essential-human-side-of-operating-your-api/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/14/could-i-please-get-an-api-discovery-tool-that-evaluates-an-openapi-diff/"><img src="https://s3.amazonaws.com/kinlane-productions2/openapi/openapi-logo.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/14/could-i-please-get-an-api-discovery-tool-that-evaluates-an-openapi-diff/">Could I Please Get An API Discovery Tool That Evaluates An OpenAPI Diff</a></h3>
			<p><em>14 Nov 2017</em></p>
			<p>I am increasingly tracking on OpenAPI definitions published to Github by leading API providers I track on. Platforms like Stripe, Box, New York Times are actively managing their OpenAPI definitions using Github, making them well suited for integration into their platform operations, API consumer scenarios, and even within analyst systems like what I have going on as the API Evangelist. Once I have an authoritative source of an OpenAPI, meaning a public URI for an OpenAPI that is actively being maintained by the API provider, I have a pretty valuable feed into the roadmap, as well as change log for an API. I feel like we are getting to the point where there are enough authoritative OpenAPIs that we can start using as a machine readable notification and narrative tool for helping us stay in tune with one or many APIs across the landscape. Helping us stay in tune with APIs in real-time, and giving APIs an effective tool for communicating out changes to the platform–we just need more OpenAPIs, and some new tooling to emerge. I’m envisioning an OpenAPI client that regularly polls OpenAPIs and caches them. Anytime there is a change it does a diff, and isolated anything new. Think of an RSS reader, but for OpenAPIs, and going well beyond new entries, and actually creates a narrative based upon the additions and changes. Tell me about the new paths added, and any new headers, parameters, or maybe how the schema has grown. Provide me insights on what has changed, and possibly what has been removed, or will be removed in future editions. As an API analyst, I’d like to be able to have an OpenAPI-enabled approach to receiving push notifications when an API changes, with a short, concise summary about what has change in my inbox, via Twitter, or Github notification. OpenAPI already provides API discovery features through the documentation it generates, and I’m increasingly using Github to find new APIs after...[<a href="/2017/11/14/could-i-please-get-an-api-discovery-tool-that-evaluates-an-openapi-diff/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/12/stripes-openapi-is-available-on-github-in-version-3-0/"><img src="https://s3.amazonaws.com/kinlane-productions2/stripe/stripes-openapi-specification-on-github.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/12/stripes-openapi-is-available-on-github-in-version-3-0/">Stripes OpenAPI Is Available On Github In Version 3.0</a></h3>
			<p><em>12 Nov 2017</em></p>
			<p>I can’t write about every API provider who publishes their OpenAPI to Github, there are just too many. But, I can write about the rockstar API providers who do though, and showcase what they are doing, so I can help influence the API providers who have not started publishing their OpenAPIs in this way. If you are looking for a solid example of a leading API provider publishing their OpenAPI to Github, I recommend taking a look at the payment provider Stripe. Their repository contains OpenAPI specifications for Stripe’s API, with multiple files available in the in the openapi/ directory: spec3.{json,yaml} - OpenAPI 3.0 spec. spec2.{json,yaml} - OpenAPI 2.0 spec. We’re continuing to generate this for now, but it will be deprecated in favor of spec3. fixtures3.{json,yaml} - Test fixtures for resources in spec3. See below for more information. fixtures2.{json,yaml} - Test fixtures for resources in spec2. It is pretty exciting to see them already embracing version 3.0. They even provide a listing of the OpenAPI vendor extensions they are using, which are specific to their API. I’ll be adding these to my OpenAPI toolbox when I have the time, adding to the number of vendor extensions I have indexed. Stripe provides another pretty solid example of an API provider taking ownership of their OpenAPI spec, publishing to Github for their consumers to put tow rok, but clearly they are also using as part of their own internal workflows as well. Every API provider should have a Github repository with an up to date OpenAPI like Stripe does. I know many API architects envision a hypermedia API discovery landscape, where APIs are defined and discoverable by default, but I think an OpenAPI on Github is the best we can hope for at this stage in the evolution of the space. With the momentum I’m seeing in the number API providers publishing their OpenAPIs to Github, I’m feeling like Github is going to become the continuous...[<a href="/2017/11/12/stripes-openapi-is-available-on-github-in-version-3-0/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/12/locking-up-any-open-data-taxonomy-is-short-sighted-in-todays-online/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/open-referral/211tax.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/12/locking-up-any-open-data-taxonomy-is-short-sighted-in-todays-online/">Locking Up Any Open Data Taxonomy Is Short Sighted In Todays Online</a></h3>
			<p><em>12 Nov 2017</em></p>
			<p>I published a taxonomy API as part of my Human Services Data API (HSDA) work recently, and as part of the work I wanted it to support a handful of the human services taxonomies available currently. The most supported taxonomy available out there is the AIRS/211 LA County Taxonomy. It is a taxonomy in use by 211 of LA County, as well as owned and licensed by them. From what I gather, it is the most common format in use, and you can find licensing pages for it from other municipal 211 providers. Before you can download a copy of the taxonomy you have to agree to the license I’ve posted at the bottom of this post, something I was unwilling to do. Taxonomies shouldn’t be locked up this way. Let alone taxonomies for use in open data, helping citizens at the municipal level. I understand that 211 LA will argue that they’ve put a bunch of work into the schema, and therefore they want to protect what they view their intellectual property, but in 2017 this is wrong. This isn’t the way things should be done, sorry. The AIRS taxonomy should be openly available, and reusable in a machine readable format, and evolved by an open governance process. There is no reason for this valuable taxonomy, that has the potential to make our cities better, should be locked up like this–it needs to be widely used, and adopted without any legal friction along the way. I understand that it takes work, and resources to keep a taxonomy meaningful, and usable, but we should not stand in the way of people finding human services, and restricting 211 providers from using the same vocabulary. There are other was to generate revenue, and evolve forward a taxonomy in an online, collaborative environment, much like we are currently doing with open source software. This kind of stuff drives me nuts, and the licensing around this important technology is...[<a href="/2017/11/12/locking-up-any-open-data-taxonomy-is-short-sighted-in-todays-online/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/10/you-can-lead-a-horse-to-water-but-you-cannot-make-them-drinkthe-api-edition/"><img src="http://kinlane-productions2.s3.amazonaws.com/algorotoscope/bluelake/clean_view/file-00_00_38_67.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/10/you-can-lead-a-horse-to-water-but-you-cannot-make-them-drinkthe-api-edition/">You Can Lead A Horse To Water But You Cannot Make Them Drink--The API Edition</a></h3>
			<p><em>10 Nov 2017</em></p>
			<p>I have seven years of API research available at apievangelist.com. I regularly publish short form, and long form versions of this information on my blogs on a weekly basis. I publish prototypes, demo websites and portals, and develop API training curriculum for use across a wide variety of industries. I regularly take versions of my API research, and rework, rebrand, and dial in to speak to a specific company, organizations, institution, agency, or industry. In many cases I make this information freely available, helping make sure it is available to those who need it. Despite all this work, many folks who are already doing APIs refuse to read, listen, and learn from what is already going on in the API space, and doomed to repeat the mistakes many of us have already made and learned from in our API journeys. Many folks don’t really understand my motivations and think I have some sort of agenda to sell them something, disrupt their current reality, or other uninformed perspective. Ultimately, not trusting what I’m putting out there. I guess viewing that the water is poised in some way. Others don’t feel they need it, either because they feel like they have all the answers, or the problems haven’t become a reality in their worlds yet, so my solutions seem irrelevant. I find it tough to argue with someone about preventative care when it comes to their API operations, when they spend their days triaging bugs, problems, and legacy technology challenges. They are fire fighters, water isn’t for drinking! A long standing example of this can be found in the hypermedia realm. No matter how much some very smart people, with a wealth of experience deploying and managing APIs warn about challenges with maintaining API SDKs and clients, some folks will never see it as a problem until they actually face it themselves. I can showcase endless numbers of healthy practices extract from companies like AWS, Twitter, and...[<a href="/2017/11/10/you-can-lead-a-horse-to-water-but-you-cannot-make-them-drinkthe-api-edition/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/10/i-can-keep-evangelizing-the-same-api-stories-for-the-next-decade-in-government/"><img src="http://kinlane-productions2.s3.amazonaws.com/algorotoscope/builder/filtered/34_33_700_500_0_max_0_1_1.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/10/i-can-keep-evangelizing-the-same-api-stories-for-the-next-decade-in-government/">I Can Keep Evangelizing The Same API Stories For The Next Decade In Government</a></h3>
			<p><em>10 Nov 2017</em></p>
			<p>I spoke on a panel at the Red Hat, Fed Scoop Government Symposium in Washington D.C. yesterday. I had some great conversations with technology vendors, as well as government agencies about everything API. I enjoy being outside the Silicon Valley echo chamber when it comes to technology because I enjoy helping folks understand the basics of what is going on with the basics of APIs, over getting too excited over the latest wave of new technology, and a constant need to be moving forward before ever getting a handle on the problems on the table. It can be hard to to repeat some of the same stories I’ve been telling for the last seven years while in these circles, but honestly the process helps me refine what I’m saying, and continue to actively think through the sustained relevancy of the stories I’ve been telling. After this round of discussions in D.C. I feel there are a some themes in my work, I can keep refining, and crafting stories for sharing in the government space. Open - I know its a tired term, but learning to be more open with other agencies, partners, and the public is an essential component of doing APIs in the federal government. Documentation - Do not reinvent the wheel with documentation, and leverage OpenAPI to help you keep documentation usable, up to date, and valuable to developers using existing open source API documentation solution. Support - Provide email, office hours, Twitter, ticketing, Github issues, and other common support building blocks for API consumers, making sure people know they can get help when they need. Communication - Talk to your consumers. Have a blog, Twitter account, and other social channels for communicating internally, with partners, and publicly with API consumers. Experiment - See your APIs as an R&amp;D extension of an agency, and allow for experimentation with APIs, as well as the consumption of the APIs. Think about sandboxes, data virtualization, and...[<a href="/2017/11/10/i-can-keep-evangelizing-the-same-api-stories-for-the-next-decade-in-government/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/10/are-people-ready-for-an-online-apidriven-world-that-is-programmable/"><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories-new/van-gogh-starry-night-container-bridge-2.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/10/are-people-ready-for-an-online-apidriven-world-that-is-programmable/">Are People Ready For An Online API-Driven World That Is Programmable?</a></h3>
			<p><em>10 Nov 2017</em></p>
			<p>I am struggling with helping some folks get beyond their API being just readable, and helping them understand the potential of having POST, PUT, and other writable aspects to their resources, making things much more programmable. My client has a firm grasp on the ability to GET data from their API and publish on websites. They also have the concept that they can GET other data from other 3rd party APIs, and display on their website alongside their data. Where they are struggling is that they can also add new data to their API, and update existing data they are making available via their API, and ultimately their website as well. This hurdle isn’t limited to any single project I’m working on. I find a number of people who seem to have a decent grasp on APIs in general, struggling with or completely avoiding conversations around making the data writeable. They are able to make the transition from web to API when it comes to retrieving data, but making the same jump when it comes to adding and updating data is proving to be more difficult. I think there will always be a cognitive load with jumping from read to write, as you have to think more about security, data quality, and other common concerns. However, beyond that, I’m trying to explore what might be the challenges people are facing. Many of the folks I’m working with are a bit shaky on their grasp of APIs, and aren’t too confident in sharing what they don’t understand. As I do, I’ll put it out to the universe and ask my audience what they’ve seen. On the surface, I’d say that adding or updating data into a database online is tougher to wrap your head around without some context, and some of the affordances we enjoy in the browser. Adding a Tweet through mobile application or website? No problem. POST a tweet through API, is a little...[<a href="/2017/11/10/are-people-ready-for-an-online-apidriven-world-that-is-programmable/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/10/admitting-there-is-so-much-i-do-not-understand-makes-be-better-at-apis/"><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories/server-racks-clouds_copper_circuit.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/10/admitting-there-is-so-much-i-do-not-understand-makes-be-better-at-apis/">Admitting There Is So Much I Do Not Understand Makes Be Better At APIs</a></h3>
			<p><em>10 Nov 2017</em></p>
			<p>One of the reasons I’m so good at APIs is because I embrace how little I know. This rolling realization keeps my appetite wet when it comes to learning to things, and working hard to discover, and realize sensible API practices. I am comfortable with the fact that I do not know something. I enjoy coming up against things I do not understand, eager to learn more. However, I think there is one big difference in the way I approach technology from other developers, is that I’m not confident that I will ever be able to fully understand a particular domain, let alone think that technology, or specifically APIs are a solution to a specific set of problems within every domain. Many developers are overly confident in what they know. They are also overly confident in their ability to learn new things. They are also overly confident that they can hammer out a technological solution that will solve all problems within a domain. I feel like many technologists aren’t in the game to learn, they are in the game to prove they have the chops to solve problems, and when they can’t they just walk away. When you approach APIs in this way you are leaving a lot of opportunity for learning and growth on the table. APIs shouldn’t be seen as simply a solution. APIs are just a tool (like the web) in a business toolbox, that should be applied when appropriate, and not applied when it doesn’t make sense. Beyond developers, I feel like many business users are scared off by the uncertainty in the world of APIs. They don’t thrive in an environment where there are so many possibilities, configurations, and ways to do things right and wrong. APIs give you more control over your data, content, and algorithms, allowing you to provide access to them in many ways, and reach across many client channels like the web, mobile, and other device...[<a href="/2017/11/10/admitting-there-is-so-much-i-do-not-understand-makes-be-better-at-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/09/using-apis-to-manage-my-apis/"><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories/cargo-ship-on-sea_blue_circuit.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/09/using-apis-to-manage-my-apis/">Using APIs To Manage My APIs</a></h3>
			<p><em>09 Nov 2017</em></p>
			<p>I’m going further down the AWS rabbit hole lately with my APIs. Historically my APIs ran on an AWS EC2 instance with leveraged Linux for the OS, Apache for the web server, and Slim for the RESTful framework of my APIs–all with an RDS MySQL backend. I’ve now evolved the EC2 instance to be spread across numerous AWS Lambda scripts, tied together into various stacks of APIs using AWS API Gateway. At first, I was hesitant to go further down the AWS rabbit hole, but the security benefits of AWS-driven solutions, as well as the API-driven aspects of operating my APIs, is slowly shifting my view of how I need to be managing my APIs. AWS RDS, Lambda, and API Gateway all have APIs. I’ve been spending the week developing Lambda scripts that help me manage my APIs, using the AWS APIs behind these three services, leveraging them to setup, configure, deploy, manage, and test my APIs. I enjoy how APis push me to think about my digital resources, and when my digital resources are APIs, the benefts begin to feel like API inception. I’m increasingly having APIs that do one thing and do it well, when it comes to API operations, allowing me to distill down the building blocks of my API operations, into a very workable world of API functionality. I am now deploying, backing up, migrating, and working with the database behind my APIs using APIs. I primarily use AWS RDS MySQL instances behind my APIs, but when I’m using AWS DynamoDB, I leverage AWS APIs even more, as DynamoDB lets you do adds, updates, queries, and deletes using the API, elevating beyond SQL to manage the contents of each data store. Whether it is RDS or DynamoDB, I’m using APIs manage the operational side of each database behind the API, and I’m beginning to explore how to make my database more ephemeral, and scalable using AWS APIs, giving me more control...[<a href="/2017/11/09/using-apis-to-manage-my-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/09/the-open-web-application-security-project-owasp-and-api-security/"><img src="https://s3.amazonaws.com/kinlane-productions2/guides/security/open-web-application-security-project-owasp.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/09/the-open-web-application-security-project-owasp-and-api-security/">The Open Web Application Security Project (OWASP) And API Security</a></h3>
			<p><em>09 Nov 2017</em></p>
			<p>This is a story from my latest API Evangelist API security industry guide. My partner ElasticBeam has underwritten my API security research, allowing me to publish a formal PDF of my guide, providing business and technical users with a walk-through of the moving parts, tools, and companies doing interesting things with API security. When I publish each guide, I publish each story here on the blog, helping build awareness around my research–this is a short one on OWASP. The Open Web Application Security Project (OWASP) is a 501(c)(3) worldwide not-for-profit charitable organization focused on improving the security of software, with a mission to make software security visible, so that individuals and organizations are able to make informed decisions. OWASP is looking to provide impartial, practical information about application security (AppSec) to individuals, corporations, universities, government agencies and other organizations worldwide. Operating as a community of like-minded professionals, OWASP issues software tools and knowledge-based documentation on application security. As the web API space has expanded OWASP has expanded its focus to include the most common threats to APIs. OWASP has acknowledged the overlap between web applications, and web APIs, and quickly becoming a valuable source for API specific security knowledge, expanding beyond its web application roots. Providing one of the best resources to find security related information, and tooling you can apply throughout your API operations. OWASP doesn’t endorse commercial services, and is a member driven organization, so you will find all the information they provide to be vendor neutral, and focused on the task at hand. You will find me regularly anchoring my API security work in what the OWASP community is doing, as security should always be a team effort. API security isn’t my primary focus as API Evangelist, but helping guide you to where you can find the latest information is what this guide is about. OWASP is your source for unbiased API security information! You can download or purchase my API Evangelist...[<a href="/2017/11/09/the-open-web-application-security-project-owasp-and-api-security/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/09/the-impact-of-api-management-on-api-security/"><img src="https://s3.amazonaws.com/kinlane-productions2/guides/security/api-security-guide-api-management.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/09/the-impact-of-api-management-on-api-security/">The Impact Of API Management On API Security</a></h3>
			<p><em>09 Nov 2017</em></p>
			<p>This is a story from my latest API Evangelist API security industry guide. My partner ElasticBeam has underwritten my API security research, allowing me to publish a formal PDF of my guide, providing business and technical users with a walk-through of the moving parts, tools, and companies doing interesting things with API security. When I publish each guide, I publish each story here on the blog, helping build awareness around my research–this is a short one on API management. API management has done an amazing job in helping companies, organizations, institutions, and government agencies make their digital resources more available on-line in a secure way. Allowing API providers to require developers to sign up, obtain keys, and tokens which need to accompany all API calls. This, along with encryption by default has gone a long way towards making data, content, and algorithms more accessible, while also being secure. However, many API providers have stopped here, and think their resources are secure, when in reality there is so much more work to be done. Requiring all developers obtain keys to access resources, and encryption data in transit is an important part of API security, but it is just one tool in the API security toolbox. Out of API management you also receive an enhanced set of logging, analysis, and reporting tools for how developers are putting API resources to work. When done well, this pushes the API security conversation forward, allowing API providers to balance access with security, and be proactive when it comes to limiting access, or even shutting off access when their is abuse. The problem is not all API providers are investing here, let alone going beyond what API management providers offer. The awareness brought to the table my API management is valuable, but there are so many aspects of API operations at the web server, DNS, and other levels that are often left out of the API management conversation. I’ll be pushing...[<a href="/2017/11/09/the-impact-of-api-management-on-api-security/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/09/learning-to-play-nicely-with-others-using-apis/"><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories/dark-clouds-la-buildings.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/09/learning-to-play-nicely-with-others-using-apis/">Learning To Play Nicely With Others Using APIs</a></h3>
			<p><em>09 Nov 2017</em></p>
			<p>This is a topic I talk about often, write about rarely, but experience on a regular basis doing APIs. It has to do with encounters I have with people in companies who do not know how to share and play nicely with other companies and people, and want to do APIs. For a variety of reasons these folks approach me to learn more about APIs, but are completely unaware of what it takes, and how it involves working with external actors. Not all of these APIs are public, but many of them involve engaging with individuals outside the corporate firewall, possess a heavy focus on the technical, and business of doing APIs, but rarely ever consider the human and more political aspects of engagements with APIs. I find that people tend to have wildly unrealistic expectations of technology, and believe that APIs will magically connect them to some unlimited pool of developers, or seamlessly connect disparate organizations across vast distances. People come to me hoping I will be able to explain it all to them in a single conversation, or provide in a short white paper, which is a state of being that also makes individual very susceptible to vendor promises. People want to believe that APIs will fix the problems they have introduced into their operations via technology, and effortlessly connect them with outside revenue streams and partnerships, unencumbered by the same human challenges they face within their firewalls. Shortly after getting to know people it often becomes apparent that they possess a lot of baggage, legacy processes and beliefs, that they are often unaware of. Or, I guess more appropriately they are unaware that these legacy beliefs are not normal, and are something everybody faces. Where they are usually pretty uniquely dysfunctional to a specific organization. People usually have hints that these problems aren’t normal, but just aren’t equipped to operate outside their regular sphere of influence, and within days or weeks of...[<a href="/2017/11/09/learning-to-play-nicely-with-others-using-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/08/the-api-evangelist-api-security-industry-guide/"><img src="https://s3.amazonaws.com/kinlane-productions2/guides/security/api-evangelist-api-security-industry-guide-screenshot-2017-11-08.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/08/the-api-evangelist-api-security-industry-guide/">The API Evangelist API Security Industry Guide</a></h3>
			<p><em>08 Nov 2017</em></p>
			<p>This edition of my API security industry guide has been underwritten by ElasticBeam, who provides next generation API security, leveraging machine learning, and behavorial analysis that works with the existing web and API management solutions you already have in place across your API operations. I have been working on this resulting guide from my API security research for over a year now. Thanks to ElasticBeam I’ve finally gotten it out the door. As with all my industry guides, it is a work in progress, and something that will never be finished. I’ll keep taking what I’ve learned, and publishing in as a PDF every couple months, and receive the edits, and feedback from my readers and the wider community, then publish again. I’m feeling like I’m finally finding my groove again with these guides, and there is no better time to be back on game, especially when it comes to API security. Security is the number one concern of companies, organizations, institutions, and government agencies considering investing more resources into their API infrastructure, as well as companies who are ramping up their existing efforts. At the same time it is also the most deficient area when it comes to investment in API infrastructure by existing API providers. Many groups are rushing along their API journey, and deploying web, mobile, device, and other applications, but rarely stopping to properly secure things with each step along the way. In 2016 I began investing more into the topic of API security. I have been ramping up my research into how APIs were being secured, and how they weren’t being secured. I’ve been tracking on breaches, vulnerabilities, as well as the companies who are offering products and services that help API providers secure their APIs, as well as some of the open source tooling that is available. As I do with my approach to researching everything APIs, along the way I’m keeping notes on the common building blocks, and...[<a href="/2017/11/08/the-api-evangelist-api-security-industry-guide/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/08/i-appreciate-this-api-walk-through-from-fannie-mae-but-just-give-me-the-api/"><img src="https://s3.amazonaws.com/kinlane-productions2/fannie-mae/fannie-mae-d-messages-api.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/08/i-appreciate-this-api-walk-through-from-fannie-mae-but-just-give-me-the-api/">I Appreciate This API Walk Through From Fannie Mae But Just Give Me The API!</a></h3>
			<p><em>08 Nov 2017</em></p>
			<p>I came across the new Desktop Underwriter (DU) API from Fannie Mae which provides lenders a comprehensive credit risk assessment data that determines whether a loan meets Fannie Mae’s eligibility requirements. They have a slick new website for the project, with the tag line “building on certainty”, and a smooth HTML story to walk you through what the new DU API can do. While the API seems very exciting, and valuable, the whole production is missing one thing–the API! I am sure you have to be a partner to get access to the API, but you can tell the whole things is being led by people who have never actually used an API. Otherwise you would give us an API to actually use, and allow us to kick the tires. A hallmark of modern APIs is that you get to play with it. Marketing materials, and a sharp single page application website isn’t enough. We need the documentation, and be able to actually see what the request and response structure is, so that we can better understand the value being generated, and how we will be integrating with it. Without this, there isn’t any value. Of course, you don’t have to make the real API 100% public, you can always create API access tiers, and even deploy a sandboxed or virtualized version of the API and data for new users, protecting your valuable resources–just do not hide the API away from us, and make us consumers beg for access. When you hide your APIs, you leave first impressions like you did with me. Wouldn’t it be better if my first impression was all about writing a story on how cool your API was, and how all my readers should be using it? Instead, I’m using you as a case of how to not do APIs. There is no reason the Fannie Mae Desktop Underwriter (DU) API can’t be publicly available, allowing us analysts and developers...[<a href="/2017/11/08/i-appreciate-this-api-walk-through-from-fannie-mae-but-just-give-me-the-api/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/08/apis-and-other-ways-of-serving-up-machine-learning-models/"><img src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope/stories/crypto-machine-bletchley_copper_circuit.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/08/apis-and-other-ways-of-serving-up-machine-learning-models/">APIs And Other Ways Of Serving Up Machine Learning Models</a></h3>
			<p><em>08 Nov 2017</em></p>
			<p>As with most areas of the tech sector, behind the hype there are real world things going on, and machine learning is one area I’ve been studying, learning, and playing withd what is actually possible when it comes to APIs. I’ve been studying the approach across each of the major cloud platforms, including AWS, Azure, and Google t push forward my understanding of the ML landscape. Recently the Google Tensorflow team released an interesting overview of how they are serving up Tensorflow models, making machine learning accessible across a wide variety of use cases. Not all of these are API specific, but I do think they are should be considered equally as part of the wider machine learning (ML) application programming interface (API) delivery approach. Over the past year and half, with the help of our users and partners inside and outside of Google, TensorFlow Serving has advanced performance, best practices, and standards for ML delivery: Out-of-the-box Optimized Serving and Customizability - We now offer a pre-built canonical serving binary, optimized for modern CPUs with AVX, so developers don’t need to assemble their own binary from our libraries unless they have exotic needs. At the same time, we added a registry-based framework, allowing our libraries to be used for custom (or even non-TensorFlow) serving scenarios. Multi-model Serving - Going from one model to multiple concurrently-served models presents several performance obstacles. We serve multiple models smoothly by (1) loading in isolated thread pools to avoid incurring latency spikes on other models taking traffic; (2) accelerating initial loading of all models in parallel upon server start-up; (3) multi-model batch interleaving to multiplex hardware accelerators (GPUs/TPUs). Standardized Model Format - We added SavedModel to TensorFlow 1.0, giving the community a single standard model format that works across training and serving. Easy-to-use Inference APIs - We released easy-to-use APIs for common inference tasks (classification, regression) that we know work for a wide swathe of our applications. To support more...[<a href="/2017/11/08/apis-and-other-ways-of-serving-up-machine-learning-models/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/08/additional-call-pricing-info-are-the-pressure-relief-valves-for-api-plans/"><img src="https://s3.amazonaws.com/kinlane-productions2/bitscoop/bitscoop-pricing-plans-additional-calls.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/08/additional-call-pricing-info-are-the-pressure-relief-valves-for-api-plans/">Additional Call Pricing Info Are The Pressure Relief Valves For API Plans</a></h3>
			<p><em>08 Nov 2017</em></p>
			<p>I’ve complained about unfair API pricing tiers several times over the last couple years, even declaring API access tiers irrelevant in a mult-API consumer world. Every time I write about this subject I get friends who push back on me that this is a requirement for them to generate revenue as a struggling startup. With no acknowledgement that their API consumers might also be struggling startups trying to scale consumption within these plans, only to reach a rung in the ladder they might not be able to actually reach. My goal in this storytelling isn’t to condemn API providers, but make them aware of what things look like from the other side, and that their argument essentially pulls up the ladder after they’ve gotten theirs–leaving the rest of us at the bottom. My complaint isn’t with startups crafting pricing tiers, and trying to make their revenue projects more predictable. My complaint is when the plans are priced too far apart and I can’t afford to move from one plan to the next. More importantly, my complaint is when the tier I can’t moved from is rate limited with a cap on usage, and I can’t burst beyond my plans limits without scaling to the next access tier which I cannot afford to reach. I understand putting hard caps on public or free tier plans, but when you are squarely in a paid access tier, you shouldn’t be shut down when you reach the ceiling. Sure, I might pay a premium for each additional call, but I shouldn’t be shut down and forced to move to the next higher access tier–which might be out of my monthly price range. I just can’t go from $49.95 to $499.95 in monthly payments as a small business, sorry. The key element that needs to be present for me, even in situations where I cannot afford to jump to the next tier, is the ability to go beyond my plans...[<a href="/2017/11/08/additional-call-pricing-info-are-the-pressure-relief-valves-for-api-plans/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/07/when-we-are-told-that-api-security-investments-will-affect-profitability/"><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories/castle_walls_cannon_satan_red.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/07/when-we-are-told-that-api-security-investments-will-affect-profitability/">When We Are Told That API Security Investments Will Affect Profitability</a></h3>
			<p><em>07 Nov 2017</em></p>
			<p>I was listening to Mark Zuckerberg talk about how security investments will affect the platforms profitability on the Facebook earnings call this last week. This line of thinking sounds pretty consistent with what I’m hearing from other folks when it comes to why they haven’t been investing more into their API security. My challenge for this line of thought is about shutting down proactive security investments, and does not speak of responsive security investments–meaning after you’ve had a breach, or when there is other security investment. From a leadership perspective this view of security just doesn’t do it for me, and I’d push back, and require it consider what profitability will look like if we do not invest properly in security. Viewing security in this way is common. It is also a short-sighted view of security, in the name of profits today, over health of a platform down the road. It demonstrates that leadership is more focused on profits, than whatever the platform focus actually doing. I would add that I think this line of thinking reflects a perspective of leadership that is out of sync with the technical details of operating a platform, and the current threat landscape. I get that a company has to be profitable, and that it is the job of the CEO is to represent the investors, but after Equifax, and the many other breaches, as well as what I’m seeing on the ground at companies I’m talking to, it is pretty clear that things are out of whack when it comes to overall security investment. I work with a lot of folks who want to invest in API security more, but they just don’t have the resources. I’ve been in leadership roles where I’ve had my hands tied when it came to decisions around infrastructure to deliver on PCI, and other compliance, as well as being able to hire security focused talent. This type of thought regarding security practices...[<a href="/2017/11/07/when-we-are-told-that-api-security-investments-will-affect-profitability/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/07/postman-as-a-live-coding-environment-in-presentations-at-apistrat/"><img src="https://s3.amazonaws.com/kinlane-productions2/postman/postman-working-screenshot.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/07/postman-as-a-live-coding-environment-in-presentations-at-apistrat/">Postman As A Live Coding Environment In Presentations At APIStrat</a></h3>
			<p><em>07 Nov 2017</em></p>
			<p>We just wrapped up the 8th edition of APIStrat in Portland, Oregon this last week. I’ll be working through my notes, and memory of the event in future posts, but thing that stood out for me was the presence of Postman at the event. No, I’m not talking about their booth, and army of evangelists and company reps on site–although this was the first time I’ve seen them out in such force. I’m talking about the usage of the API development environment by presenters, as a live coding environment in their talks, replacing the command line and browser for how you demonstrate the magic of APIs to your audience. On the first day of the conference I attended two separate workshops where Postman was the anchor for the talk. As they worked their way through their slides they kept switching back to the Postman application to show some sort of real results, from an actual, or mocked API. It is the new live coding environment for API evangelist, architects, designers, developers, and security folks. It is the quickest way to go from API concept, to demonstrating API solutions in any presentation. What I also really like is that it transcends any single programming language. In the past, I’ve always hated when someone would bust out some .NET code to show an API call, or something very language or platform specific. Postman reflects a more API way of doing things, that is elevated above the dogma of any single programming language community. I am beginning to use Postman and Restlet client in my API training and curriculum more. Directing my users to actually try something out in the API client before moving on to the next step. It is kind of becoming the new interactive API documentation, but something that is linkable from any story, training materials, or incorporated directly into a live talk. As an evangelist it is yet another reason to maintain OpenAPI definitions...[<a href="/2017/11/07/postman-as-a-live-coding-environment-in-presentations-at-apistrat/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/07/hiding-apis-in-plain-sight/"><img src="http://kinlane-productions2.s3.amazonaws.com/algorotoscope/methuselah/clean_view/file-00_00_20_99.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/07/hiding-apis-in-plain-sight/">Hiding APIs In Plain Sight</a></h3>
			<p><em>07 Nov 2017</em></p>
			<p>I’m always surprised by how secretive folks are. I know that it is hard for many folks to be as transparent as I am with my work, but if you are doing public APIs, I have a basic level of expectation that you are going to be willing to talk and share stories publicly. I regularly have conversations with enterprise folks who are unwilling to talk about what they are doing on the record, or allow me to share stories about their PUBLIC API EFFORTS!!! I get the super secret internal stuff. I’ve worked for the government. I don’t have a problem keeping things private when they should be, but the secretive nature of companies around public API efforts continues to keep me shaking my head. People within enterprise groups almost seem paranoid when it comes to people keeping an eye on what they are up to. I don’t doubt their competitors keep an eye on what they are doing, but thinking that people are watching every move, everything that is published, and will be able to understand what is going on, and be able to connect the dots is borderline schizophrenic. I publish almost everything I do public by default on Github repositories, and my readers, clients, and other folks still have trouble finding what I am doing. You can Google API Evangelist + any API topic and find what I’m working on each day, or you can use the Github search to look across my repositories, and I still have an inbox and social messaging full of requests for information. My public by default stance has done amazing things for my search engine and social media presence. I don’t even have to optimize things, and I come up for almost every search. I get regular waves of connections from folks on topics ranging from student art to the government, because of my work. The schema, API definitions, documentation, tests, and stories for any...[<a href="/2017/11/07/hiding-apis-in-plain-sight/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/07/developing-a-talent-pool-within-your-api-community/"><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories/art-museum/art-museum_blue_circuit_3.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/07/developing-a-talent-pool-within-your-api-community/">Developing A Talent Pool Within Your API Community</a></h3>
			<p><em>07 Nov 2017</em></p>
			<p>There are many reasons for having an API. The direct reason is to provide your partners and 3rd party developers access to your data, content, and algorithmic resources using the web. However, there are many indirect, and less obvious reasons for having an active API program at your company, organization, institution, or government agency. Things that you probably haven’t thought of, but the groups who are already doing APIs have known about these benefits for a while. One of these benefits is in the area of talent acquisition, and building relationships with, and identifying folks with the skills you are looking for. I remember the first time I heard the executives at Paypal say that they often hire out of their development community. After hearing that I began asking more API providers about the talent acquisition opportunities within their API developer ecosystem, and about 50% of the people I talked said they had hired someone building an application on their API, or had shown up to a hackathon to participate and build interesting things. It is easy to think of our API platforms as simply a place for developing applications, but along with each integration and application, there is one or many humans behind it, who have an understanding of your API, and possibly the industry you are targeting. Once you are introduced to the concept, it makes complete sense to be using an API as a talent acquisition vehicle, allowing developers to flex their skills in a place you are already paying attention in. This is my new response to people who are either looking for talent. Have you tried your API community? Many of the people I’ve tested this out on do not have a public API program. They aren’t at this place in their journey where they have a public presence in this way. Either because they don’t have any public resources to make available, or they just haven’t evolved to the...[<a href="/2017/11/07/developing-a-talent-pool-within-your-api-community/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/06/api-security-beginning-to-outweigh-my-vendor-lockin-concerns/"><img src="https://s3.amazonaws.com/kinlane-productions2/amazon/iam/aws-iam-api-gateway.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/06/api-security-beginning-to-outweigh-my-vendor-lockin-concerns/">API Security Beginning To Outweigh My Vendor Lock-In Concerns</a></h3>
			<p><em>06 Nov 2017</em></p>
			<p>I’ve been on the AWS train since day one. I’ve been integrating Amazon S3 and EC2 into my business(es) since they first launched a decade ago. While the platform has faithfully provided my storage and compute for over a decade I’ve always been wary of vendor lock-in. After a decade long ride on Microsoft (1998-2008), I felt pretty burned. Then recently after a similar decade long ride on Google (2005-2015), I felt burned, but in a different way. After a decade on AWS I’m nervous, but I don’t feel as burned, however I’d say there is one aspect of doing business online that is making me put aside some of my concerns regarding vendor lock-in on AWS, and even on Google, and Azure–SECURITY. I’m just not convinced I can do this alone, and I need the help of the platforms I operate on to help make sure my operations are secure. I spent the weekend setting up a set of APIs using AWS RDS as the backend database, AWS Lambda as the code layer, and AWS API Gateway as the API front-end. As part of this work I established an identity and access management (IAM) role with policies tailored for brokering the exchanges between RDS, Lambda, and the API Gateway. I’m leaning on AWS for two key API security pieces here: 1) API key management with AWS API Gateway, and 2) backend security using AWS IAM. The key management stuff is pretty straightforward and something I can easily replicate, but the AWS IAM stuff is a little more involved, and I’m grateful for how easy AWS IAM makes it for me to setup roles, cherry pick from common policies, and lock down the infrastructure I a using to drive the backend of my APIs and other applications. As I moved another API project into the home stretch this weekend, I migrated an RDS, and EC2 instance into a separate account for a client. I had...[<a href="/2017/11/06/api-security-beginning-to-outweigh-my-vendor-lockin-concerns/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/06/an-example-of-how-every-api-provider-should-be-using-openapi-out-of-the-slack/"><img src="https://s3.amazonaws.com/kinlane-productions2/slack/slack-standard-practice.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/06/an-example-of-how-every-api-provider-should-be-using-openapi-out-of-the-slack/">An Example Of How Every API Provider Should Be Using OpenAPI Out Of The Slack</a></h3>
			<p><em>06 Nov 2017</em></p>
			<p>The Slack team has published the most robust and honest story about using OpenAPI, providing a blueprint that other API providers should be following. What I like most about approach by Slack to develop, publish, and share their OpenAPI, is the honesty behind why their are doing it to help standardize around a single definition. They publish and share the OpenAPI to Github, which other API providers are doing, and I think should be standard operating procedure for all API providers, but they also go into the realities regarding the messy history of their API documentation–an honesty that I feel ALL API providers should be embracing. My favorite part of the story from Slack is the opening paragraph that honestly portrays how they’ve got here: “The Slack Web API’s catalog of methods and operations now numbers nearly 150 reads, writes, rights, and wrongs. Its earliest documentation, much still preserved on api.slack.com today, often originated as hastily written notes left from one Slack engineer to another, in a kind of institutional shorthand. Still, it was enough to get by for a small team and a growing number of engaged developers.” Even though we all wish we could do APIs correctly, and supporting API document perfectly from day one, this is never the reality of API operations, and something OpenAPI will not be a silver bullet for fixing all of this, but can go a long way in helping standardize what is going on across teams, and within an API community. Slack focuses on SDK development, Postman client usage, alternative forms of documentation, and mock servers as the primary reasons for publishing the OpenAPI for their API. They also share some of the back story regarding how they crafted the spec, and their decision making process behind why they chose OpenAPI over other specifications. They also share a bit of their road map regarding the API definition, and that they will be adopting v3.0 of OpenAPI v3.0,...[<a href="/2017/11/06/an-example-of-how-every-api-provider-should-be-using-openapi-out-of-the-slack/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/11/06/a-simple-api-using-aws-rds-lambda-and-api-gateway/"><img src="https://s3.amazonaws.com/kinlane-productions2/amazon/api-gateway/aws-rds-lambda-api-gateway.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/11/06/a-simple-api-using-aws-rds-lambda-and-api-gateway/">A Simple API Using AWS RDS, Lambda, and API Gateway</a></h3>
			<p><em>06 Nov 2017</em></p>
			<p>I wrote about a simple API with AWS DynamoDB, Lambda, and API Gateway last week. I like this approach because of the simple nature of AWS DynamoDB. One benefit of going this route is that you can even bypass Lambda, as the AWS API Gateway can work directly with AWS DynamoDB API. I’m just playing around with different configurations and pushing forward my understanding of what is possible, and this week I switched out the database in this with AWS RDS, which opens up the ability to use MySQL or Postgres as the backend for any API. For this example, I’m using a simple items database, which you can build with this SQL script after you fire up an RDS instance (I’m using MySQL): Next I wanted to have the basic CRUD operations for my API. I opted to use Node.js running in Lambda for the code layer of this API, starting with the ability to get all records from the database: After that I want to be able to insert new records: Then of course be able to get a single record: Then be able to update a single record: And of course I want to be able to delete records: Now that I have the business logic setup in AWS Lambda for reading, and writing data to my relational database I want an API front-end for this backend setup. I am using AWS API Gateway as the API layer, and to setup I’m just importing an OpenAPI definition to jumpstart things: This gives me the skeleton framework for my API, with the paths and methods I need to accomplish the basics of reading and writing data. Now, I just need to wire up each API method to its accompanying Lambda function, something API Gateway makes easy. Now I have an API for my basic backend. There is one thing you have to do to make each method work properly with the Lambda function....[<a href="/2017/11/06/a-simple-api-using-aws-rds-lambda-and-api-gateway/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/10/26/my-response-on-the-department-of-veterans-affairs-va-rfi-for-the-lighthouse/"><img src="https://s3.amazonaws.com/kinlane-productions2/veterans-affairs/va-logo.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/10/26/my-response-on-the-department-of-veterans-affairs-va-rfi-for-the-lighthouse/">My Response On The Department Of Veterans Affairs (VA) RFI For The Lighthouse</a></h3>
			<p><em>26 Oct 2017</em></p>
			<p>I am working with my partners in the government API space (Skylight, 540, Agile Six) to respond to a request for information (RFI) out of the Department of Veterans Affairs (VA), for what they call the Lighthouse API Management platform. The RFI provides a pretty interesting look into the way the government agency which supports our vets is thinking about how they should be delivering government resource using APIs, but also how they play a role in the wider healthcare ecosystem. My team is meeting today to finalize our response to the RFI, and in preparation I wanted to prepare my thoughts, and in my style of doing things, involves publishing them here on API Evangelist. You can read the whole RFI, but I’ll provide the heart of it, to help set the table for my response. Introduction: To accelerate better and more responsive service to the Veteran, the Department of Veterans Affairs (VA) is making a deliberate shift towards becoming an Application Programming Interface (API) driven digital enterprise. A cornerstone of this effort is the setup of a strategic Open API Program that is adopting an outside-in, value-to-business driven approach to create APIs that are managed as products to be consumed by developers within and outside of VA. Objectives: VA has started the process of establishing an API Management Platform, named Lighthouse. The purpose of Lighthouse is to establish the Next Generation Open Digital Platform for Veterans, accelerating the transformation in core domains of VA, such as Health, Benefits, Burial and Memorials. This platform will be a system for designing, developing, publishing, operating, monitoring, analyzing, iterating and optimizing VA’s API ecosystem. These APIs will allow VA to leverage its investment in various digital assets, support application rationalization, and allow it to decouple outdated systems and replace them with new, commercial, off the shelf, Software as a Service (SaaS) solutions. It will enable creation of new, high value experiences for our Veterans, VA’s provider partners,...[<a href="/2017/10/26/my-response-on-the-department-of-veterans-affairs-va-rfi-for-the-lighthouse/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/10/25/we-are-all-using-apis/"><img src="https://s3.amazonaws.com/kinlane-productions2/api-evangelist-logos/apis-are-all-around-us.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/10/25/we-are-all-using-apis/">We Are All Using APIs</a></h3>
			<p><em>25 Oct 2017</em></p>
			<p>When I talk to ordinary people about what I do as the API Evangelist, they tend to think APIs don’t have much of anything to do with their world. APIs exist in a realm of startups, technology, and make believe that doesn’t have much to do with their ordinary lives. When trying to make the connection with folks on airplanes, in the hotel lobby, and at the coffee shop, I always resort to the most common API-driven thing in all of our lives–the smart phone. Pulling out my iPhone is the quickest way I can go from zero to API understanding, with almost anyone. When people ask what an API is, or how it has anything to do with them, I always pull out my iPhone, and say that all of the applications on the home page of your mobile phone use APIs to communicate. When you post something to your Facebook wall, you are using the Facebook API. When you publish an image to Instagram, you are using the Instagram API. When you check the balance on your bank account, you are using your banks API. APIs are everywhere. We are all using APIs. We are all impacted by good APIs, and bad APIs. Most of the time we just don’t know it, and are completely unaware of what is going on behind the curtain that is our smart phones. I started paying attention to APIs in 2010 when I saw the impact mobile phones were beginning to have in our lives, and the role APIs were playing behind this new technological curtain. In 2017, I’m watching APIs expand to our homes via our thermostats, and other appliances. I’m seeing APIs in our cars. Applied to security cameras, sensors, signage, and other common objects throughout public spaces. APIs aren’t something everyone should be doing, however I feel they are something that everyone should be aware of. I usually compare it to the financial and...[<a href="/2017/10/25/we-are-all-using-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/10/25/i-am-talking-about-jekyll-as-a-hypermedia-client-at-apistrat-in-portland-or/"><img src="https://s3.amazonaws.com/kinlane-productions2/jekyll/jekyll-logo.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/10/25/i-am-talking-about-jekyll-as-a-hypermedia-client-at-apistrat-in-portland-or/">I Am Talking About Jekyll As A Hypermedia Client At APIStrat in Portland OR</a></h3>
			<p><em>25 Oct 2017</em></p>
			<p>Static website, and headless CMS approaches to providing API driven solutions have grown in popularity in recent years. Jekyll has been leading the charge when it comes to static website deployment, partly due to Github being behind the project, and their adoption for Github Pages. I’ve been pushing forward a new approach to using Jekyll as a hypermedia client to help deliver some of my API training and curriculum, and as part of this work I’m giving a talk at APISTrat next week on the concept. APIStrat is a great forum for this kind of project, helping me think through things in the form of a talk, the opportunity to share with an audience, and get immediate feedback on its viability, which I can then use to push forward my thinking on this aspect of my API work. If you aren’t familiar with Jekyll, I recommend spending some time reading about it, and even implementing a simple site using Github Pages. I have multiple non-developers in my life who I’ve introduced to Jekyll, and it has made a significant impact on the way they do their work. Even if you do know about Jekyll, additionally I recommend spending time learning more about the underscore data folder, and the concept of Jekyll collections. Every Jekyll site has its default data collection, and the opportunity to create any additional collection, using any name you desire. Within these folders you can publish static CSV, JSON, and YAML data files, using any schema you desire. All of these data collections then become available for referencing through the static Jekyll website or application. All of this functionality is native Jekyll. Nothing revelatory from me. What I’m looking to push things forward around is what happens when the data collections are using a hypermedia media type. I’m using Siren, which allows me to publish structured data collections, complete with links that define a specific experience across the data and content stored...[<a href="/2017/10/25/i-am-talking-about-jekyll-as-a-hypermedia-client-at-apistrat-in-portland-or/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/10/25/helping-business-users-get-over-perceived-technical-gaps-when-it-comes-to-api/"><img src="https://s3.amazonaws.com/kinlane-productions2/photos/cactus-flower.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/10/25/helping-business-users-get-over-perceived-technical-gaps-when-it-comes-to-api/">Helping Business Users Get Over Perceived Technical Gaps When It Comes To API</a></h3>
			<p><em>25 Oct 2017</em></p>
			<p>Every single API project I’m working on currently has one or more business users involved, or specifically leading the work. With every business user, no matter how fearless they are, there is always a pretty heavy perception that some things are over their head. I see this over and over when it comes to API design, and the usage of OpenAPI to define an API. I’ve known a handful of folks who aren’t programmers, and have learned OpenAPI fluently, but for the most part, all business users tend to put up a barrier when it comes to learning OpenAPI–it lives in the realm of code, and exists beyond what they are capable of. I get that folks are turned off by being exposed to code. Learning to read code takes a significant amount of time, and with the more framework, libraries, and other layers, you can find yourself pretty lost, pretty quickly. However, with OpenAPI, everything I do tends to be YAML, making it much more readable to humans. While there are rules and structure to things, I don’t feel it is out of the realm of the average user to study, learn, and eventually bring into focus. Along with the OpenAPI rules, there are a good deal of HTTP literacy required to fully understand what is going on, but I feel like the API design process is a much more forgiving environment to learn these things for both developers and business users. I put the ownership of everything technical being complicated squarely on the shoulders of IT and developer folks. We’ve gone out of our way to make this stuff difficult to access, and out of reach of the average person. We’ve spent decades keeping people we didn’t see fit from having a seat at the table. However, increasingly I also feel like there is a significant amount of ownership to be given to business users who are willing to put up walls when...[<a href="/2017/10/25/helping-business-users-get-over-perceived-technical-gaps-when-it-comes-to-api/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/10/25/a-suite-of-human-services-api-definitions-using-openapi/"><img src="http://org.open.referral.adopta.agency/images/openreferral-expanded.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/10/25/a-suite-of-human-services-api-definitions-using-openapi/">A Suite Of Human Services API Definitions Using OpenAPI</a></h3>
			<p><em>25 Oct 2017</em></p>
			<p>I’m needing to quantify some of the work that has occurred around my Human Services Data Specification work as part of a grant we received from Stanford. The grant shas helped us push forward almost three separate revisions of the API definition for working with human services data, and one of the things I’m needing to do is quantify the work that has occurred specifically around the OpenAPI definitions. At this point the specification is pretty verbose, and is now spanning multiple documents, making it difficult to quantify and share within an executive summary. To help support I wanted to craft some language that could help introduce the value that has been created to a non-technical audience. The Human Services Data Specification (HSDS) provides the common schema for accessing, storing, and sharing of human data, providing a machine readable definition that human service practitioners can follow in their implementations. The Human Services Data API (HSDA) takes this schema, and provides an API definition for accessing, as well as adding, updating, and deleting data using a web API. While there are a growing number of code projects emerging that support HSDS/A, the center of the project is a set of OpenAPI definitions that outline the finer details of working with human services data via a web API. With the assistance of the grant from Stanford, Open Referral was able to move forward the HSDA specification from version 1.0, to 1.1, 1.2, and now we are looking at delivering version 1.3 of the specification before end of 2017. The core OpenAPI definition for HSDA provides guidance for the design of human services APIs, with a focus on the core set of resources needed to operate a human services project. There are the handle of core resources defined as part of what is called HSDA core: Organizations (OpenAPI Definition) - Providing a framework for adding, updating, reading, and deleting organizational data. Describing the paths, parameters, and HSDS schema...[<a href="/2017/10/25/a-suite-of-human-services-api-definitions-using-openapi/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/10/24/your-api-road-map-helps-others-tell-stories-about-your-api/"><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories/los-angeles-downtow-freeway_blue_circuit_5.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/10/24/your-api-road-map-helps-others-tell-stories-about-your-api/">Your API Road Map Helps Others Tell Stories About Your API</a></h3>
			<p><em>24 Oct 2017</em></p>
			<p>There are many reasons you want to have a road map for your API. It helps you communicate with your API community where you are going with your API. It also helps you have a plan in place for the future, which increases the chances you will be moving things forward in a predictable and stable way. When I’m reviewing and API I don’t see a public API road map available, I tend to give them a ding on the reliability and communication for their operations. One of the reasons we do APIs is to help us focus externally with our digital resources, which communication plays an important role, and when API providers aren’t communicating effectively with their community, there are almost always other issues right behind the scenes. A road map for your API helps you plan, and think through how and what you will be releasing for the foreseeable future. Communicating this plan externally helps force you think about your road map in context of your consumers. Having a road map, and successfully communicating about it via a blog, on Twitter, and other channels helps keep your API consumers in tune with what you doing. In my opinion, an API road map is an essential building block for all API providers, because it has direct value on the health of API operations, but because it also provides an external sign of the overall health of a platform. Beyond the direct value of having an API road map, there are other reasons for having one that will go beyond just your developer community. In a story in Search Engine Land about Google Posts, the author directly references the road map as part of their storytelling. “In version 4.0 of the API, Google noted that “you can now create Posts on Google directly through the API.” The changelog include a bunch of other features, but the Google Posts is the most notable.” Adding another significant...[<a href="/2017/10/24/your-api-road-map-helps-others-tell-stories-about-your-api/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/10/24/the-api-portal-outline-for-a-project-i-am-working-on/"><img src="https://s3.amazonaws.com/kinlane-productions2/portal/api-portal-forkable.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/10/24/the-api-portal-outline-for-a-project-i-am-working-on/">The API Portal Outline For A Project I Am Working On</a></h3>
			<p><em>24 Oct 2017</em></p>
			<p>I am working through a project for a client, helping them deliver a portal for their API. As I do with any of my recommendations with my clients, I take my existing API research, and refine it to help craft a strategy to meets their specific needs. Each time I do this it gives me a chance to rethink some of my recommendations I’ve already gathered, as well as learn from new types of projects. I’ve taken the building blocks from my API portal, as well as my API management research, and have taken a crack at organizing them into an outline that I can use to guide my current project. Here is a walk through of the outline I’m recommending as part of a basic API portal implementation, to support a simple public API: Overview - / - Everything starts with a landing page, with a simple overview of what an API does. Then you need some basics to help make on-boarding as frictionless as possible, providing everything an API consumer needs to get going: Getting Started - /getting-started/ - Handful of steps with exactly what is needed to get started. Authentication - /authentication/ - An overview of what type of authentication is used. Documentation - /documentation/ - Documentation for the APIs that are available. FAQ - /faq/ - Answer the most common questions. Code - /code/ - Provide code samples, libraries, and SDKs to get going. Then get API consumers signed up, or able to login and get at their API keys as quickly as you possibly can: Sign Up - /developer/ - Provide a simple sign up for a developer account. Login - /developer/ - Allow users to quickly log back in after they have account. Next, provide a wealth of communication and support mechanisms, helping make sure developers are aware of what is going on: Blog - /blog/ - A simple blog dedicated to sharing stories about the API. Support -...[<a href="/2017/10/24/the-api-portal-outline-for-a-project-i-am-working-on/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/10/24/some-new-api-evangelist-art/"><img src="https://s3.amazonaws.com/kinlane-productions2/api-evangelist-logos/api-evangelist-butterfly-vertical.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/10/24/some-new-api-evangelist-art/">Some New API Evangelist Art</a></h3>
			<p><em>24 Oct 2017</em></p>
			<p>When I first started API Evangelist I spent two days trying to create a logo. I then spent another couple days trying to find a service to create something. Unhappy with everything I produced, I resorted to what I considered a temporary logo, where I just typed a JSON representation of the logo, mimicking what a JSON response for calling a logo through an API might look like. Seven years later, the logo has stuck, resulting in me never actually invested any more energy into my logo. The API Evangelist imagery is long overdue for an overhaul. I stopped wearing the logo on my signature black t-shirts a couple years back, and I do not want to reach the 10 year mark before I actually do anything new. My logo, and the other artwork I’ve accumulated over the last several years played their role, but I’m stoked to finally begin the process of evolving some artwork for API Evangelist. To help me move the needle I’ve began working with my friend Bryan Mathers (@BryanMMathers), where I have experienced his Visual Thinkery induced journey, where he generates image ideas by engaging in a series of conversations. Producing some whimsical, colorful, and entertaining images for anything he can imagine out of our discussions. It is something I’ve experienced as part of our parent company Contrafabulists, and stoked to experience as part of my API Evangelist work. Bryan doodled the butterfly image while we were talking, and didn’t anticipate it would be the one I’d choose to be the logo. Honestly, at first I didn’t think it was logo quality, but after spending time looking and thinking about, I feel it suits what I’m doing very well. It still has the technical elements in the brackets in the wing outline, and the digital or pixel nature of the color in the wings, but is moving beyond the tech and represents the natural, more human side of things I...[<a href="/2017/10/24/some-new-api-evangelist-art/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/10/24/aws-api-gateway-export-in-openapi-and-postman-formats/"><img src="https://s3.amazonaws.com/kinlane-productions2/amazon/aws-api-gateway-export.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/10/24/aws-api-gateway-export-in-openapi-and-postman-formats/">AWS API Gateway Export In OpenAPI and Postman Formats</a></h3>
			<p><em>24 Oct 2017</em></p>
			<p>I wrote about being able to import an OpenAPI into the AWS API Gateway to jumpstart your API the other day. OpenAPI definitions are increasingly used for every stop along the API life cycle, and being able to import an OpenAPI to start a new API, or update an existing in your API gateway is a pretty important feature for streamlining API operations. OpenAPI is great for defining the surface area of deploying and managing your API, as well as potentially generate client SDKs, and interactive API documentation for your API developer portal. Another important aspect of this API lifecycle is being able to get your definitions out in a machine readable format as well. All service providers should be making API definitions a two-way street, just like Amazon does with the AWS API Gateway. Using the AWS Console you can export an OpenAPI definition for any API. What makes things interesting is you can also export an OpenAPI complete with all the OpenAPI extensions they use to customize each API within the API Gateway. Also, they provide an export to OpenAPI, but with Postman specific extensions, allowing you to use use in the desktop client tooling when developing as well as integrating with any API. I’ve said it before, and I’ll say it again. Every API service provider should allow for the importing and exporting of common API definition formats like OpenAPI and Postman. If you are selling services and tooling to API designers, developers, architects, and providers, you should ALWAYS provide a way for them to generate a static definition of what is going on–bonus, if you allow them to publish API definitions to Github. I know some API service providers like to allow for API import, but worry about customers abandoning their service if there is an export. Too bad, offer better services, and affordable pricing models, and people will stick around. Beyond selling services to folks with day jobs, having the...[<a href="/2017/10/24/aws-api-gateway-export-in-openapi-and-postman-formats/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/10/23/budget-api-management-using-github/"><img src="https://s3.amazonaws.com/kinlane-productions2/github/github-oauth-api-management.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/10/23/budget-api-management-using-github/">Budget API Management Using Github</a></h3>
			<p><em>23 Oct 2017</em></p>
			<p>I am always looking for the cheapest, easiest ways to get things done in the world of APIs. As a small business owner I’m always on the hunt for hacks to get done what I need, and hopefully make things easier for my users, while keeping things free, or at least minimally priced for my business. When it comes to my simplest of APIs, where I’m not looking to fully manage, but I do want anyone using them to authenticate, and pass in API keys, so that I can track on their use. In some cases I’m going to bill against this usage, but for the most part I just want to secure, and quantify their consumption. The quickest and dirtiest way I will enable authentication for any API is using Github. First thing you do is create a Github OAuth application, which is available under settings for your Github user or organization. Then I add a JavaScript icon and login link, and then paste a PHP script at another location, where it will be handling the login. All you have to do is update the URLs in both scripts, and when someone clicks on icon, they’ll be authenticated and then dropped back on the original page with username, and valid OAuth token–which then at this point you have a validated user, and valid token. In some situations I just require that the appid and appkey be passed in with each API call. I do not rate limit, or bill against usage. I am just looking to identify consumers. Other projects I’m actively billing against consumption, but I’m doing this by processing the web server logs for the API. Again, bare bones operations. For the next level up, in the login PHP script I’m actually adding a user to a specific plan I’ve setup for an API using the AWS API Gateway, and adding their key to the gateway. Now a user has access to...[<a href="/2017/10/23/budget-api-management-using-github/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/10/23/apis-reduce-everything-to-a-transaction/"><img src="https://s3.amazonaws.com/kinlane-productions2/api-evangelist-logos/reduce+everything+to+a+transaction_tr.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/10/23/apis-reduce-everything-to-a-transaction/">APIs Reduce Everything To A Transaction</a></h3>
			<p><em>23 Oct 2017</em></p>
			<p>My partner in crime Audrey Watters crafted a phrase that I use regularly, that “APIs reduce everything to a transaction”. She first said it jokingly a few years back, but is something I regularly repeat, and think about regularly, as I feel it profoundly describes the world I study. I like the phrase because of its dual meaning to me. If I say it with a straight face, in different company, I will get different responses. Some will be positive, and others will be negative. Which I think represents the world of APIs in a way that show how APIs are neither good, bad, or neutral. If you are an API believer, when I describe how APIs reduce everything to a transaction, you probably see this as a positive. You are enabling something. You are distilling down aspects of our personal and business worlds down into a small enough representation, so that it can be transmitted via an API. Enabling payments, messages, likes, shares, and other aspects of our digital economy. Your work as an API believer is all about reducing things down to a transaction, so that you can make people’s lives better, and enable some kind of functionality that will deliver value online, and via our mobile phones. API transactions are enablers, and by using APIs, you are working to make the world a better place. If you aren’t an API believer, when I describe how APIs reduce everything to a transaction, you are probably troubled, and left asking why I would want to do this. Not everything can or should be distilled down into a single transaction. Shifting something to be a transaction opens it up for being bought and sold. This is the nature of transactions. Even if you are delivering value to end-users by reducing a piece of their world to a transaction, now that it is a transaction, it is vulnerable to other market forces. It is these unintended...[<a href="/2017/10/23/apis-reduce-everything-to-a-transaction/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/10/23/api-monetization-framework-as-introduced-by-aws-marketplace/"><img src="https://s3.amazonaws.com/kinlane-productions2/amazon/aws-marketplace-aws-saas-seller-integration-guide.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/10/23/api-monetization-framework-as-introduced-by-aws-marketplace/">API Monetization Framework As Introduced By AWS Marketplace</a></h3>
			<p><em>23 Oct 2017</em></p>
			<p>I am learning about the AWS Marketplace through the lens of selling your API there, adding a new dimension to my API monetization and API plan research. I’ve invested a significant amount of energy to try and standardize what I learn from studying the pricing and plans for the API operations of the leading API providers. As I do this work I regularly hear from folks who like to tell me how I’ll never be able to standardize and normalize this, and that it is too big of a challenge to distill down. I agree that things seem too big to tame at the current moment, but with API pioneers like AWS, who have been doing this stuff for a while, you can begin to see the future of how this stuff will play itself out. Amazon set into motion a significant portion of how we think about monetizing our API resources. The pay for what you use model has been popularized by Amazon, and continue to dominate conversations around how we generate revenue around our valuable digital assets. AWS has some of the most sophisticated pricing structure around their API services, as well as very mature pricing calculators, and have created markets around their resources (ie. spot instances for compute). You can see these concepts playing out in the guidance they offer software developers in their AWS Marketplace Seller Guide, which helps sellers modify their SaaS products to sell them through AWS Marketplace using two models: 1) metering, or 2) contract. When you list or application in the AWS Marketplace you must choose between one of these models, but both involve thinking critically about your monetization strategy, which includes your hard costs, as well as where the value will lie with your customers–striking the balance necessary to operate a viable API business. According to the AWS Marketplace Seller Guide, each SaaS application owner listing through AWS Marketplace has two options for listing and billing...[<a href="/2017/10/23/api-monetization-framework-as-introduced-by-aws-marketplace/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/10/23/a-simple-api-with-aws-dynamodb-lambda-and-api-gateway/"><img src="https://s3.amazonaws.com/kinlane-productions2/amazon/aws-dynamodb-lambda-api-gateway.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/10/23/a-simple-api-with-aws-dynamodb-lambda-and-api-gateway/">A Simple API With AWS DynamoDB, Lambda, and API Gateway</a></h3>
			<p><em>23 Oct 2017</em></p>
			<p>I’ve setup a few Lambda scripts from time to time, but haven’t had any dedicated project time to push forward API serverless concepts. Over the weekend I had a chance to deploy a couple of APIs using AWS DynamoDB, Lambda, and API Gateway, lighting up some of the serverless API possibilities in my brain. Like most areas of the tech sector, I think the term is dumb, and there is too much hype, but I think underneath there is some interesting possibilities, at least enough to keep me playing around with things. Right now my primary API setup is Amazon Aurora (MysQL) backend, with API deployed on EC2, using Slim API framework in PHP. It is clean, simple, and gets the job done. I use 3Scale, or Github for the API management layer. This new approach simplifies some things for me, but definitely goes further down the AWS rabbit hole with the adoption of API Gateway and Lamdba, but also introduces some interesting enough benefits, that has me considering for use on some specific projects. Identity and Access Management (IAM) Role The first thing you need to do to make the whole AWS thing work is setup a role using AWS IAM. I created a role just for this project, and added CloudWatchFullAccess, AmazonDynamoDBFullAccess, and AWSLambdaDynamoDBExecutionRole. I need this role to handle a bunch of management level things with the database, and logging. IAM is one of the missing aspects of hand crafting my APIs, and is why I am considering adopting on behalf of my customers, to help them get a handle on security. Simple API Database Backends Using AWS DynamoDB I am a big fan of relational databases, mostly out of habit and experience. A client of mine is fluent in AWS DynamoDB, which is a simple NoSQL solution, so I felt compelled to ensure the backend database for their APIs spoke DynamoDB. It’s a pretty simple database, so I got to work...[<a href="/2017/10/23/a-simple-api-with-aws-dynamodb-lambda-and-api-gateway/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/10/20/selling-your-aws-api-gateway-driven-api-through-the-aws-marketplace/"><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories/cargo-ship-on-sea_diego_rivera1.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/10/20/selling-your-aws-api-gateway-driven-api-through-the-aws-marketplace/">Selling Your AWS API Gateway Driven API Through The AWS Marketplace</a></h3>
			<p><em>20 Oct 2017</em></p>
			<p>I am getting intimate with AWS API Gateway. Learning about what it does, and what it doesn’t do. The gateway brings a number of essential API management elements to the table, like issuing keys, establishing plans, and enforcing rate limits. However, it also lacks many of the other active elements of API management like billing for usage, which is an important aspect of managing API consumption for API providers. With AWS, things tend to work like legos, meaning many of their services work together to deliver a larger picture, and I’ve been learning more about how AWS API Gateway works with the AWS Marketplace to deliver some of the business of API features I’m looking for. Here is the blurb from the AWS API Gateway documentation regarding how you can setup AWS API Gateway to work with AWS Marketplace, making your API available for sale as a SaaS service: After you build, test, and deploy your API, you can package it in an API Gateway usage plan and sell the plan as a Software as a Service (SaaS) product through AWS Marketplace. API buyers subscribing to your product offering are billed by AWS Marketplace based on the number of requests made to the usage plan. To sell your API on AWS Marketplace, you must set up the sales channel to integrate AWS Marketplace with API Gateway. Generally speaking, this involves listing your product on AWS Marketplace, setting up an IAM role with appropriate policies to allow API Gateway to send usage metrics to AWS Marketplace, associating an AWS Marketplace product with an API Gateway usage plan, and associating an AWS Marketplace buyer with an API Gateway API key. Details are discussed in the following sections. To enable your customers to buy your product on AWS Marketplace, you must register your developer portal (an external application) with AWS Marketplace. The developer portal must handle the subscription requests that are redirected from the AWS Marketplace console. While...[<a href="/2017/10/20/selling-your-aws-api-gateway-driven-api-through-the-aws-marketplace/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/10/20/api-management-dashboard-the-provider-view/"><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories/cargo-ship-on-sea_atari_missle.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/10/20/api-management-dashboard-the-provider-view/">API Management Dashboard: The Provider View</a></h3>
			<p><em>20 Oct 2017</em></p>
			<p>I’m helping some clients think through their approach to API management. These projects have different needs, as well as different resources available to them, so I’m looking to distill things down to the essential components needed to get the job done. I’ve taken a look at the API consumer account basics as well as their usage, and next I want to consider the view of all of this from the API provider vantage point. For both of my current projects, I’m needing to think about the UI elements that deliver on API management elements from the API provider perspective. To help me think though the UI elements needed for helping manage the essential elements of managing APIs I wanted to create a simple list of each screen that will be needed to get the job done. So far, I have the following X UI elements as part of my API management base: Creation - The landing page for account creation. Ideally, these are using OpenID / OAuth for major providers, eliminating the need for passwords. Login - The page for logging back in after a user has registered. Ideally, these are using OpenID / OAuth for major providers, eliminating the need for passwords. Dashboard - The landing page once an API provider is logged in – providing access to all aspects of API management. APIs - A list of APIs, with detail pages for managing each individual API definition. Plans - A list of API plans, with detail pages for managing each individual API plan definition. Accounts - A list of API consumer accounts, with detail pages for managing each individual API consumer. Usage - - A list of API calls from logs, with tools for breaking down by API, plan, or consumer. Invoices - A list of all invoices that have been generated for a specific time period, across specific consumers. With a detail page for seeing individual invoice details. There may be more...[<a href="/2017/10/20/api-management-dashboard-the-provider-view/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/10/20/api-management-dashboard-the-consumer-view/"><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories/cargo-ship-on-sea_constitution.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/10/20/api-management-dashboard-the-consumer-view/">API Management Dashboard: The Consumer View</a></h3>
			<p><em>20 Oct 2017</em></p>
			<p>I’m helping some clients think through their approach to API management. These projects have different needs, as well as different resources available to them, so I’m looking to distill things down to the essential components needed to get the job done. I’ve taken a look at the API consumer account basics as well as their usage, and next I want to consider the view of all of this from the API provider vantage point. For both of my current projects, I’m needing to think about the UI elements that deliver on API management elements from both the API provider and consumer levels. I’ve already tackled the API provider view, next up is the API consumer view. To help me think though the UI elements needed for helping manage the essential elements of managing API consumption for developers I wanted to create a simple list of each screen that will be needed to get the job done. So far, I have the following X UI elements as part of my API management base: Creation - The landing page for developer account creation. Ideally, these are using OpenID / OAuth for major providers, eliminating the need for passwords. Login - The page for logging back in after a developer has registered. Ideally, these are using OpenID / OAuth for major providers, eliminating the need for passwords. Dashboard - The landing page once an API consumer is logged in – providing access to all aspects of their API access. Account - The ability to update developer account information. Key(s) - The ability to get the master set, or multiple copies of API keys. Plans - Viewing all available plans, with the ability to see which plan a consumer is part of and switch plans if relevant. Usage - See history of all API consumption by API and time period. Credit Card - The addition and updating of account credit card. Billing - See history of all invoices for...[<a href="/2017/10/20/api-management-dashboard-the-consumer-view/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/10/20/api-developer-account-usage-basics/"><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories/cargo-ship-on-sea_copper_circuit.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/10/20/api-developer-account-usage-basics/">API Developer Account Usage Basics</a></h3>
			<p><em>20 Oct 2017</em></p>
			<p>I’m helping some clients think through their approach to API management. These projects have different needs, as well as different resources available to them, so I’m looking to distill things down to the essential components needed to get the job done. I spent some time thinking through the developer account basics, and now I want to break down the aspects of API consumption and usage around these APIs and developer accounts. I want to to think about the moving parts of how we measure, quantify, communicate, and invoice as part of the API management process. Having A Plan We have developers signed up, with API keys that they’ll be required to pass in with each API call they make. The next portion of API management I want to map out for my clients is the understanding and management of how API consumers are using resources. One important concept that I find many API providers, and would be API providers don’t fully grasp, is service composition. Something that requires the presence of a variety of access tiers, or API plans, which define the business contract we are making with each API providers. API plans usually have these basic elements: plan id - A unique id for the plan. plan name - A name for the plan. plan description - A description for the plan. plan limits - Details about limits of the plan. plan timeframe - The timeframe for limits applied. There can be more than one plan, and each plan can provide different types of access to different APIs. There might be plans for new users versus verified ones, as well as possibly partners. The why and how of each plan will vary from API provider to provider, but their are all essential to managing API usage. Something that needs to be well defined, in place, with APIs and consumers organized into their respective tiers. Once this is done, we can begin thinking about the...[<a href="/2017/10/20/api-developer-account-usage-basics/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/10/20/api-developer-account-basics/"><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories/cargo-ship-on-sea_blue_circuit.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/10/20/api-developer-account-basics/">API Developer Account Basics</a></h3>
			<p><em>20 Oct 2017</em></p>
			<p>I’m helping some clients think through their approach to API management. These projects have different needs, as well as different resources available to them, so I’m looking to distill things down to the essential components needed to get the job done. The first element you need to manage API access is the ability for API consumers to be able to sign up for an account, that will be used to identify, measure usage, and engage with each API consumer. Starts With An Account While each company may have more details associated with each account, each account will have these basics: account id - A unique identifier for each API account. name - A first name and last name, or organization name. email - A valid email address to communicate with each user. Depending on how we enable account creation and login, there might also be a password. However, if we use existing OpenID or OAuth implementations, like Github, Twitter, Google, or Facebook, this won’t be needed. We are relying on these authentication formats as the security layer, eliminating the need for yet another password. However, we still may need to store some sort of token identifying the user, adding these two possible elements: password - A password or phrase that is unique to each user. token - An OAuth or other token issued by 3rd party provider. That provides us with the basics of each developer API developer account. It really isn’t anything different than a regular account for any online service. Where things start to shift a little specifically for APIs, is that we need some sort of keys for each account that is signing up for API access. The standard approach is to provide some sort of API key, and possibly a secondary secret to compliment it: api key - A token that can be passed with each API call. api secret - A second token, that can be passed with each API...[<a href="/2017/10/20/api-developer-account-basics/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/10/19/the-tractor-beam-of-the-database-in-an-api-world/"><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories-new/dragon-shadows-black-white-outline.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/10/19/the-tractor-beam-of-the-database-in-an-api-world/">The Tractor Beam Of The Database In An API World</a></h3>
			<p><em>19 Oct 2017</em></p>
			<p>I’m an old database person. I’ve been working with databases since my first job in 1987. Cobol. FoxPro. SQL Server. MySQL. I have had a production database in my charge accessible via the web since 1998. I understand how databases are the center of gravity when it comes to data. Something that hasn’t changed in an API driven world. This is something that will make microservices in a containerized landscape much harder than some developers will want to admit. The tractor beam of the database will not give up control to data so easily, either because of technical limitations, business constraints, or political gravity. Databases are all about the storage and access to data. APIs are about access to data. Storage, and the control that surrounds it is what creates the tractor beam. Most of the reasons for control over the storage of data are not looking to do harm. Security. Privacy. Value. Quality. Availability. There are many reasons stewards of data want to control who can access data, and what they can do with it. However, once control over data is established, I find it often morphs and evolves in many ways, that can eventually become harmful to meaningful and beneficial access to data. Which is usually the goal behind doing APIs, but is often seen as a threat to the mission of data stewards, and results in a tractor beam that API related projects will find themselves caught up in, and difficult to ever break free of. The most obvious representation of this tractor beam is that all data retrieved via an API usually comes from a central database. Also, all data generated or posted via an API, also ends up within a database. The central database always has an appetite for more data, whether scaled horizontally or vertically. Next, it is always difficult to break off subsets of data into separate API-driven project, or prevent newly established ones from being pulled in,...[<a href="/2017/10/19/the-tractor-beam-of-the-database-in-an-api-world/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/10/19/importing-openapi-definition-to-create-an-api-with-aws-api-gateway/"><img src="https://s3.amazonaws.com/kinlane-productions2/amazon/api-gateway/aws-api-gateway-create-new-api.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/10/19/importing-openapi-definition-to-create-an-api-with-aws-api-gateway/">Importing OpenAPI Definition To Create An API With AWS API Gateway</a></h3>
			<p><em>19 Oct 2017</em></p>
			<p>I’ve been learning more about AWS API Gateway, and wanted to share some of what I’m learning with my readers. The AWS API Gateway is a robust way to deploy and manage an API on the AWS platform. The concept of an API gateway has been around for years, but the AWS approach reflects the commoditization of API deployment and management, making it a worthwhile cloud API service to understand in more depth. With the acquisition or all the original API management providers in recent years, as well as Apigee’s IPO, API management is now a default element of major cloud providers. Since AWS is the leading cloud provider, AWS API Gateway will play a significant role into the deployment and management of a growing number of APIs we see. Using AWS API Gateway you can deploy a new API, or you can use it to manage an existing API–demonstrating the power of a gateway. What really makes AWS API Gateway reflect where things are going in the space, is the ability to import and define your API using OpenAPI. When you first begin with the new API wizard, you can upload or copy / paste your OpenAPI, defining the surface area of the API, no matter how you are wiring up the backend. OpenAPI is primarily associated with publishing API documentation because of the success of Swagger UI, and secondarily associated with generating SDKs and code samples. However, increasingly the OpenAPI specification is also being used to deploy and define aspects of API management, which is in alignment with the AWS API Gateway approach. I have server side code that will take an OpenAPI and generate the server side code needed to work with the database, and handle requests and responses using the Slim API framework. I’ll keep doing this for many of my APIs, but for some of them I’m going to be adopting an AWS API Gateway approach to help standardize API...[<a href="/2017/10/19/importing-openapi-definition-to-create-an-api-with-aws-api-gateway/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/10/19/adding-ping-events-to-my-webhooks-and-api-research/"><img src="https://s3.amazonaws.com/kinlane-productions2/github/github-webhook-ping-events.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/10/19/adding-ping-events-to-my-webhooks-and-api-research/">Adding Ping Events To My Webhooks And API Research</a></h3>
			<p><em>19 Oct 2017</em></p>
			<p>I am adding another building block to my webhooks research out of Github. As I continue this work, it is clear that Gthub will continue to play a significant role in my webhook research and storytelling, because they seem to be the most advanced when it comes to orchestration via API and webhooks. I’m guessing this is a by-product of continuous integration (CI) and continuous deployment (CD), which Github is at the heart of. The API platforms that have embraced automation and orchestration as part of what they do, always have the most advanced webhook implementations, and provide the best examples of webhooks in action, which we can all consider as part of our operations. Today’s webhook building block is the ping event. “When you create a new webhook, we’ll send you a simple ping event to let you know you’ve set up the webhook correctly. This event isn’t stored so it isn’t retrievable via the Events API. You can trigger a ping again by calling the ping endpoint.” A pretty simple, but handy features when it comes to getting up and going with webhooks, making sure everything is working properly out of the gate–something that clearly comes from experience, and listening to the problems your consumers are encountering. These types of subtle webhook features are exactly the types of building blocks I’m looking to aggregate as part of my research. As I do with other areas of my research, is at some point I will publish all of these into a single, (hopefully) coherent guide to webhooks. After going through the webhook implementations across the leading providers like Github, I should have a wealth of common patterns in use. Since webhooks aren’t any formal standard, it is yet another aspect of doing business with APIs we have to learn from the health practices already in use across the space. It helps to emulate providers like Github, because developers are pretty familiar with how Github...[<a href="/2017/10/19/adding-ping-events-to-my-webhooks-and-api-research/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/10/18/most-api-developers-will-not-care-as-much-as-you-do/"><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories-new/40_45_800_500_0_max_0_-5_-5.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/10/18/most-api-developers-will-not-care-as-much-as-you-do/">Most API Developers Will Not Care As Much As You Do</a></h3>
			<p><em>18 Oct 2017</em></p>
			<p>I believe in the potential of what APIs can do, and care about learning how we can do things right. Part of it is my job, but part of it is me wanting to do things well. Master my approach to delivering APIs, using my well-rounded API toolbox. Reading the approach of other leading API providers, and honing my understanding of healthy, and not so healthy practices. I thoroughly enjoy studying what is going on and then applying it across what I do. However I am reminded regularly that most people are not interested in knowing, and doing things right–they just want things done. As many of us discuss the finer details of API design, and the benefits of one approach over the other, other folks would rather us just point them to the solution that will work for them. They really don’t care about the details, or mastering the approach, they just want it to work in their situation. Whether it is the individual, the project or organization they are working in, the environment is just not conducive to learning, understanding, and growth. They are just interested in services and tools that can deliver the desired solution for as cheap as possible–free, and open source whenever available. You can see this reality playing out across the space. An example is OpenAPI (fka Swagger). It has largely been successful because of Swagger UI. Most people think OpenAPI is all about documentation, with their understanding reflecting the solution they delivered, not the full benefits brought to the table as part of the process of implementing the specification. This is just one example of how folks across the API space are interested in solutions, rather than the journey. This is why many API programs will stagnate and fail, because folks do them thinking they’ll achieve some easier way of doing things, easy integrations, effortless innovation, or some other myth around API Valhalla. I feel like much of...[<a href="/2017/10/18/most-api-developers-will-not-care-as-much-as-you-do/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/10/16/the-basics-of-api-management/"><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories-new/42_16_600_400_0_max_1_1_1-5.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/10/16/the-basics-of-api-management/">The Basics Of API Management</a></h3>
			<p><em>16 Oct 2017</em></p>
			<p>I am developing a basic API management strategy for one of my client’s API. With each area of their API strategy I am taking what I’ve learned monitoring the API sector, but pausing for a moment to think about again, and then applying to their operations. Over the years I have separated out many aspects of API management, distilling it down to a core set of elements that reflect the evolution of API management as its evolved into a digital commodity. It helps me to think through these aspects of API operations in general, but also applying to a specific API I am working on, helping me further refine my API strategy advice. API management is the oldest area of my research. It has spawned every other area of the lifecycle I track on, but also is the most mature aspect of the API economy. This project I am working on gives me an opportunity to think about what is API management, and what should be spun off into separate areas of concern. I am looking to distill API management down to: Portal - A single URL to find out everything about an API, and get up and running working the resources that are available. On-Boarding - Think just about how you get a new developer to from landing on the home page of the portal to making their first API call, and then an application in production. Accounts - Allowing API consumers to sign up for an account, either for individual, or business access to API resources. Applications - Enable each account holder to register one or many applications which will be putting API resources to use. Authentication - Providing one, or multiple ways for API consumers to authenticate and get access to API resources. Services - Defining which services are available across one or many API paths providing HTTP access to a variety of business services. Logging - Every call to the API...[<a href="/2017/10/16/the-basics-of-api-management/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/10/16/operating-your-api-portal-using-github/"><img src="https://s3.amazonaws.com/kinlane-productions2/jekyll/jekyllrb.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/10/16/operating-your-api-portal-using-github/">Operating Your API Portal Using Github</a></h3>
			<p><em>16 Oct 2017</em></p>
			<p>Operating on Github is natural for me, but I am regularly reminded what a foreign concept it is for some of the API providers I’m speaking with. Github is the cheapest, easiest way to launch a public or private developer portal for your API. With the introduction of Github Pages, each Github repository is turned into a place to host any API related project. In my opinion, every API should begin with Github, providing a place to put your API definition, portal, and other elements of your API operations. If you are just getting going with understand how Github can be used to support your API operations, I wanted to provide a simple checklist of the concepts at play, that will lead you being able to publish your API portal to Github. Github Account - You will need an account to be able to use Github. Anything you do on Github that is public will be free. You can do private portals on Github, but this story is about using it for a public API portal. Github Organization - I recommend starting an organization for your API operations, instead of under just a single users account. Then you can make the definition for the API the first repository, and possibly the portal your second repository you create. Github Repo - A Github repository is basically a folder on the platform which you can start the code, pages, and other content used as part of API operations. Github Pages - Each Github repository has the ability to turn on a public project site, which can be used as a hosting location for a developer portal. Jekyll - Github Pages allows any Github repository to become a website hosting location which you can access via your Github user account, or even provide an address using your own domain. I recommend every API provider think about hosting their API portal on Github. The learning curve isn’t that significant...[<a href="/2017/10/16/operating-your-api-portal-using-github/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/10/16/api-design-maturity-at-capital-one/"><img src="https://s3.amazonaws.com/kinlane-productions2/capital-one/capital-one-api-maturing-pyramid.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/10/16/api-design-maturity-at-capital-one/">API Design Maturity At Capital One</a></h3>
			<p><em>16 Oct 2017</em></p>
			<p>API design is something that many have tried to quantify and measure, but very few ever establish any meaningful way of doing so properly in my experience. I’ve been learning about the approach to API governance from the Capital One DevExchange team, and found their approach to defining API design maturity pretty interesting. I’m mostly interested in their approach because it speaks to actual business objectives, and aren’t about the common technical aspects we see API design being quantified across the community each day. Capital One breaks things down into five distinctive layers that offer value to any organization doing APIs. Starting at the bottom of their maturity period, here are the levels of maturity they are measuring things by: Functional - Doing the basics, providing some low-level functionality, and nothing more. Reliable - An API that is reliable, and scalable, beyond just basic functionality. Intuitive - Where an investment in developer experience is made, further standardizing and streamlining what an API does. Empowering - Where an API really begins to deliver value to an organization by being function, reliable, and intuitive, which all contributes significantly to operations. Transformative - APIs that are game changer. Few APIs ever rise to this level, but all should aspire to this level of maturity. It provides a whole other lens for looking at API design through. Moving beyond just, is it RESTful? Hypermedia, GraphQL, gRPC, or other emerging approach. It also understands that not all APIs will be equal, and that we should be standardizing the value the design of our APIs deliver to our business operations. Forcing us to ask some pretty simple questions about the API design patterns we are using, and the actual value they bring to the table. Moving beyond API design being about technical details, and considering the business, and other political aspects of doing APIs. The Capital One API design maturity definition also demonstrates another important aspect of all of this. That...[<a href="/2017/10/16/api-design-maturity-at-capital-one/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/10/16/adwords-api-release-and-sunset-schedule-for-2018/"><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories-new/beach-rocks-currents_kand_two.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/10/16/adwords-api-release-and-sunset-schedule-for-2018/">AdWords API Release and Sunset Schedule For 2018</a></h3>
			<p><em>16 Oct 2017</em></p>
			<p>APIs are not forever, and eventually will go away. The trick with API deprecation is to communicate clearly, and regularly with API consumers, making sure they are prepared for the future. I’ve been tracking on the healthy, and not so healthy practices when it comes to API deprecation for some time now, but felt like Google had some more examples I wanted to add to our toolbox. Their approach to setting expectations around API deprecation is worthy of emulating, and making common practice across industries. The Google Adwords API team is changing their release schedule, which in turns impacts the number of APIs they’ll support, and how quickly they will be deprecating their APIs. They will be releasing new versions of the API three times a year, in February, June and September. They will also be only supporting two releases concurrently at all times, and three releases for a brief period of four weeks, pushing the pace of API deprecation alongside each release. I think that Google’s approach provides a nice blueprint that other API provides might consider adopting. Adopting an API release and sunset schedule helps communicate the changes on the horizon, but it also provides a regular rhythm that API consumers can learn to depend on. You just know that there will be three releases a year, and you have a quantified amount of time to invest in evolving integration before any API is deprecated. It’s not just the communication around the roadmap, it is about establishing the schedule, and establishing an API release and sunset cadence that API consumers can be in sync with. Something that can go a lot further than just publishing a road map, and tweeting things out. I’ll add this example to my API deprecation research. Unfortunately the topic is one that is widely communicated around in the API space, but Google has long a strong player when it comes to finding healthy API deprecation examples to follow....[<a href="/2017/10/16/adwords-api-release-and-sunset-schedule-for-2018/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/10/12/obfuscating-the-evolving-code-behind-my-api/"><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories/christianity-under-construction_copper_circuit.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/10/12/obfuscating-the-evolving-code-behind-my-api/">Obfuscating The Evolving Code Behind My API</a></h3>
			<p><em>12 Oct 2017</em></p>
			<p>I’m dialing in a set of machine learning APIs that I use to obfuscate and distort the images I use across my storytelling. The code is getting a little more hardened, but there is still so much work ahead when it comes to making sure it does exactly what I needed it to do, with only dials and controls I need–nothing more. I’m the only consumer of my APIs, which I use them daily, with updates made to the code along the way, evolving the request and response structures until they meet my needs. Eventually the APIs will be done (enough), and I’ll stop messing with them, but that will take a couple months more of pushing forward the code. While the code for these APIs are far from finished, I find the API helps obfuscate and diffuse the unfinished nature of things. The API maintains a single set of paths, and I might still evolve the number of parameters it accepts, and the fields it outputs, the overall will keep a pretty tight surface area despite the perpetually unfinished backend. I like this aspect of operating APIs, and how they can be used as a facade, allowing you to maintain one narrative on the front-end, even with another occurring behind behind the scenes. I feel like API facades really fit with my style of coding. I’m not really an A grade programmer, more a B- level one, but I know how to get things to work–if I have a polished facade, things look good. Honestly, I’m pretty embarrassed by my wrappers for TensorFlow. I’m still figuring everything out, and finding new ways of manipulating and applying Tensor Flow models, so my code is rapidly changing, maturing, and not always complete. When it comes to the API interface I am focused on not introducing breaking changes, and maintaining a coherent request and response structure for the image manipulation APIs. Even though the code will at...[<a href="/2017/10/12/obfuscating-the-evolving-code-behind-my-api/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/10/12/bots-voice-and-conversational-apis-are-your-next-generation-of-api-clients/"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-conversational-interfaces.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/10/12/bots-voice-and-conversational-apis-are-your-next-generation-of-api-clients/">Bots, Voice, And Conversational APIs Are Your Next Generation Of API Clients</a></h3>
			<p><em>12 Oct 2017</em></p>
			<p>Around 2010, the world of APIs began picking up speed with the introduction of the iPhone, and then Android mobile platforms. Web APIs had been used for delivering data and content to websites for almost a decade at that point, but their potential for delivering resources to mobile phones is what pushed APIs into the spotlight. The API management providers pushed the notion of being multi-channel, and being able to deliver to web and mobile clients, using a common stack of APIs. Seven years later, web and mobile are still the dominant clients for API resources, but we are seeing a next generation of clients begin to get more traction, which includes voice, bot, and other conversational interfaces. If you deliver data and content to your customers via your website and mobile applications, the chance that you will also be delivering it to conversational interfaces, and the bots and assistants emerging via Alexa and Google Home, as well as on Slack, Facebook, Twitter, and other messaging platforms, is increasing. I’m not selling that everything will be done with virtual assistants, and voice commands in the near future, but as a client we will continue to see mainstream user adoption, and voice be used in automobiles, and other Internet connected devices emerging in our world. I am not a big fan of talking to devices, but I know many people who are. I don’t think Siri, Alexa, and Google Home will live up to the hype, but there is enough resources being invested into these platforms, and the devices that they are enabling, that some of it will stick. In the cracks, interesting things will happen, and some conversational interfaces will evolve and become useful. In other cases, as a consumer, you won’t be able to avoid the conversational interfaces, and be required to engage with bots, and use voice enabled devices. This will push the need to have conversationally literate APIs that can deliver data...[<a href="/2017/10/12/bots-voice-and-conversational-apis-are-your-next-generation-of-api-clients/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/10/12/air-an-asthma-api/"><img src="https://s3.amazonaws.com/kinlane-productions2/propeller/air-asthma-api-text-phone-aa3.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/10/12/air-an-asthma-api/">Air, An Asthma API</a></h3>
			<p><em>12 Oct 2017</em></p>
			<p>You don’t find me showcasing specific APIs often. I’m usually talking about an API because of their approach to the technology, business, or politics of how they do APIs. It just isn’t my style to highlight APIs, unless I think they are interesting, and delivering value that is worth talking about, or possibly reflecting a meaningful trend that is going on. In this case it is a useful API that I think brings value, but also provides an example of an API I can showcase to non-developer folks as a meaningful example of an API. The API I’m talking about today, is the Air API, an asthma API from Propeller, which provides a set of free tools to help people understand current asthma conditions in their neighborhoods. The project is led by the Propeller data scientists and clinical researchers, looking to leverage Air API to help predict how asthma may be affected by local conditions, including a series of tools that share local asthma conditions, ranging from an email or text subscription, to an embeddable Air Widget for other websites. The Air API provides an easy to explain example of what is possible with APIs. Environmental APIs will continue to be an important aspect of doing APIs. Aggregating sensor and other data to help us understand the air, water, weather, and other critical environmental factors that impact our lives each day. I like the idea of these APIs being open and available to 3rd party developers to build tools on top of them, while the platforms using them as a marketing vehicle for their other products and services, while making sure to keep the valuable data accessible to everyone. I’ll put the Air API into my toolbox of APIs I use to help onboard folks with APIs. If they are impacted by asthma, or know someone who is, it helps make the personal connection, which can be important when on-boarding folks with the abstract concepts...[<a href="/2017/10/12/air-an-asthma-api/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/10/11/their-security-practices-are-questionable-but-their-communication-is/"><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories/status-berlin_propaganda_leaflets.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/10/11/their-security-practices-are-questionable-but-their-communication-is/">Their Security Practices Are Questionable But Their Communication Is</a></h3>
			<p><em>11 Oct 2017</em></p>
			<p>I study the API universe every day of the week, looking for common patterns in the way people are using technology. I study almost 100 stops along the API lifecycle, looking for healthy practices that companies, organizations, institutions, and government agencies can follow when dialing in their API operations. Along the way I am also looking for patterns that aren’t so healthy, which are contributing to many of the problems we see across the API sector, but more importantly the applications and devices that they are delivering valuable data, content, media, and algorithms to. One layer of my research is centered around studying API security, which also includes keeping up with vulnerabilities and breaches. I also pay attention to cybersecurity, which is a more theatrical version of regular security, with more drama, hype, and storytelling. I’ve been reading everything I can on the Equifax, Accenture, and other scary breaches, and like the other areas of the industry I track on, I’m beginning to see some common patterns emerge. It is something that starts with the way we use (or don’t use) technology, but then is significantly amplified by the human side of things. There are a number of common patterns that contribute to these breaches on the technical side, such as not enough monitoring, logging, and redundancy in security practices. However, there are also many common patterns emerging from the business approach by leadership during security incidents, and breaches. These companies security practices are questionable, but I’d say the thing that is the most unacceptable about all of these is the communication around these security events. I feel like they demonstrate just how dysfunctional things are behind the scenes at these companies, but also demonstrate their complete lack of respect and concern for individuals who are impacted by these incidents. I am pretty shocked by seeing how little some companies are investing in API security. The lack of conversation from API providers about their security...[<a href="/2017/10/11/their-security-practices-are-questionable-but-their-communication-is/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/10/11/the-grpc-meetup-kit/"><img src="https://s3.amazonaws.com/kinlane-productions2/grpc/grpc-logo.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/10/11/the-grpc-meetup-kit/">The gRPC Meetup Kit</a></h3>
			<p><em>11 Oct 2017</em></p>
			<p>I wrote about Tyk’s API surgery meetups last week, and adding a new approach to our API event and workshop toolbox, and next I wanted to highlight the gRPC Meetup Kit, a resource for creating your own gRPC event. gRPC is an approach out of Google for designing, delivering, and operating high performance APIs. If you look at the latest wave of APIs out of Google you’ll see they are all REST and/or gRPC. Most of them are dual speed, providing both REST and gRPC. gRPC is an open source initiative, but very much a Google led effort that we’ve seen picking up momentum in 2017. While I am keeping an eye on gRPC itself, this particular story is about the concept of providing a Meetup kit for your API related service or tooling, providing an “In a Box” solution that anyone can use to hold a Meetup. The gRPC team provides three groups of resources: gRPC 101 Presentation Talk - A 15 minute course introduction video. Slides - Slides that go along with the talk. Codelab - A 45m codelab that attendees can complete using Cloud Shell. Resources and community gRPC Website Codelab Building a gRPC service with Node.js Building a gRPC service with C# GitHub Source Extended gRPC Ecosystem Blog Youtube Channel Ask Questions Gitter Chat Google Group Stack Overflow Keep in Touch Twitter Request Support for Your Event gRPC Stickers Sign up for office hours with gRPC team It provides a nice blueprint for what is needed when crafting your own Meetup Kit as well as some material you could weave into any other type of Meetup, or workshop that might contain gRPC. Maybe an API design and protocol workshop, where you cover all of the existing approaches out there today like REST, Hypermedia, gRPC, GraphQL, and others. If nothing else the gRPC Meetup Kit provides a nice forkable project, that you could use as scaffolding for your own kit. As I...[<a href="/2017/10/11/the-grpc-meetup-kit/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/10/11/the-api-coaches-at-capital-one/"><img src="https://s3.amazonaws.com/kinlane-productions2/capital-one/21586757_10155715320589813_1876210064026688571_o.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/10/11/the-api-coaches-at-capital-one/">The API Coaches At Capital One</a></h3>
			<p><em>11 Oct 2017</em></p>
			<p>API evangelism and even advocacy at many organizations has always been a challenge to introduce, because many groups aren’t really well versed in the discipline, and often times it tends to take on a more marketing or even sales like approach, which can hurt its impact. I’ve worked with groups to rebrand, and change how they evangelize APIs internally, with partners, and the public, trying to ensure the efforts are more effective. While I still bundle all of this under my API evangelism research, I am always looking for new approaches that push the boundaries, and evolve what we know as API evangelism, advocacy, outreach, and other variations. I was introduced to a new variation of the internal API evangelism concept a few weeks back while at Capital One talking with my friend Matthew Reinbold(@libel_vox) about their approach to API governance. His team at the Capital One API Center of Excellence has the concept of the API coach, and I think Matt’s description from his recent API governance blueprint story sums it up well: At minimum, the standards must be a journey, not a destination. A key component to “selective standardization” is knowing what to select. It is one thing for us in our ivory tower to throw darts at market forces and team needs. It is entirely another to repeatedly engage with those doing the work. Our coaching effort identifies those passionate practitioners throughout our lines of business who have raised their hands and said, “getting this right is important to my teams and me”. Coaches not only receive additional training that they then apply to their teams. They also earn access to evolving our standards. In this way, standards aren’t something that are dictated to teams. Teams drive the standards. These aren’t alien requirements from another planet. They see their own needs and concerns reflected back at them. That is an incredibly powerful motivator toward acceptance and buy-in. A significant difference here between...[<a href="/2017/10/11/the-api-coaches-at-capital-one/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/10/11/provide-an-open-source-threat-information-database-and-api-then-sell-premium/"><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories/old-door-lock_copper_circuit.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/10/11/provide-an-open-source-threat-information-database-and-api-then-sell-premium/">Provide An Open Source Threat Information Database And API Then Sell Premium</a></h3>
			<p><em>11 Oct 2017</em></p>
			<p>I was doing some API security research and stumbled across vFeed, a “Correlated Vulnerability and Threat Intelligence Database Wrapper”, providing a JSON API of vulnerabilities from the vFeed database. The approach is a Python API, and not a web API, but I think provides an interesting blueprint for open source APIs. What I found interesting (somewhat) from the vFeed approach was the fact they provide an open source API, and database, but if you want a production version of the database with all the threat intelligence you have to pay for it. I would say their technical and business approach needs a significant amount of work, but I think there is a workable version of it in there. First, I would create a Python, PHP, Node.js, Java, Go, Ruby version of the API, making sure it is a web API. Next, remove the production restriction on the database, allowing anyone to deploy a working edition, just minus all the threat data. There is a lot of value in there being an open source set of threat intelligence sharing databases and API. Then after that, get smarter about having a variety different free and paid data subscriptions, not just a single database–leverage the API presence. You could also get smarter about how the database and API enables companies to share their threat data, plugging it into a larger network, making some of it free, and some of it paid–with revenue share all around. There should be a suite of open source threat information sharing databases and APIs, and a federated network of API implementations. Complete with a wealth of open data for folks to tap into and learn from, but also with some revenue generating opportunities throughout the long tail, helping companies fund aspects of their API security operations. Budget shortfalls are a big contributor to security incidents, and some revenue generating activity would be positive. So, not a perfect model, but enough food for thought...[<a href="/2017/10/11/provide-an-open-source-threat-information-database-and-api-then-sell-premium/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/10/10/explore-download-api-and-share-data/"><img src="https://s3.amazonaws.com/kinlane-productions2/nyc-open-data/nyc-opendata-explore-download-api.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/10/10/explore-download-api-and-share-data/">Explore, Download, API, And Share Data</a></h3>
			<p><em>10 Oct 2017</em></p>
			<p>I’m regularly looking through API providers, service providers, and open data platforms looking for interesting ways in which folks are exposing APIs. I have written about Kentik exposing the API call behind each dashboard visualization for their networking solution, as well as CloudFlare providing an API link for each DNS tool available via their platform. All demonstrating healthy way we can show how APIs are right behind everything we do, and today’s example of how to provide API access is out of New York Open Data, providing access to 311 service requests made available via the Socrata platform. The page I’m showcasing provides access 311 service requests from 2010 to present, with all the columns and meta data for the dataset, complete with a handy navigation toolbar that lets you view data in Carto or Plot.ly, download the full dataset, access via API, or simply share via Twitter, Facebook, or email. It is a pretty simple example of offering up multiple paths for data consumers to get what they want from a dataset. Not everyone is going to want the API. Depending on who you are you might go straight for the download, or opt to access via one of the visualization and charting tools. Depending on who you are targeting with your data, the list of tools might vary, but the NYC OpenData example via Socrata provides a nice example to build upon. With the most important message being do not provide only the options you would choose–get to know your consumers, and deliver solutions they will also need. It provides a different approach to making APIs behind available to users than the Kentik or CloudFlare approaches do, but it adds to the number of examples I have to show people how APIs and API enabled integration can be exposed through the UI, helping educate the massess about what is possible. I could see standardized buttons, drop downs, and other embeddable tooling emerge for...[<a href="/2017/10/10/explore-download-api-and-share-data/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/10/10/connecting-service-level-agreements-to-api-monitoring/"><img src="https://s3.amazonaws.com/kinlane-productions2/apimetrics/api-metrics-latency-sla.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/10/10/connecting-service-level-agreements-to-api-monitoring/">Connecting Service Level Agreements To API Monitoring</a></h3>
			<p><em>10 Oct 2017</em></p>
			<p>Monitoring your API availability should be standard practice for internal and external APIs. If you have the resources to custom build API monitoring, testing, and performance infrastructure, I am guessing you already have some pretty cool stuff in place. If you don’t, then you should not be reinventing the wheel out there, and you should be leveraging one of the existing API monitoring services out there on the market. When you are getting started with monitoring your APIs I recommend you begin with uptime and downtime, and once you deliver successfully on that front, I recommend you work on API performance, and the responsiveness of your APIs. You should begin with making sure you are delivering the service level agreement you have in place with your API consumers. What, you don’t have a service level agreement? No better time to start than now. If you don’t already have an explicitly stated SLA in place, I recommend creating one internally, and see what you can do to live up to your API SLA, then once you ensure things are operating at acceptable levels, you share with your API consumers. I am guessing they will be pretty pleased to hear that you are taking the initiative to offer an SLA, and are committed enough to your API to work towards such a high bar for API operations. To help you manage defining, and then ultimately monitoring and living up to your API SLA, I recommend taking a look at APIMetrics, who is obsessively focused on API quality, performance, and reliability. They spend a lot of time monitoring public APIs, and have developed a pretty sophisticated approach to ranking and scoring your API to ensure you meet your SLA. As you can see in the picture for this story, the APIMetrics administrative dashboard provides a pretty robust way for you to measure any API you want, and establish metrics and triggers that let you know if you’ve met...[<a href="/2017/10/10/connecting-service-level-agreements-to-api-monitoring/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/10/10/algorithmic-observability-should-work-like-machine-readable-food-labels/"><img src="https://s3.amazonaws.com/kinlane-productions2/algorithms/new-food-labels.jpg" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/10/10/algorithmic-observability-should-work-like-machine-readable-food-labels/">Algorithmic Observability Should Work Like Machine Readable Food Labels</a></h3>
			<p><em>10 Oct 2017</em></p>
			<p>I’ve been doing a lot of thinking about algorithmic transparency, as well as a more evolved version of it I’ve labeled as algorithmic observability. Many algorithmic developers feel their algorithms should remain black boxes, usually due to intellectual property concerns, but in reality the reasons will vary. My stance is that algorithms should be open source, or at the very least have some mechanisms for auditing, assessing, and verifying that algorithms are doing what they promise, and that algorithms aren’t doing harm behind the scenes. This is a concept I know algorithm owners and creators will resist, but algorithms observability should work like food labels, but work in a more machine readable way, allowing them to be validated by other external (or internal) systems. Similar to food you buy in the store, you shouldn’t have to give away the whole recipe and secret sauce behind your algorithm, but there should be all the relevant data points, inputs, outputs, and other “ingredients” or “nutrients” that go into the resulting algorithm. I talked about algorithm attribution before, and I think there should be some sort of algorithmic observability manifest, which provides the “label” for an algorithm in a machine readable format. It should give all the relevant sources, attribution, as well as input and outputs for an algorithm–with different schema for different industries. In addition to there being an algorithmic observability “label” available for all algorithms, there should be live, or at least virtualized, sandboxed instances of the algorithm for verification, and auditing of what is provided on the label. As we saw with the Volkswagen emissions scandal, algorithm owners could cheat, but it would provide an important next step for helping us understand the performance, or lack of performance when it comes to the algorithms we are depending on. Why I call this algorithmic observability, instead of algorithmic transparency, is each algorithm should be observable using it’s existing inputs and outputs (API), and not just be...[<a href="/2017/10/10/algorithmic-observability-should-work-like-machine-readable-food-labels/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 12px;"><a href="/2017/10/10/a-guest-blogger-program-to-create-unique-content-for-your-api/"><img src="https://s3.amazonaws.com/kinlane-productions2/runscope/runscope-featured-guest-series.png" alt="API Evangelist" width="325" align="left" /></a></div>
			<h3><a href="/2017/10/10/a-guest-blogger-program-to-create-unique-content-for-your-api/">A Guest Blogger Program To Create Unique Content For Your API</a></h3>
			<p><em>10 Oct 2017</em></p>
			<p>Creating regular content for your blog is essential to maintaining a presence. If you don’t publish regularly, and refresh your content, you will find your SEO, and wider presence quickly becoming irrelevant. I understand that unlike me, many of you have jobs, and responsibilities when it comes to operating your APIs, and carving out the time to craft regular blog posts can be difficult. To help you in your storytelling journey I am always looking for other stories to help alleviate your pain, while helping keep your blog active, and ensure folks will continue stumbling across your API, or API service, while Google, or on social media. Another interesting example of how to keep your blog fresh came from my partners over at Runscope, who conducted a featured guest blog post series, where they were paying API community leaders to help “create an incredible resource of blog posts about APIs, microservices, DevOps, and QA.” Which has produced a handful of interesting posts: Monolith to Microservices: Transforming a web-scale, real-world e-commerce platform using the Strangler Pattern You Might Not Need GraphQL 3 Easy Steps to Cloud Operational Excellence Building a Steam Powered IoT API with Thingsboard One thing to note is that Runscope paid $500.00 per post to help raise the bar when it comes to the type of author that will step up for such an effort. I’ve seen companies try to do this before, offering gift cards, swag, and even nothing in return, with varying grades of success and failure. I’m not saying a guest author program for your blog will always yield the results you are looking for, but it is a good way to help build relationships with your community, and help augment your existing workload, with some regular storytelling on the blog. A guest blogger program is a tool I will be adding to my API communications research, expanding on the tools API operators have in their toolbox to keep their...[<a href="/2017/10/10/a-guest-blogger-program-to-create-unique-content-for-your-api/">Read More</a>]</p>
			<p><hr /></p>
	  

		<hr />
		<ul class="pagination" style="text-align: center;">
			
				<li style="text-align:left;"><a href="/blog/page7" class="button"><< Prev</a></li>
			
				<li style="width: 75%"><span></span></li>
			
				<li style="text-align:right;"><a href="/blog/page9" class="button">Next >></a></li>
			
		</ul>

  </div>
</section>

              <footer>
	<hr>
	<div class="features">
		<article>
			<div class="content">
				<p align="center"><a href="https://www.postman.com" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/partners/postman-logo.png" width="60%" style="padding: 15px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
		<article>
			<div class="content">
				<p align="center"><a href="https://github.com/postmanlabs/newman" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/postman/newman-logo.png" width="60%" style="padding: 15px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
	</div>
</footer>


            </div>
          </div>

          <div id="sidebar">
            <div class="inner">

              <nav id="menu">
  <header class="major">
    <h2>Menu</h2>
  </header>
  <ul>
    <li><a href="/">Home</a></li>
    <li><a href="/blog/">Blog</a></li>
  </ul>
</nav>

              <section>
	<div class="mini-posts">
		<header>
			<h2 style="text-align: center;"><i>API Evangelist Sponsors</i></h2>
		</header>
		<article>
			<div class="content">
				<p align="center"><a href="https://www.postman.com" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/partners/postman-logo.png" width="75%" style="padding: 5px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
		<article>
			<div class="content">
				<p align="center"><a href="https://tyk.io/" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/tyk/tyk-logo.png" width="75%" style="padding: 5px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
		<article>
			<div class="content">
				<p align="center"><a href="https://www.openapis.org/" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/specifications/openapi.png" width="75%" style="padding: 5px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
		<article>
			<div class="content">
				<p align="center"><a href="https://www.asyncapi.com/" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/asyncapi/asyncapi-horiozontal.png" width="75%" style="padding: 5px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
		<article>
			<div class="content">
				<p align="center"><a href="https://json-schema.org/" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/specifications/json-schema.png" width="75%" style="padding: 5px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
		<article>
			<div class="content">
				<p align="center"><a href="https://github.com/postmanlabs/newman" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/postman/newman-logo.png" width="75%" style="padding: 5px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
	</div>
</section>


            </div>
          </div>

      </div>

<script src="/assets/js/skel.min.js"></script>
<script src="/assets/js/util.js"></script>
<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
<script src="/assets/js/main.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-1119465-51"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-1119465-51');
</script>


</body>
</html>
