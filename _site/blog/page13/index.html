<!DOCTYPE html>
<html xmlns="https://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
  <html>
  <title>API Evangelist </title>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
  <!--[if lte IE 8]><script src="/assets/js/ie/html5shiv.js"></script><![endif]-->
  <link rel="stylesheet" href="/assets/css/main.css" />
  <link rel="stylesheet" href="/assets/css/bootstrap.min.css" />
  <!--[if lte IE 9]><link rel="stylesheet" href="/assets/css/ie9.css" /><![endif]-->
  <!--[if lte IE 8]><link rel="stylesheet" href="/assets/css/ie8.css" /><![endif]-->

  <!-- Icons -->
  <link rel="shortcut icon" type="image/x-icon" href="https://apievangelist.com/favicon.ico">
	<link rel="icon" type="image/x-icon" href="https://apievangelist.com/favicon.ico">

  <link rel="alternate" type="application/rss+xml" title="API Evangelist Blog - RSS 2.0" href="https://apievangelist.com/blog.xml" />
  <link rel="alternate" type="application/atom+xml" title="API Evangelist Blog - Atom" href="https://apievangelist.com/atom.xml">

  <!-- JQuery -->
  <script src="/js/jquery-latest.min.js" type="text/javascript" charset="utf-8"></script>
  <script src="/js/bootstrap.min.js" type="text/javascript" charset="utf-8"></script>
  <script src="/js/utility.js" type="text/javascript" charset="utf-8"></script>

  <!-- Github.js - http://github.com/michael/github -->
  <script src="/js/github.js" type="text/javascript" charset="utf-8"></script>

  <!-- Cookies.js - http://github.com/ScottHamper/Cookies -->
  <script src="/js/cookies.js"></script>

  <!-- D3.js http://github.com/d3/d3 -->
  <script src="/js/d3.v3.min.js"></script>

  <!-- js-yaml - http://github.com/nodeca/js-yaml -->
  <script src="/js/js-yaml.min.js"></script>

  <script src="/js/subway-map-1.js" type="text/javascript"></script>

  <style type="text/css">

    .gist {width:100% !important;}
    .gist-file
    .gist-data {max-height: 500px;}

    /* The main DIV for the map */
    .subway-map
    {
        margin: 0;
        width: 110px;
        height: 5000px;
        background-color: white;
    }

    /* Text labels */
    .text
    {
        text-decoration: none;
        color: black;
    }

    #legend
    {
    	border: 1px solid #000;
        float: left;
        width: 250px;
        height:400px;
    }

    #legend div
    {
        height: 25px;
    }

    #legend span
    {
        margin: 5px 5px 5px 0;
    }
    .subway-map span
    {
        margin: 5px 5px 5px 0;
    }

    </style>

    <meta property="og:url" content="">
    <meta property="og:type" content="website">
    <meta property="og:title" content="API Evangelist">
    <meta property="og:site_name" content="API Evangelist">
    <meta property="og:description" content="A network of research sites dedicated to the technology, business, and politics of APIs.">
    <meta property="og:image" content="http://s3.amazonaws.com/kinlane-productions/api-evangelist/t-shirts/KL_InApiWeTrust-1000.png">

    <meta name="twitter:url" content="">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="API Evangelist">
    <meta name="twitter:site" content="API Evangelist">
    <meta name="twitter:description" content="A network of research sites dedicated to the technology, business, and politics of APIs.">
    
      <meta name="twitter:creator" content="@apievangelist">
    
    <meta property="twitter:image" content="http://s3.amazonaws.com/kinlane-productions/api-evangelist/t-shirts/KL_InApiWeTrust-1000.png">


</head>

  <body>

			<div id="wrapper">
					<div id="main">
						<div class="inner">

              <header id="header">
	<a href="http://apievangelist.com" class="logo"><img src="https://kinlane-productions2.s3.amazonaws.com/api-evangelist/api-evangelist-logo-400.png" width="75%" /></a>
	<ul class="icons">
		<li><a href="https://twitter.com/apievangelist" class="icon fa-twitter"><span class="label">Twitter</span></a></li>
		<li><a href="https://github.com/api-evangelist" class="icon fa-github"><span class="label">Github</span></a></li>
		<li><a href="https://www.linkedin.com/company/api-evangelist/" class="icon fa-linkedin"><span class="label">LinkedIn</span></a></li>
		<li><a href="http://apievangelist.com/atom.xml" class="icon fa-rss"><span class="label">RSS</span></a></li>
	</ul>
</header>

    	        <section>
	<div class="content">

		<h3>The API Evangelist Blog</h3>

	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/oxford_university_press.jpg" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/04/10/my-oxford-dictionaries-talk-about-the-world-of-apis/">My Oxford Dictionaries Talk About The World Of APIs</a></h3>
			<p><em>10 Apr 2017</em></p>
			<p>This is from a conversation I had with the Oxford Dictionaries API team last week while in Oxford. I led a conversation with 30-40 folks across several teams at the Oxford University Press offices. I tried to paint a relevant and realistic picture of the world of APIs, as it would pertain to their organization. I talked for about an hour, with another hour of discussion with the group, where we discussed some of these areas in more detail. History of APIsTo help connect the dots of where the world of APIs is going I wanted to take a brief walk through the history of APIs and make sure everyone is up to speed. The current wave of web APIs began in early 2000's with SalesForce, Amazon, and eBay leveraging web technologies to deliver commerce related IT services that leverage web technology over traditional enterprise approaches. These early API efforts focused on the integration of CRM, sales, and auction or affiliate related commerce activity, following the first dot-com bubble. Then around 2003, a new type of companies emerged that was employing APIs to connect people online&nbsp;and help them share links, images, and other social content, over the buying and selling of products. Flickr, then Facebook and Twitter emerged as API pioneers, opening up simple web APIs that allowed their communities of developers to integrate, and develop new websites and applications that helped drive the social evolution of the web. By 2006, API pioneer Amazon had internalized APIs at the commerce giant, requiring internal groups to use them to conduct business internally at the company, something that would result in a new web service for storing information on the web they called Amazon S3. Shortly after they released Amazon S3 they also launched a second API for deploying and managing servers on the Internet, changing how companies can deploy infrastructure for the web--something we now collectively call cloud computing. This is when the web API thing...[<a href="/2017/04/10/my-oxford-dictionaries-talk-about-the-world-of-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/github_guides.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/04/10/an-introduction-to-github-for-api-providers/">An Introduction To Github For API Providers</a></h3>
			<p><em>10 Apr 2017</em></p>
			<p>I have had a number of requests from folks lately to write more about Github, and how they can use the social coding platform as part of their API operations. As I work with more companies outside of the startup echo chamber on their API strategies I am encountering more groups that aren't Github fluent&nbsp;and could use some help getting started. It has also been a while since I've thought deeply about how API providers should be using Github&nbsp;so it will allow me to craft some fresh content on the subject. Github As Your Technical Social NetworkThink of Github as a more technical version of Facebook, but instead of the social interactions being centered around wall posts, news links, photos, and videos, it is focused on engagement with repositories. A repository is basically a file folder that you can make public or private, and put anything you want into it. While code is the most common thing put into Github repositories, they often contain data file, presentations, and other content, providing a beneficial way to manage many aspects of API operations. The Github BasicsWhen putting Github to use as part of your API operations, start small. Get your profile setup, define your organization, and begin using it to manage documentation or other simple areas of your operations--until you get the hang of it. Set aside any pre-conceived notions about Github being about code, and focus on the handful of services it offers to enable your API operations. Users - Just like other online services, Github has the notion of a user, where you provide a photo, description, and other relevant details about yourself. Avoid making a user accounts for your API, making sure you show the humans involved in API operations. It does make sense to have a testing, or other generic platform Github users accounts, but make sure your API team each have their own user profile, providing a snapshot of everyone involved. &nbsp;...[<a href="/2017/04/10/an-introduction-to-github-for-api-providers/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2017_03_31_at_2.40.15_pm.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/31/taking-a-look-at-the-stoplight-api-spec-editor/">Taking A Look At The Stoplight API Spec Editor</a></h3>
			<p><em>31 Mar 2017</em></p>
			<p>I'm keeping an eye on the different approaches by API service providers when it comes to providing API editors within their services and tooling. While I wish there was an open source GUI API editor out there, the closest thing we have is from these API service providers, and I am trying to track on what the best practices are so that when someone does step up and begin working on an open, embeddable solution, they can learn from my stories about what is working or not working across the space. One example I think has characteristics that should be emulated is the API Spec Editor from Stoplight. The GUI editor lets you manage all the core elements of an OpenAPI like the general info, host, paths, and even the shared responses and parameters. They even provide what they call a CRUD builder where you paste the JSON schema, and they'll generate the common paths you will need to create, read, update, and delete your resources. Along the way you can also make calls to API endpoints using their interactive interface, helping ensure your API definition is actually in alignment with your API. The Stoplight API Spec Editor bridges the process of defining your OpenAPI for your operations, with actually documenting and engaging with an API through an interactive client interface. I like this approach to coming at API design from multiple directions. Apiary first taught us that API definitions were about more than just documentation, and I think our API editors should keeping evolving on this concept, and allowing us to engage with any stops along the API life cycle&nbsp;like we are seeing from API service providers like Restlet. I'm already keeping an eye on Restlet and APIMATIC's approach to providing a GUI API design editor within their solutions&nbsp;and will keep an eye out on other providers as I have time. Like other areas of the API sector, I'm hoping I can develop a...[<a href="/2017/03/31/taking-a-look-at-the-stoplight-api-spec-editor/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-tools-school.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/31/rest-linked-data-hypermedia-graphql-and-grpc/">REST, Linked Data, Hypermedia, GraphQL, and gRPC</a></h3>
			<p><em>31 Mar 2017</em></p>
			<p>I'm endlessly fascinated by APIs&nbsp;and enjoy studying their evolution. One of the challenges in helping evangelize APIs that I come across regularly is the many different views of what is or isn't an API amongst people who are API literate, as well as helping bring APIs into focus for the API newcomers&nbsp;because there are so many possibilities. Out of the two, I'd say that dealing with API dogma is by far a bigger challenge, than explaining APIs to newbies--dogma can be very poisonous to productive conversations and end up working against everyone involved in my opinion.&nbsp; I'm enjoying reading about the evolution in the API space when it comes to GraphQL and gRPC. There are a number of very interesting implementations, services, tooling, and implementations emerging in both these areas. However, I do see similar mistakes being made regarding dogmatic behavior, aggressive marketing tactics, and shaming folks for doing things differently, as I've seen with REST, Hypermedia, and linked data efforts. I know folks are passionate about what they are doing, and truly believe their way is right, but I'm concerned you will all suffer from the same deficiencies&nbsp;in adoption I've seen with previous implementations. I started API Evangelist with the mission of counteracting the aggressive approach of the RESTafarians. I've spent a great deal of time thinking about how I can turn average developers and even business folks on to the concept of APIs--no not just REST or just hypermedia, but web APIs in general. Something that I now feel includes GraphQL and gRPC. I've seen many hardworking folks invest a lot into their APIs, only to have them torn apart by API techbros (TM) who think they've done it wrong--not giving a rats ass regarding the need to actually help someone understand the pros and cons of each approach. I'm confident that GraphQL will find its place&nbsp;in the API toolbox, and enjoy significant adoption when it comes to data-intensive&nbsp;API implementations. However, I'd say...[<a href="/2017/03/31/rest-linked-data-hypermedia-graphql-and-grpc/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2017_03_30_at_6.48.27_pm.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/30/using-google-sheet-templates-for-defining-api-tests/">Using Google Sheet Templates For Defining API Tests</a></h3>
			<p><em>30 Mar 2017</em></p>
			<p>The Runscope team recently published a post on a pretty cool approach to using Google Sheets for running API tests with multiple variable sets, which I thought is valuable at a couple of levels. They provide a template Google Sheet for anyone to follow, where you can plug in your variable, as well as your Runscope API Key, which allows you to define the dimensions of the tests you wish to push to Runscope via their own API. The first thing that grabs me about this approach is how Runscope is allowing their customers to define and expand the dimensions of how they test their API using Runscope in a way that will speak to a wider audience, beyond just the usual API developer audience. Doing this in a spreadsheet allows Runscope customers to customize their API tests for exactly the scenarios they need, without Runscope having to customize and respond to each individual customer's needs--providing a nice balance. The second thing that interests me about their approach is the usage of a Googe Sheet as a template for making API calls, whether you are testing your APIs, or any other scenario an API enables. This type of templating of API calls opens up the API client to a much wider audience, making integration copy and pastable, shareable, collaborative, and something anyone can reverse engineer and learn about the surface area of an API--in this scenario, it just happens to be the surface area of Runscope's API testing API. Runscope's approach is alignment with my previous post about sharing data validation examples. A set of assertions could be defined within a spreadsheets and any stakeholder could use the spreadsheet to execute and make sure the assertions are met. This would have huge implications for the average business user to help make sure API contracts are meeting business objectives. I'm considering using this approach to empower cities, counties, and states to test and validate human services API implementations...[<a href="/2017/03/30/using-google-sheet-templates-for-defining-api-tests/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2017_03_30_at_3.12.32_pm.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/30/complimentary-apis-for-the-oxford-dictionaries-api/">Complimentary APIs For The Oxford Dictionaries API</a></h3>
			<p><em>30 Mar 2017</em></p>
			<p>Many API providers I meet have the "build it and they will come" mentality, thinking that if they build an API, developers will come and use it. It does happen, but many APIs only have so many direct uses, and will have a limited number of resulting implementations. This is one of the reasons I recommend companies do APIs in the first place, to get beyond the obvious and direct implementations, and incentivize entirely new applications that a provider may not have considered. Developing innovative applications an API provider may not have considered is the primary focus of companies I talk to, but only a handful have begun thinking about the other APIs that are out there that might compliment an API. An example of this is with my friends over at the Oxford Dictionary APIs, where building applicaitons with built-in dictionaries is pretty obvious. However, the complimentary API partnering and usage might not be as obvious, something I'm encouraging their team to think more about. What are some examples of complimentary APIs for the Oxford Dictionaries API? API Design - This example is more meta API, than complimentary API, but I'd like to see more API design tooling to begin to use dictionaries as part of their GUI and IDE interfaces. Providing more structure to the way we design our APIs, helping ensure that the design of leading APIs are more intuitive, and coherent--achieving a less technical interface, and something that speaks to humans. Machine Learning - I'm using a number of machine learning APIs to accomplish a variety of business tasks from object recognition in images, to text and language pattern recognition in content I produce or curate. There are a number of opportunities to extend the responses I get back from these APIs using a dictionary, helping increase the reach of the machine learning services I employ, and making them more effective and meaningful in my business operations. Search - I use...[<a href="/2017/03/30/complimentary-apis-for-the-oxford-dictionaries-api/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/1_z1ibgzv_gvmvo_zt8jnevw.jpeg" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/30/an-opportunity-to-emulate-slack-buttons/">An Opportunity To Emulate Slack Buttons</a></h3>
			<p><em>30 Mar 2017</em></p>
			<p>Slack released their Slack Buttons last year, to help as they state "reduce the number of small yet high-frequency tasks that quietly devour a user&rsquo;s time." I know folks are obsessed with voice, bot, and other conversational interfaces, but I agree with Slack, that there is a huge opportunity to help users execute common API-driven functions with a single push of a button. It is something I blog about regularly, helping folks realize the opportunity in the development of API driven, embeddable buttons, that go beyond what Slack is doing and would run anywhere on the web, in the browser, or even on mobile and other Internet connected devices. Zapier has taken a stab at this with Push by Zapier, and they have the inventory of APIs to support it. However, what I am thinking about should be even easier, embeddable anywhere, and leverage the web technology already in use (forms, inputs, GET, POST, etc.). If in a browser it should work like bookmarklets, and if it exists within the pages of a website or application, it should work as some simple copy/paste HTML with minimum JS when necessary to avoid blockage by ad blockers and other privacy protection tooling. I understand that it is easy to follow the pack when it comes to the latest technology trends, and I'm sure voice and bots will gain some mindshare when it comes to conversational interfaces. However, sometimes we just need the easy button for those high-frequency tasks that quietly devour our time, as Slack puts it. As I see JSON-LD embedeed into more web pages, further pleasing the Google search algorithm, there would also be more semantic opportunities for browser buttons to engage with the data and content within web pages in a more meaningful, and context aware way. API driven buttons and similiar embeddables and browser tooling is such an interesting opportunity that I would tackle myself, but I'm so resistant to anything that might...[<a href="/2017/03/30/an-opportunity-to-emulate-slack-buttons/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/oxford_dictionaries_api_home_screenshot.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/29/learning-to-use-our-words-better-when-defining-our-apis/">Learning To Use Our Words Better When Defining Our APIs</a></h3>
			<p><em>29 Mar 2017</em></p>
			<p>I am playing around with the Open API for the Oxford Dictionaries API, and I'm struck by the importance of not just dictionaries like the Oxford Dictionaries, but also the importance of OpenAPI, and API providers defining their APIs like the Oxford folks have. While we aren't as far down the road as we are with the English dictionary, we are beginning to make progress when it comes to defining the paths, parameters, and other characteristics using OpenAPI, learning to speak and communicate in the digital world using APIs. We use words to craft titles, paragraphs, outlines, and other ways that we communicatie in our personal and professional lives. We also use words to craft titles, paragraphs, outlines, collections, and other ways our systems our communicating in our personal and professional lives using the OpenAPI specification. In both these forms of communicating we are always trying to find just the right words, or series and orders of words to get across exactly the meaning we are looking for--we just have centuries of doing this when it comes writing and speaking, and only a decade or so of doing this with defining our digital resources using APIs. Eventually, I'd like to see entire dictionaries of JSON Schema, ALPS, or other machine readable specification, available by industry, and topic. The way we craft our API definitions and design our APIs often feels like we have barely learned to speak, let alone read or write. I'd like to see more reuse of common dictionaries already in use by leading API providers, and I'd like to see us get more thoughtful in how we express ourselves via our API definitions. The most successful APIs I find out there don't just provide a machine readable interface, they provide an intuitive interface that makes sense to humans, while also being machine readable for use in other systems. It feels like to me that we should integrating the Oxford Dictionaries API into...[<a href="/2017/03/29/learning-to-use-our-words-better-when-defining-our-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://image.slidesharecdn.com/emnworkshop-restfullwebapisbuilddocumentmanage-slideshare-150206082129-conversion-gate02/95/restful-web-apis-build-document-manage-11-638.jpg?cb=1423211259" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/29/helping-your-customers-operate-throughout-the-api-life-cycle/">Helping Your Customers Operate Throughout The API LIfe Cycle</a></h3>
			<p><em>29 Mar 2017</em></p>
			<p>When I started API Evangelist back in 2010 the only stop along the API life cycle that service providers were talking about was API management. In 2017, there are numerous stops along the API life cycle from design, to testing, all the way to deprecation. The leading API providers are expanding the number of stops they service, and the smart ones are making sure that if they only service on or two stops, they do so by providing via API definitions like OpenAPI, ensuring their customers are able to seamlessly weave multiple service providers together to address their full life cycle of needs. I've been working with my partner Restlet to advise them on expanding their platform to be what I consider to be an API life cycle provider. When I first was introduced to Restlet they were the original open source enterprise grade API deployment framework. Then Restlet became a cloud API deployment and management provider, and with their acquisition of DHC they also became an API client, and testing provider. Now with their latest update, they have worked hard to help their developer and business customers service almost every stop along a modern API life cycle, from design to deprecation. While Restlet is developing tooling to help companies define what the API life cycle means to them, the heartbeat of what Restlet delivers centers around API definitions like OpenAPI and RAML. API definitions provide the framework when your designing, deploying, documenting, managing, and testing your APIs using Restlet. They also provide the ability for you to get your API definitions in and out of the platform, and load them into potentially other API services, allow API operators to get what they need done. In my opinion, making API definitions just as importan tas any other service or tooling you offer along the API life cycle. Serving a single or handful of stops along the API life cycle can be today's version of vendor...[<a href="/2017/03/29/helping-your-customers-operate-throughout-the-api-life-cycle/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/glitch_fishes.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/29/all-api-startups-should-be-more-like-glitch/">All API Startups Should Be More Like Glitch</a></h3>
			<p><em>29 Mar 2017</em></p>
			<p>I was playing around with, and better understanding the new collaborative developer community that is Glitch, and I saw they had published a blog post about how they won't screw up Glitch. The topic was in alignment with another post I was working on regarding what I'd like to see fro API startups, but I think Anil articulates it better than even I could, and I think folks are going to respect it a lot more when it comes from a seasoned veteran like him, over an opinionated evangelist like me. In hist post, Anil shares five key points I think every startup should be thinking about from day one: No lock-in.&nbsp;We use totally standard infrastructure for Glitch, including regular old Node.js, and normal JavaScript for your code. You can export all of your code to GitHub with a click, or download a zip file of your code instantly at any time. And it&rsquo;s gonna stay that way. The key thing that we think will keep you using Glitch is by your deep emotional connection to your fellow members of the community. And that&rsquo;s not lock-in, that&rsquo;s love! Aww. We&rsquo;re not gonna take features away from you and then start charging for them. This is one of those tricky things that a lot of companies do when they start building a business model for their product &mdash; they ask, &ldquo;what would people pay for?&rdquo; And then they realize&hellip; oh crap, the stuff people want to pay for is already offered for free. We&rsquo;ve thought about this pretty carefully so we&rsquo;ll be able to support our current features going forward. (It doesn&rsquo;t cost much for us to run your Glitch app, and that cost is going down each month. No biggie.) When we do start charging for stuff, we&rsquo;ll check with you first.&nbsp;We imagine we&rsquo;ll add some paid features on top of what Glitch has now (maybe domain names?&nbsp;Everybody loves mapping domain names!)&nbsp;and when we do,...[<a href="/2017/03/29/all-api-startups-should-be-more-like-glitch/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/parse_building_apps_isnt_easy_shut_down.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/28/i-think-the-parse-twitter-page-sums-it-up-pretty-well/">I Think The Parse Twitter Page Sums It Up Pretty Well</a></h3>
			<p><em>28 Mar 2017</em></p>
			<p>Building a business is hard. Building a business that depends on other business is hard. We would like it if all of our vendors stuck around forever, but this is not the reality of doing business in today's climate. My stance on this situation that nothing lasts forever, but startups and the enterprise could be more honest about the business of startups, which is seriously beginning to impact the trust we all have in the platforms, tools, and APIs we depend on for our businesses. I was working my way through some legacy tweets, and I came across Parse's Twitter home page, which I think sums up the promise being made by each wave of startups, and the end results of these promises--although I have to say that Parse actually handled it pretty well, compared with other startups that I have seen in action. Building apps is not easy. However, we need solutions that will get us all the way there. I actually think that in the end, Parse handled it pretty well, better than StackMob did, when Paypal bought them. In the end, you could take the open source version of Parse and install it, and they communicated the deprecation pretty well, giving folks quite a bit of time to take care of business. However, this is the way it should be from day one. There should be APIs, and open source available to ease operation and migration--as well as communication about what the future will hold. If API focused startups don't start being more honest about their true business strategy, and the realities of the future from day one, fewer developers and users will buy what is being sold. Sure, there will always be new waves of young developers who will still believe, but the more experienced folks, who are often in charge of making purchasing decisions, will become increasingly skeptical about baking in APIs into their operations--screwing this up for the rest...[<a href="/2017/03/28/i-think-the-parse-twitter-page-sums-it-up-pretty-well/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/delicious_xml.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/28/being-able-see-an-api-request-in-browser-is-important/">Being Able See An API Request In Browser Is Important</a></h3>
			<p><em>28 Mar 2017</em></p>
			<p>
There are a number of things at work making this whole web API thing actually work. One of them that came up while I was at Google discussing APIs a couple weeks ago, while we were listening to Dan Ciruli (@danciruli) was the importance of being able to see an API request in the browser. It is something I think we often overlook when it comes to understanding why web APIs have reached such a wide audience.
I remember when I first realized I could change the URL in my Delicious account and get an XML listing of my bookmarks--this is when the API light first went on in my head. The web wasn't just for humans, it could be structured for use in other websites. Seeing the XML in the browser presented me links in a machine readable way, that triggered me to think about else I could with them, and which other systems I could put them to work in.
Being able to see the results of an API call in the browser helps stimulate the imagination when it comes to what is possible. This is similar to why API client tooling like Postman and Restlet Client are popular with developers--they help us see the possibilities. While not all APIs are simple enough to allow for viewing in the browser, when at all possible, we should keep things this easy, because you never know when it will make a mark, and help folks better understand what is going on under the hood, allowing them to put our APIs to work in ways we never expected.
[<a href="/2017/03/28/being-able-see-an-api-request-in-browser-is-important/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/api_definitions_apitransfomer_screenshot.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/28/api-definition-api-transformer/">API Definition: API Transformer</a></h3>
			<p><em>28 Mar 2017</em></p>
			<p>This is an article from the current edition of the&nbsp;API Evangelist industry guide to API definitions. The guide is designed to be a summary of the world of API definitions, providing the reader with a recent summary of the variety of specifications that are defining the technology behind almost every part of our digital world OpenAPI Spec is currently the most used API definition format out there, with the number of implementations, and tooling, with API Blueprint, Postman Collections, and other formats trailing behind. It can make sense to support a single API definition when it comes to an individual platforms operations, but when it comes to interoperability with other systems it is important to be multi-lingual and support multiple of the top machine-readable formats out there today. In my monitoring of the API sector, one service provider has stood out when it comes to being a truly multi-lingual API definition service provider--the SDK generation provider, APIMATIC. The company made API definitions the heart of its operations, generating what they call development experience (DX) kits, from a central API definition uploaded by users--supporting OpenAPI Spec, API Blueprint, Postman Collections, and other top formats. The approach has allowed the company to quickly expand into new areas like documentation, testing, continuous integration, as well as opening up their API definition translation as a separate service called API Transformer. API Transformer allows anyone to input an API Blueprint, Swagger, WADL, WSDL, Google Discovery, RAML 0.8 - 1.0, I/O Docs - Mashery, HAR 1.2, Postman Collection 1.0 - 2.0, Mashape, or APIMATIC Format API definition and then translate and export in a&nbsp; API Blueprint, Swagger 1.0 - 1.2, Swagger 2.0 JSON, Swagger 2.0 YAML, WADL - W3C 2009, RAML 0.8 - 1.0, Postman Collection 1.0 - 2.0, and their own APIMATIC Format. You can execute API definition translations through their interface or seamlessly integrate with the API Transformer API definition conversation API. There is no reason that an API...[<a href="/2017/03/28/api-definition-api-transformer/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/google_machine_training_execution_api.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/27/i-predict-a-future-flooded-with-google-prediction-galleries/">I Predict A Future Flooded With Google Prediction Galleries</a></h3>
			<p><em>27 Mar 2017</em></p>
			<p>I was roaming through Google's Prediction API, and I thought their prediction gallery provides us a look at a shift occurring right now in how we deliver APIs.&nbsp;I predict that machine learning galleries and marketplaces will&nbsp;become all the rage, independently operating like Algorithmia, or part of a specific API like the Google prediction gallery. Ok, let me put it out there that I hate the use of word prediction. If I was naming the service, I would have called it "execution", or more precisely a "machine training (MT) model execution API". I know I'll never get my way, but I have to put it out there how bullshit many of the terms we use in the space are--ok, back to the API blah blah blah, as my daughter would say. A common element of API portals for the last decade has included an application gallery, showcasing the apps that are developed on top of an API. Now, when an API offers up machine learning (training) (ML) execution capabilities, either generally or very specialized model execution (ie, genomics, financial), there should also be a gallery of available mobiles, or simply models that have been delivered as part of platform operations--just like we have done with APIs &amp; applications. I see this stuff as the evolution of the algorithmic layer of API operations. Meaning that most APIs are delivering data or content, but there is a 3rd layer that is about wrapping algorithms, and in the current machine learning and artificial intelligence craze, this approach to delivering algorithmic APIs will continue to be popular. It's not an ML revolution, it is simply an evolution in how we are delivering API resources, leveraging ML models as the core wrapper (Google was smart for open sourcing TensorFlow). Developing ML models, and making them deployable via AWS, Google, Azure, as well as marketplaces like Algorithmia will become a common approach for the API providers who are further along in their...[<a href="/2017/03/27/i-predict-a-future-flooded-with-google-prediction-galleries/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/api_definitions_us_data_federation_screenshot.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/27/api-definition-u-s-data-federation/">API Definition: U.S. Data Federation</a></h3>
			<p><em>27 Mar 2017</em></p>
			<p>This is an article from the current edition of the&nbsp;API Evangelist industry guide to API definitions. The guide is designed to be a summary of the world of API definitions, providing the reader with a recent summary of the variety of specifications that are defining the technology behind almost every part of our digital world. The U.S. Data Federation is a federal government effort to facilitate data interoperability and harmonization across federal, state, and local government agencies by highlighting common data formats, API specifications, and metadata vocabularies. The project is focusing on being a coordinating interoperability across government agencies by showcasing and supporting use cases that demonstrate unified and coherent data architectures across disparate agencies, institutions, and organizations. The project is designed to shine a light on &ldquo;emerging data standards and API initiatives across all levels of government, convey the level of maturity for each effort, and facilitate greater participation by government agencies&rdquo;--definitely in alignment with the goal of this guide. There are currently seven projects profiled as part of the U.S. Data Federation, including Building &amp; Land Development Specification, National Information Exchange Model, Open Referral, Open311, Project Open Data, Schema.org, and the Voting Information Project. By providing a single location for agencies to find common schema documentation tools, schema validation tools, and automated data aggregation and normalization capabilities, the project is hoping to incentivize and stimulate reusability and interoperability across public data and API implementations. Government agencies of all shapes and sizes can use the common blueprints available in the U.S. Data Federation to reduce costs, speed up the implementation of projects, while also opening them up for augmenting and extending using their APIs, and common schema. It is unclear what resources the U.S. Data Federation will have available in the current administration, but it looks like the project is just getting going, and intends to add more specifications as they are identified. The model reflects an approach that should be federated and evangelized...[<a href="/2017/03/27/api-definition-u-s-data-federation/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-hang-loose.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/27/a-looser-more-evolvable-api-contract-with-hypermedia/">A Looser More Evolvable API Contract With Hypermedia</a></h3>
			<p><em>27 Mar 2017</em></p>
			<p>I wrote about how gRPC API implements deliver a tighter&nbsp;API contract, but I wanted to also explore more thought from that same conversation, about how hypermedia APIs can help deliver a more evolvable API contract. The conversation where these thoughts were born was focused on the differences between REST and gRPC, in which hypermedia and GraphQL also came up. Leaving me thinking about how our API design and deployment decisions can impact the API contract we are putting forth to our consumers. In contrast to gRPC, going with a hypermedia design for your API, your client relationship can change and evolve, providing an environment for things to flex and change. Some APIs, especially internal API, and trusted partners might be better suited for gRPC performance, but when you need&nbsp;to manage volatility and change across a distributed client base, hypermedia might be a better approach. I'm not advocating one over the other, I am just trying to understand the different types of API contracts brought to the table with each approach, so I can better articulate in my storytelling. I'd say that hypermedia and gRPC approaches give API providers a different type of control over API clients that are consuming resources. gRPC enables dictating a high performance tighter coupling by generating clients, and hypermedia allows for shifts in what resources are available, what schema are being applied, and changes that might occur with each version, potentially without changes to the client. The API contract can evolve (within logical boundaries), without autogeneration of clients, and interference at this level. As I learn about this stuff&nbsp;and consider the API contract implications, I feel like hypermedia helps API provides navigation change, evolve and shift to deliver resources to a more unknown, and distributed client base. gRPC seems like it provides a better contract for use in your known, trusted, and higher performance environments. Next, I will be diving into what API discovery looks like in a gRPC world, and...[<a href="/2017/03/27/a-looser-more-evolvable-api-contract-with-hypermedia/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2017_03_21_at_10.42.50_pm.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/24/uber-is-painting-bigger-picture-of-their-drivers-with-driver-api-partnerships/">Uber Is Painting Bigger Picture Of Their Drivers With Driver API Partnerships</a></h3>
			<p><em>24 Mar 2017</em></p>
			<p>I was taking a look at the new Uber Driver API and trying to understand the possibilities with the API, and some of the the motivations behind Uber's launch of the API. According to Uber, "our Driver API lets you build services and solutions that make the driver experience more productive and rewarding. With the driver's permission, you can use trip data, earnings, ratings and more to shape the future of the on-demand economy." Providing an interesting opportunity for partners to step up and help build useful apps that Uber drivers can leverage in their worlds, helping them be more successful in their work. The first dimension of the Uber Driver API I find interesting is that it is not an API that is about their core business--ridesharing. It is focused on making their drivers more successful, and developing tools, and integrations that make their lives easier. I could see something like this evolving to other platforms like AirBnB, and other sharing or gig economy platforms, helping operators make sense of their worlds, while also strengthening partnerships and hopefully their relationship with operators along the way.&nbsp; The second dimension I find interesting is thinking about why Uber is publishing their Driver API. At first glance it is all about making their drivers happy--something Uber needs a lot of help with currently. However, once you think a little more about it, you can start to see a bigger picture that Uber is looking to paint of their drivers. The company's leverage over drivers has proven to only go so far, and they need to understand more about the lives of their drivers, and if they can invite corporate partners to do their taxes, and potentially other key tasks in their lives, a greater picture of their&nbsp;life will come into focus.&nbsp; If an Uber driver is also a Lyft driver, the Uber Driver API gives them more of a look into their competitor's accounting. They also get...[<a href="/2017/03/24/uber-is-painting-bigger-picture-of-their-drivers-with-driver-api-partnerships/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/periscope_twitter.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/24/moving-apis-out-of-the-partner-realm-and-making-them-more-public/">Moving APIs Out Of The Partner Realm And Making Them More Public</a></h3>
			<p><em>24 Mar 2017</em></p>
			<p>It is common for API providers to be really private with their APIs, and we often hear about providers restricting access as time goes by. So, when API providers loosen up restrictions on their APIs, inviting wider use by developers, making them public--I think it is worth taking notice.&nbsp; A recent example of this in the wild is from the API poster child Twitter, with their Periscope video service. Twitter has announced that they are slowly opening up access to the Periscope video API, something that has been only available to a handful of trusted partners, and via the mobile application--there was no way to upload a video without using your mobile device. Twitter is still "limiting access to fewer strategic partners for a period", but at least you can apply to see if your interests overlap with Twitters interests. It also sounds like Twitter will continue to widen access as time goes on, and as it makes sense to their Periscope strategy. While I wished we lived in a world where API developers were all well behaved, and API providers could open up services to the public from day one, this isn't the reality we find on the web today. Twitter's cautious approach to rolling out the Periscope API should provide other API providers with an example of how you can do this sensibly, only letting in the API consumers that are in alignment with your goals. Slowly opening up, making sure the service is stable, and meets the needs of consumers, partners, as well as helps meet a platform's business objectives. Hopefully, Twitter's approach to launching the Periscope API provides us with a positive example of how you can become more public APIs, instead of always locking things down. There is no single way to launch your APIs, but I'd say that Twitter's cautious approach is probably a good idea when you operate in such a competitive space, or when you don't have...[<a href="/2017/03/24/moving-apis-out-of-the-partner-realm-and-making-them-more-public/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/api_definitions_webconcepts_screenshot.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/24/api-definition-webconcepts-info/">API Definition: WebConcepts.info</a></h3>
			<p><em>24 Mar 2017</em></p>
			<p>This is an article from the current edition of the&nbsp;API Evangelist industry guide to API definitions. The guide&nbsp;is designed to be a summary of the world of API definitions, providing the reader with a recent summary of the variety of specifications that are defining the technology behind almost every part of our digital world. Keeping up with the standards bodies like International Organization for Standardization (ISO) and Internet Engineering Task Force (IETF)&nbsp; can be a full-time job. Thankfully,&nbsp; Erik Wilde (@dret) has help simply and made the concepts and specifications that make the web work more accessible and easier to understand, with his WebConcepts.info project. According to Erik, &ldquo;the Web&rsquo;s Uniform Interface is based on a large and growing set of specifications. These specifications establish the shared concepts that providers and consumers of Web services can rely on. Web Concepts is providing an overview of these concepts and of the specifications defining them.&rdquo; His work is a natural fit for what I am trying to accomplish with my API definition industry guide, as well as supporting other areas of my research. One of the areas that slows API adoption is a lack of awareness of the concepts and specifications that make the web work among developers who are providing and consuming APIs. The modern API leverages the same technology that drives the web--this is why it is working so well. The web is delivering HTML for humans, and APIs are using the same to deliver machine-readable data, content, and access to algorithms online. If a developer is not familiar with the fundamental building blocks of the web, the APIs they provide, and the applications they build on top of APIs will always be deficient. This project provides an overview of 28 web concepts with 643 distinct implementations&nbsp; aggregated across five separate organizations including the International Organization for Standardization (ISO), Internet Engineering Task Force (IETF), Java Community Process (JCP), Organization for the Advancement of Structured Information...[<a href="/2017/03/24/api-definition-webconcepts-info/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/runscope_data_validation.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/23/sharing-api-data-validation-examples/">Sharing API Data Validation Examples</a></h3>
			<p><em>23 Mar 2017</em></p>
			<p>I was studying examples of how I can validate the data returned from a human services APIs demo, and develop a set of API tests, as well as API service providers who can implement the tests, for cities to consider as part of their API deployments that are serving up locations and organizations where you can find critical services. I'm looking for examples of the common things like API availability and response time, but I'm also looking to get very granular and specialized to organizational, location, and service APIs.

The image I borrowed from RunScope helps visualize what I'm talking about, showing us how we can keep an eye on the basics, but also getting really granular when specifying what we expect from of our APIs. I have a pretty good imagination when it comes to thinking of scenarios I want to test for, but I'm also looking for any API providers who might be already sharing their tests&nbsp;and being more transparent when it comes to their API monitoring and testing practices. If you know of any API&nbsp;providers that would be willing to share the lists of what types of things they test for, I'd love to hear more.&nbsp;
I'm thinking a regular blog series on different examples of how people are testing APIs from a diverse range of business sectors might help stimulate people's imagination when it comes to API testing concepts. I'm thinking it is another area that we could all learn a lot from each other&nbsp;if there was just a little bit of sharing. I'd love it if the examples were machine readable and reusable in any API testing service, but I would settle for just a blog post, or sharing of a bulleted list of API tests via email, or another channel. ;-)
[<a href="/2017/03/23/sharing-api-data-validation-examples/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw_deploy_google_aws_microsoft.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/23/deploying-your-apis-exactly-where-you-need-them/">Deploying Your APIs Exactly Where You Need Them</a></h3>
			<p><em>23 Mar 2017</em></p>
			<p>Building on earlier stories about how my API partners are making API deployment more modular and composable, and pushing forward my understanding of what is possible with API deployment, I'm looking into the details of what DreamFactory enables when it comes to API deployment. "DreamFactory is a free, Apache 2 open source project that runs on Linux, Windows, and Mac OS X. DreamFactory is scalable, stateless, and portable" -- making it pretty good candidate for running it wherever you need. After spending time at Google and hearing about how they want to enable multi-cloud infrastructure deployment, I wanted to see how my API service provider partners are able to actually power these visions of running your APIs anywhere, in any infrastructure. Using DreamFactory you can deploy your APIs using Docker, Kubernetes, or directly from a Github repository, something I'm exploring as standard operating procedure for government agencies, like we see with 18F's&nbsp;US Forest Service ePermit Middlelayer API--in my opinion, all federal, state, and local government should be able to deploy API infrastructure like this. One of the projects I am working on this week is creating a base blueprint of what it will take to deploy a human services API for any city in Google or Azure. I have a demo working on AWS already, but I need a basic understanding of what it will take to do the same in any cloud environment. I'm not in the business of hosting and operating APIs for anyone, let alone for government agencies--this is why I have partners like DreamFactory, who I can route specific projects as they come in. Obviously, I am looking to support my partners, as they support me, but I'm also looking to help other companies, organizations, institutions, and government agencies better leverage the cloud providers they are already using. I'll share more stories about how I'm deploying APIs to AWS, as well as Google and Azure, as I do the work over...[<a href="/2017/03/23/deploying-your-apis-exactly-where-you-need-them/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/api_definitions_openapi_30_screenshot.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/23/api-definition-open-api-specification-3-0-0rc0/">API Definition: Open API Specification 3.0.0-RC0</a></h3>
			<p><em>23 Mar 2017</em></p>
			<p>This is an article from the current edition of the&nbsp;API Evangelist industry guide to API definitions. The guide&nbsp;is designed to be a summary of the world of API definitions, providing the reader with a recent summary of the variety of specifications that are defining the technology behind almost every part of our digital world. The OpenAPI Specification, formerly known as Swagger is approaching an important milestone, version 3.0 of the specification, but it is also the first major release since the specification was entered into the Linux Foundation. Swagger was the creation of Tony Tam of Wordnik back in 2010, but after the project was acquired by SmartBear in 2015, the company donated the specification to the newly formed OpenAPI Initiative (OAI) which is part of the Linux Foundation. Swagger has now been reborn as the OpenAPI Specification, and in early 2017 is approaching its first major release under the guidance of a diverse group of governing members. Version 3.0 of the API specification format has taken a much more modular, and reusable approach to defining the surface area of an API, enabling more power and versatility when it comes to describing the request and response models, as well as providing details on the common components that make up API usage like the underlying data schema and security definitions. There are numerous changes to the API specification, but there are just a handful that will have a significant impact across every stop along the API life cycle where API definitions are making an impact. Hosts When describing your API, you can now provide multiple hosts, allowing you to better deal with the complexity of how APIs might be located in a single location, or spread across multiple cloud location, and global infrastructure. Content Negotiation You can now provide content objects to define the relationship between response objects, media types, and schema, opening up the negotiation of exactly the type of content needed, encouraging the design...[<a href="/2017/03/23/api-definition-open-api-specification-3-0-0rc0/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/google_cloud_launcher_lead.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/22/opportunity-for-push-button-api-deployment-with-google-cloud-launcher/">Opportunity For Push Button API Deployment With Google Cloud Launcher</a></h3>
			<p><em>22 Mar 2017</em></p>
			<p>
I'm keeping an eye on the different approaches to deploying infrastructure coming out of AWS, Google, Microsoft and other providers. In my version of the near future, we should be able to deploy any API we want, in any infrastructure we want with a single push of a button. We are getting there, as&nbsp;I'm seeing more publish to Heroku buttons, AWS and Azure deployment packages, and I recently came across the Google Cloud Launcher, which I think will work well for deploying a variety of API driven solutions--we just need more selection&nbsp;and a button!
All the parts and pieces for this type of push button API deployment exist already, we just need someone to step up and provide a dead simple framework for defining and embedding the buttons, abstracting away the complexities of each cloud platform. I want to be able to take a single manifest for my open source or wholesale API on Github, and allow anyone to deploy it into Heroku, AWS, Google, Azure, or anywhere else they want. I want the technical, business, and legal complexities of deployment abstracted away for me, the API provider.
API management has matured a lot over the last 10 years, and API design and definitions are currently flourishing. We need a lot more investment in helping people easily deploy APIs, wherever they need. I think this layer of interoperability is the responsibility of the emerging API service providers like Restlet, DreamFactory, or maybe even APIMATIC. I will keep tracking on what I'm seeing evolve out of the leading cloud platforms like AWS, Azure, and now Google with their Cloud Launcher. I will also keep pushing on my API service provider partners in the space to enable API deployment like this--I am guessing they will just need a little nudging to see the opportunity around providing API deployment in this seamless, cloud-agnostic way.
[<a href="/2017/03/22/opportunity-for-push-button-api-deployment-with-google-cloud-launcher/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/devicons_screenshot.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/22/api-icon-vocabulary/">API Icon Vocabulary</a></h3>
			<p><em>22 Mar 2017</em></p>
			<p>I am working on profiling 75 of the Google APIs, and one thing I struggle with at this scale is standardizing the images I use, or more specifically, icons that represent each service as well as the value they deliver under the hood--something Google seriously needs to get more organized in by the way. I have written before about having a set of icons for the API sector, for SDK related icons, and also about how Amazon is getting more organized when it comes to icons for the AWS platform, as I beat this drum about the need for common imagery. While I am glad that Amazon is started to think about iconography when it comes to working with APIs at scale, a lead that Google and Microsoft should follow, I'm hoping that API icons are something that someone will tackle at the same level as say a Schema.org. I would like to see API provider (company) level icons, building on the work of Devicon, but I'd also like to see individual icons developed for common resources that are made available via APIs--like compute, storage, images, video, etc. What Amazon is doing provides the best model we have so far, but I want to make sure icons are not vendor specific. I would like to see a universal icon to represent a compute API for instance, whether it was Amazon, Google, or Microsoft. Think about IFTTT or Zapier, but something that would universally represent the valuable bits and bytes we are putting to use via individual platforms, but are increasingly also moving around between platforms--I want a common visual iconography we can use to communicate about what is being done with APIs. There is a ton of work involved with establishing a project of this scale. Ideally, it is something that would also involve API providers, and not just be an external thing. I'd also like to see each icon be more than just a...[<a href="/2017/03/22/api-icon-vocabulary/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/api_definitions_human_services_screenshot.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/22/api-definition-human-services-api-specification/">API Definition: Human Services API Specification</a></h3>
			<p><em>22 Mar 2017</em></p>
			<p>This is an article from the current edition of the API Evangelist industry guide to API definitions. The guide&nbsp;is designed to be a summary of the world of API definitions, providing the reader with a recent summary of the variety of specifications that are defining the technology behind almost every part of our digital world. A lot of attention is given to APIs and the world of startups, but in 2017 this landscape is quickly shifting beyond just the heart of the tech space, with companies, organizations, institutions, and government agencies of all shapes and sizes are putting APIs to work. API definitions are being applied to the fundamental building blocks of the tech sector, quantifying the computational, storage, images, videos, and other essential resources powering web, mobile, and device based applications. This success is now spreading to other sectors, defining other vital resources that are making a real impact in our communities. One API making an impact in communities is the Human Services Data Specification (HSDS), also known as the Open Referral Ohana API. The project began as a Code for America project, providing an API, website, and administrative system for managing the organizations, locations, and the human services that communities depend on. Open Referral, the governing organization for HSDS, and the Ohana API is working with API Evangelist and other partners to define the next generation of the human services data specification, API definition, as well as the next generation of API, website, admin, and developer portal implementations. The HSDS Specification API isn&rsquo;t about any single API, it is a suite of API-first definitions, schema, and open tooling that cities, counties, states&nbsp;and federal government agencies can download or fork, and employ to help manage vital human services for their communities. Providing not just a website for finding vital services, but a complete API ecosystem that can be deployed incentivizing developers to build important web, mobile, and other applications on top of a central...[<a href="/2017/03/22/api-definition-human-services-api-specification/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-target.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/21/with-each-api-we-increase-the-attack-surface-area/">With Each API We Increase The Attack Surface Area</a></h3>
			<p><em>21 Mar 2017</em></p>
			<p>It is easy for me to get excited about a new API. I'm an engineer. I'm a dude. I am the API Evangelist. It easy to think about the potential for good when it comes to APIs. It is much harder to suspend the logical side of my brain&nbsp;and think about the ways in which APIs can be used in negative ways. As a technologist it is natural for me to focus in on the technology, and tune out the rest of the world--it is what we do. It takes a significant amount of extra effort to stop, suspend the portion of your brain that technology whispers to, and think about the unintended consequences, and the pros and cons of why we are doing APIs. Technologists aren't very good at slowing down and thinking about the pros/cons of connecting something to the Internet, let alone whether or not an API should even exist in the first place (it has to exist!). As I read a story about the increases in DDOS attacks on the network layer of our online world, I can't help but think that with each new API we deploy, that we are significantly increasing the attack surface area for our businesses, organizations, institutions, and government agencies. It feels like we are good at thinking about the amazing API potential, but we really suck at seeing what a target we are putting on our back when we do APIs. We seem to be marching forward, drunk on the potential of APIs&nbsp;and Internet-connected everything. We aren't properly securing the technology we have, something we can see playing out with each wave of vulnerabilities, breaches, and leaks. We are blindly pushing forward with new API implementations, and using the same tactics we are using for our web and mobile technology, something we are seeing play out with the Internet of Things, and the vulnerable cameras, printers, and another object we are connecting to the Internet...[<a href="/2017/03/21/with-each-api-we-increase-the-attack-surface-area/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/api-evangelist-site/blog/kin-lane-drone-catch.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/21/reminding-myself-of-why-i-do-api-evangelist/">Reminding Myself Of Why I Do API Evangelist</a></h3>
			<p><em>21 Mar 2017</em></p>
			<p>This is my regular public service reminder of why I do API Evangelist. I do not evangelize APIs because I think everybody should be doing them, that they are the solution to all of our problems, or because I have an API I want you to buy (I have other things for you to buy). I do API Evangelist because I want to better understand how platforms like Facebook, Twitter, Uber, and others are operating&nbsp;and impacting our personal and professional lives. I do believe in APIs as an important tool in our professional toolboxes, but Silicon Valley, our government(s), and many other bad actors have shown me that APIs will more often be used for shady things, rather than the positive API vision I have in my head. I still encourage companies, organizations, institutions,&nbsp;and agencies to do APIs, but I spend equal amount of time ensuring people are doing APIs in a more open and equitable way&nbsp;while still encouraging folks to also embark on their API journeys--taking more control over how we store, share, and put our bits and bytes to work each day.&nbsp; APIs are playing a role in almost every news story we read today, from fake news and elections to cyber security,&nbsp;healthcare with the FHIR API standard, or banking with PSDS, to automobiles and transportation with Tesla and Uber. I can keep going all day long, talking about the ways APIs are influencing and delivering vital aspects of our personal and professional lives. In ALL of these situation's it's not the API that is important, it is the access, availability, and observability of the technology that is impacting the lives of humans--APIs are just the digital connector where our mobile phones and other devices are being connected to the Internet. I like to regularly remind myself why the fuck I'm doing API Evangelist, so I don't burn out like I have before and end up roaming the streets foaming at the mouth...[<a href="/2017/03/21/reminding-myself-of-why-i-do-api-evangelist/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/google_spectrum_database.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/21/considering-standards-in-our-api-design-over-being-a-special-snowflake/">Considering Standards In Our API Design Over Being A Special Snowflake</a></h3>
			<p><em>21 Mar 2017</em></p>
			<p>
Most of the APIs I look at are special snowflakes. The definition&nbsp;and designs employed are usually custom-crafted without thinking other existing APIs, or standards that already in place. There are several contributing factors to why this is, ranging from the types of developers who are designing APIs, to incentive models put in place because of investment&nbsp;and intellectual property constraints. So, whenever I find an API that is employing an existing standard, I feel compelled to showcase&nbsp;and help plant the seeds in others minds that we should be speaking a common language instead of always being a special snowflake.
One of these APIs that I came across recently was the Google Spectrum Database API which has employed a standard&nbsp;defined by the&nbsp;IETF Protocol to Access White Space (PAWS). &nbsp;I wouldn't say the API is the best-designed API, but it does follow a known standard, that is already in use by an industry, which in my experience can go further than having the best-designed API. The best product doesn't always win in this game, sometimes it is just about getting adoption with the widest possible audience.&nbsp;I am guessing that the Google Spectrum Database API is targeting a different type of engineering audience than their more modern, machine learning and other APIs are, so following standards is probably more of a consideration.
I wish more APIs would share a little bit about the thoughts that went into the definition and design of their APIs, sharing their due diligence of existing APIs and standards, and other considerations that were included in the process of crafting an API. I'd like to see some leadership in this area, as well as some folks admitting that they didn't have the time, budget, expertise, or whatever the other reasons why you are a special snowflake. It is a conversation we should be having, otherwise, we may never fully understand why we aren't seeing the adoption we'd like to see with our APIs.
[<a href="/2017/03/21/considering-standards-in-our-api-design-over-being-a-special-snowflake/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/open_api_toolbox_icons.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/20/the-openapi-toolbox-and-my-api-definition-research/">The OpenAPI Toolbox And My API Definition Research</a></h3>
			<p><em>20 Mar 2017</em></p>
			<p>
I have the latest edition of my API definition research published, complete with a community-driven participation model, but before I moved on to my design, deployment, and management guides, I wanted to take a moment and connect my OpenAPI toolbox to this research.
My API definition research encompasses any specification, schema, or authentication and access scope used as part of API operations, providing a pretty wide umbrella. I am always on the hunt for specifications, schema, media types, generators, parsers, converters, as well as semantics and discovery solutions that are defining the layers of the API space.&nbsp;
This is one reason I have my OpenAPI Toolbox, which helps focus my research into the fast-growing ecosystem developing around the OpenAPI specification. I'm always looking for people who are doing anything interesting with the OpenAPI specification. When I find one I get to work crafting &nbsp;a title, description, image, and project link so that I can add to&nbsp;the OpenAPI Toolbox YAML file, driving the toolbox website. If you are developing any open tooling that uses the OpenAPI specification please let me know by submitting a Github issue for the toolbox, or if you are feeling brave...go ahead and add yourself and submit a pull request.
My OpenAPI Toolbox is connected to my API definition research at the hip. The toolbox is just a sub-project for my wider API definition research. If you are doing anything interesting with API definitions, schema, or scope please let me know. I am happy to add to my API definition research. The best of the best from my API definition research and the OpenAPI Toolbox will be included in my industry guide, receiving wider distribution than just my network of API Evangelist sites.
[<a href="/2017/03/20/the-openapi-toolbox-and-my-api-definition-research/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2017_03_20_at_9.47.56_am.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/20/google-support-buttons/">Google Support Buttons</a></h3>
			<p><em>20 Mar 2017</em></p>
			<p>I talked about the gap between developer relations and support at Google, something that Sam Ramji (@sramji) has acknowledged is being worked on. Support for a single API can be a lot of work&nbsp;and is something that is exponentially&nbsp;harder with each API and developer to add to your operations, and after looking through 75 of the Google APIs this weekend, you see evidence that Google is working on it. While there are many Google APIs that still have sub-standard support for their APIs, when you look at Google Sheets you start seeing evidence of their evolved approach to support, with a consistent set of buttons that tackle many of the common areas of API support. For general questions, Google provides two buttons linked to StackOverflow: The search just drops you into Stack Overflow, with the tag "google sheets api", and the ask a new question drops you into the Stack Overflow submit new question form. For bug reporting, they provide a similar set of buttons: The search and report bug buttons drop you into the Google Code issues page for Google Sheets, leveraging the issues management for the Gooogle Code repository--something that can just as easily be done with Github issues. Then lastly, they provide a third set of buttons when you are looking to submit a feature: Even though there is a typo on the first button, they also leverage Google Code issue management to handle all feature requests. Obviously working to centralize bug and feature reporting, and support management using Google Code--something I do across all my API projects using Github organizations, repositories, and their issue management. I'm guessing Google Support is tapping into Google Code to tackle support across projects at scale. These support buttons may seem trivial, but they represent a more consistent approach by the API giant to be consistent in how they approach support across their API offerings--something that can go a long way in my experience. It gives...[<a href="/2017/03/20/google-support-buttons/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/api_definitions_2017_03.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/20/api-evangelist-industry-guide-to-api-definitions/">API Evangelist Industry Guide To API Definitions</a></h3>
			<p><em>20 Mar 2017</em></p>
			<p>I keep an eye on over 70 areas of the API sector, trying to better understand how API providers are getting things done, and what services and tooling they are using, while also keeping my perspective as an API consumer--observing everything from the outside-in. The most important area of my research is API definitions--where I pay attention to the specifications, schema, scopes, and other building blocks of the API universe.&nbsp; The way my research works&nbsp;is that I keep an eye on the world of APIs through monitoring the social media, blogs, Github, and other channels of companies, organizations, institutions, and agencies doing interesting things with APIs. I curate information as I discover&nbsp;and learn across the API sector, then I craft stories for my blog(s). Eventually, all of this ends up being published to the main API Evangelist blog, as well as the 70+ individual areas of my research from definition to deprecation.&nbsp; For a couple years now I have also published a guide for the top areas of my research, including API definitions, design, deployment, and management. These guides have always been a complete snapshot of my research, but in 2017 I am rebooting them to be a more curated, summary of each area of my research. My API definition guide is now ready for prime time after receiving some feedback from my community, so I wanted to share with you. I am versioning and managing all of my API industry guides using the Github repositories in which I publish each of my research areas, so you can comment on the API definition guide, and submit suggestions for future editions using the Github issues for the project.&nbsp;My goal with this new edition of the API Evangelist API definition guide is to make it a community guide to the world of API definitions, schema, scopes. So please, let me know your thoughts--it is meant to be a community guide. I am keeping my API definition guide...[<a href="/2017/03/20/api-evangelist-industry-guide-to-api-definitions/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/api_definitions_2017_03.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/20/a-community-strategy-for-my-api-definition-guide/">A Community Strategy For My API Definition Guide</a></h3>
			<p><em>20 Mar 2017</em></p>
			<p>I have tpublished the latest edition of my API definition guide. I've rebooted my industry guides to be a more polished, summary version of my research instead of the rougher, more comprehensive version I've bee publishing for the last couple of years. I'm looking for my guides to better speak to the waves of new people entering the API space, and help them as they continue on their API journey. In addition to being a little more polished, and having more curated content, my API guides are now going to also be more of a community thing. In the past I've kept pretty tight control over the content I publish to API Evangelist, only opening up the four logos to my partners. Using my API industry guides I want to invite folks from the community to help edit the content, and provide editorial feedback--even suggesting what should be in future editions. I'm also opening up the guides to include paid content that will help pay for the ongoing publication of the guides with the following opportunities available in the next edition: One Page Articles - Sponsored suggested topics, where I will craft the story and publish in the next edition of the guide--also published on API Evangelist blog after the guide is published. Two Page Articles&nbsp;- Sponsored suggested topics, where I will craft the story and publish in the next edition of the guide--also published on API Evangelist blog after the guide is published.Sponsor Slot -&nbsp; Sponsor Slot - On the service and tooling pages there are featured slots, some of which I will be giving to sponsors, who have related produces and services. Private Distribution - Allow for private distribution of the industry guide, to partners, and behind lead generation forms, allowing you to use API Evangelist research to connect with customers. Even though I will be accepting paid content within these industry guides, and posts via the blog now, they will all be...[<a href="/2017/03/20/a-community-strategy-for-my-api-definition-guide/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/openapi_spec_structural_improvements.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/16/what-will-it-take-to-evolve-openapi-tooling-to-version-3-0/">What Will It Take To Evolve OpenAPI Tooling to Version 3.0</a></h3>
			<p><em>16 Mar 2017</em></p>
			<p>I am spending some time adding more tools to my OpenAPI Toolbox, and I'm looking to start evaluating what it will take for tooling providers to evolve their solution from version 2.0 of the OpenAPI Spec to version 3.0. I want to better understand what it will take to evolve the documentation, generators, servers, clients, editors, and other tools that I'm tracking on as part of my toolbox research. I'm going to spend another couple of weeks populating the toolbox with OpenAPI solutions. Getting them entered with all the relevant metadata. Once I feel the list is good enough, I will begin reaching out to each tool owner, asking what their OpenAPI 3.0 plans are. It will give me a good reason to reach out and see if anyone is even home. I'm assuming that a number of the projects are abandoned, and even that their owners do not have the resources necessary to go from 2.0 to 3.0. Regardless, this is something I want to track on as part of this OpenAPI toolbox research. The overall architecture of OpenAPI shifted pretty significantly from 2.0 to 3.0. Things are way more modular, and reusable&nbsp;in there, something that will take some work to bring out in most of the tooling areas. Personally, I'm pretty excited for the opportunities when it comes to API documentation and API design editors with OpenAPI 3.0 as the core. I am also hoping that developers step up to make sure that the generators, as well as the server and client code generators become available in a variety of programming languages--we will need this to make sure we keep the momentum that we've established with the specification so far. If you are looking at developing any tooling using OpenAPI 3.0 I'd love to hear from you. I'd like to hear more about what it will take to either migrate your tool from version 2.0 to 3.0&nbsp;or even hear what it will take...[<a href="/2017/03/16/what-will-it-take-to-evolve-openapi-tooling-to-version-3-0/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/bw_google_aws_microsoft.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/16/the-ability-to-deploy-apis-in-aws-google-or-microsoft-clouds/">The Ability To Deploy APIs In AWS, Google, or Microsoft Clouds</a></h3>
			<p><em>16 Mar 2017</em></p>
			<p>I spent a day last week at the Google Community Summit, learning more about the Google Cloud road map, and one thing I kept hearing them focus on was the notion of being able to operate on any cloud platform--not just Google. It's a nice notion, but how real of a concept is it to think we could run seamlessly on any of the top cloud platforms--Google, AWS, and Microsoft.&nbsp; The concept is something I'll be exploring more with my Open Referral, Human Services Data Specification (HSDS) work. It's an attractive concept, to think I could run the same API infrastructure in any of the leading cloud platforms. I see two significant hurdles in accomplishing this: 1) Getting the developer and IT staff (me) up to speed, and 2) Ensuring your databases and code all runs and scales seamlessly whichever platforms you operate in. I guess I'd have to add 3) Ensure your orchestration and continuous integration works seamlessly across all platforms you operate on. I am going to get to work deploying an HSDS compliant API on each of the platforms. My goal is to have just a simple yet complete API infrastructure running on Amazon, Google, and Microsoft. It is important to me that these solutions provide a complete stack helping me manage DNS, monitoring, and other important aspects. I'm also looking for there to be APIs for managing all aspects of my API operations--this is how I orchestrate and continuously integrate the APIs which I roll out. Along with each API that I publish, I will do a write up on what it took to stand up each one, including the cloud services I used, and their API definitions. I am pretty content (for now) on the AWS platform, leveraging Github Pages as the public facade for my projects, and each repositories acting as the platform gears of API code, and definitions. Even though I'm content where I am at, I want...[<a href="/2017/03/16/the-ability-to-deploy-apis-in-aws-google-or-microsoft-clouds/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/autocomplete.gif,qx38712.pagespeed.ce.mdv9wuhtbw.gif" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/16/api-environment-variable-autocomplete-and-tooltips-in-postman/">API Environment Variable Autocomplete And Tooltips In Postman</a></h3>
			<p><em>16 Mar 2017</em></p>
			<p>
The Postman team has been hard at work lately,&nbsp;releasing their API data editor, as well as introducing variable highlighting and tooltips. The new&nbsp;autocomplete menu contains a list of all the variables in the current environment, followed by global variables, making your API environment setups more accessible from the Postman interface. Introducing a pretty significant time saver, once you have your environments setup properly.
This is a pretty interesting feature, but what makes me most optimistic, is when this approach becomes available for parameters, headers, and some of the data management features we are seeing emerge with the new Portman data editor. It all feels like the UI equivalent of what we've seen emerge in the latest OpenAPI 3.0 release, helping us better manage and reuse the schema, data, and other bits we put to use across all of our APIs.&nbsp;
Imagine when you can design and mock your API in Postman, crafting our API&nbsp;using a common vocabulary. Reusing environment variables, API path resources, parameters, headers, and other common elements already in use across operations. Imagine when I get tooltip suggesting that I use Schema.org vocabulary, or possibly even RFCs for a date, currency, and other common definitions. Anyways, I'm liking the features coming out of postman, and I'm also liking that they are regularly blogging about this stuff, so I can keep up to speed on what is going on, and eventually cover here on the blog, and include in my research.
[<a href="/2017/03/16/api-environment-variable-autocomplete-and-tooltips-in-postman/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2017_03_12_at_11.20.06_pm.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/15/tracking-on-licensing-for-the-solutions-in-my-openapi-toolbox/">Tracking On Licensing For The Solutions In My OpenAPI Toolbox</a></h3>
			<p><em>15 Mar 2017</em></p>
			<p>
I wanted to provide an easy way to publish and share some of the tools that I'm tracking on in the OpenAPI ecosystem, so I launched my API toolbox. In addition to tracking on the name, description, logo, and URL for OpenAPI tooling, I also wanted to categorize them, helping me better understand the different types of tools that are emerging. As I do with all my research, I published the OpenAPI Toolbox as a Github repository, leveraging its YAML data core to store all the tools.&nbsp;
It will be a never ending project for me to add, update, and archive abandoned projects, but before I got too far down the road I wanted to also begin tracking on the license for each of the tools. I'm still deciding whether or not I want the toolbox to exclusively contain openly licensed tools, or look to provide a more comprehensive directory of tooling that includes unknown and proprietary solutions. I think for now I will just flag any tool I cannot find a license for, and follow up with the owner--it gives me a good excuse to reach out and see if there is anyone home.
Eventually, I want to also provide a search for the toolbox that allows users to search for tools&nbsp;and filter by license. Most of the tools have been Apache 2.0 or MIT license, details that I will continue to keep tracking and reporting on. If you know of any tooling that employs the OpenAPI Specification that should be included feel free to submit a Github issue for the project, or submit a pull request on the repository and add it to the YAML data file that drives that OpenAPI Toolbox.
[<a href="/2017/03/15/tracking-on-licensing-for-the-solutions-in-my-openapi-toolbox/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/schema-org/schema-org.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/15/thinking-about-schema-org039s-relationship-to-api-discovery/">Thinking About Schema.org&#039;s Relationship To API Discovery</a></h3>
			<p><em>15 Mar 2017</em></p>
			<p>I was following the discussion around adding a&nbsp;WebAPI class to Schema.org's core vocabulary, and it got me to think more about the role Schema.org has to play with not just our API definitions, but also significantly influencing API discovery. Meaning that we should be using Schema.org as part of our OpenAPI definitions, providing us with a common vocabulary for communicating around our APIs, but also empowering the discovery of APIs.&nbsp; When I describe the relationship between Schema.org to API discovery, I'm talking about using the pending WebAPI class, but I'm also talking about using common Schema.org org within API definitions--something that will open the definitions to discovery because it employs a common schema. I am also talking about how do we leverage this vocabulary in our HTML pages, helping search engines like Google understand there is an API service available: I&nbsp;will also be exploring how I can better leverage Schema.org in my APIs.json&nbsp;format, better leveraging a common vocabulary describing API operations, not just an individual API. I'm looking to expand the opportunities for discovering, not limit them. I would love all APIs to take a page from the hypermedia playbook, and have a machine readable index for each API, with a set of links present with each response, but I also want folks to learn about APIs through Google, ensuring they are indexed in a way that search engines can comprehend. When it comes to API discovery I am primarily invested in APIs.json (because it's my baby) describing API operations, and OpenAPI to describe the surface area of an API, but I also want this to map to the very SEO driven world we operate in right now. I will keep investing time in helping folks use Schema.org in their API definitions (APIs.json&nbsp;&amp; OpenAPI), but I will also start investing in folks employing JSON+LD and Schema.org as part of their search engine strategies (like above), making our APIs more discoverable to humans as well as...[<a href="/2017/03/15/thinking-about-schema-org039s-relationship-to-api-discovery/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-connection.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/15/the-relationship-between-dev-relations-and-support/">The Relationship Between Dev Relations And Support</a></h3>
			<p><em>15 Mar 2017</em></p>
			<p>I saw an interesting chasm emerge while at a Google Community Summit this last week, while I heard their support team talk, as well as their developer relations team discuss what they were up to. During the discussion, one of the companies presents discussed how their overall experience with the developer relations team has been amazing, their experience with support has widely been a pretty bad experience--revealing a potential gap between the two teams. This is a pretty common gap I've seen with many other API platforms. The developer relations team is all about getting the word out, and encouraging platform usage&nbsp;and support teams are there to be the front line for support&nbsp;and being the buffer between integration, and platform engineering teams. I've been the person in the role as the evangelist when there is a bug in an API, and I'm at the mercy of an already overloaded engineering team, and QA staff, before anything gets resolved--this is a difficult position to be in. How wide this chasm becomes ultimately depends on how much of a priority the API is for an engineering team, and how overloaded they are. I've worked on projects where this chasm is pretty wide, taking days, even weeks to get bugs fixed. I'm guessing this is something a more DevOps&nbsp;focused approach to the API life cycle might help with, where an API developer relations and support team have more access to making changes&nbsp;and fixing bugs--something that has to be pretty difficult to deal with at Google scale. Anyways, I thought the potential chasm between developer relations and support was worthy&nbsp;enough to discuss and include in my research. It is something we all should be considering no matter how big or small our operations are. There is no quicker way to kill the morale of your API developer relations and support teams by allowing a canyon like this to persist. What challenges have you experienced when it comes to getting...[<a href="/2017/03/15/the-relationship-between-dev-relations-and-support/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2017_03_12_at_10.50.56_pm.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/15/azure-and-office-apis-in-visual-studio/">Azure and Office APIs in Visual Studio</a></h3>
			<p><em>15 Mar 2017</em></p>
			<p>I was reviewing the latest changes with Visual Studio 2017&nbsp;and came across the section introducing connected services, providing a glimpse of Microsoft APIs baked into the integrated development environment (IDE). I've been pushing for more API availability in IDE's for some time now, something that is not new, with Google and SalesForce having done it for a while, but is something I haven't seen any significant movement in for a while now. I have talked about delivering APIs in Atom using APIs.json, and have long hoped Microsoft would move forward with this in Visual Studio. All APIs should be discoverable from within any IDE, it just makes sense as a frontline for API discovery, especially when we are talking about developers. Microsoft's approach focuses on connecting developers of&nbsp;mobile applications, with "the first Connected Service we are providing for mobile developers enables you to connect your app to an Azure App Service backend, providing easy access to authentication, push notifications, and data storage with online/offline sync". In the picture, you can see Office 365 APIs, but since I don't have Visual Studio I can't explore this any further. If you have any insight into these new connected services features in the IDE, please let me know your thoughts and experiences. If Microsoft was smart, all their APIs would be seamlessly integrated into Visual Studio, as well as allow developers to easily import any other API using OpenAPI, or Postman Collections.&nbsp; While I think that IDEs are still relevant to the API development life cycle I feel like maybe there is a reason IDEs haven't caught up in this area. It feels like a need that API lifecycle tooling like Postman,&nbsp;Restlet Client, and Stoplight are stepping up to service the area. Regardless I will keep an eye on. It seems likno-braineriner for Microsoft to make their APIs available via their own IDE products, but maybe we are headed for a different future where a new breed of...[<a href="/2017/03/15/azure-and-office-apis-in-visual-studio/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2017_03_12_at_9.16.57_pm.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/15/a-tighter-api-contract-with-grpc/">A Tighter API Contract With gRPC</a></h3>
			<p><em>15 Mar 2017</em></p>
			<p>I was learning more about gRPC from the Google team last week, while at the Google Community Summit, as well as the API Craft SF Meetup. I'm still learning about gRPC, and how it contributes to the API conversation, so I am trying to share what I learn as I go, keeping a record for others to learn from&nbsp;along the way. One thing I wanted to better understand was something I kept hearing regarding gRPC delivering more of a tighter API contract between API provider and consumer. In contrast to more RESTful APIs, a gRPC client has to be generated by the provider. First, you define a service in a .proto file (aka Protocol Buffer), then you generate client code using the protocol buffer compiler. Where client SDKs are up for debate in the world of RESTful APIs, and client generation might even be frowned upon in some circles, when it comes to gRPC APIs, client generation is a requirement--dictating a much&nbsp;tighter coupling and contract, between API provider and consumer.&nbsp; I do not have the first-hand experience with this process yet, I am just learning from my discussions last week, and trying to understand how gRPC is different from the way we've been doing APIs using a RESTful approach. So far it seems like you might want to consider gRPC if you are looking for significant levels of performance from your APIs, in situations where you have a tighter relationship with your consumers, such as internal, or partner scenarios. gRPC requires a tighter API contract between provider and consumer, something that might not always be possible, depending on the situation.&nbsp; While I'm still getting up to speed, it seems to me that the .proto file, or the protocol buffer definition acts as the language for this API contract. Similar to how OpenAPI is quickly becoming a contract for more RESTful APIs, although it is often times much looser contract. I'll keep investing time into learning...[<a href="/2017/03/15/a-tighter-api-contract-with-grpc/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/dataeditor.gif,qx38712.pagespeed.ce.jrrfqkxj5z.gif" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/14/getting-our-schema-in-order-with-postman039s-new-data-editor/">Getting Our Schema In Order With Postman&#039;s New Data Editor</a></h3>
			<p><em>14 Mar 2017</em></p>
			<p>
In 2017 I think that getting our act together when it comes to our data&nbsp;schema will prove to be just as important as getting it together when it comes to our API definitions and design. This is one reason I'm such a big fan of using OpenAPI to define our APIs because it allows us to better organize the schema of the data included as part of the API request and response structure. So I am happy to see Postman announce their new data editor, something I'm hoping will help us make sense of the schema we are using throughout our API operations.
The Postman data editor provides us with some pretty slick data management UI features including&nbsp;drag and drop, a wealth of useful keyboard shortcuts, bulk actions, and other timesaving features. Postman has gone a long way to inject awareness into how we are using APIs over the last couple of years, and the data editor will only continue developing this awareness when it comes to the data we are passing back and forth. Lord knows&nbsp;we need all the help we can get&nbsp;when it comes to getting our data backends in order.
The Postman data editor makes me happy, but I'm most optimistic about what it will enable, and what Postman has planned as part of their roadmap. They end their announcement with "we&nbsp;have a LOT of new feature releases planned to build on top of this editor, capabilities inspired by things you already do using&nbsp;spreadsheets". For me, this points to some features that would directly map to the most ubiquitous data tools out there--the spreadsheet. With a significant&nbsp;portion of business in the world is done via spreadsheets, it makes the concept of integration into the API toolchain a pretty compelling thing.
[<a href="/2017/03/14/getting-our-schema-in-order-with-postman039s-new-data-editor/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2017_03_12_at_1.24.18_pm.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/13/lots-of-talk-about-machine-learning-marketplaces/">Lots Of Talk About Machine Learning Marketplaces</a></h3>
			<p><em>13 Mar 2017</em></p>
			<p>I spent last week in San Francisco listening to Google's very machine learning focused view of the future. In addition to their Google Next conference, I spent Tuesday at the Google Community Summit, getting an analyst look at what they are up to. Machine Learning (ML) was definitely playing a significant role in their strategy, and I heard a lot talk of machine learning marketplaces. Beyond their own ML offerings like video intelligence and vision APIs, Google also provides you with an engine for publishing your own ML models. They also have a machine learning advanced solution lab, throwing a machine learning hackathon, and pushing a machine learning certification program&nbsp;as part of their cloud and data offerings. As the Google machine learning roadmap was being discussed throughout the day, the question of where can I publish my ML models, and begin selling them, came up regularly--something I feel like is going to be a common theme of the 2017 ML hype. I'm guessing we will see a relationship between the Google ML engine, Google Cloud Endpoints emerge, and eventually some sort of ML marketplace like we have with Algorithmia. We are already seeing this shift in the AWS landscape, between their Lambda, ML, API Gateway, and AWS Marketplace offerings. You see hints of the future in the AWS serverless API portal I wrote about previously. The technology, business, and politics of providing retail and wholesale access to algorithms and machine learning models in this way fascinates me, but as with every other successful area of the API economy, about 90% of this will be shit, and 10% will be actually doing anything interesting with compute&nbsp;and APIs. I'm doing all my image and video texture transfer machine learning model training using AWS and Algorithmia. I then use Algorithmia to get access to the models I've trained, and if I ever want to open up partner level (wholesale), or public (retail) access to my ML Models I...[<a href="/2017/03/13/lots-of-talk-about-machine-learning-marketplaces/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-dna.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/13/greyballing-is-embedded-in-api039s-dna/">Greyballing Is Embedded In API&#039;s DNA</a></h3>
			<p><em>13 Mar 2017</em></p>
			<p>I've been simmering on thoughts around Uber's greyballing&nbsp;for some time now, where they target regulators and police in different cities, and craft a special Uber experience just for them. Targeting users like this are not new, all companies do it, it's just that Uber has a whole array of troubling behavior going on, and the fact that they were so aggressively pushing back on regulators, is why this is such a news story. I'm familiar with this concept because greyballing is embedded in the DNA of APIs, we just call it API management. Every web, mobile, and device that uses an API have a unique fingerprint, identifying the application, as well as the user. Not all apps&nbsp;or users are created equal, and everyone gets's a tailored experience. I wanted to explore the spectrum of experiences I see on a regular basis, helping us all understand how this broadway production works. Greyballing - Uber's situation is focused on creating a special scenario for regulators, but many companies also do this for their competitors, and anyone they see as a threat. Smoke and mirrors for those who threaten you is the name of the game. Sales Funnel - Where are you in my sales funnel? Based upon your application or user fingerprint, and IP address you will receive a different experience, support, and access to resources--the bigger opportunity you are, the better experience you will get. Country - Due to laws in specific countries, platforms have to deliver a different experience based upon the country, and region an application and user are operating within.&nbsp; Virtualization - We regularly create sandboxes, staging, and alternate means of providing an environment for applications and users to operate in, delivering a more virtualized experience, based upon platform objectives. Analytics - Dashboards, analytics, and other visualizations provide us with snapshots of our world. These metrics, KPIs, analytics, visualizations, and other reporting drive everything, even when companies like Facebook and Twitter misreport and...[<a href="/2017/03/13/greyballing-is-embedded-in-api039s-dna/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2017_03_12_at_5.33.25_pm.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/13/airmap039s-api-enabled-digital-notice-and-awareness-system/">Airmap&#039;s API Enabled Digital Notice And Awareness System</a></h3>
			<p><em>13 Mar 2017</em></p>
			<p>I am spending time learning more about what Airmap is doing with their digital notice and awareness system. I first learned about what Airmap was up to when I learned they&nbsp;were behind the notifications of national parks, and forest fires that displayed via the iPhone enabled radio controller for my DJI Phantom 3 Pro drone. I found it to be a pretty slick way to&nbsp;notify me of issues with the drone, my radio signal, and the environment around me, so when I came back to civilization I set out researching more about what Airmap does, staying in tune with what they are up to ever since. Now, Airmap's&nbsp;digital notice and awareness system caught my attention: AirMap&rsquo;s Digital Notice &amp; Awareness System works by sending an encrypted digital flight notice from a drone operator to a secure airspace management dashboard accessible by airspace authorities. Moving this beyond just the drone operator getting notifications about device or environmental conditions based upon my latitude, longitude, and elevation. This system allows for an event driven notification system to be put in place between drone operator(s) and the cloud, modeling an airplane flight control system, but for the drone universe.&nbsp; For me, this is just one possible control system for drones--a cloud, mobile, and device based flight control system. I'm thinking about movie production, agricultural, mining, disaster, and many other types of control systems. Airmap&nbsp;provides you with some of the APIs you will need to develop a drone platform and/or application(s) that will deliver in these areas: Status API - Provide nearby airspace information, including advisories, and notice requirements. Airspace API - Interact with the surrounding airspace including its obstacles, rules, and requirements. Flight API - Create and query flights, verify a pilot meets flight requirements, and provide digital notice. Pilot API - Manage a pilot's profile, preferences, and provide identity verification. Aircraft API - Information about drone manufacturers, models, and metadata. Maps - Provides a TileJSON spec map style...[<a href="/2017/03/13/airmap039s-api-enabled-digital-notice-and-awareness-system/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-connect-the-dots.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/10/telling-a-more-complete-story-with-hypermedia/">Telling A More Complete Story With Hypermedia</a></h3>
			<p><em>10 Mar 2017</em></p>
			<p>I spend a lot of time connecting the dots with APIs, trying to understand what resources are available via an API, and then how I can actually put them to use. I can usually land the documentation page of an API, and be up to speed about what resources are available, and have a basic level of understanding of how I can put the APIs to work withing 15 minutes--if the API is reasonably designed, and somewhat documented. Where things get tougher for meÂ and require much heavier of a cognitive load, is going from the basicsÂ to understanding what is possible when you can really connect the dots between all the APIs a provider makes available. While I was profiling, and learning more about the AWS API Gateway, which is an API that let's you deploy and manage your APIs, I found that their usage of the hypermedia format HAL, significantly contributed to me going from basicsÂ to aÂ better understanding the big picture, and what is possible at scale. Each API path I learned about gave me a wealth of links describing what was possible next, providing details on what I should be doing next, perpetually introducing and teaching me about what is possible with the AWS API Gateway. I am hyper aware of the cost of getting up and running using an API. As a one person shop, reviewing thousands of APIs, my time is precious. I've looked at all of the AWS APIs, and it's easy to get a basic understanding of the resources available with their classic action= approach, but I rarely ever see the big picture of what is possible with the API. After spending the same amount of time in the AWS Gateway API as I would have spent learning any of the other AWS APIs, I found that I had a much greater understanding of what was possible, due to the presence of the hypermedia design pattern. Hypermedia provides a much...[<a href="/2017/03/10/telling-a-more-complete-story-with-hypermedia/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-toolbox.jpg" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/10/focus-on-having-a-robust-and-diverse-api-toolbox/">Focus On Having A Robust And Diverse API Toolbox</a></h3>
			<p><em>10 Mar 2017</em></p>
			<p>I'm learning a lot about HTTP/2 and gRPC this week, so I have been thinking about how we isolate ourselves by focusing in on individual toolsets, where we should really be expanding our horizons, helping ensure we have the most robust and diverse API toolbox we possibly can. Depending on what part of the tech universe an engineer comes from they'll have a different view on just exactly what I mean when I say API to them. The most common perspective that people respond with is REST. Folks automatically think this is what I mean when I say API--it isn't. That is your dogma&nbsp;or your gullibility to other people's dogma--please expand your horizons. When I say APIs, I mean an application programming interface that leverages web technology (aka HTTP, HTTP/2). Sure REST is the dominating philosophy in this discussion, but I see no benefit in limiting ourselves in this fashion--I see API as a toolbox, with the following toolsets: REST - Considering Roy Fielding's&nbsp;guidance when it comes to leveraging HTTP in my API design. Hypermedia - Considering the web, and the role that links can play in your API design. Webhooks - Helping keep APIs a two-way street, expanding your API to respond to events not just single requests. GraphQL - Helping put powerful query tooling in the hands of API consumers when working with large and complex datasets. gRPC - Acknowledging that the HTTP protocol is evolving, and our API contract can evolve along with the specification. This represents the major toolsets that are currently in my API toolbox. Sure there are a number of other individual tools and specifications in there as well, but this represents the top tier toolsets I am looking at when it comes to getting things done. In my opinion, there is a time and place for each of these toolsets to be put to use. I can easily geek out on any of these areas, but because I'm...[<a href="/2017/03/10/focus-on-having-a-robust-and-diverse-api-toolbox/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/managing_grpc_apis_with_google_cloud_endpoints_3_638.jpg" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/10/api-definitions-covering-both-rest-and-grpc-apis/">API Definitions Covering Both REST and gRPC APIs</a></h3>
			<p><em>10 Mar 2017</em></p>
			<p>I have been learning more about the way Google designs and defines their APIs after their release of their API design guide. When I research a company's APIs I always spend time looking through their Github repositories for anything interesting, and while poking around in Google's I found a repository of "interface definitions for a small (but growing) set of Google APIs". I keep track of any Github repo I find containing API definitions, but Google's repo stood out because it contained a set of API definitions that covered both APIs that support both REST and gRPC. Straight from the Github repo, they support two ways of access APIs: "Google APIs use&nbsp;Protocol Buffers&nbsp;version 3 (proto3) as their Interface Definition Language (IDL) to define the API interface and the structure of the payload messages. The same interface definition is used for both REST and RPC versions of the API, which can be accessed over different wire protocols." JSON over HTTP: You can access Google APIs directly using JSON over HTTP, using&nbsp;Google API client libraries&nbsp;or third-party API client libraries. Protocol Buffers over gRPC: You can access Google APIs published in this repository through&nbsp;GRPC, which is a high-performance binary RPC protocol over HTTP/2. It offers many useful features, including request/response multiplex and full-duplex streaming. This is the first example of this I've seen in the wild, and it feels like we are shifting from an HTTP to an HTTP/2&nbsp;API world. I don't think regular old REST or web APIs are going anywhere, I think they'll continue to be a staple, but it looks like Google is laying the groundwork for two-speed APIs, that are defined using a common API definition--you pick the speed you need. I've been hearing tales of gRPC usage for a while and seeing more APIs defined using protocol buffers, but Google's approach signals a wider more significant shift for me. I'm still learning about gRPC, so I can't quite visualize the overlap between&nbsp;gRPC and...[<a href="/2017/03/10/api-definitions-covering-both-rest-and-grpc-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/bw_onion.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/09/the-three-layers-of-api-hype/">The Three Layers Of API Hype</a></h3>
			<p><em>09 Mar 2017</em></p>
			<p>I read a lot of content about APIs. I read a lot of redundant and fluffy marketing and technical jargon, trying to understand exactly what an API does, or doesn't do. Before I criticize, I have to admit that crafting really good API marketing and documentation is hard. Only about 5% of what I read is good, a significant portion is just incomplete and lazily done by someone who doesn't care--the rest is actually incorrect, misleading, and straight up hype. There are three layers to the API hype onion in my experience: Marketing - The fluff on the main page written by the marketing team who usually doesn't care about the API and has taken the time to get to know what it does. Documentation - The technical fluff in the API portal usually written by someone technical, and not quite possessing the skills to talk to humans, let alone coherently explain something to another human being. API - The actual naming, ordering, parameters, and overall request and response structure for an API that actually accomplishes something--it may not always accomplish exactly what I'm looking for, but at least it is. While I still read marketing&nbsp;and documentation, because they provide me with clues about the intent behind API operations, when I actually want the honest take of what an API does, I always go straight to the API and get to work making API calls. This is a problem that is only increasing as we enter into the artificial intelligence and machine learning hype phase. After you finish writing the marketing, documentation, and have your API up and running--step back, and re-read everything, and think about the synchronicity between these three areas of your operations. It takes a lot of practice&nbsp;and hard work to do right, but I think if you just take a moment, step back, and think about these layers to how you articulate what your APIs does--you will immediately find yourself in...[<a href="/2017/03/09/the-three-layers-of-api-hype/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-version.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/09/guidance-on-versioning-your-api-from-google/">Guidance On Versioning Your API From Google</a></h3>
			<p><em>09 Mar 2017</em></p>
			<p>I always enjoy learning about how companies are versioning their APIs. The topic is always one of the most discussed areas when we do APIStrat workshops, and is an aspect of the API space that I think there is never a 100% right way of doing things. Making it an area I recommend learning as many different approaches as you can, then decide on the right solution for your particular situation. To help you in your journey, and mine, I try to document any official versioning strategies published by API providers I research. Today I have one from Google, providing some very interesting insight into how they version their APIs. Google uses&nbsp;Semantic Versioning, which follows this approach to each version number MAJOR.MINOR.PATCH, incrementing the: MAJOR&nbsp;version when you make incompatible API changes, MINOR&nbsp;version when you add functionality in a backwards-compatible manner, PATCH&nbsp;version when you make backwards-compatible bug fixes. When it comes to their REST APIs Google puts the version in URL, and I'm still learning more about their approach to how it's applied to the proto package for gRPC APIs. They also have some good advice when it comes to what is breaking and non-breaking changes. Backwards-compatible (non-breaking) changes: Adding an API interface to an API service definition Adding a method to an API interface Adding an HTTP binding to a method Adding a field to a request message Adding a field to a response message Adding a value to an enum Adding an output-only resource field Backwards-incompatible (breaking) changes: Removing or renaming a service, field, method or enum value Changing an HTTP binding Changing the type of a field Changing a resource name format Changing visible behavior of existing requests Changing the URL format in the HTTP definition Adding a read/write field to a resource message This Google API versioning advice comes from their API design guide. I also found some versioning advice from them as part of the Google Cloud Endpoints documentation, which provides...[<a href="/2017/03/09/guidance-on-versioning-your-api-from-google/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/api-evangelist-logos/api-evangelist-butterfly-vertical.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/09/from-awareness-observability-to-api-ratings/">From Awareness, Observability, To API Ratings</a></h3>
			<p><em>09 Mar 2017</em></p>
			<p>This is the third post in my effort to try and define the three sides of my API monitoring. I'm trying to quantify what is needed as a sort of API industry monitoring dashboard -- if there is such a thing. To help me think through this, I have taken my approach to monitoring the API space and I'm breaking them up into three buckets API awareness, API observability, and now API ratings. While the three areas share many common characteristics, the motivations behind each area are significantly different--enough so, I want to look at them and evolve them separately. A rating system for the API space is something I usually get one or two requests to discuss each quarter, sustained throughout the year. I have very different actors approaching me to solve this, from hedge fund managers, to venture capital managers, to startups and enterprise organizations. Everyone (except one) who has approached me to date has been woefully unaware of the scope of doing something like creating a Standard and Poors or Moody's for the API economy, which is always a red flag for me when it comes to understanding their motivations. I do not have the resources to develop an API ranking system on my own, and I have no desire to exclusively own such a thing--it needs to be an open, community driven thing. However, I do have interest it trying to define possible algorithms for such a ranking system, derived from the approach I've developed for myself. I am driving this work from a master dump of my research, and the approach I have used to track on in the world of APIs since 2010--an analyst 100K view, and here is what I'm considering... Discovery -&nbsp;If we are rating APIs, they need to be discoverable, and accessible--if you can't find them, understand what they do, and kick the tires--you really can't rate something. How many APIs? What is churn? Applications&nbsp;- Find...[<a href="/2017/03/09/from-awareness-observability-to-api-ratings/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/ivan_goncharov.jpg" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/08/people-doing-interesting-things-with-apis/">People Doing Interesting Things With APIs</a></h3>
			<p><em>08 Mar 2017</em></p>
			<p>I just wanted to take a moment and highlight some folks who are doing interesting things with APIs. I spend a lot of time focusing on the companies, products, and services from&nbsp;the sector, but I don't talk a lot about individual people. So I wanted to pause for a moment and just highlight a couple of people doing really interesting things with APIs right now.
If have been paying attention to API definitions in the last year, then you probably have come across APIs.guru, the Wikipedia for APIs. They have 244 OpenAPI definitions available in their catalog, which&nbsp;is the most comprehensive directory of machine readable API definitions out there. If you have an OpenAPI for your API you should be publishing it to APIs.guru. if you don't, you should be creating one, and then publishing it to APIs.guru.
Here are the hardworking, API-savvy folks behind APIs.guru:





Ivan Goncharov

Github:&nbsp;https://github.com/IvanGoncharov
Twitter:&nbsp;https://twitter.com/E1Goncharov





Roman Hotsiy 

Twitter:&nbsp;https://twitter.com/RomanHotsiy
Github:&nbsp;https://github.com/RomanGotsiy

&nbsp;




I am in the middle of a project where I am building on the work these two have invested in with APIs.guru. I'm hoping that with the next wave of this work, I'll have some complete API definitions I can contribute to APIs.guru. I encourage you to make sure your API definitions are published to the directory so that other people like me can include your APIs in our work.
Beyond the APIs.guru directory, I recommend checking out their Github repository, as they are doing some interesting things with GraphQL. If you need help crafting an API definition for your API platform, or in need of other API advice, I recommend messaging the APIs.guru team. I'm sure they'd be happy to talk to you, and see where they can help you with your API efforts.
[<a href="/2017/03/08/people-doing-interesting-things-with-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/api_discussions_copper_circuit.jpg" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/08/a-framework-for-our-all-day-api-discussion/">A Framework For Our All Day API Discussion</a></h3>
			<p><em>08 Mar 2017</em></p>
			<p>This is an outline I pulled together for a potential project I am working on this week. It's derived from my research, and previous workshops I've done with companies, organizations, institutions, and government agencies in the past. I wanted to share here, in hopes it would stimulate API-focused conversations with some interesting folks. I put together a framework to guide a full day discussion between us, which will leave you with a greater awareness of what an API focus can bring to your company, and leave you with a strategy that you could apply to your API operations back home. This framework is assembled from the last seven years of monitoring the API practices of leading companies like Amazon, Google, Facebook, Twitter, and others, but tailored to meet the needs of a retail and digital commerce focused company. I don't expect you to digest everything here in a single reading, it is the complete list of building blocks which we will move around, and organize in a guide for you to take back with you. API 101I wanted to start with the basics&nbsp;and help provide you and your organization grasp the fundamental concepts of why having an API focus is important to doing business in 2017. It is important that all stakeholders have a base level awareness of the what and why of APIs are, as well as the technical, business, and legal implications of API operations. Here is an outline for our discussion: What Is API?&nbsp;- Discuss your overall web strategy, and discuss how your API operations will augment, complement, and extend your web presence. Why do API?&nbsp;- Cover why APIs will help you deliver to web and mobile, as well as bring more flexibility in any&nbsp;system to system integrations internally, and with your partners. API Consumption&nbsp;- Talk about the current and future consumption of 3rd party APIs&nbsp;and from trusted partners, as well as thoughts about internal usage. Providing APIs&nbsp;- Talk about the overall...[<a href="/2017/03/08/a-framework-for-our-all-day-api-discussion/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/sonossystem.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/07/there-is-more-to-this-than-just-having-an-api/">There Is More To This Than Just Having An API</a></h3>
			<p><em>07 Mar 2017</em></p>
			<p>There is a reason why I encourage API providers to look at not just the technology of APIs&nbsp;but also invest heavily into the business and politics of API operations. There is a reason I evangelize a more open, web-based approach to doing APIs, even if you are peddling hardware and device APIs. It is because there are a number of human-centered elements present when doing APIs, that will&nbsp;define your services, and ultimately contribute to whether or not they are a success&nbsp;or a failure. One example of this from my API news curation archives is from the Sonos API ecosystem, and a pretty big blunder in communication the audio device platform made late last year, that is significantly impacting their partnerships in 2017. &nbsp;Directly from the CEPro article: A collective cheer roared from home-technology installers at&nbsp;CEDIA Expo 2016, when&nbsp;Sonos announced an API&nbsp;for home-automation integration starting with&nbsp;Control4&nbsp;(Nasdaq:&nbsp;CTRL),&nbsp;Crestron,&nbsp;iPort,&nbsp;Lutron&nbsp;and&nbsp;Savant. These partners &ndash; and most other respectable smart-home systems providers &ndash; have integrated with Sonos for many years, albeit with unsanctioned drivers created through reverse-engineering of a fairly straightforward UPnP-based protocol. But the new API kind of snuck up on dealers and vendors alike, with their customers waking up to a brand new&nbsp;Sonos&nbsp;experience in late December, courtesy of an auto-update by Sonos. The new experience was inferior to the original, with users unable to access Spotify or Amazon Music from the home automation system, except to select favorites created through Sonos&rsquo;s own app. When you are operating an API that many different businesses depend on, communication is essential. this is why I advocate that API providers always have a clear communication and support strategy, as well as the road map, issue management, and change log processes. Every single change has to be considered for its impact on the community, and you have to have a plan for how you will be communicating and supporting&nbsp;your API consumers needs around a change.&nbsp; This is also why API providers should be understanding the...[<a href="/2017/03/07/there-is-more-to-this-than-just-having-an-api/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2017_03_05_at_6.44.14_pm.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/07/the-tyk-wordpress-api-portal/">The Tyk Wordpress API Portal</a></h3>
			<p><em>07 Mar 2017</em></p>
			<p>
I am finally seeing more solutions available for API providers when it comes to publishing an portal for their API operations. I've long had my minimum viable API portal definition, which I recently deployed to support the Miami Open211 API, and I also wrote about AWS serverless approach to an API portal. Next up, is a WordPress solution from my API management partner Tyk.
The WordPress API portal solution has the following features:

Automatic developer registration on Tyk when developers sign up in WP
Configuration of API policies available for token registration
Developers may request an access token for the available API policies
Automatic or manual approval of key requests
Storage of token (references) by name and API policy
Revoking of tokens by developer
Display usage statistics per key
Request quota usage per key

All the basics you need when standing up a basic API operation. If WordPress is your go-to content management system, then it might make sense for you to think about API portal&nbsp;in these terms. The&nbsp;Swiss Federal Railways (SBB-CFF-FFS)&nbsp;is already using the plugin&nbsp;in production, and you can download the plugin on Github, or find it over at WordPress.org.
We need multiple versions of API portals like this, designed for every type of platform a company, organization, institution, and government agency might be already using as a default platform for their operations. This is why API management providers need to follow Tyk's&nbsp;lead and make sure your solution is API driven--practicing what you preach so that your API management solution can be integrated anywhere.


[<a href="/2017/03/07/the-tyk-wordpress-api-portal/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/company/logos/grpc.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/07/i-am-learning-about-grpc-apis-from-google/">I Am Learning About gRPC APIs From Google</a></h3>
			<p><em>07 Mar 2017</em></p>
			<p>I have been processing Google's API design guide, and an unexpected part of the work has been learning more about gRPC, which Google is&nbsp;"converging designs of socket-based RPC APIs with HTTP-based REST APIs." -- something I have not seen in an API design guide until now. "gRPC uses&nbsp;protocol buffers&nbsp;as the Interface Definition Language (IDL) for describing both the service interface and the structure of the payload messages", and is something I'm hearing more chatter about from larger providers, which I think represents the evolving world of API design beyond the old REST days. According to the site, "gRPC is used in last mile of computing in mobile and web client since it can generate libraries for iOS and Android and uses standards based HTTP/2 as transport allowing it to easily traverse proxies and firewalls. There is also work underway to develop a JS library for use in browsers. Beyond that, it is ideal as a microservices interconnect, not just because the core protocol is very efficient but also because the framework has pluggable authentication, load balancing etc. Google itself is also transitioning to use it to connect microservices." To help me learn anything I need an example to reverse engineer, showing me how things work--so here are the examples they provide from the site: Google Cloud BigTable Client APIs Google Cloud PubSub APIs Google Cloud Speech APIs I'm going to add a research area for gRPC, similar to hypermedia, as well as GraphQL. It helps me better keep track of the&nbsp;news&nbsp;about each approach to crafting APIs, and a single place I can go to reference service providers, and working examples. I've had gRPC / Protocol Buffers on my monitoring list for some time now, but seeing Google invest so heavily in this area gives me a signal that I should be paying attention to gRPC more, and gathering more examples that I can share with my readers. I'm thinking that I will assemble some sort...[<a href="/2017/03/07/i-am-learning-about-grpc-apis-from-google/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2017_03_04_at_10.46.01_pm.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/06/thinking-about-openapi-provenance/">Thinking About OpenAPI Provenance</a></h3>
			<p><em>06 Mar 2017</em></p>
			<p>
I am building on the great work by the APIs.guru team, assembling a collection of Google definitions. I will be forking their Google Open definitions and wrap them in APIs.json indexes, so I can analyze the APIs at the 100K level, and potentially augment, and enrich the existing OpenAPIs that the APIs.guru team has worked so hard on.&nbsp;
When APIs.guru crafts an OpenAPI for an API, they have a set of OpenAPI extensions that&nbsp;provides a snapshot of the history for each OpenAPI. They provide six OpenAPI extensions, specific to their API discovery objectives:
x-apiClientRegistration:&nbsp; &nbsp; &nbsp;url: 'https://console.developers.google.com' x-logo: &nbsp; &nbsp; &nbsp;url: 'https://www.gstatic.com/images/icons/material/product/2x/blogger_64dp.png' x-origin: &nbsp; &nbsp; &nbsp;format: google &nbsp; &nbsp; &nbsp;url: 'https://www.googleapis.com/discovery/v1/apis/blogger/v3/rest' &nbsp; &nbsp; &nbsp;version: v1 x-preferred: true x-providerName: googleapis.com x-serviceName: blogger
I like that they include the origin of thier API definitions. I want to do the same, but I would like to turn x-origin into a collection so that I can add multiple entries into it, and evolve it beyond just origin. I want to show the provenance for the API definition, that I build mine on top of APIs.guru's hard work, and that they built theirs on Google's using their discovery format. I'm going to add x-provenance to mine&nbsp;and start tracking on the source of where my API definitions originate and include anything else present when I imported.
It is important that we are able to have many different copies of an API's definition, in a variety of formats. There will be copies of API definitions all over Github, and the web, for a variety of different purposes. I'd like to see more stewards of API definitions include some sort of origin, provenance, and history for their API definitions. If they are yours, they are authoritative and it isn't necessary, but if they are for 3rd party APIs, try to capture as much information as you can about where it comes from, to help everyone understand it's history.
[<a href="/2017/03/06/thinking-about-openapi-provenance/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/materia_screen_entities.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/06/please-develop-an-embeddable-open-source-visual-api-editor/">Please Develop An Embeddable Open Source Visual API Editor</a></h3>
			<p><em>06 Mar 2017</em></p>
			<p>This is a repeat story of one I&nbsp;wrote two years ago, but things haven't changed so I'm going to rant about again, 2017 style. We need someone to develop an open source, visual API design editor. There is the Swagger Editor, but that is more a web IDE, and I'm looking for a well designed, intuitive, visual editor for managing your OpenAPI definitions, that is embeddable and easily integrated into any web or mobile system. There are examples of nice visual API design editors with some of the leading API service providers, but I'm looking for something any API service provider could put to work. I included these examples in my last story, except I'm including Stoplight this round instead of Gelato, because they gave me an upgrade my account message,&nbsp;and wouldn't let me see the interface. These are currently my favorite three API design editors: Restlet&nbsp;- A design, deployment, management service provider. APIMATIC&nbsp; - An SDK, API definition transformer, and continous integration provider. Stoplight&nbsp;- An API design, definition, documentation, and orchestration provider. I enjoy using all three of their API design interfaces. They are well thought out&nbsp;and provide what you need to design new APIs, as well manage the design of your existing APIs. While they are doing a good job at this, it is something I'd like to see standardized, and open sourced, so that other service providers do not have to reinvent the wheel here. We shouldn't have to use a different API design interface for each service we depend on, we need a common editor, making things more familiar.&nbsp; Ok, rant over. This is something I'll keep talking about until there is a solution. Oh, I have to say, I am impressed with what the Materia&nbsp;team has done for API design on the desktop. Between them and Stoplight, there has been positive motion forward. I'm just looking to give things another nudge and help folks understand the opportunity. I'll explore possible...[<a href="/2017/03/06/please-develop-an-embeddable-open-source-visual-api-editor/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2017_03_04_at_11.11.44_pm.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/06/do-you-have-an-api-design-guide-for-your-operations/">Do You have An API Design Guide For Your Operations?</a></h3>
			<p><em>06 Mar 2017</em></p>
			<p>Everyone developing APIs struggles with API design. Ok, maybe a few of the gurus out there don't, but the rest of us need education, practice, and ideally someone or something to help guide us through the best practices when it comes to API design. I try to track what different companies are doing when it comes to API design, and maintain a list of any API design guides I come across in my work. If you are looking to start getting a grasp on API design at your company, organization, institution or agency, I recommend starting on the journey to define your own API design guide--you will be surprised what you can learn along the way. You can kick things off by visiting my API design research, but I strongly recommend you head over to the API Stylebook, and build on this important work. My friend Arnaud has aggregated 12 of the leading API design guides out there and is currently processing Google's API design guide, adding more knowledge&nbsp;to the repository. He takes each API design guide and breaks them down into common API design topics that you can consider as part of your own process, and resulting guide. His work is all machine readable and forkable so that you can easily assemble your own guide, and get to work learning, defining, and refining--then you can submit your guide to the API Stylebook when you are ready. API design and API definitions are the top two most trafficked areas of my website in 2017, and most of 2016. API design is top of mind for API providers who are further along in their journey, and the ones who are seriously rocking it usually have some sort of guide, helping keep things consistent. If you need any help, feel free to reach out. I am not an API design expert, but I know my way around the finer details, and concepts at play, and I'm happy...[<a href="/2017/03/06/do-you-have-an-api-design-guide-for-your-operations/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-integration-automation.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/03/i-want-to-just-post-information-directly-to-your-api-platform/">I Want To Just POST Information Directly To Your API Platform</a></h3>
			<p><em>03 Mar 2017</em></p>
			<p>I was dreaming of a more modular, event-driven approach to API monetization&nbsp;the other day, and I found myself thinking more about the motivations behind each API call made, from the perspective of both the consumer and the provider. With this story I am just thinking about just the POST, or how we usually add something to a system via API--this is not always the case, but it is the common usage of the verb.&nbsp; I don't have any numbers to support this, but the majority of APIs I encounter are GET only. The more mature API platforms have diverse stacks, using their verbs, but when companies are just getting going with their API operations, they rarely use POST, PUT, PATCH, and DELETE. When it comes to having APIs, and incentivizing developers to generate some&nbsp;value using APIs, it seems like a company wants to encourage the creation of valuable data and content. I was talking with Lufthansa Airlines the other day, and one of the things that they said to me that stood out&nbsp;when we were talking about the different APIs available, was that none of them matter if someone doesn't buy (POST) a ticket. Today, while on the phone with one of my partners, they asked if they could put my industry guides behind a lead generation form--something I allow my partners do. However, I wish more of them had a POST path for me to submit new leads, share stories, topics, and other times, for a variety of reasons--I promise would help generate value with each API call. With this work I am ramping up for my API monetization and API plan research, thinking about the bigger picture of how we generate value, as well as make money doing all of this. I guess that I am just lamenting the stagnation of how APIs are being designed, and deployed, with any sensible or even creative monetization strategies. To help me get through this I...[<a href="/2017/03/03/i-want-to-just-post-information-directly-to-your-api-platform/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2017_03_01_at_10.08.35_pm.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/03/google-shares-their-api-design-guide/">Google Shares Their API Design Guide</a></h3>
			<p><em>03 Mar 2017</em></p>
			<p>Google released an API design guide recently. I'll be adding the design guide to the list of examples I have in my API design research. The Google API design guide is pretty straight forward in its purpose, with a goal of helping, "developers design&nbsp;simple, consistent and easy-to-use&nbsp;networked APIs", but I thought it was noteworthy that they were also looking to help "converging designs of socket-based RPC APIs with HTTP-based REST APIs." gRPC and Protocol Buffers has been on my task list to learn more about for a while now, but without any projects at scale, it's probably not a task I'll find much time for anytime soon. I'll try to carve off more time to learn how folks like Google are doing it, through their guides and storytelling. One thing I did know, which Google reinforces is that"many companies use socket-based RPC APIs to carry most network traffic, which can be orders of magnitude higher than public REST APIs." I like&nbsp;their approach that, "both RPC APIs and HTTP REST APIs are needed for various reasons. Ideally, an API platform should provide best support for all APIs". They also provide a note that "This Design Guide explains how to apply REST principles to API designs independent of programming language, operating system, or network protocol. It is NOT a guide solely to creating REST APIs." I like this because we are getting past the notion that API design is simply about REST--it is clearly evolving to be more about getting the work&nbsp;done&nbsp;than any single philosophy or dogma. In addition to encouraging more API providers to craft an API design guide for their companies using API Stylebook, and sharing their API design guides with the public, I will also be encouraging companies to think beyond just REST when they consider their API design best practices. I'm hoping that more companies will continue to do the hard work of getting their API design house in order&nbsp;because that means they...[<a href="/2017/03/03/google-shares-their-api-design-guide/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2017_03_01_at_10.46.36_pm.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/03/deploy-a-grape-doorkeeper-driven-api-to-heroku-with-a-click-of-a-button/">Deploy A Grape Doorkeeper Driven API To Heroku With A Click Of A Button</a></h3>
			<p><em>03 Mar 2017</em></p>
			<p>There have been many advances in the way that we deploy APIs in the last couple of years, but I still want more of an embeddable, push botton way to deploy generic or even more specialized APIs. This is something I've ranted about before, asking where the deploy to AWS and Google buttons. I'm seeing more AWS solutions emerge, helping deploy from Github using AWS Codeploy, and the regular number of deploy to Heroku buttons, but not the real growth I'd like to see occur--making it a drum I will keep beating&nbsp;until I get what I want. I was working on my OpenAPI toolbox, cataloging open source tools that put the OpenAPI specification to work, and came across a deploy with Heroku button for the Grape Doorkeeper, which helps you "create an awesome versioned API, secured with OAuth2 and automatically documented". This should be the&nbsp;default for all server-side API deployment frameworks, allowing push button deployment of any open source API framework to the cloud platform of your choosing. If I have my way, it won't just be API frameworks that will have deployment buttons. Specialized API designs, available in a variety of frameworks will be available for deployment with a single click of a button. We should be able to deploy a product API, or a user API, to AWS, Heroku, Google, or Microsoft, with a single click. There should be a wealth of open source templates for us to choose from on Github, with deploy buttons, and easy to follow wizards that help us set things up properly. Smells like an opportunity to me. I'll have to think more about where the revenue would come from in such a model, but I'm sure it would be easy enough to upsell deployments to some premium features and services. I understand that both the areas of API design and API deployment are playing catch-up with API management at the moment, but someone needs to get to...[<a href="/2017/03/03/deploy-a-grape-doorkeeper-driven-api-to-heroku-with-a-click-of-a-button/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2017_03_01_at_9.03.53_pm.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/02/my-developer-portal-checklist-for-a-human-services-api/">My Developer Portal Checklist For A Human Services API</a></h3>
			<p><em>02 Mar 2017</em></p>
			<p>I was handed the URL for a human services API implementation for Miami. It was my job to now deploy a portal, documentation, and other supporting resources for the API implementation. This project is part of the work I'm doing with Open Referral to help push forward the API conversation around the human services data specification (HSDS). I got to work forking my minimum viable API portal definition, to provide a doorway for the Miami Open211 API. &nbsp;Next, I got to work on setting up a basic presence for the human services API. I started with giving the portal a title, and a basic description of what the service does, then I got to work on each of the portal elements that will help people put the data to work. Getting StartedIt can be hard to cut through what you need to get going with an API&nbsp;and cut through all the information available. The portal has a getting started page providing a basic introduction, a handful of links to the documentation, code, and where to get help--the page is driven from a YAML data store available in the _data folder for the repository. AuthenticationI included an authentication page to make it clear that the API is publicly available, but also provide a placeholder to explain that we will be opening up write access to the organizations, locations, and services that are being made available--the page is driven from a YAML data store available in the _data folder for the repository. Frequently Asked QuestionsNext, I wanted to always have the most frequently asked questions front and center where anyone can find it. I am using this page as a default place to publish any questions asked via Github, Twitter, or email. The page is driven from a YAML data store available in the _data folder for the repository. DocumentationNow for the documentation, the most important piece of the puzzle. I published a Liquid documentation driven by...[<a href="/2017/03/02/my-developer-portal-checklist-for-a-human-services-api/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-documentation-interactive.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/02/getting-back-to-work-on-my-openapi-toolbox/">Getting Back To Work On My OpenAPI Toolbox</a></h3>
			<p><em>02 Mar 2017</em></p>
			<p>I used to have a Github repository dedicated to Swagger tooling and implementations, but I took it down after Swagger was donated to the Linux Foundation. I've rebooted it as my OpenAPI Toolbox, providing a single Github repository for managing an active list of open source tooling built on top of the OpenAPI specification.
Here is a snapshot of my toolbox of OpenAPI-driven solutions, as it stands today. This site is a Jekyll-driven website running on Github, using Github Pages. The tools in this toolbox are driven by a YAML file in the _data folder for this repository, with the HTML pages driven using Liquid.
Here are the tools organized by type of implementation (something that is evolving quickly):















Documentation


Generators


Servers









&nbsp;



Clients


Editors

&nbsp;



Here they are organized by programming language, providing another dimension to look at the tooling being developed on top of OpenAPI.




 






  
 
  
 
  


 

  
 
  
 
  



This project is forkable using the Github repository, and accessible as JSON. If you have a tool you think should be added, or there is something that needs fixing, you can submit an issue on the Github repository, or submit a pull request. It is meant to be a community project, designed to be forkable, shareable, and machine-readable.
I've just started adding the tools I have in my database. I only have 37 so far, but will be adding more as I have time. Once I have it up to date, I will start thinking about other ways to slice and dice the tools, to better understand what is being built on the OpenAPI specification, what tools are being built on the upcoming 3.0 version, as well as working to identify where the gaps and opportunities are for developing tooling.
[<a href="/2017/03/02/getting-back-to-work-on-my-openapi-toolbox/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-api-operations.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/02/dreaming-of-a-more-modular-event-driven-api-monetization/">Dreaming Of A More Modular Event Driven API Monetization</a></h3>
			<p><em>02 Mar 2017</em></p>
			<p>I was learning about the approach Amazon has taken with their serverless API developer portal, and highlighting their approach to API plans, and couldn't help but think there was more to it all than just rate limiting your API. Amazon's approach to API plans is in alignment with other API management providers, allowing you to deploy your APIs, meter, rate limit, and charge for access to your API--standard business of APIs stuff. Controlling access to a variety of API resources is something that has been well-defined over the last decade by API management providers like 3Scale, and now Tyk&nbsp;and DreamFactory. They provide you with all the tools you need to define access to APIs, and meter access based upon a wide variety of parameters. While I haven't seen the type of growth I expected to see in this area, we have seen a significant amount of growth because API management providers are helping to standardize things--something that will grow significantly because of availability&nbsp;from cloud providers like AWS, Microsoft, and Google. We have a lot of work ahead of us, standardizing how we charge for API consumption at scale. We have even more work ahead of us to realize that we can turn all of this on its head, and start paying for API consumption at scale. I do not understand how we've gotten so hung up on the click and the view, when there are so many&nbsp;other richer, and more meaningful actions already occurring&nbsp;every second, of each day online. We should be identifying these opportunities, then paying and incentivizing developers to consume APIs in most valuable way possible.&nbsp; With modern approaches to API management, we already have the infrastructure in place. We need to just start thinking about our APIs differently. We also need to get better at leveraging POST, PUT, and PATCH, as well as GET, when it comes to paying for consumption. Imagine a sort of event driven API affiliate layer to the&nbsp;web,...[<a href="/2017/03/02/dreaming-of-a-more-modular-event-driven-api-monetization/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2017_02_26_at_3.44.42_pm.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/01/new-york-times-manages-their-openapi-using-github/">New York Times Manages Their OpenAPI Using Github</a></h3>
			<p><em>01 Mar 2017</em></p>
			<p>
I come across more companies managing their OpenAPI definition as a single Github repository. One example of this is from the New York Times, who as the API definitions for their platform available as its own Github repository. It demonstrates the importance of maintaining your API definitions separately from any particular implementation, such as just your documentation.
You can find Individual OpenAPIs for their&nbsp;archive_api, updated description, article_search,books_api, community, geo_api, most_popular_api, movie_reviews, semantic_api, times_tags, timeswire, top_stories&nbsp;broken down into separate folders within the Github repository. The NYT also provides markdown documentation, alongside the machine-readable OpenAPI definition in each folder, helping make sure things are human-readable.
It just makes sense to manage your API definitions this way. It's more than just documentation. When you do this, you are taking advantage of the repository and version control features of Github, but you also open things up for participation through forking and pull requests. The resulting definition and machine readable contract can then be injected anywhere into the integration&nbsp;and API lifecycle, internally or externally.
I personally like it when companies manage their API definitions in this way. It gives me a central truth to work with when profiling their operations, something that will be used across my research and storytelling. The more you describe your APIs in this way, the more chance I will be writing about them&nbsp;and including them across my work.
[<a href="/2017/03/01/new-york-times-manages-their-openapi-using-github/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/github_api_topics.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/01/mapping-github-topics-to-my-api-evangelist-research/">Mapping Github Topics To My API Evangelist Research</a></h3>
			<p><em>01 Mar 2017</em></p>
			<p>I was playing around with the&nbsp;new Github topics, and found that it provides an interesting look at the API space, one that I'm hoping will continue to evolve, and maybe I can influence. I typed 'api-' into Github's topic tagging tool for my repository, and after I tagged each of my research areas with appropriate tags, I set out exploring these layers of Github by clicking on each tag. It is something that became quite a wormhole of API exploration. I had to put it down, as I could spend hours looking through the repositories, but I wanted to create a machine-readable mapping to my existing API research areas, that I could use to regularly keep an eye on these slices of the Github pie--in an automated way. Definitions&nbsp;- These are the topics I'm adding to my monitoring of the API space when it comes to API definitions. I thought it was interesting how folks are using Github to manage their API definitions. api-definition&nbsp;(search via Github topics) api-description&nbsp;(search via Github topics) api-specs&nbsp;(search via Github topics) api-blueprint&nbsp;(search via Github topics) api-transformer&nbsp;(search via Github topics) openapi&nbsp;(search via Github topics) openapi-specification&nbsp;(search via Github topics) openapi-spec&nbsp;(search via Github topics) openapi-validation&nbsp;(search via Github topics) openapi-documentation&nbsp;(search via Github topics) openapi-sampler&nbsp;(search via Github topics) postman-apps&nbsp;(search via Github topics) postman-collection&nbsp;(search via Github topics) api-json&nbsp;(search via Github topics) api-linter&nbsp;(search via Github topics) I like how OpenAPI is starting to branch out into separate areas, as well as how this area touches on almost every other area&nbsp;liste here. I am going to work to help shape the tags present based on the definitions, templates, and tooling I find on Github in my work. Design&nbsp;- There was only&nbsp;one API design related item, but is something I expect to expand rapidly as I dive into this area further. api-design&nbsp;(search via Github topics) I know of a number of projects that should be tagged and added to the area of API design, as well as have a number...[<a href="/2017/03/01/mapping-github-topics-to-my-api-evangelist-research/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2017_02_26_at_7.12.16_pm.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/03/01/a-machine-readable-definition-for-your-aws-api-plan/">A Machine Readable Definition For Your AWS API Plan</a></h3>
			<p><em>01 Mar 2017</em></p>
			<p>
I was learning about the AWS Serverless Developer Portal, and found their API plan layer to be an interesting evolution in how we define the access tiers of our APIs. There were a couple different layers of AWS's approach to deploying APIs that I found interesting, including the AWS marketplace integration, but I wanted to stop for a moment and focus in on their API plan approach.
Using the AWS API Gateway you can establish a variety of API plans, with the underlying mechanics of that plan configurable via the AWS API Gateway user interface or the AWS API Gateway API. In the documentation for the&nbsp;AWS Serverless Developer&nbsp;Portal, they include a JSON snippet of the configuration of the plan for each API being deployed.
This reminds me that I needed to take another look at my API plan research, and take the plan configuration, rate limit, and other&nbsp;service composition API definitions I have, and aggregate their schema into a single snapshot. It has been a while since I worked on my machine-readable API plan definition, and there are now enough API management solutions with an API layer out there, I should be able to pull a wider sampling of the&nbsp;schema in play. I'm not in the business of defining what the definition should be, I am only looking to aggregate what others are doing.
I am happy to see more folks sharing machine-readable OpenAPI definitions describing the surface area of their APIs. As this work continues to grow we are going to have to also start sharing machine-readable definitions of the monetization, plan, and access layers of our API operations. After I identify the schema in play for some of the major API management providers I track on, I'm going to invest more work into my standard API plan definition to make the access levels of APIs more discoverable using APIs.json.
[<a href="/2017/03/01/a-machine-readable-definition-for-your-aws-api-plan/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2017_02_25_at_6.02.50_pm.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/02/28/will-the-experian-api-focus-on-the-people-being-ranked/">Will The Experian API Focus On The People Being Ranked?</a></h3>
			<p><em>28 Feb 2017</em></p>
			<p>I was reading about Experian the credit score company "ventures nimbly into the API economy" this week. I'm happy to see any company begin their API journey, especially companies whose important algorithms impact our lives in such a major way. APIs are critical when it comes to shining a light on how algorithms work and don't work. According to the Experian developer page, "the Experian Connect API provides easy access to embed credit functionality on your websites and mobile apps. Consumer-empowered sharing allows you to create products and services for previously unreachable markets". Sadly I can't see much about the API itself, as you have to fill out a form and request access to see documentation&nbsp;or anything beyond just a basic description. The Experian Connect API says you get access to credit scores and reports, but most of it sounds like your standard marketing speak. I find API documentation and actually playing with an API provide a much more honest take on what's going on. Their approach reflects what I've seen from other very secretive companies who are used to maintaining tight control over their algorithms, processes, and partnerships.&nbsp; Another aspect of the Experian Connect API I noticed as I read was it doesn't focus on solutions for the end-users who is being scored and reported on, it is designed for businesses looking to pull reports on people for a variety of purposes. When you read the story about the Experian API, and the description on the Experian developer page, it is all very business focused--centering on the opportunity for businesses, not the people it scores and ranks.&nbsp; Credit scores are one of the OG big data companies, long tracking information on people, and selling access to business and the government. While Experian's venture into the API economy is worth noting, I'm guessing their API journey won't be a very public one. It's just not in their DNA. I wish they would see the value...[<a href="/2017/02/28/will-the-experian-api-focus-on-the-people-being-ranked/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/aws_serverless_portal.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/02/28/the-aws-serverless-api-portal/">The AWS Serverless API Portal</a></h3>
			<p><em>28 Feb 2017</em></p>
			<p>I was looking through the Github accounts for Amazon Web Services and came across their Serverless API Portal--a pretty functional example of a forkable developer portal for your API, running on a variety of AWS services. It's a pretty interesting implementation&nbsp;because in addition to the tech of your API management it also helps you with the business side of things.&nbsp; The AWS Serverless Developer Portal "is a reference implementation for a developer portal application that allows users to register, discover, and subscribe to your API Products (API Gateway Usage Plans), manage their API Keys, and view their usage metrics for your APIs..[]..it also&nbsp;supports subscription/unsubscription through a SaaS product offering through the AWS Marketplace."--providing a pretty compelling API portal solution running on AWS. There are a couple things I think are pretty noteworthy: Application Backend (/lambdas/backend) - The application backend is a Lambda function built on the aws-serverless-express library. The backend is responsible for login/registration, API subscription/unsubscription, usage metrics, and handling product subscription redirects from AWS Marketplace. Marketplace SaaS Setup Instructions - You can sell your SaaS product through AWS Marketplace and have the developer portal manage the subscription/unsubscription workflows. API Gateway will automatically provide authorization and metering for your product and subscribers will be automatically billed through AWS Marketplace AWS Marketplace SNS Listener Function (Optional) (/listener) - The listener Lambda function will be triggered when customers subscribe or unsubscribe to your product through the AWS Marketplace console. AWS Marketplace will generate a unique SNS Topic where events will be published for your product. This is the required infrastructure we'll need to get to what I've been talking about for some time with my wholesale API and virtual API stack stories. Amazon is providing you with the infrastructure you need to set up the storefront for your APIs, providing the management layer you will need, including monetization via their marketplace. This is a retail layer, but because your&nbsp;infrastructure is setup in this way, there is no...[<a href="/2017/02/28/the-aws-serverless-api-portal/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/api_observability_lighthouse.jpg" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/02/28/a-checklist-for-api-observability/">A Checklist For API Observability</a></h3>
			<p><em>28 Feb 2017</em></p>
			<p>I have had the Wikipedia page for Observability open in a browser tab for weeks now. I learned about the concept from Stripe a while back and is something that I am looking to help define APIs from an external vantage point. In this world of fake news and wild promises of artificial intelligence and machine learning, we need these black boxes to be as observable as they can--I am hoping that APIs can be one of the tools in this observability toolbox. Stripe is approaching this concept from the inside, with a focus on stability and reliability of their API operations. I am focusing on this concept from the outside, to "measure how well internal states of a system can be inferred by knowledge of its external outputs". More of a regulatory, auditing, and journalistic way of thinking, but in the API way of doing things. Some of this is about understanding, but some of it is also about holding providers accountable for what they are peddling. The other day I mapped out what API monitoring means to me, rebranding it as what I'd prefer to call API awareness. I went through the elements I use to understand what is going on with APIs across the sector, but this time I am thinking about them in terms of observability. Meaning, not what I'm doing to be aware of APIs, but what is expected from providers to meet (my) minimum viable definition of a platform being observable. Discovery - Do APIs exist? Are they easily discoverable? Are they public? Can anyone put them to use?&nbsp; Applications&nbsp;- Find new applications built on top of APIs. People&nbsp;- People who are doing interesting things with APIs. Organization&nbsp;- Any company, group, or organization working with APIs. Services&nbsp;- API-centric services that might help solve a problem. Tools&nbsp;- Open source tools that put APIs to work solving a problem. Versions -&nbsp;What versions are currently in use, what new versions are available,...[<a href="/2017/02/28/a-checklist-for-api-observability/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2017_02_25_at_9.00.37_pm.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/02/27/the-api-definition-for-the-tyk-api-gateway/">The API Definition For The Tyk API Gateway</a></h3>
			<p><em>27 Feb 2017</em></p>
			<p>If you are selling a service you should have an API. It is something you hear me talk about a lot here on the blog. I push on this subject because it is important, and there are numerous API service providers out there who do not have an API&nbsp;or choose to not make them available. In a DevOps,&nbsp;continuous integration world, we need the entire stack to have APIs--making our API platforms programmatic, just like the data, content, and algorithms we are making available via the APIs we are deploying. If you need an example of this in the wild, you don't have to look much further than my partner in crime Tyk, who have a simple API for their API gateway--no matter where you deploy the gateway, you can manage it using it's APIs. The&nbsp;Tyk&nbsp;API Gateway API provides you with a base set of paths for you to manage your gateway. An open source, lightweight, fast and scalable API Gateway. Set rate limiting, request throttling, and auto-renewing request quotas to manage how your users access your API. Tyk supports access tokens, HMAC request signing, basic authentication and OAuth 2.0 to integrate old and new services easily. Tyk can record and store detailed analytics which can be segmented by user, error, endpoint and client ID across multiple APIs and versions. Integrate your existing or new applications with Tyk using a simple REST API, Tyk even support hot-reloads so you can introduce new services without downtime. Tyk API Management Paths Available (OpenAPI Spec) /tyk/apis/ -- Get APIs [GET] - Gets a list of *API Definition* objects that are currently live on the gateway /tyk/apis/ -- Create API [POST] - Create an *API Definition* object /tyk/apis/{apiID} -- Delete API [DELETE] - Deletes an *API Definition* object, if it exists /tyk/apis/{apiID} -- Get API [GET] - Gets an *API Definition* object, if it exists /tyk/apis/{apiID} -- Update API [PUT] - Updates an *API Definition* object, if it exists /tyk/health/...[<a href="/2017/02/27/the-api-definition-for-the-tyk-api-gateway/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2017_02_26_at_8.38.50_pm.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/02/27/i-need-your-help-with-my-api-definition-industry-guide/">I Need Your Help With My API Definition Industry Guide</a></h3>
			<p><em>27 Feb 2017</em></p>
			<p>I am approaching seven years doing API Evangelist. I have over 70 areas of my core API lifecycle research available on the website&nbsp;and have four of those areas (definitions, design, deployment, &amp; management) that I've been publishing industry guides for the last couple of years. In 2017, I want to take those guides, and hopefully a handful of other research areas to the next level. My guides have always been about the&nbsp;quantity of information, over the quality of the final guide. I want to turn that on its head and focus on the&nbsp;quality of information and presentation over the quantity, publishing an executive summary of each of my API industry research areas. With my new guide, I am looking to add a touch of design, but I'm also looking to expand&nbsp;the exposure and storytelling opportunities for my partners in the space. Using Adobe In Design I have been able to handle the design enhancements, but I am in need of help making sure my industry guide are ready for consumption by a wider, and more mainstream audience--this is where you come in. I need your feedback. Seriously, I need you to help me with everything copy editing to being&nbsp;an overall critic--let me know what works and what doesn't--I'm looking to make this a community affair. My API Definition research operates as a Github repository, providing access to the data and content behind each area. I use the Github Issues for each of my API research like I would for any other project I'm managing using Github. If you have the time, I would be grateful if you would take look at my API definition guide&nbsp;and submit a single Github issue with your&nbsp;feedback,. I'm even willing to give some exposure in each edition, thanking the folks who helped out in the 'about page' of the guide. Also, if you help out enough I'd be willing to give one of the sponsor slots to your company, project,...[<a href="/2017/02/27/i-need-your-help-with-my-api-definition-industry-guide/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/blog/aws-api-gateway-icon.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/02/27/an-example-of-an-api-service-provider-using-hypermedia/">An Example Of An API Service Provider Using Hypermedia</a></h3>
			<p><em>27 Feb 2017</em></p>
			<p>There&nbsp;is a growing number of hypermedia APIs available in the wild these days. However there aren't a lot of examples of hypermedia API service providers making the API lifecycle&nbsp;more dynamic and living. When people ask me for examples of hypermedia APIs out there I like to have a handful of URLs I can share with them, providing a diverse set they can consider as part of their own operations. One really good example of an API service provider putting hypermedia to use is Amazon Web Services--specifically with the AWS API Gateway. &nbsp;AWS describes it best in the documentation&nbsp;for the gateway API: The Amazon API Gateway web service is a resource-based API that uses Hypertext Application Language (HAL). HAL provides a standard way for expressing the resources and relationships of an API as hyperlinks. Using HAL, you use HTTP methods (GET, PUT, POST, DELETE) to submit requests and receive information about the API in the response. Applications can use the information returned to explore the functionality of the API. If you have used other common AWS APIs like EC2 or S3, then you know that they aren't the best designed APIs out there. They provide a lot of functionality&nbsp;but leave a lot to be desired when it comes to the actual design. The AWS API Gateway API is a well designed, highly functional API for managing the operations of your API. With each API call, you get the desired response, along with a collection of links defining what else is possible. I wish that all tools in our API toolbox were designed like the AWS API Gateway is. In this single API call you can see how hypermedia contributes to the life cycle of any API being managed. You can manage access, and evolve into a staging or production environment, and the other possibilities available when each resource is put to work. Instead of having to go back to the API documentation to learn what options...[<a href="/2017/02/27/an-example-of-an-api-service-provider-using-hypermedia/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/api_platform_upside_down.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/02/20/a-well-thought-out-api-platform/">A Well Thought Out API Platform</a></h3>
			<p><em>20 Feb 2017</em></p>
			<p>
I was playing with one of the API deployment solutions that I track on, appropriately called API Platform. It is an open source PHP solution for defining, designing, and deploying your linked data APIs. I thought their list of features provided a pretty sophisticated look at what an API can be, and was something I wanted to share.

Create a&nbsp;CRUD&nbsp;API in minutes
JSON-LD,&nbsp;Hydra,&nbsp;HAL&nbsp;native support
Automatic&nbsp;Swagger&nbsp;documentation
Built with&nbsp;Symfony&nbsp;and&nbsp;Doctrine
Docker&nbsp;integration
Data validation and error management
Pagination, filtering and sorting
Generate the data model using&nbsp;Schema.org
FOSUser,JWT, CORS and&nbsp;OAuth&nbsp;support
Implements&nbsp;OWASP's recos
Modular
Designed for speed and caching
Behat,&nbsp;PHPUnit&nbsp;and&nbsp;Postman&nbsp;spec &amp; testing
100% open source (MIT)

There are a couple of key elements here. API definition-driven with JSON-LD, Hydra, HAL, and OpenAPI Spec out of box. Containerized. Schema.org FTW! JWT, and OAuth. OWASP's security checklist. Postman Ready! These features make for a pretty compelling approach to designing and deploying your APIs. While I see some of these features in other platforms, it is the first with an open source solution possessing such an impressive resume.&nbsp;
I'm going to take this list and add to my list of API design, and deployment building blocks in my research. These are features that other API deployment solutions should be considering as part of their offering. This approach to API deployment may not be the right answer for every type of API, but I know many data and content focused APIs thatwouldl benefit significantly from a deployment solution like API Platform.
[<a href="/2017/02/20/a-well-thought-out-api-platform/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-two-arrows.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/02/17/api-definitions-influencing-api-design/">API Definitions Influencing API Design</a></h3>
			<p><em>17 Feb 2017</em></p>
			<p>I was having a conversation about whether I should be putting my API definition or my API design work first--which comes earlier in the lifecycle of an API? The conclusion was to put definition first because you need a common set of definitions to work with when designing your API(s). You need definitions like HTTP and HTTP/2. In, 2017 you should be employing definitions like OpenAPI Spec, and JSON Schema. These definitions help set the tone of your API design process. In my opinion, one of the biggest benefits of designing, developing, and operating APIs on the web has been forcing developers to pick up their heads and pay attention to what everybody else is doing and wanting. I suffer from this. Doing web APIs, providing my own, and consuming 3rd party APIs forces me to pay attention to providers and consumers outside my bubble--this is good. Common definitions help us elevate the design of our APIs by leveraging common concepts, standards, and schema. Every time you employ ISO 8601, you have to think about folks in another time zone. Every time you use ISO 4217, you have to think about people who buy and sell their products and services in a different currency than you. When you use Schema.org, your postal addresses considers the world beyond just US zip codes, and consider a world wid web of commerce. I am placing definitions before design in my API research listing. In reality, I think this is just a cycle. Common definitions feed my design process, and the more experienced I get with design, the more robust my toolbox of API definitions gets. Ultimately this depends on what I'm calling a definition, but for the sake of this story I am considering the building blocks of the web as the first line of definitions, then secondarily the definitions that are using OpenAPI Spec and JSON Schema as the next line of definitions. Definitions influence my design process, and the design...[<a href="/2017/02/17/api-definitions-influencing-api-design/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/bw_light_bulb_bright_api.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/02/16/trying-to-define-api-awareness/">Trying To Define API Awareness</a></h3>
			<p><em>16 Feb 2017</em></p>
			<p>I have a regular call with a really smart API person who is trying to move forward a really cool project for the API space. It is some thought provoking voodoo and I need to be able to write about it--this is how I flush out my thoughts and move forward. He is not quite ready to talk about his project publicly, so I will just talk about and explore in terms of my API Evangelist research and how it applies to the area(s) of the API space he is looking to make an impact. This topic spans several areas of my API research, but if I had to give it a single label I would call it API awareness. When you hear me talk about my monitoring the API space, API awareness is the result. I wanted to try and communicate this from my vantage point but also share with other analysts, practitioners, and even the average individual online today. This is my attempt to distil my approach to monitoring the API space and establishing a sustained awareness of APIs at any level. Individual ("Normals")It may sound crazy to you, but everyone should be API aware. No, they should be paying attention to APIs like I do, or even at the level of the average individual working in the tech sector, but they should have a baseline awareness, and here is my attempt at quantifying that: APIs Exist - Everyone should be aware that APIs exist, and hopefully have one or two examples of what they can do in their business or personal lives -- even if it's' just pulling tweets, photos, or getting news updates via an RSS feed. API Integration - Everyone should be aware that they can move data and content between the online services they use and depend on. If you know APIs exist and are aware of services like Zapier or Datafire, you will be more successful in what...[<a href="/2017/02/16/trying-to-define-api-awareness/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/walled_garden_blue_gray_circuit.jpg" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/02/16/api-lifecycle-service-providers-instead-of-walled-gardens/">API Lifecycle Service Providers Instead Of Walled Gardens</a></h3>
			<p><em>16 Feb 2017</em></p>
			<p>It is a common tactic of older software companies to offer open source, services, and tools in a way that all roads just lead into their walled garden. There are many ways to push vendor lock-in and the big software vendors from 2000 through 2010 have mastered how to route you back to their walled gardens and make sure you stay there. Web APIs have set into motion a shift in how we architect our web, mobile, and device applications, as well as providing services to the life cycle that are behind the operation of these web APIs. While this change has the potential to positive it often it can be very difficult to tell apart the newer breed of software companies from the legacy version, amidst all the hype around technology and startups. I've been having conversations recently which are pushing me to think more about middleware, or what I'd refer to as API life cycle tooling. In my opinion, these are companies who are selling services and tools to the API life cycle, which in turn is fueling our web, mobile, device, and other applications. In my opinion, as a server provider, you should be selling to a company and API provider's life cycle needs, not your walled garden needs. I understand that you want all of a companies business, and you want to lock them into your platform, but that was how we did business 10 years ago. The API service providers I'm shining a light on in 2017 are servicing one or many stops along the API life cycle, supporting API definitions, and providing value without getting in the way, or locking customers in. They do this on-premise, or in the cloud of your choice, and allow you to seamless overlap many different API service providers providing a variety of solutions across the API life cycle. You will notice this patterns in the companies I partner with like APIMATIC, Restlet, Tyk, and Dreamfactory. I find I have...[<a href="/2017/02/16/api-lifecycle-service-providers-instead-of-walled-gardens/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2017_02_13_at_10.20.02_pm.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/02/14/box039s-seamless-approach-to-api-documentation/">Box&#039;s Seamless Approach To API Documentation</a></h3>
			<p><em>14 Feb 2017</em></p>
			<p>
The document platform Box updated their developer efforts recently, helping push&nbsp;forward the definition of what API documentation can be. I've long been advocating moving APIs out from the shadow of the developer portal, and make it more seamless with any UI, kind of like CloudFlare does with their DNS dashboard. There is no reason the API should have to be&nbsp;hidden from users--it should be right behind the UI for everyone to discover.
Box does this. You can interact with files just like it is the regular interface. When push the get the folder items, upload file, or other option available to you in the documentation--you get example API request and response in the right-hand column. It is a blend of a regular UI, and some of the attractive and interface documentation we've seen emerge lately like ReDoc. Making it easy to see and understand what an API does, while speaking in the context of solving a relevant problem for a human.
API documentation doesn't have to be overly technical and boring. It can look like a regular user interface, and the API can be right behind the UI curtain, providing a snapshot of the requests and responses that are doing the heavy lifting behind. I'm finally seeing the movement I have wanted to see with API documentation in 2017. I'm feeling like this is going to be common theme with the world of APIs for all of us--we will never see things move as fast as we want, but eventually the world evolves, and we will see investment in the areas that make a difference on the ground at API operations, and for the consumers who are putting APIs to work in their regular world.
[<a href="/2017/02/14/box039s-seamless-approach-to-api-documentation/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/bw_gear_life_cycle.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/02/14/api-lifemiddlewarecycle-api/">API Life(middleware)Cycle API</a></h3>
			<p><em>14 Feb 2017</em></p>
			<p>I have had a series of calls with an analyst group lately, discussing the overall API landscape in 2017. They have a lot of interesting questions about the space, and I enjoyed their level of curiosity and awareness around what is going on--it helps me think through this stuff, and (hopefully) better explain it to folks who aren't immersed in API like I am.  This particular group is coming at it from a middleware perspective and trying to understand what APIs have done to the middleware market, and what opportunities exist (if at all). This starting point for an API conversation got me thinking about the concept of middleware in contrast to, or in relationship to what I'm seeing emerge as the services and tooling for the API life cycle. Honestly, when I jumped on this call I Googled the term middleware to provide me with a fresh definition. Middleware: software that acts as a bridge between an operating system or database and applications, especially on a network. What does that mean in the age of API? Did API replace this? There is middleware for deploying APIs from backend systems. There is middleware for brokering, proxying and providing a gateway for APIs. Making middleware as a term pretty irrelevant. I think middle traditionally meant a bridge between backend and the frontend, where web APIs make things omnidirectional--in the middle of many different directions and outcomes. The answer to the question of what has API done to middleware is just "added dimensions to its surface area". Where is the opportunity? "All along the API lifecycle". Middleware (aka services & tooling) is popping up through the life cycle to help design, deploy, manage, test, monitor, integrate, and numerous other stops along the API life cycle. All the features of our grandfathers API gateway are now available as a microservices buffet, allowing us to weave middleware nuggets into any system to system integrations as well as other web, mobile, and...[<a href="/2017/02/14/api-lifemiddlewarecycle-api/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api-evangelist-site/company/logos/ckan-logo.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/02/14/a-ckan-openapi-spec/">A CKAN OpenAPI Spec</a></h3>
			<p><em>14 Feb 2017</em></p>
			<p>



I was working on publishing an index of the General Service Administration (GSA) APIs I currently have in my API monitoring system, and I remembered that I updated my Data.gov work publishing a cache of the index on Github. Part of this work I had left a note for myself about finding / creating an OpenAPI Spec for the Data.gov API, which since it is a CKAN implementation should be pretty easy--I hoped.
After Googling for a bit I found one created by the French government open data portal&nbsp;-- thank you!!. It looks pretty complete with 102 paths, and 79 definitions, providing a pretty nice jumpstart for anyone looking to documentation their CKAN open data implementation.&nbsp;

This API definition can be used to generate API documentation using Swagger UI or ReDoc, as well as generate SDKs using APIMATIC, and monitoring using Runscope or API Science. If you come across any other API definitions for CKAN, or any interesting documentation and other tools--please let me know, I want to keep aggregating CKAN related solutions.
Open source tools that have APIs, and have open API definitions like this are the future. These are the tools that companies, institutions, organizations, and government agencies should be putting to work in their operations because&nbsp;it helps reduce costs, but also having an API that uses common API specifications means it will speak the same language as other important tools and services, increasing the size of the toolbox available for implementatioperations your API operatons.

[<a href="/2017/02/14/a-ckan-openapi-spec/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/jekyll_open_referral.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/02/13/using-github-as-an-api-index-and-data-store/">Using Github As An API Index And Data Store</a></h3>
			<p><em>13 Feb 2017</em></p>
			<p>I am spending a lot of time studying how companies are using Github as part of their software and API development life cycle, and how the social coding platform is used. More companies like Netflix are using as part of their continuous integration workflow, something&nbsp;that&nbsp;API service providers like APIMATIC are looking to take advantage of with a new wave of services and tooling. This usage of Github goes well beyond just managing code, and are making the platform more of an engine in any continuous&nbsp;integration and API life cycle workflow. I run all my API research project sites on Github. I do this because it is secure&nbsp;and static, as well as introduces a very potent way to not just manage a single website, but over 200 individual open data and API projects. Each one of my API research areas leverages a Github Jeykll core, providing a machine readable index of the companies, news, tools, and other building blocks I'm aggregating throughout my research. Recently, this approach has moved beyond the core areas of my API research&nbsp;and is something I'm applying to my API discovery work, profiling the resources available with popular API platforms like Amazon Web Services, and across my government work like with my GSA index. Each of these projects managed using Github, providing a machine readable index of the disparate APiI, in a single APIs.json index which includes OpenAPI Specs for each of the APIs included. When complete, these indexes can provide a runtime discovery engine of APIs&nbsp;used as part of integrations, providing an&nbsp;index of single APIs, as well as potentially across many distributed APiI brought together into a single meaningful collection. I've started pushing this approach even further with my Knight Foundation funded Adopta.Agency work, and making the Github repository not just a machine-readable index of many APIs, I'm also using the _data folder as a JSON or YAML data store, which can then also be indexed as part of the APIs.json&nbsp;and...[<a href="/2017/02/13/using-github-as-an-api-index-and-data-store/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/curtain.jpg" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/02/13/the-reasons-why-we-pull-back-the-curtain-on-technology/">The Reasons Why We Pull Back The Curtain On Technology</a></h3>
			<p><em>13 Feb 2017</em></p>
			<p>Photo by Shelah I was trying to explain to a business analyst this week the difference between SDK and API, which he said was often used interchangeably by people he worked with. In my opinion SDK and API can be the same thing, depending on how you see this layer of our web, mobile, and device connectivity. The Internet has been rapidly expanding this layer for some time now, and unless you are watching it really don't see any difference between API and SDK--it is just where the software connects everything. For me, an SDK is where the data, content&nbsp;and algorithmic production behind the curtain is packaged up for you -- giving you a pre-defined&nbsp;look at what is possible, prepared for you with a specific language or platform in mind. Most of the hard work of understanding what is going on has been translated and crafted, providing you with a set of instructions of what you can do with this resource in your application--your integration is pretty rigidly defined, not much experimentation or hacking encouraged. An API has many of the same characteristics as an SDK, but the curtain is pulled back on the production a little bit more. Not entirely, but you do get a little more of a look at how things work, what data and content are available, and algorithmic resources are accessible. You still get the view which a provider intends you to have, but there are&nbsp;fewer assumptions about what you'll do with the resources put on the interface, leaving you to do more of the heavy lifting with how these resources will get put to use. Most of the early motivations behind choosing an open approach to web APIs over more closed and as proprietary SDK, pulling back the curtain on how we develop software, weren't entirely intentional. Companies like Flickr and Twitter weren't trying to make their mark on the politics of how we integrate software, they were busy...[<a href="/2017/02/13/the-reasons-why-we-pull-back-the-curtain-on-technology/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/share_bookmarklet_flow.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/02/10/where-are-the-interesting-api-bookmarklet-examples/">Where Are The Interesting API Bookmarklet Examples?</a></h3>
			<p><em>10 Feb 2017</em></p>
			<p>
I have been kvetching about the quality of embeddable tooling out there, so I'm working on&nbsp;discovering anything interesting. I started with bookmarklets, which I think is one of the most underutilized, and simplest examples of working with APIs on the web. Here are a couple of interesting bookmarklets for APIs out there:

Twitter - Probably the most iconic API and bookmarklet out there -- share to Twitter.
Pinboard - An API-driven bookmarklet for saving bookmarks that I use every day.
Hypothesis - A whole suite of API-driven bookmarklets for annotating the web.
Socrata - A pretty cool bookmarklet for quickly viewing documentation on datasets.
Tin Can API - A bookmarklet for recording self-directed learning experiences.

When you search for API bookmarklets you don't get much. Nothing stands out as being innovative. I will keep looking when I have time, and I'll keep curating and understanding any new approaches, and examples, and tooling when possible.
Ultimately it just confounds me, because a simple JS bookmarklet triggering one or more API interactions is a no brainer. We have examples of this in action, making an impact on login, sharing, annotation, and more, so why don't we have more examples? IDK. It is something I'll explore as I push forward my embeddable API research.
Maybe I'm just missing something...
[<a href="/2017/02/10/where-are-the-interesting-api-bookmarklet-examples/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2017_02_10_at_11.56.17_am.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/02/10/what-do-you-get-when-you-search-for-the-schema-org-logo/">What Do You Get When You Search For The Schema.org Logo?</a></h3>
			<p><em>10 Feb 2017</em></p>
			<p>
I spend a lot of time looking for logos of the companies that I write about. A lack of consistency around how companies manage (or don't) their logos, and make them available (or don't) regularly frustrates the hell out of me. While doing my regular work I found myself Googling for the Schema.org logl -- what came up made me smile.
When you Google for Schema.org logo you don't get the logo for Schema.org, you get the schema for a logo, which is the image property of a thing&nbsp;and is used by brands, organizations, places, products, and services. I still had to actually do a separate search to find the Schema.org logo, but it did make me smile, and make me think even deeper about how we manage (or don't) our bits online.
Schema.org is so important. It keeps popping up on my radar, and I'm seeing more examples of it being used as part of JSON-LD API and web search implementations. As I work on my human services data specification&nbsp;(HSDS) project I'm going to carve off time to weave JSON-LD and Schema.org into my storytelling. I can't just show people Schema.org and expect them to understand the importance, I'm going to have to show them with meaningful examples of it working out in the wild.
[<a href="/2017/02/10/what-do-you-get-when-you-search-for-the-schema-org-logo/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2017_02_09_at_12.15.02_pm.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/02/09/having-a-program-for-researchers-baked-into-your-api-operations/">Having A Program For Researchers Baked Into Your API Operations</a></h3>
			<p><em>09 Feb 2017</em></p>
			<p>I wrote about the need for service level agreements dedicated to researchers who are depending on APIs a couple weeks ago, and while I was doing my work profiling of AWS, I came across their approach to supporting research. Amazon has a dedicated program research and technical computing on AWS, where they: "helps researchers process complex workloads by providing the cost-effective, scalable and secure compute, storage and database capabilities needed to accelerate time-to-science. With AWS, scientists can quickly analyze massive data pipelines, store petabytes of data and share their results with collaborators around the world, focusing on science not servers." Amazon has three distinct ways in which they are helping researchers, as well as the industries and people they impact: AWS Research Cloud Program - The AWS Research Cloud Program helps you focus on science, not servers---all with minimal effort and confidence that your data and budget are safe in the AWS Cloud. Government and education-based researchers are eligible to receive program benefits. Apply to join the program, in order to access the AWS Research Cloud Handbook and other cloud resources built for researchers, by researchers. AWS Research Initiative - The AWS Research Initiative (ARI) brings Amazon Web Services (AWS) and the National Science Foundation (NSF) together, with AWS providing AWS Cloud Services through provision of AWS Promotional Credits, awarded to NSF grant applicants to leverage Critical Techniques, Technologies and Methodologies for Advancing Foundations and Applications of Big Data Sciences and Engineering (BIGDATA). Open Data - Organizations around the globe are increasingly making their data open and available for the public to discover, access, and use. This is fueling entrepreneurship, accelerating scientific discovery, and creating efficiencies across many industries. Amazon Web Services provides a comprehensive tool kit for sharing and analyzing data at any scale.&nbsp; Amazon helps researchers by providing them with cloud resources for doing their research, assisting them with the budget of it all, while also opening you up to other grant opportunities,...[<a href="/2017/02/09/having-a-program-for-researchers-baked-into-your-api-operations/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/tyk_variants_1200px.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/02/09/api-management-is-getting-more-modular-and-composable/">API Management Is Getting More Modular And Composable</a></h3>
			<p><em>09 Feb 2017</em></p>
			<p>I've been keeping an eye on the API management space for about seven years now, and I actually have to say, even with all the acquisitions, IPOs, commoditization, etc, I am actually pretty happy with where the sector has evolved. API management always resembled its older cousin the API gateway for me, so when companies like 3Scale started offering a freemium model, that I could deploy in the cloud&nbsp;with a couple lines of code---I jumped on the API management bandwagon. It was easy&nbsp;and gave you all the service composition, onboarding, analytics, and metering tools you needed out of the box. I have been pushing on providers to provide an open source API management solution for quite some time, and providers like WSO2 finally stepped up to bring an enterprise-grade solution to the table, then solutions like API Umbrella also emerged for the government. Now in 2017, we have several open source solutions available to us, which makes me happy, but what I really like is how modular, versatile, and API-driven they are. I'm spending time learning more about my partner's solutions, and today I'm working my way through what is possible with Tyk. Tyk is what API management should be. It has all the user and organization management and assists you with the onboarding, authentication, service composition, rate limiting, and analytics that are core to any API management solution. However, what is really powerful for me is that you can deploy Tyk anywhere in the cloud, on-premise, on-device, and all of its features are API-driven, and interconnected because of it's APIs, webhooks, and other orchestration features. APIs aren't just about deploying a web API on a server, and making it available through a single base URL--they are everywhere, and our management tools need to reflect this. We don't just have a single API stack anymore and we use a handful of 3rd party APIs. We are weaving together many different internal and partner stacks, as...[<a href="/2017/02/09/api-management-is-getting-more-modular-and-composable/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/open_api_initiative_members.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/02/09/api-evangelist-joins-the-open-api-initiative-oai/">API Evangelist Joins The Open API Initiative (OAI)</a></h3>
			<p><em>09 Feb 2017</em></p>
			<p>It was an interesting journey getting the API specification formerly known as Swagger into the Linux foundation last year. After SmartBear donated the spec to the newly formed Open API Initiative, I was considering joining the governing body behind the spec, but with all I had going on last year, I didn't feel it was the right time. Participating in governance groups hasn't really ever been my thing, and there are a handful of large organizations involved, and who am I really? I'm just a single person ranting about APIs. However, in 2017 I am changing my tune and will be joining the Open API Initiative (OAI) It is an important time for API definitions, and there is a lot riding on the success of OpenAPI, as well as API definitions in general. I feel like we need as many voices at the table as we possibly can. We need government agencies, enterprise, small businesses, startups, and individual analysts like myself. I feel pretty strongly that API definitions should be openly licensed, accessible, and following the most commonly used patterns available to us across the API sector. We don't need to all be speaking a different language when it comes to deploying compute resources or working with images, and API definitions are how we get there. After a ramping up period, I will work with OAI on their marketing strategy, helping tell stories, and learn about interesting implementations and use cases when possible--dovetailing nicely with what I am already doing. I'll be tuned into the conversation about the spec, but will definitely be standing off to the side as an observer for quite some time. I'm pretty stoked with what they've done with version 3.0 of the spec, and at this point, I have a lot to learn before I open up my mouth and chime in on anything. I'm just enjoying watching the personalities play out in the Slack room--this stuff should be a...[<a href="/2017/02/09/api-evangelist-joins-the-open-api-initiative-oai/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/apimatic_dx_kits.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/02/08/the-unlimited-possibilities-when-you-become-api-definition-fluent/">The Unlimited Possibilities When You Become API Definition Fluent</a></h3>
			<p><em>08 Feb 2017</em></p>
			<p>
I was a regular check-in&nbsp;with one of my favorite API service providers this week, talking about some of the new features they are rolling out in coming weeks, and they demonstrated for me why API definitions are so important in 2017. &nbsp;APIMATIC got their start deploying SDKs for your API, but have quickly moved into providing API documentation, testing, continuous integration, and some additional stops that they have planned for release in coming months.
As I was sharing how happy I was with their movement into new areas of the API life cycle, and praising their agility&nbsp;when it came to rolling out new features, they responded with:
"The credit goes to machine-readable descriptions. Once you have them then there are endless possibilities. Thanks for motivating us to support all the description formats in first place :-)"
This is why being fluent in API definitions is so important to operating your API, or in APIMATIC's case, operating as an API service provider. There are an increasing number of API providers who support the importing and exporting of API definitions, but nobody has gone full API definition as APIMATIC as. They didn't just center their SDK, documentation, testing and continuous integration solutions around API definitions, they exposed their API definition translation engine as a service called API Transformer, allowing anyone else to follow their lead.
When people first learn about API definitions, the 101 lessons usually center around API documentation, and maybe secondarily the generation of the server or client-side&nbsp;SDKs. However API definitions are rapidly being used for every other stop along the life cycle from design to deprecation, as well as the unknown future stops along the way that only&nbsp;become possible because all your API resources are well defined, and machine-readable. It is this agility and flexibility that I want to incentivize, helping companies be as effective as APIMATIC has been when it comes to delivering new API-driven solutions.

[<a href="/2017/02/08/the-unlimited-possibilities-when-you-become-api-definition-fluent/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2017_02_08_at_8.18.41_am.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/02/08/sharing-compute-costs-for-open-data-and-api-consumers-using-the-cloud/">Sharing Compute Costs For Open Data And API Consumers Using The Cloud</a></h3>
			<p><em>08 Feb 2017</em></p>
			<p>I recently wrote about how Algorithmia offloads the compute costs around machine learning using AWS, structuring their image style transfer modeling so that the consumer pays the cost for deploy an AWS GPU instance. It is an interesting way to shift the burden of paying for the hard costs around API operations.
Another interesting approach I extracted from a story I wrote yesterday is from Amazon Web Services (AWS) with their approach to open data. Amazon Public Datasets are available as Amazon Elastic Block Store (Amazon EBS) snapshots and/or Amazon Simple Storage Service (Amazon S3) buckets. AWS hosts the master copy of the dataset, and when you want to use, you fire it up in your AWS account, and get to work.
I find some of these approaches to managing, and offloading the heavy costs of working with algorithms, datasets, and other resources interesting. I especially find this approach interesting because it is in the service of public data, providing an option for how the private sector can help share the load in managing government, research, and other public data, and offloading the heavy costs to those who are going to put the data to use. 
I will figure out how to add this into my API monetization and plan research. Providing a list of these types of approaches to providing on-premise, wholesale, and containerized or virtualized approaches to making data, content, and algorithms available. I will definitely keep looking for unique approaches to API deployment like this--after a couple of these grabbing my attention, I'm feeling like I am seeing another shift in both the technology and business of how we deploy and consume APIs.
[<a href="/2017/02/08/sharing-compute-costs-for-open-data-and-api-consumers-using-the-cloud/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/push_by_zapier_icon_button.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/02/08/api-embeddables-in-a-conversational-interface-world/">API Embeddables In A Conversational Interface World</a></h3>
			<p><em>08 Feb 2017</em></p>
			<p>I would say that embeddable tooling is one of saddest areas of the API space for me in recent years. When it comes to buttons, badges, widgets, and other embeddable goodies that put APIs work, the innovation has been extremely underwhelming. Login, like, share, and a handful of other embeddable tooling have taken hold, but there really isn't any sort of sophisticated approach to putting APIs to work using web, mobile, browser embeddables.&nbsp; The only innovation I can think of recently is from Zapier with their Push by Zapier solution -- allowing you to orchestrate with the zaps you've&nbsp;creative, putting APIs to work using the variety of recipes they've cooked up. I'm thinking that I will have to step up my storytelling around what is possible with Push by Zapier, helping folks understand the possibilities. Push by Zapier is a Google Chrome extension, making it more browser than embeddable, but the approach transcends embeddable, browser, and even into the conversation (bot, voice, etc.) for me. It's all about getting users frictionless access to API driven actions. Whether you are building Zapier pushes, Alexa Skills, or a Slackbot, you need to trigger, and daisy chain together API driven requests and responses ending in the desired location. I'm just looking for dead simple ways of doing all of this&nbsp;in my browser, embedded on web pages, and anywhere I desire. I'm just looking for a way to embed, link, and display the doorway to meaningful actions that anyone can implement, from wherever they want--where the action takes place is up to the API provider. I want a vocabulary of simple and complex embeddables,&nbsp;either just HTML, some JS, and maybe a little CSS magic to round off. When I explain to someone in a Tweet or email explaining that they can publish a news article to a Google spreadsheet, I want my sentence to accomplish what I'm trying to articulate. I want to be able to speak in API--I...[<a href="/2017/02/08/api-embeddables-in-a-conversational-interface-world/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/beachclouds_clean_view.jpg" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/02/07/maintaining-on-premise-capacity-as-well-as-cloud-expertise/">Maintaining On Premise Capacity As Well As Cloud Expertise</a></h3>
			<p><em>07 Feb 2017</em></p>
			<p>The "cloud" has done some very interesting things for individuals, companies, organizations, institutions, and government&nbsp;agencies, and is something that shouldn't be ignored. However, I watch organizations of all shapes and sizes make a similar mistake when it comes to outsourcing too much of their operations to vendors, and cloud services. Each organization's needs will be different, but technology leaders should be mindful of how they invest in talent, alongside how much they invest in external services. I struggle with this in my own business on a daily basis, but I've also seen small businesses make the same mistake, as well as witnessed the damage of this all the way up the Department of Veterans Affairs (VA) in the federal government. The VA has outsourced it's technological soul to vendors, leaving the ability to make sound architectural choices to those who control the puppet strings outside of the agency. I'm seeing a lot of smaller organizations doing this same thing, but with cloud services (outsource 2.0), instead of the traditional software vendor (outsource 1.0)--outsourcing their technological soul to the cloud. Outsourcing capacity is something I struggle with constantly. There is only so much I can do as a one-person shop, but there is also a limit on what I can spend on services in the cloud, creating a naturally occurring balancing effect. In addition to this natural effect, I am also constantly evaluating what I should be learning myself, and investing in my own internal capacity, as opposed to outsourcing it. I have to be extra careful regarding who I depend on because if service changes, is shut down, or maybe prices me out of range -- it could be pretty damaging to my operations. I am hyper aware of this vicious&nbsp;cycle when it comes to my dependence on the cloud or any single service. I was just having a conversation around the hard decisions that a school district was having to make in this area....[<a href="/2017/02/07/maintaining-on-premise-capacity-as-well-as-cloud-expertise/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/carryload_diego_rivera1.jpg" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/02/07/helping-carry-the-load-when-it-comes-to-public-data-and-apis/">Helping Carry The Load When It Comes To Public Data And APIs</a></h3>
			<p><em>07 Feb 2017</em></p>
			<p>I am finally getting back to my Knight Foundation funded grant work on Adopta Agency, I'm investing some research cycles into finding some tools that civic, science, journalism and other public data activists can put to use in their critical work. We've seen folks rise to the occasion when it came to climate data, helping migrate vital resources from federal government servers, something I'd like to see happen across other business sectors, as well as continue as an ongoing thing throughout this administration, and beyond. I have long been a proponent of the private sector sharing the load when it comes to managing public data and APIs. After leaving DC during the 2013 federal government shutdown I began evangelizing the importance of individuals and companies stepping up to help with the heavy lifting of making sure public data is available when we need it most--resulting in my Adopta.Agency work.  I feel pretty strongly that the federal government has an important role to play in this conversation, but I also feel that the private sector needs to step up and help--additionally, I also feel that is important that individuals step up and be present in the discussion. Github plays a central role in my Adopta.Agency work. Any government data I turn into an API lives on Github as JSON, CSV, or other machine-readable format--taking advantage fo the Github platform for managing, as well as helping me eliminate or completely reduce the costs of managing public data. I spend money each month on hosting my public data work (it's my addiction), but I couldn't do it without a place to park it and offset storage and bandwidth costs. With this in mind, I'm spending time trying to find other services that public data and API folks can put to work for them, either eliminating or reducing the cost of managing open public data on the web. My Adopta.Agency toolkit starts with Github and extends to the open source blueprint...[<a href="/2017/02/07/helping-carry-the-load-when-it-comes-to-public-data-and-apis/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2017_02_07_at_10.13.17_am.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/02/07/dedicated-space-for-telling-the-stories-of-your-api-consumers/">Dedicated Space For Telling The Stories Of Your API Consumers</a></h3>
			<p><em>07 Feb 2017</em></p>
			<p>Telling the story of what your&nbsp; API accomplishes may seem like a pretty simple, straightforward thing, but you'd be surprised how many API providers DO NOT do this on a regular basis, or do not have dedicated stories, showcase, or similar section to their website. This is why I beat this drum on a regular basis -- if you do not tell the story of the cool things people are doing with your API or your API services, they will never know how your solution works, and will probably never think of your service again--even with they actually have that specific problem that you solve. To help demonstrate this in a very meta way, I am going to showcase how my clients, showcase their clients. Deep man. Next up is my partner DreamFactory, providing six very compelling stories about how their API deployment and management platform is being put to use: TECHeGO - DreamFactory is at the core of TECHeGO's powerful ERP platform&nbsp; Verizon Cloud - Discover how DreamFactory gave Verizon Cloud a turnkey developer portal. Intel - Learn how Intel uses DreamFactory to expose legacy SQL data as a powerful REST API for AngularJS. Maxwell Lucas - Read how Maxwell Lucas uses DreamFactory to deliver a world-class travel advisory application for their enterprise companies. Senske Services - Find out how Senske Services uses DreamFactory to REST-enable Microsoft SQL Server for a mobile ticketing application. The Binary Workshop - Discover why Binary Workshop uses DreamFactory as the REST API platform for their co-working SaaS applications. Shortrunposters.com - Find out how DreamFactory enabled communication between the shop floor, a backend MySQL database, and a proprietary e-commerce portal. Honestly, this type of blog posts makes for easy content for me, and obviously, it makes my partner DreamFactory happy, but more importantly, it is yet ANOTHER reminder for you to tell the story of the people who are using your APIs and services. Telling stories is essential to...[<a href="/2017/02/07/dedicated-space-for-telling-the-stories-of-your-api-consumers/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2017_02_05_at_1.14.24_pm.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/02/06/what-i-would-like-to-see-from-api-providers-when-it-comes-to-public-analytics/">What I Would Like To See From API Providers When It Comes To Public Analytics</a></h3>
			<p><em>06 Feb 2017</em></p>
			<p>I'm putting some thought into the what a public analytics layer might look like for federal, state, county, and city governments. Something that looks like analytics.usa.gov, but for APIs. This is one of the things I really like about government is that you get to push forward ideas that you just can't convince folks to do in the private sector. There is no way companies will share their web or API traffic numbers publicly because there are too much smoke and mirrors involved in the process--for some reasons folks like accountability in government, but not in private sector??? API analytics are a slightly different beast than web analytics, so I wanted to step back and think about what is important to me, an API consumer, or potential API consumer when I am looking at what API does, or a group of APIs actually&nbsp;do: APIs - Depending on how APIs are grouped, if there are many APIs across the different organization, groups, or event external agencies, help me understand which APIs are available, giving me a quick snapshot of which are most used, and how they compare against each other. Paths - Within each API, which individual API paths are the most used, showing me the most used aspects of any available API. Not always a sign of popularity, as the API design may be a factor here, but it will help me see how others are using. Applications - Which applications&nbsp;are making the most use of an API. This may be a number of calls or the number of APIs they are putting to use as well. Are these applications web, mobile, analysis, visualization, a system to system integration, or something else--details about what the app accomplishes and delivers helps a lot. Industries - Which industries are applications that put an API to work servicing? Would be helpful to understand which industries are finding API resources useful, and actually getting traction. Users - I am...[<a href="/2017/02/06/what-i-would-like-to-see-from-api-providers-when-it-comes-to-public-analytics/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/api-evangelist-logos/api-evangelist-red-seal.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/02/06/application-the-action-of-putting-something-into-operation/">Application: The Action of Putting Something Into Operation</a></h3>
			<p><em>06 Feb 2017</em></p>
			<p>I hate how technology dehumanizes things and went you bundle that with the current model for how things get funded, it tends to do this at scale, and with troubling efficiency. I'm the API Evangelist. I am not selling APIs as a technology solution, I am fighting to keep this sliver of our increasingly technical worlds open, and serving humans--otherwise I feel there is no hope for any of this to work with any kind of equity and compassion for the people it should be serving.
One of the reasons I blog is to help me refine the stories I tell in the API space, both virtually and in person. In an effort to make the API acronym more accessible to the masses, and also a reminder to the technorati that all of this is about doing meaningful things for the tech sector, I'm continuing to push my definition of API on the world. So, what does API stand for? Application Programming Interface. Historically application meant the&nbsp;web, and then in 2010 that started shifting to be more&nbsp;about mobile, and now it's being dominated by discussion about connecting other devices to the web, aka Internet of Things.
When I hear the word&nbsp;application, I think of the more non-technical definition of it: the action of putting something in operation. While this definition isn't perfect, it is better than simply thinking about web, mobile, and devices. It moves us closer to actually doing something useful, meaningful, functional, and actually serving humans. Sure, that operation could be in the service of systems and mechanisms that exploit and hurt people, but I feel like it gets us closer to having a conversation about why something is in operation, and not just simply about tech for tech's sake.
[<a href="/2017/02/06/application-the-action-of-putting-something-into-operation/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/swingingbridge_blue_circuit.jpg" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/02/06/api-definitions-documentation-and-hypermedia/">API Definitions, Documentation And Hypermedia</a></h3>
			<p><em>06 Feb 2017</em></p>
			<p>I wrote about what is at stake with API definitions currently and someone made a thoughtful comment on the importance of continuing to discuss hypermedia amidst all of this--I agree. I've long been an advocate for OpenAPI Spec and API Bueprint as a bridge from where we are, to where we need to be, getting us closer to the world hypermedia folks think we should have. I'd love it if every API allowed for content negotiation using one of the major hypermedia formats like HAL, Collection+JSON, or JSON-LD, but unfortunately, we have a lot of education and training ahead of us before we'll get there. A combination of APIs.json for discovery, and OpenAPI Spec for defining the request and response structure of an API can seem clunky compared to the elegant (hopefully) design of a hypermedia API, but not every API architect has the know-how, or the time and resources to always do things properly. This doesn't mean that we shouldn't strive for a better future, but it just isn't always a reality on the ground, and as easy to achieve as many hypermedia believers might envision. As the momentum picks up with API specification formats like OpenAPI, as well as the services and tooling popping up in the ecosystem we must have to keep an eye out for opportunities to make sure the bridge continues being extended to accommodate linking, relationships, and the other benefits hypermedia design patterns bring to the table. OpenAPI Spec 3.0 gives a slight nod towards what I'm talking about with the ability to add some basic linking--it falls short of true hypermedia flows, but it is one more step on the bridge I'm talking about. Technology has this amazing effect on us, that we either get too caught up in the future and forget the past, or even ignore the present, but I feel like OpenAPI Spec and other definitions are having the opposite effect where we forget the future, as well...[<a href="/2017/02/06/api-definitions-documentation-and-hypermedia/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/aws_console.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/02/02/the-amazon-console-came-after-the-api-and-cli/">The Amazon Console Came After The API And CLI</a></h3>
			<p><em>02 Feb 2017</em></p>
			<p>I've spent a lot of time thinking about the Amazon Web Services ecosystem lately. I've gone through and generated OpenAPI Specs for the majority of their APIs, as well as an APIs.json&nbsp;index for the collection of valuable services. I have also written about the relationship between the Amazon API and CLI, and while doing this research I had jotted&nbsp;down thoughts about their approach to the Amazon Console. For most API providers the API is a secondary thing, implemented after their website, applications, and even mobile applications in many situations. When AWS launched in 2006 they were only API and CLI, and after a couple of years, they got to work on providing their AWS Console, which plays a pretty significant role in working with the platform. The AWS console is pretty utilitarian, and lacking in a lot of UI / UX polish, but it plays an important role in working with the platform&nbsp;and is generally in sync with what features are available via the API and CLI. I don't think there are any major lessons here, I just think it is interesting what has unfolded at Amazon, compared to how many other companies invest so much in the SaaS, and user interface portions of their operations, where AWS has definitely focused more heavily on the CLI and API, with the console only recently coming into focus. I do not think there is any 100% right way to do this, but I think making sure there are parity and consistency between what is available via a UI, and the API and CLI are important. AWS doesn't always accomplish keeping all of this in sync, but you can see they work hard at it. Most times the CLI and API docs are side by side and even interlinked, and with some of the services, they provide you with a link in the developer area to the AWS Console portion for a specific service. I think whichever comes...[<a href="/2017/02/02/the-amazon-console-came-after-the-api-and-cli/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="https://s3.amazonaws.com/kinlane-productions2/bw-icons/bw-conversation-bubbles.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/02/02/preparing-for-conversations-about-schema-definitions-and-scopes/">Preparing For Conversations About Schema, Definitions And Scopes</a></h3>
			<p><em>02 Feb 2017</em></p>
			<p>I am focusing heavily on schema, definitions, and scopes in 2017, because it is the most important layer in the tech sector, the API space, and is something that touches almost every industry, while also reaching into our personal worlds. I'm working on refining my argument in 2017 that I'm not selling APIs as a solution all by themselves, I'm pushing APIs to help us tame this insane beast that we've let out of the closet, and will never be able to put back in. SchemaWhether it is JSON schema, MSON or Data Packages, current approaches to defining the data used as part of each API request or response are defining what has become to be known as the API economy (for good and bad). The schema describes the digital bits that are being created and moved around online today. They are the videos, images, blog posts, messages, and other digital elements that make up our online business and personal worlds.  Defining schema are critical to platforms working properly, and having them in a machine readable way allows for them to be shared between platforms, providers, and applications. Defining these bits allows us to have a conversation about these bits, which can also open up the conversation about whether or not we should be collecting, storing, and sharing these bits in the first place. I know many tech people don't want to have these conversations outside their inner circles, but we should--it is important for all of this to work for everyone. DefinitionsAPI specification formats like OpenAPI Spec and API Blueprint have emerged to give us a way to define the surface area of APIs that are used across web, mobile, and device applications. These specification formats are allowing us to define, describe, and have a conversation around the valuable data, content, and algorithmic resources being made available via APIs using the web. The resulting API definitions are currently being used by companies as part of every...[<a href="/2017/02/02/preparing-for-conversations-about-schema-definitions-and-scopes/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2017_01_31_at_2.29.16_pm.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/02/01/including-end-users-in-the-conversation-about-their-bits-being-sold/">Including End Users In the Conversation About Their Bits Being Sold</a></h3>
			<p><em>01 Feb 2017</em></p>
			<p>Fitbit recenttly announced a program to pay their wearable users up to $1500 for&nbsp;integrating their Charge 2 into the&nbsp;UnitedHealthcare Motion&nbsp;program powered by Qualcomm Life&rsquo;s 2net Platform. The "UnitedHealthcare Motion is an employer-sponsored wearable device&nbsp;wellness program&nbsp;that offers financial incentives for enrollees who meet daily step goals". Pulling back the curtain just a little bit on the value of your Internet of Things data, and specifically the devices you strap to your body. I am not a fan of corporations strapping devices to their employees as part of these wellness programs (or for any reason), and using cash incentive to achieve the desired behavior. I feel this is a doorway to some pretty dark human resources strategies, but I do think these events pull back the curtains on what is going on, even just a little bit for users. I am sure it's not Fitbit's intention to include end-users in all of their monetization of their data, but I see this as an opportunity to educate end-users in these situations. Most Internet users are not aware of the amount of information being gathered, bought and sold when they use the Internet, and their mobile phones. This lack of awareness is translating pretty nicely to the world of connected devices, adding some valuable demographic dimensions, to an already valuable user profile. While insurance companies are interested in improving their margins with this data, they are also interested in the new revenue streams they can create by selling data to other brokers, hedge funds, and more.&nbsp; One of the only hopes I have in this area is that startups will continue to pull back the curtain on this behavior either intentionally or unintentionally with products, services, and programs like the wellness program that Fitbit is offering. Showing users that there is value in their data, and this can be a positive first step in educating them about what is happening in the tech world. Once they get a taste...[<a href="/2017/02/01/including-end-users-in-the-conversation-about-their-bits-being-sold/">Read More</a>]</p>
			<p><hr /></p>
	  
		  <div align="left" style="width:325px; height:250px; overflow:hidden; float: left; padding: 20px;"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/1027205_health_and_personal_care_project_snake_always_accessible_v2_1920x1080.png" alt="API Evangelist" width="250" align="left" /></div>
			<h3><a href="/2017/02/01/amazon-dash-ok-idea-dumb-implementations/">Amazon Dash: Ok Idea. Dumb Implementations</a></h3>
			<p><em>01 Feb 2017</em></p>
			<p>The AWS IoT Button, based on the Amazon Dash Button hardware, was kind of sorta an interesting model, allowing you to trigger virtual things with a physical click of a button, but now they've virtualized their approach, which I guess is a decent enough of an idea (not new), but their implementation is just not that smart. I think they just went from virtual to physical, and back again that they kind of got whiplash, and didn't really think it through before launching. I'm not big on bashing people's technology implementations, as I would rather focus on shining a light on what is progressive in the space, but the area of embeddable tooling built using APIs has suffered so much in the last couple years, I'm not keen on big providers further sucking the oxygen out of the room--AWS can do better. Having a big branded virtualized button with a&nbsp;click for more info on one side, and purchase if you click on the other side seems like something your brands suggested, and not your actual consumers or developers. I can see the physical AWS IoT button getting some traction, even though the majority of the implementations will be cheezy. Making virtualized buttons should behave like the physical thing seems kind of useless. It seems like AWS could have designed a suite of well-designed HTML + JS button and bookmarklets that engineers can make very useful on the web as well as in a mobile environment. The branding, analytics, and overall experience could make things much more interesting&nbsp;than what you have now, and brand partners could get to work wiring these experiences up to make some pretty valuable API calls, and even daisy chain together multiple API calls across providers. API powered embeddable buttons is one of the areas of the API space that has left me underwhelmed. After we saw significant movement from Twitter and Facebook with some of their embeddable social buttons, there wasn't...[<a href="/2017/02/01/amazon-dash-ok-idea-dumb-implementations/">Read More</a>]</p>
			<p><hr /></p>
	  

		<!-- Pagination links -->
		<table width="100%">
			<tr>
				<td align="left" width="33%">
				  
				    <a href="/blog/page12" class="previous">
				      &#8592; Previous
				    </a>
				  
			</td>
			<td align="center" width="33%">
			  <span class="page_number ">
			    Page: 13 of 37
			  </span>
			</td>
			<td align="right" width="33%">
		  
		    <a href="/blog/page14" class="next">Next &#8594;</a>
		  
			</tr>
			</tr>
		</table>

  </div>
</section>

              <footer>
	<hr>
	<div class="features">
		<article>
			<div class="content">
				<p align="center"><a href="https://www.postman.com" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/partners/postman-logo.png" width="75%" style="padding: 15px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
		<article>
			<div class="content">
				<p align="center"><a href="https://github.com/postmanlabs/newman" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/postman/newman-logo.png" width="75%" style="padding: 15px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
	</div>
	<hr>
	<p align="center">
		relevant work:
		<a href="http://apievangelist.com">apievangelist.com</a> |
		<a href="http://adopta.agency">adopta.agency</a>
	</p>
</footer>


            </div>
          </div>

          <div id="sidebar">
            <div class="inner">

              <nav id="menu">
  <header class="major">
    <h2>Menu</h2>
  </header>
  <ul>
    <li><a href="/">Home</a></li>
    <li><a href="/blog/">Blog</a></li>
  </ul>
</nav>

              <section>
	<div class="mini-posts">
		<header>
			<h2 style="text-align: center;"><i>API Evangelist Sponsors</i></h2>
		</header>
		<article>
			<div class="content">
				<p align="center"><a href="https://www.postman.com" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/partners/postman-logo.png" width="75%" style="padding: 5px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
		<article>
			<div class="content">
				<p align="center"><a href="https://tyk.io/" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/tyk/tyk-logo.png" width="75%" style="padding: 5px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
		<article>
			<div class="content">
				<p align="center"><a href="https://www.openapis.org/" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/specifications/openapi.png" width="75%" style="padding: 5px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
		<article>
			<div class="content">
				<p align="center"><a href="https://www.asyncapi.com/" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/asyncapi/asyncapi-horiozontal.png" width="75%" style="padding: 5px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
		<article>
			<div class="content">
				<p align="center"><a href="https://json-schema.org/" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/specifications/json-schema.png" width="75%" style="padding: 5px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
		<article>
			<div class="content">
				<p align="center"><a href="https://github.com/postmanlabs/newman" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/postman/newman-logo.png" width="75%" style="padding: 5px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
	</div>
</section>


            </div>
          </div>

      </div>

<script src="/assets/js/skel.min.js"></script>
<script src="/assets/js/util.js"></script>
<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
<script src="/assets/js/main.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-1119465-51"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-1119465-51');
</script>


</body>
</html>
