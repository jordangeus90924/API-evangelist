<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>API Evangelist</title>
  <updated>2021-02-17T00:00:00Z</updated>
  <link rel="self" href="http://localhost:4000/atom.xml"/>
  <author><name>Kin Lane</name></author>
  <id>http://localhost:4000/atom.xml</id>
	<entry>
    <title>Open Data Using Postman Collections</title>
    <link href="http://apievangelist.com/2021/02/17/open-data-using-postman-collections/"/>
    <updated>2021-02-17T00:00:00Z</updated>
    <content><![CDATA[I am pushing forward how Postman can be used for public data. I have a whole mess of different data sets I need available for different projects I am working on. For one project I am aggregating ten separate environmental data sources available as a mix of CSV, JSON, and excel files, as well as a couple of actual APIs. I am looking to build an embeddable dashboard widget using data across these ten sources, and I am looking to organize all of them via a single public workspace, helping normalize them all as simple APIs returning CSV or JSON. The project is just a POC, and once it moves toward production we’ll launch actual APIs, but for now I am able to mock them using Postman. The process got me thinking about how this approach can be used to make simple public datasets available via forkable Postman collections. Simple Data APIs Using Collections As I began aggregating the datasets into Postman, the first couple of datasets were pretty basic. Simple CSV or JSON files, and a couple basic APIs. I just created a collection, added a new request, and pasted the URL into the request and pulled the data from the source. Once I had the response from each API I would save the response as an example for the request. Then the entire CSV or JSON would be stored locally within the collection. For most of them I’d convert the data to, or from JSON or CSV, and add a parameter property so that each response could returned depending on what format the consumer desires for the visualizations. Now that I have an example stored for each dataset as part of the collection I can mock the collection, making the data available as a simple “mocked” API. This approach provides a public or private URL I can share with anyone who is building a prototype application-—in this case a widget. Going from dataset to a simple API in just a few clicks. Each of these mock servers are rate limited so I don’t want to share with anyone who will create a lot of traffic, but for low volume design and development it works just fine. Also, anyone can fork the collections, publish their own mock servers within their own accounts—-pulling a fresh copy of the dataset whenever it gets updated. Localizing the mock servers so that they can do what they want with the data and put data to use within their own workspaces. Sharding Larger Datasets as Collections After working through a couple of the datasets I came across a couple pretty large ones that were to big to publish as a single request example, pushing me to find another way by sharding the data on top level data points. Properties like year, month, and categories make for good sharding targets, which I make available as separate requests within a single collection. If a dataset is large enough or works better as separate collections I would...]]></content>
    <id>http://apievangelist.com/2021/02/17/open-data-using-postman-collections/</id>
  </entry><entry>
    <title>Gathering My Thoughts on API Discovery</title>
    <link href="http://apievangelist.com/2021/02/11/gathering-my-thoughts-on-api-discovery/"/>
    <updated>2021-02-11T00:00:00Z</updated>
    <content><![CDATA[I am working to load up all my API discovery experiences into my head for some upcoming conversations. So I sat down and pulled together a summary of my API discovery research to date to help refresh my memory of what has happened and how we got here. API discovery is the one of the few layers of the API space that I am personally committed to helping move things forward and being able to see all the moving parts together helps me keep doing this. Let’s take a stroll through my memory of the evolution of API discover over the last fifteen years so that I can speak more coherently about all of this with a variety of folks. ProgrammableWeb ProgrammableWeb was the first source of being able to discover API, and in 2020 it is still the place you go to find APIs. Really not much has changed in the last fifteen years with ProgrammableWeb except for the owners and operators, and the look and feel of the site. It is still where you go to look for new and existing APIs, and where you find APIs when Googling. I have fond memories of writing for ProgrammableWeb, and the site is still a great source of information for me, but I am left frustrated that PW hasn’t moved forward the API discovery conversation in any interesting ways over the years. I just think it is a missed opportunity, and reflects much about the API space that I think holds us all back. Mashape -&gt; Rapid API After ProgrammableWeb, the next evolution in the API space when it came to API discovery was Mashape, which is now known as Rapid API. The API marketplace was born out of the age of API management and provides basic management capabilities alongside with API discovery services. Providing a pretty rich set of APIs you can search and onboard with using the Rapid API marketplace. Mashape and Rapid API definitely moved forward the API discovery conversation a bit, but much like ProgrammableWeb, it stopped there. RapidAPI is definitely giving ProgrammableWeb a run for their money when it comes to the SEO game, but there really hasn’t been much out of RapidAPI beyond the fundamentals of a simple API marketplace—-that is fine, but I’m always looking for forward motion. US Federal Government Data.json Index Next I am going to take a little detour, but it relates to API discovery, I promise. In 2013 I went to work for the Obama administration to work on helping federal agencies publish their public data assets using APIs. I was dedicated to the Department of Veterans Affairs, but also spent time working with other agencies to follow the presidential mandate to publish what is called a data.json file in the root of the web site domains for the 15 executive agencies—-you can still find the fifteen files available today. HHS Commerce Veterans Interior Agriculture Defense Education Homeland Security Housing and Urban Development Labor State Transportation Treasury Justice I...]]></content>
    <id>http://apievangelist.com/2021/02/11/gathering-my-thoughts-on-api-discovery/</id>
  </entry><entry>
    <title>API Storytelling with Mike and Aidan</title>
    <link href="http://apievangelist.com/2021/02/11/api-storytelling-with-mike-and-aidan/"/>
    <updated>2021-02-11T00:00:00Z</updated>
    <content><![CDATA[If you have followed my work you know that I like telling stories. Stories are the single most important tool in my Chief Evangelist and API Evangelist toolbox. None of the code matters in my opinion, and the stories surrounding the code is what makes the actual impact on our reality. The stories we tell each other, as well as the stories we tell ourselves. Everything in the world of technology and APIs is made up of stories. I am hovering around 5000 stories here on API Evangelist, which reflects everything I am when it comes to API Evangelist. Stories are how I make sense of the API world that has unfolded in the last twenty years. Storytelling is how I work through all of the things I do not understand, moving everything API from a very abstract realm into something that is more tangible, visible, and sometimes more meaningful to me in the real world. I couldn’t have done any of this without stories. Throughout my storytelling as the API Evangelist I have also taught myself to work through my own personal baggage over at kinlane.com. Applying the same methodology to my past and figuring out who I am today. API Evangelist has always been very much a performance, but the storytelling I engaged in as part of the performance went much deeper than being just a business production. Over the years, both of these streams of storytelling (apievangelist.com &amp; kinlane.com) have influenced others in the world, having an impact on their storytelling, or help them embark on their own storytelling journey. I’ve learned a lot from these engagements, and made a lot of friends around the world because of a shared love for storytelling. This shared storytelling journey has recently manifested itself as a video conversation between Mike Amundsen (@mamund) and Aidan Cunniffe (@aidandcunniffe), which we are simply calling API Storytelling. We only have one discussion under our belt and we aren’t quite sure where we are going with this, but the result for me is a nourishing 60 minutes of storytelling goodness. Why did we choose APIs? We talk about it a little bit in the video, but APIs are something that can be associated with almost every aspect of our world, making for a pretty good switchboard for endless storytelling. The three of us are all API storytellers, but we also have witnessed first hand how storytelling helps you personally grow and make sense of the world as well as ourselves. I love hearing how Mike and Aidan wrestle with storytelling and how it works in their world. Listening to how they use storytelling to break down their business worlds, but also their personal life. We don’t have a plan for our API storytelling conversations. We are just showing up with our storytelling bag and sharing little bits this and that and seeing where it all goes. If you watch the first edition of this API storytelling conversation you’ll see that we talk about what we’d...]]></content>
    <id>http://apievangelist.com/2021/02/11/api-storytelling-with-mike-and-aidan/</id>
  </entry><entry>
    <title>Making Sense of the Different Types of API Testing</title>
    <link href="http://apievangelist.com/2021/01/30/making-sense-of-the-different-types-of-api-testing/"/>
    <updated>2021-01-30T00:00:00Z</updated>
    <content><![CDATA[I have to admit something. I don&amp;rsquo;t fully grasp the entire landscape of API testing. I mean, I have a pretty decent awareness and experience in testing APIs, but I can&amp;rsquo;t close my eyes and coherently break down each layer or type of testing, let alone competently navigate the many different types of services and tooling available on the market for API testing. Like most other dimensions of the API universe the content and guidance on the subject of API testing is all over the place. After a couple of hours Googling and making my way through my bookmarks, I uncovered a pretty expansive dictionary for what I&amp;rsquo;d consider to be under the umbrella of API testing. First off, I have to talk about API testing in the most general sense before I get into the more and less formal API testing approaches. It was a dimension of API testing I hadn&amp;rsquo;t considered before I began working at Postman, but API testing meaning that I am just kicking the tires on a API, learning what it is all about, and how you use it. This is what the majority of Postman&amp;rsquo;s 13 million users are doing when they say they are testing an API with the Postman platform. THis experimental and curious approach to API testing provides a great onramp to the world of API publishing and consumption, but does little to help us articulate what API testing is or isn&amp;rsquo;t. Beyond just &amp;ldquo;testing out&amp;rdquo; an API, from what I can gather across about 25 separate API testing articles, there are 25 different layers to the API testing onion: Validation Testing - I am guessing a general type of validation &amp;mdash; seems pretty broad. Functional Testing - Adopted as part of code testing practices, applied to unit of code. Component Testing - Similar to functional, but testing based upon small unit of compute. User Interface Testing - Testing of the API in the context of the end user interface. Load Testing - Seeing how many requests each API is able to handle in a timeframe. Performance Testing - Overlapping with load testing, but benchmarking the API performance. Reliability Testing - Understanding the overall reliability of each individual API. Runtime Error Detection - Focusing specifically on errors encountered at runtime. Security Testing - A broad umbrella for testing the layers of API security that is present. Authorization Tests - Focused on testing the authentication for each individual API. Penetration Testing - Seeing you can actually get into an API through alternate ways. Fuzz Testing - Blasting an API with garbage, noise, and other junk to see what it does. Interoperability Testing - Testing how well an API plays with other external APIs. Integration Testing - Testing an API based upon its dependency on external APIs. Discovery Testing - Understanding the discoverability of an API as part of operations. Usability Testing - Testing an API from the perspective of how usable it is to consumers. Behavioral Testing - Driving testing based upon...]]></content>
    <id>http://apievangelist.com/2021/01/30/making-sense-of-the-different-types-of-api-testing/</id>
  </entry><entry>
    <title>Keeping API Entropy Low is Needed to Continue API Growth and Expansion</title>
    <link href="http://apievangelist.com/2021/01/30/keeping-api-entropy-low-is-needed-to-continue-api-growth-and-expansion/"/>
    <updated>2021-01-30T00:00:00Z</updated>
    <content><![CDATA[I love the word entropy. It means so many things to so many different people. In means different things in the physical realm versus the informational or virtual realms. It is one of those big words you can say to confuse people, or actually get yourself in trouble being able to actually defend your position on what entropy means when around smart people. It is said that famed mathematician John Von Neumann had told fellow mathematician and creator of Information Theory that he should use the word entropy instead of information because that no one understands entropy and then you can win arguments about your theory. I also read that Shannon and Norbert Weiner also dueled over the meaning, seeing it in very opposite ways. I like the word for all of these reasons, but mostly because of its relationship to uncertainty.&amp;nbsp; In the realm of physics entropy means, a thermodynamic quantity representing the unavailability of a system's thermal energy for conversion into mechanical work, often interpreted as the degree of disorder or randomness in the system In the more virtual realm of information theory, the entropy of a random variable is the average level of information, surprise, or uncertainty inherent in the variable's possible outcomes. While I could easily use entropy as a metaphor for APIs in the physical sense, it is really the appropriation of it for information theory that really brings it home for me. Entropy in Shannon&amp;rsquo;s time was centered around noise or static in communication, but when you look at how APIs enable communication between systems, and allowing web, mobile, device, and network applications to communicate, this static or noise reveals itself as friction, errors, outages, instability, unreliability, and misaligned business and political priorities.&amp;nbsp; &amp;nbsp;Think about the level of information one encounters when it comes to putting APIs to work these days. Consider the surprise one encounters when seemingly similar API resources speak entirely different dialects or behave inconsistently. Stop to think about the amount of uncertainty that exists between each version of an API, let alone each version of an API across the increasing number of APIs your average organization depends upon today. The velocity at which an organization moves, or should be moving, considered alongside the velocity of each individual API being published or consumed, reveals the reality of API entropy on the ground within your average enterprise organization, as well as the industries in which they operate. When an API and resulting integration or application is brand new API entropy is usually relatively low, but as momentum increases, and the number of consumers increases, entropy will ultimately increase and contribute to the eventual decline of&amp;nbsp; an API, the applications they power, and even platform that they operate on. APIs work best where the cognitive load involved with putting them to work is low, where common patterns are employed, and predictability and reliability are high. The reduction of API entropy within API operations and communities can come in many forms. Popular API documentation...]]></content>
    <id>http://apievangelist.com/2021/01/30/keeping-api-entropy-low-is-needed-to-continue-api-growth-and-expansion/</id>
  </entry><entry>
    <title>Examples of Minimum Viable and Complete Landscape APIs.json Index Files</title>
    <link href="http://apievangelist.com/2021/01/29/examples-of-minimum-viable-and-complete-landscape-apis-json-index-files/"/>
    <updated>2021-01-29T00:00:00Z</updated>
    <content><![CDATA[I am preparing for the next version of APIs.json and I am taking another pass over what the specification is, but also taking a fresh look at why the specification exists. Part of this fresh look involves assessing what I consider to be the low bar for an APIs.json index, as well as what the entire scope might look like. To help me (and you) understand the scope of what APIs.json or APIs.yaml can do when it comes to indexing our API operations and making them discoverable in a machine readable way. The most important thing to remember about APIs.json is that it is all about indexing API operations in a way that acknowledges that there are two sides of this API integration game which need to be indexed and made discoverable across an organization. Human Readable - Providing URL references for the aspects of API Operations that human stakeholders will need to understand what is happening with APIs and how to put them to work in applications. Machine Readable - Providing URL references for aspects of API Operations that are system and applications can use to make sense of API Operations, accessing as a machine readable definition. APIs.json is about indexing all of these human and machine readable aspects of our API Operations with an emphasis on evolving human readable elements to also be machine readable so that as much of the surface area of our API operations is indexable by other systems and applications as possible. There is another dimension of APIs.json as a specification that is helpful to understand beyond the human and machine readable elements, by providing a vocabulary for describing two separate scopes of API operations, helping define the scope of information provided. API Specific Properties - References to details about a specific API, providing human and machine readable details about an API, so that consumers understand everything that is possible. Common Properties - References to details that support all APIs being indexed, providing information about how to onboard with a platform, and understand what is possible across A?PIs. Similar to migrating human readable elements to be more machine readable, I’d say the goal in this dimension is all about standardizing our API operations across all of the APIs being made available, providing common set of resources across operations, while providing only what is needed to define the surface area of each individual API—helping be consistent in the business and technology of our API operations. An Example Minimum Viable APIs.json File To demonstrate what is possible with APIs.json when it comes to indexing operations I want to have an example of what I’d consider to be the minimum viable example of what an API Operations might look like in the wild. That represents what I’d like to see from all APIs, providing the minimal amount of details and operational resources that any API should possess, acknowledging that the API itself isn’t enough, and there will always be other supporting elements needed. An Example Minimum Viable...]]></content>
    <id>http://apievangelist.com/2021/01/29/examples-of-minimum-viable-and-complete-landscape-apis-json-index-files/</id>
  </entry><entry>
    <title>Evaluating APIs.json API Property Types Alongside OpenAPI Extensions</title>
    <link href="http://apievangelist.com/2021/01/23/evaluating-apis-json-api-property-types-alongside-openapi-extensions/"/>
    <updated>2021-01-23T00:00:00Z</updated>
    <content><![CDATA[I am giving some much needed love to my APIs.yaml and API.json API discovery format while using the work to also just think about the wider API landscape. This is the original intent behind APIs.json&amp;hellip;to help me make sense of the API landscape.&amp;nbsp; Most folks are thinking about APIs as a producer, or as a consumer&amp;mdash;hopefully both. However, there are fewer people who also pay attention to the entire API landscape, and APIs.json emerged out of this need for me in 2014. In 2020 I find myself totally immersed in the API landscape as part of my API Specification Toolbox project which grew out of Postman becoming a member of the OpenAPI Initiative, and I wanted toht spend why Saturday afternoon (I know I have a problem) thinking about the API landscape at the 250K.&amp;nbsp; APIs.json API Property Types Using APIs.json or APIs.yaml you can define the properties of one or many APIs for a variety of purposes. Each API you describe can have an array of properties which can be common human readable elements like documentation or sign up, as well as machine readable properties like OpenAPI, AsyncAPI, or JSON Schema. APIs.json property types are intentionally human or machine readable with the intent on evolving every human readable element to have a machine readable element&amp;mdash;think the relationship between documentation (Human) and OpenAPI (Machine) when understand the objective. I have several thousand API Providers and API service providers in my API Evangelist database. I track on the properties of all of these companies, organizations, institutions, and government agencies that I come across. When I group the property types across the thousands of APIs I have indexed, I end up with this default set of building blocks for API providers, grouped by different areas of the API lifecycle. Onboarding These are the properties of any API operation that help consumers, or any other party onboard with the concept of an API, begin using the API, as well as allowing them to return on a regular basis to get what what they need for integration.&amp;nbsp; About - The overview of what an API or provider offers to consumers. Getting Started - How you get started with actually consuming an API. Authentication - What is involved with authenticating with an API. Documentations - The human readable documentation for APIs. Plans - What the pricing, access, and rate limits are for each API. Signup - Where you sign up to actually begin using an API. Login - How you login back into the platform for each API. Dashboard - The landing page for consumer after logging in. These API property types are essential to helping API consumers understand what is possible and assisting them in getting up and running with each API. As the number of APIs each of us depends on increases, friction at any of these areas might be the deciding factor for whether a consumer successfully onboards with an API or not. Definitions These are the common machine readable API specifications...]]></content>
    <id>http://apievangelist.com/2021/01/23/evaluating-apis-json-api-property-types-alongside-openapi-extensions/</id>
  </entry><entry>
    <title>What Does Open Mean in the World of APIs?</title>
    <link href="http://apievangelist.com/2021/01/11/what-does-open-mean-in-the-world-of-apis/"/>
    <updated>2021-01-11T00:00:00Z</updated>
    <content><![CDATA[The word &amp;ldquo;open&amp;rdquo; gets thrown around so much in the API space I find myself needing to regularly ground myself in what it actually means. It gets thrown around in so many different ways that I find eventually I start to believe the bullshit and regularly have to pause and recalibrate. It is one of those words that has been captured and used by people looking to manipulate the space so often it often means the exact opposite of what we all think it means, but it is also such an important word that I think we have to fight to keep it in our vocabulary. I feel like I am perpetually fighting with some invisible force over one of the front doors to the house we all live in, and I am determined for the door to not get completely shut, and I have to make sure the door actually ends up go where someone expects when they do open the door. Let&amp;rsquo;s begin by actually taking inventory regarding the many different ways people use the word &amp;ldquo;open&amp;rdquo; to describe the world of APIs. Gathering all the ways it gets wielded in service of publishing and consuming APIs. Some of the ways in which it gets wielded are good, and some of them are bad. At this point I am just looking to be able to see the spectrum of use, and I am not looking to entirely pass judgement on anyone who uses it in specific ways. Here is the laundry list of ways &amp;ldquo;open&amp;rdquo; is wielded that impact the landscape I pay attention to on a daily basis, and have been helping shape for the last decade.&amp;nbsp; &amp;nbsp;Publicly Available - Open means something is available to anyone in the public, allowing them to use an API, and any resources around them. &amp;nbsp;Access - An API or supporting resource is open for access by the public or the developer community in general, making it something they can use. &amp;nbsp;Business - Stating that a digital resource is open for business, and consumers can purchase or be purchased in an ongoing way using an API. &amp;nbsp;Source - Focusing on the code behind or in front of an API, and acknowledging that APIs are built upon and evolved using open source code. Specifications - Applying to API specifications like OpenAPI or OpenID, and ensuring that the specs we leverage across our APIs are always open. Standards - Looking at specific industries and business sectors, and ensuring that the standards that are in place for industries are available openly. Licensing - The word open is regularly applied to the legal side of the API world, which leverages the lawyers to loose up or tighten down the open screws. Exploitation - Many APIs and the platforms they reside upon are open for exploitation, or possibly open to the exploitation of API consumers and end-users. Discovery&amp;nbsp;- Can I find the API? Is it easy to discover and explore for any potential consumer, and able...]]></content>
    <id>http://apievangelist.com/2021/01/11/what-does-open-mean-in-the-world-of-apis/</id>
  </entry><entry>
    <title>Taking a Fresh Look at APIs Across All the United States Federal Agencies</title>
    <link href="http://apievangelist.com/2020/12/27/taking-a-fresh-look-at-apis-across-all-the-united-states-federal-agencies/"/>
    <updated>2020-12-27T00:00:00Z</updated>
    <content><![CDATA[It has been a while since I looked at the 250K view of what is going on with APIs across federal government agencies in the United States. Since working for the Obama administration in 2013 I am perpetually on a quest to map out what is happening across federal agencies, helping drive the conversation forward. I belieive APIs can make the most impact when our federal government helps lead the way, and I am looking to help push things forward in the following ways. Keep mapping out the Federal Government API Landscape - I am determined to produce a map of the APIs that exist across federal agencies and keep the list alive and active. Establish Public API Workspaces for Federal Agencies - I am looking to establish public API workspaces for agencies who are implementing APIs--helping do some work from the outside-in. Refresh My Memory of What is Happening - I thrive on knowing what is going on across federal agencies, and doing these reviews pushes me to refresh my awarenss of APIs at this level. Fire Up new Conversations - These sotries always rise up in the SEO game and bring in new conversations with folks who are doing interesting things with APIs in government. I always learn a lot looking through the different government agencies. I learn even more wading through the different datasets, databases, and various incarnations of APIs. There is way too much work here than one person can handle, and much of what I come across labeled as an API really isn't an API, but could be with a little work. While doing these roundups I always reach a point where I feel like I am not doing enough, but ultimately I have to strike a balance between being comprehensive and just scratching the surface. Providing just enough information to allow me to plant seeds that might grow into new conversations down the road, while not spend all of my days sifting through the backwaters of federal government websites. This is my latest attempt to map out what is happenign with APIs across federal agencies in 2020, with some learnings and ongoing thought about what else can be done down below. Administration for Children and Families (ACF) The Administration for Children and Families is a division of the United States Department of Health and Human Services. It is headed by the Commissioner and Deputy Commissioner. It has a $49 billion budget for 60 programs that target children, youth and families.&amp;nbsp; Links Website Twitter APIs Unaccompanied Children Reporting API Agency for Healthcare Research and Quality (AHRQ) The Agency for Healthcare Research and Quality is one of twelve agencies within the United States Department of Health and Human Services. The agency is headquartered in North Bethesda, Maryland, a suburb of Washington, D.C. Links Website Data APIs Clinical Decision Support (CDS) Connect Clinical Decision Support (CDS) Knowledgebase Electronic Preventive Services Selector (ePSS) My Own Network, Powered by AHRQ (MONAHRQ) Quality Reporting Programs Agricultural Marketing Service (AMS) The...]]></content>
    <id>http://apievangelist.com/2020/12/27/taking-a-fresh-look-at-apis-across-all-the-united-states-federal-agencies/</id>
  </entry><entry>
    <title>A Postman Collection For Capitalizing Folders and Requests In Collections</title>
    <link href="http://apievangelist.com/2020/12/17/a-postman-collection-for-capitalizing-folders-requests-in-collections/"/>
    <updated>2020-12-17T00:00:00Z</updated>
    <content><![CDATA[
Sometimes I need to do bulk updates to Postman collections and there is no better way to automate this than to use a Postman Collection that uses the Postman API&amp;mdash;inception level stuff, so be careful ;-). I have setup a dedicated public workspace where I am building out these utility type operational level collections&amp;nbsp;that help me manage the API lifecycle out ahead of what the Postman GUI is capable of doing. Some of the things I am doing will eventually make its way to the Postman UI, but some of them will not. Either way, I am too impatient to wait, and one of the things I love about Postman is that I can hack my way forward through just about any situation using the Postman API.
Building on my base collection for pulling and updating collections, I added two differents requests that will help me capitalize the first letter of each word in a folder or request name of a collection.

Apply Title Case to All Folder Names in a Collection
Apply Title Case to All Request Names in a Collection

To run, all you have to do is make sure you&amp;rsquo;ve entered a collection ID (pulled from URL or info tab), and hit run&amp;mdash;it will loop through each folder and request and capitalize the words, and then save the collection using the Postman API. So you can immediately put to use the same collection with the changes you desired.
If you have any questions on the collection for pulling a collection and making changes using the Postman API, feel free to submit a comment for the collection as part of the collection workspace. I&amp;rsquo;ll be centralizing the evolution of this collection, as well as other collection related collections within this workspace. You can also fork the collection and use in your workspaces, and submit back any enhancements you&amp;rsquo;d like to see as a pull request. If you have any questions that you don&amp;rsquo;t want to see in the comments for the collection, feel free to email me at info@apievangelist.com.
]]></content>
    <id>http://apievangelist.com/2020/12/17/a-postman-collection-for-capitalizing-folders-requests-in-collections/</id>
  </entry><entry>
    <title>APIs are at the Center of the Federal Trade Commission (FTC) Lawsuit Against Facebook</title>
    <link href="http://apievangelist.com/2020/12/12/apis-are-at-the-center-of-the-federal-trade-commission-ftc-lawsuit-against-facebook/"/>
    <updated>2020-12-12T00:00:00Z</updated>
    <content><![CDATA[The Federal Trade Commission is sueing Facebook, alleging that they are illegally maintaining a monopoly on the personal social network space using a continued series of anticompetitive behavior. The suit includes a coalition of attorneys general of 46 states, bringing the latest wave of regulatory scrutiny into the social media platform, highlighting three main dimensions of how Facebook has engaged in a systematic strategy of anticompetitive practices that has resulted in their current dominant position online. Instagram - Facebook purchased Instagram to remove what they saw as one of the biggest threats they faced, while also purchasing market dominance in the image and photos sharing space. WhatsApp - Fsacebook purchased WhatsApp to remove what they saw as one of the biggest threats they faced, while also purchasing market dominance in the messaging space. API - Facebook used their API to cut off access to applications they saw as a threat, and to generally suffocate anything else they saw as a threat to their business model. The anticompetitive nature of Facebook&amp;rsquo;s Instagram and WhatsApp purchase isn't really in my wheelhouse, but how the API was used for anticompetitive activity most definitely is my speciality. I am happy to see the FTC finally elevate the abuse that has been going on at Facebook via it&amp;rsquo;s APIs, not just because of the impact on the Facebook developer community, but more importantly the wider tech sector. Facebook&amp;rsquo;s approach hurts wider competition across the tech sector, but also hurts the space API sector--ultimately giving APIs a bad reputation. To help me speak intelligently to what is occurring as part of the FTC&amp;rsquo;s lawsuit, offer my advice on what a remedy might be, while also contributing to the future of regulation in the tech sector, I wanted to gather my thoughts in a post here on the blog.&amp;nbsp; Anticompetitive Conditioning Using The Facebook API The acquisition of Instagram and WhatsApp by Facebook to neutralize threats in two keys areas are a critical part of this filing and Facebook&amp;rsquo;s strategy to dominate, but it is their API that has the biggest impact in suffocating out competition in the areas of photos and messaging, but every other dimension in which other companies can compete with Facebook via their own API. I think the FTC filing sums it up best in section 22 with the phrase &amp;ldquo;anticompetitive conditioning&amp;rdquo; 22. Anticompetitive Conditioning. In addition to its strategy of acquiring competitive threats to its personal social networking monopoly, Facebook has, over many years, announced and enforced anticompetitive conditions on access to its valuable platform interconnections, such as the application programming interfaces (&amp;ldquo;APIs&amp;rdquo;) that it makes available to third-party software applications.&amp;nbsp; This sums up the slow roll suffocation of competition that exists as part of the politics of APIs across not just Facebook, but also other leading platforms via their API ecosystems. Companies who view their API developer ecosystems as an asset use the API management layer of their APIs to incentivize developers, where companies like Facebook who have reached a size...]]></content>
    <id>http://apievangelist.com/2020/12/12/apis-are-at-the-center-of-the-federal-trade-commission-ftc-lawsuit-against-facebook/</id>
  </entry><entry>
    <title>Gathering My Thoughts on Public API Workspaces</title>
    <link href="http://apievangelist.com/2020/12/05/gathering-my-thoughts-on-public-api-workspaces/"/>
    <updated>2020-12-05T00:00:00Z</updated>
    <content><![CDATA[I have been neck deep in the release of Postman public workspaces lately. So much so, I haven't had much time to gather my thoughts about what exactly they are, and why they matter. Time for a burst of storytelling to help me make sense of just what is a public APIi workspace. One of the most common responses I've heard from folks that I talk with about public workspaces is that they are most comparable to a public GitHub repository, but designed just for APIs. Fair enough. While I see Postman public workspaces as much more than a Github public repository, it provides a great place to start when it comes to helping folks understand the potential. To help me be more articulate when it comes to speaking about why public workspaces matter, let me compare them to public repositories, and speak of the impact that GitHub has had on my reality, as well as on the wider API community. GitHub Changed My Life I have been using Github since 2010, but beginning in 2014 I began operating a significant portion of my API operations via GitHub. I ran all of my public presence there from 2014 through 2020, and I still regularly use it as a base for many API projects, and for publishing JSON and YAML files. In the last year I have pulled back much of my web presence for API Evangelist back from Github, but I still depend on it for most of my projects for the following reasons.&amp;nbsp; Free - It is free to publish repos to Github, making it a pretty sweet place to publish APIs, schema, JSON, YAML, code, and other artifacts. Network - The network effect of Github is huge. Developers get it, and the access and discoverability that comes with the platform are worth it.&amp;nbsp; Social - The social layer GitHub added to Git is really what makes the platform as powerful as it is, making things more collaborative by default. Source = Github is designed to be the source for code, but it works just as well for OpenAPIs, JSON Schema, and other artifacts you are managing. README - The readme for each repository provides a great hello world for each idea and project, allowing everything to be born as a repo. Issues - I use Github issues for everything! It is how I aggregate tasks, features, bugs, and engage with people via the hundreds of repos ii have. Pages - Github Pages combined with Jekyll has transformed how I publish data-driven websites, dashboards, and tools for others to use. SEO - Early on GitHub repos didn't index well, but eventually it became better to publish things to Github than it was to your own properties. Github changed my life. Github is how I built API Evangelist. Github is how I made sense of the API lifecycle. All my ideas for the last five years have been born and raised as a Github repository. Repositories provided me with a...]]></content>
    <id>http://apievangelist.com/2020/12/05/gathering-my-thoughts-on-public-api-workspaces/</id>
  </entry><entry>
    <title>Expanding the Vocabulary for Run in Postman Buttons</title>
    <link href="http://apievangelist.com/2020/12/05/expanding-the-vocabulary-for-run-in-postman-buttons/"/>
    <updated>2020-12-05T00:00:00Z</updated>
    <content><![CDATA[I have long been fascinated by the Run in Postman Button. A Run in Postman button can be published from any Postman collection, organizing a single, or a series of API calls into collection of API requests, and then letting them be imported and ran locally by any consumer, as a cloud monitor, or via a pipeline. Run in Postman buttons are a common way for API providers to onboard new developers with their APIs, and stay engaged with active developers through collections they&amp;rsquo;ve download via Run in Postman buttons. These embeddable goodies attached to Postman collections and potentially environments are very powerful unit of API execution, but I am finding that the label &amp;ldquo;run&amp;rdquo; isn&amp;rsquo;t sufficient in articulating what is possible with each collection, and I a looking to get a little more precise when it comes to my vocabulary attached to each Postman button I publish. The Run in Postman Button Fundamentals A Postman collection is basically a portable folder of API requests. Using Postman, developers can define the parts of one of many API requests, including the URL, parameters, headers, body, and authentication, then roll them all up as a collection that can be shared with other developers, and published as documentation, as well as using a Run in Postman button. This embeddable HTML or markdown button can be published alongside documentation, or more dynamically as individual buttons on any HTML or markdown page, attaching each button to the following elements:&amp;nbsp; Collections - Each button can execute a single collection of one or many API requests, complete with pre-request and post-request scripts. Environments - Each button can possess a single environment that can contain a variety of key / value pairs for authentication, and other purposes. You can find Run in Postman buttons sprinkled across Twitter API documentation, providing one click import of collections into each developers own workspace, where they can manually run, or automate using a monitors, or trigger via a pipeline using the command line runner. This powerful combination allows for an almost unlimited number of possibilities when it comes to crafting a collection, environment, and then publishing using a &amp;ldquo;Run in Postman&amp;rdquo; button&amp;mdash;something &amp;ldquo;run In&amp;rdquo; just does not adequately represent when articulating what is really possible.&amp;nbsp; Exposing the Semantics of Each Collection The label &amp;ldquo;run in&amp;rdquo; provides a powerful, yet generic wrapper for each collection. I&amp;rsquo;d like to see a semantic layer emerge for Run in Postman Buttons, allowing me to better define and articulate what is happening within each collection. Yes, each collection is being &amp;ldquo;ran&amp;rdquo;, but I want to be able to get more precise about what is happening within each collection, moving beyond the notion of a &amp;ldquo;reference collection&amp;rdquo;, or just a buffet menu of what is possible with an API, to very precise capabilities that are enabled by an API. Here are a few labels I would use for some of the collections I currently use across my work. Deploy Using Postman - I have a variety of collections...]]></content>
    <id>http://apievangelist.com/2020/12/05/expanding-the-vocabulary-for-run-in-postman-buttons/</id>
  </entry><entry>
    <title>A Postman Collection For Updating a Collection Host, Path, or Query Parameter</title>
    <link href="http://apievangelist.com/2020/11/30/a-postman-collection-for-updating-a-collection-host-path-or-query-parameter/"/>
    <updated>2020-11-30T00:00:00Z</updated>
    <content><![CDATA[
Sometimes I need to do bulk updates to Postman collections and there is no better way to automate this than to use a Postman Collection that uses the Postman API&amp;mdash;inception level stuff, so be careful ;-). I have setup a dedicated public workspace where I am building out these utility type operational level collections that help me manage the API lifecycle out ahead of what the Postman GUI is capable of doing. Some of the things I am doing will eventually make its way to the Postman UI, but some of them will not. Either way, I am too impatient to wait, and one of the things I love about Postman is that I can hack my way forward through just about any situation using the Postman API.&amp;nbsp;
Building on my base collection for pulling and updating collections, I added five specific requests that will help me conduct a find and replace on each API request host, path, and the query parameter key, value, and description. There are other dimensions I am looking to cover with future requests, but this gets me what I need right now. You simply add a value to the request for a find and replace value, make sure you&amp;rsquo;ve entered a collection ID (pulled from URL or info tab), and hit run&amp;mdash;it will conduct the appropriate find and replace, and then save the collection using the Postman API. So you can immediately put to use the same collection with the changes you desired.
If you have any questions on the collection for pulling a collection and making changes using the Postman API, feel free to submit a comment for the collection as part of the collection workspace. I&amp;rsquo;ll be centralizing the evolution of this collection, as well as other collection related collections within this workspace. You can also fork the collection and use in your workspaces, and submit back any enhancements you&amp;rsquo;d like to see as a pull request. If you have any questions that you don&amp;rsquo;t want to see in the comments for the collection, feel free to email me at info@apievangelist.com.]]></content>
    <id>http://apievangelist.com/2020/11/30/a-postman-collection-for-updating-a-collection-host-path-or-query-parameter/</id>
  </entry><entry>
    <title>Helping the Public Data Commons Drive Our Economy Using APIs</title>
    <link href="http://apievangelist.com/2020/11/27/helping-the-public-data-commons-drive-our-economy-using-apis/"/>
    <updated>2020-11-27T00:00:00Z</updated>
    <content><![CDATA[What is an API? An API is a digital interface for sharing data, content, and algorithms with web, mobile, and device applications using the Internet, building on web technologies to make digital resources available across many different applications. APIs have been around since computers and their networks first gained a foothold back in the 1960s, but with the rise of the web since 2000, a new breed of APIs have emerged which has changed how we build and use technology, and introduced entirely new ways of doing business, but sadly, they have also introduced entirely new ways of exploiting an destabilizing the physical world around us. APIs aren&amp;rsquo;t the latest techno solutionism, although they are oftentimes billed as that, they are the digital currents that flow around us each day. APIs power the web and mobile applications we depend on each day, while also steadily working to redefine our physical worlds by connecting everything to the Internet&amp;mdash;reshaping our virtual and physical worlds, while also remaking who we are as humans along the way. Websites Are for Humans The web as we know it has been evolving for over 50 years, but in the 1990s it became something we were able to access in our homes and businesses, laying the foundation for the ubiquitous web of applications we now access in our homes via laptops, televisions, and other appliances, as well as our cars, in our businesses, and across our communities in the form of security cameras, traffic infrastructure, digital signage and much more. Websites are hypertext markup language (HTML) that are designed to be rendered for humans in a browser, making the text, images, and other media consumable by humans using their eyes and ears, and navigated using our fingers via touch screens, keyboards, and increasingly voice controls. Websites provide us with a user interface that each person can put the web to use in their personal or professional worlds, connecting us with the digital world that has emerged before us, and increasingly throughout our physical world as well. APIs are for All Other Applications As the web has expanded over the last twenty years beyond simple web pages accessed via desktop computers, the builders of the web realized they needed to develop ways in which data, content, and algorithms could be reused across many different web and mobile devices. To accomplish this, developers began adapting web technologies using HTTP to make data, content, and algorithms available in much more standardized and machine readable ways so that the data and content could be used across many destinations. Separating the user interface from the data, content, media, or algorithms, widening how and where the digital resources could be applied, using them to power their primary web, mobile, and device applications, but also making the increasingly valuable digital resources available to partners and 3rd party developers, generating entirely new revenue streams from data, content, media, and algorithms which had limited value before. Resulting in a layer of application programming interfaces (APIs) on...]]></content>
    <id>http://apievangelist.com/2020/11/27/helping-the-public-data-commons-drive-our-economy-using-apis/</id>
  </entry><entry>
    <title>Pulling the OpenAPI For Any API You Are Managing With Postman So That You Can Apply Across the API Lifecycle</title>
    <link href="http://apievangelist.com/2020/11/23/pulling-the-openapi-for-any-api-you-are-managing-with-postman-so-that-you-can-apply-across-the-api-lifecycle/"/>
    <updated>2020-11-23T00:00:00Z</updated>
    <content><![CDATA[
I am using Postman to do more governance on my OpenAPI definitions as part of their API lifecycle. This is a top request of customers I am talking to, so I want to get better at make these individual API lifecycle capabilities much more modular and reusable as Postman collections. In Postman, the OpenAPI is the truth for each API contract throughout the API lifecycle, but each collection has become how you automate each stop along the API lifecycle. Resulting in me needing the OpenAPI for each API I am automating, and being able to pull the OpenAPI truth using the Postman API within each collection I am defining to mock, document, test, and govern each API.
You can find a single collection for pulling the OpenAPI for an API from the Postman API using it&amp;rsquo;s name (boy that is a mouthful). The collection is designed to abstract away three separate API calls into a single request. Ideally Postman will provide a similar API endpoint, but until that happens I have this collection to help make things easier. The documentation for the collection should provide you with everything you need to get up and running with the collection, pulling the API into a Postman environment for reuse. It is up to you to decide what you will do with the OpenAPI after that, possibly making multiple changes, and then saving back to Postman using the API.
If you have any questions on the collection for pulling the OpenAPI as part of the API lifecycle, feel free to submit a comment for the collection as part of the OpenAPI workspace. I&amp;rsquo;ll be centralizing the evolution of this collection, as well as other OpenAPI related collections within this workspace. You can also fork the collection and use in your workspaces, and submit back any enhancements you&amp;rsquo;d like to see as a pull request. If you have any questions that you don&amp;rsquo;t want to see in the comments for the collection, feel free to email me at info@apievangelist.com.]]></content>
    <id>http://apievangelist.com/2020/11/23/pulling-the-openapi-for-any-api-you-are-managing-with-postman-so-that-you-can-apply-across-the-api-lifecycle/</id>
  </entry><entry>
    <title>Automating the Management of Postman Collections Using a Postman Collection</title>
    <link href="http://apievangelist.com/2020/11/23/automating-the-management-of-postman-collections-using-a-postman-collection/"/>
    <updated>2020-11-23T00:00:00Z</updated>
    <content><![CDATA[
I am managing more collections via hundreds of different workspaces lately. As part of my work I am needing to make bulk changes to collections based upon a variety of properties. Sometimes I need to find and replace variables, and other times I need to rewrite or append to the descriptions for each collection. Whil I am sure eventually there will be capabilities to do some of this via the Postman interface, I find creating maintenance collections that use the Postman API to do what I need is the quickest way to get what I want, without having to wait for the Postman road map to catch up to my work.
I have a whole list of automated changes I want to make to Postman collections that I am generating from OpenAPI definitions, and to help me quickly work through this list I wanted to create a base collection that I could use to augment with common and some unique scripts for making changes to any collection, and then save the results back using the Postman API. You can find this collection in my public workspace for managing my collection work, where you can fork it and apply to the changes you need to make to collections. You are also welcome to just wait until I get specialized collections built, or feel free to submit a suggestion for a variation that maybe I haven&amp;rsquo;t considered.
If you have any questions on the collection for pulling a collection and making changes using the Postman API, feel free to submit a comment for the collection as part of the collection workspace. I&amp;rsquo;ll be centralizing the evolution of this collection, as well as other collection related collections within this workspace. You can also fork the collection and use in your workspaces, and submit back any enhancements you&amp;rsquo;d like to see as a pull request. If you have any questions that you don&amp;rsquo;t want to see in the comments for the collection, feel free to email me at info@apievangelist.com.]]></content>
    <id>http://apievangelist.com/2020/11/23/automating-the-management-of-postman-collections-using-a-postman-collection/</id>
  </entry><entry>
    <title>A High Level Look At API Specifications</title>
    <link href="http://apievangelist.com/2020/11/23/a-high-level-look-at-api-specifications/"/>
    <updated>2020-11-23T00:00:00Z</updated>
    <content><![CDATA[I am having an increasing number of conversations around how the leading API specifications work together, and what the role of each are when it comes to various stops along the API lifecycle. To help drive conversations I wanted to create a single blog post I can link to, while also loading up all of my fresh thoughts about API specs into my old brain. All of these API specifications are continuing to see massive adoption across API providers and consumers, and they are all in forward motion being iterated upon by the specification owners, so it helps to pause once or twice a year and take a look at what is going on, and work to understand how all of these API specifications work together (or don&amp;rsquo;t). What Are The Leading API Specifications There are a handful of API specifications that are relevant to delivering APIs in 2020, helping provide a vocabulary for stakeholders in the process to use when describing what each API does, so that a common definition can be applied through the API lifecycle, consistently delivering API infrasture across many teams. Here are the API specifications I am focusing on as part of my API Specification Toolbox conversations. OpenAPI - A specification for defining the surface area of HTTP 1.1 web APIs using JSON or YAML. AsyncAPI - A specification for defining the surface area of HTTP 1.1, HTTP/2, HTTP/3, TCP, MQTT, and AMQP APIs using JSON or YAML. JSON Schema - A specification for defining the underlying models in use for APIs, adopted by both OpenAPI and AsyncAPI. Postman Collections - A specification for defining executable collections of HTTP 1.1 web APIs for running in services and tooling Postman Environments -&amp;nbsp;A specification for defining key / value pairs that get applied across collections at execute time. RAML - A YAML format for describing the surface area of your HTTP 1.1 APIs, and the the underlying objects. GraphQL - A query language for APIs and a runtime for fulfilling queries on top of data and content. SOAP&amp;nbsp; - A messaging protocol specification for exchanging structured information across web services.&amp;nbsp; SOAP has been around for a number of years, but OpenAPI, AsyncAPI, JSON Schema, RAML, and GraphQL have emerged within the latest decade. OpenAPI, AsyncAPI, and JSON Schema have all evolved in concert with each other, where RAML, GraphQL, and SOAP developed in isolation. I am including all of these because I think they need to be discussed in relationship to each other, and we need to work harder to understand the overlapping layers of how we deliver APIs, as well as the common needs when it comes to the lifecycle usage of these API specifications(ie. design, documentation, testing). The success of OpenAPI ,AsyncAPI, and JSON Schema is largely due to overlapping, sharing, and reuse across the specifications, which sets a tone for how things should work we move forward and iterate upon each of these specifications, or introduce new ones. Reasons Why Each Specification Sees Adoption...]]></content>
    <id>http://apievangelist.com/2020/11/23/a-high-level-look-at-api-specifications/</id>
  </entry><entry>
    <title>Managing the Scope of Your OpenAPI</title>
    <link href="http://apievangelist.com/2020/11/18/managing-the-scope-of-your-openapi/"/>
    <updated>2020-11-18T00:00:00Z</updated>
    <content><![CDATA[Managing the size of an OpenAPI is a common challenge for API development teams. I have regular conversations with teams about the ways in which you can minimize the overall scope of an API, breaking things down into more manageable chunks, while also reducing redundancy&amp;mdash;then encouraging reuse. Like other dimensions of the API space there are differing opinions on whether it is better to have one single OpenAPI for all of your APIs, or whether it makes more sense to break things down into well defined bounded contexts. You can see this debate occurring in Monolith vs Microservices, and MonoRepo vs Multi-Repo discussions across the API space. In this game, there are no right or wrong answers, just different approaches that work well for different organizations, teams, and individuals. My goal is to help folks understand the trade-offs by informing them enough to make their own decisions and set into motion API design practices that keep the API factory floor moving along. The size of your APIs matter. The size of your OpenAPI for your APIs matters. The scope, complexity, and consistency of your APIs will define how easy they are to maintain and put to work. Organizations that do not use OpenAPI struggle with being able to define the API landscape at all, let alone being able to define the scope of individual APIs or groups of APIs. It is common for API providers who are moving into the OpenAPI realm to slam into the brick wall of API scope right away, realizing their OpenAPI definitions are too big to work with in some services and tooling, and become a maze of complexity when it comes to maintenance and consumption. While there are many ways your API design practices can reduce or at least better define the scope of your APIs and resulting APIs, there are a handful of ways you can slice and dice your APIs up to make them easier to manage, or settle in with accepting that there is one monolith OpenAPI to rule them all! Paths The design of your resource-centric HTTP APIs will help or hinder your ability to spread the scope of your APIs across multiple files. Depending on the underlying schema model, and the types of resources being made available, as well as the API design training and guidance given to teams, the number and scope of API paths being served up will vary. If you have a coherent resource and sub-resource strategy it becomes easier to break things down into more manageable groupings. Helping break your APIs and the OpenAPIs that define them into much more meaningful and reusable chunks. API paths will define your OpenAPI journey, and define the complexity and breakdown of your API lifecycle, so make sure you are thinking about the design of API paths across all teams throughout your organization.&amp;nbsp; Methods How you use your HTTP methods as part of the API design process will help you downstream when it comes to breaking things down in...]]></content>
    <id>http://apievangelist.com/2020/11/18/managing-the-scope-of-your-openapi/</id>
  </entry><entry>
    <title>Using API Mocks as Part of an API-First Workflow</title>
    <link href="http://apievangelist.com/2020/11/17/using-api-mocks-as-part-of-an-apifirst-workflow/"/>
    <updated>2020-11-17T00:00:00Z</updated>
    <content><![CDATA[I owe an answer on my thoughts about mocking APIs to my coworker Andy, and I don&amp;rsquo;t want to incur his wrath, so I figured I&amp;rsquo;d write it up and share wider as I was getting back to him. I don&amp;rsquo;t have the original question cause it was in a Zoom chat, but it was something to the effect of using mock APIs to move forward the design of an API versus using them to drive application development conversations as well as push testing forward. I&amp;rsquo;d say that using a mock as part of an API-first design process reflects where I am pushing mocks to work for me more often. I still use them to demo, prototype applications, and as part of API testing, but using them to actually evolve the contract for an API is really where I feel that a mock server will really shine, and can shift how we are delivering APIs. However, there is also a lot of education and awareness needed before I get all the folks I am having conversations with on board with this concept&amp;mdash;to help in these efforts I wanted to flesh out&amp;nbsp;a little about what I mean when it comes to API-first usage of mock APIs. Mocking From Postman Collections The first part of this conversation involves the concept that you can generate a mock server from any Postman collection. There is a three step process involved with producing a mock API in Postman using a collection. First you create a collection with the path and parameters you would like to use as the definition of the API you are mocking. Once you have your path you can select examples up near the send button and add a new example for this request. It will take your path with parameters and map to a new example where you can add a JSON example to represent what should be returned by your mock server for an example. You should now have a single request, and the example that should be returned when the API request is sent. Now you can select to mock the collection, giving it a name, mapping to an environment, making private, and a handful of other settings that will help us manage the mocked representation of our API. Once complete you will be given a URL for the mock server, which can be added to the environment or collection and used for any requests. This is the baseline of mocking of an API using Postman, which can be used as part of an API-first process, but there are a couple of other dimensions to this that will help truly strengthen mocking as a critical stop along an API-first lifecycle. Generating Mock Collections From OpenAPI For the first part of this I am just generating a mock from a standalone collection. Using Postman you can also generate a collection from an OpenAPI definition, and identify the purpose of that collection is for mocking. If you identify it as existing...]]></content>
    <id>http://apievangelist.com/2020/11/17/using-api-mocks-as-part-of-an-apifirst-workflow/</id>
  </entry><entry>
    <title>The Multiple Dimensions of API Deployment</title>
    <link href="http://apievangelist.com/2020/11/17/the-multiple-dimensions-of-api-deployment/"/>
    <updated>2020-11-17T00:00:00Z</updated>
    <content><![CDATA[API deployment is the OG stop along the API lifecycle, but is still the most underserved when it comes to API service providers providing solutions, and as part of the full lifecycle API management conversation. I remember back in 2011 folks asking me which of the API management providers would help them deploy their APIs, which at the time none of them would, being a pretty regular concern when it came to doing APIs at all, let alone doing them well. I have seen many &amp;ldquo;API deployment&amp;rdquo; solutions come and go, and after a decade I see some movements forward, but overall API deployment is still really difficult in ways that just doesn't make sense. Data APIs Making data available via simple APIs is the most common type of APIs you will come across out there, and the most common reason for providing as well as consuming APIs. Deploying data APIs are pretty straightforward to do, and there have been a wide variety of services and tooling made available to help developers deliver these types of APIs. Even with the simplicity of this type of APIs, I haven&amp;rsquo;t seen too many platform successfully monetize a data API deployment solution, or deliver a dead simple, widely adopted, single push of a button solution to delivering data APIs. It really is one of those areas that should have been 100% solved by now, and would be if it was for the incentive models that exists behind most platforms, but also due to some pretty widespread unhealthy practices when it comes to managing and publishing data, making a lot of data pretty messy to work with when it comes to making available data APIs. Content APIs These types of APIs often overlap with the world of data APIs, but I want to highlight them separately because of content delivery network (CDN) considerations, as well as movements in the headless CMS world when it comes to enabling dead simple API deployment. I would say that the headless CMS movement is one of the more significant movement forward in this area, and I am looking hard at solutions like Flotiq and Strapi to help me take the next big steps when it comes to deploying APIs from within Postman. Another significant difference between data and content APIs is who these words are meaningful to, and the business prioritization these individuals possess. Meaning data is going to mean more to developers and data folks, where content is going to be more meaningful to marketing and business folks. These things matter when it comes to having the budget to pay for a solution, which is something that ultimately drives what I am talking about when it comes to the overall state of API deployment. Algorithms and Business Logic The third main bucket of APIs that usually throws a monkey wrench into the overall API deployment conversation is when there is actual code, business logic, and algorithms being deployed as part of an API. Meaning it isn&amp;rsquo;t just...]]></content>
    <id>http://apievangelist.com/2020/11/17/the-multiple-dimensions-of-api-deployment/</id>
  </entry><entry>
    <title>Some API Specification Toolbox Projects That Will Make an Impact</title>
    <link href="http://apievangelist.com/2020/11/12/some-api-specification-toolbox-projects-that-will-make-an-impact/"/>
    <updated>2020-11-12T00:00:00Z</updated>
    <content><![CDATA[I have been conducting weekly discussions around API specifications each Friday mornings which I call the API Specification Toolbox. The goal is to just identify ways in which we can drive more discussion and participation in API specifications, focusing on OpenAPI, AsyncAPI, JSON Schema, GraphQL, and Postman Collections. My goal is to help increase awareness of these specifications, but more importantly get more people sharing what they are working on and invest more time and resources into supporting the specifications. I conduct an hour of informal discussions from 8:00 AM to 9:00 AM PST each Friday, and we record as many of our ideas and talking points on Github using issues. Some interesting ideas have emerged from the discussion, and I am taking some of the lowest hanging fruit from these ideas, organizing them, and working with the OAI, AsyncAPI, JSON Schema, and Postman team to try and bring some of these ideas to life.&amp;nbsp; There are many other ideas that didn&amp;rsquo;t make my starter list of project, but these are the ones I feel are the most important, would have the the greatest impact, and be achievable in small bursts of work, and to help drive some conversation I am having, I wanted to flesh out some of the top ideas here on the blog. I cleaned up the titles for each of these ideas, and grouped them based upon the type of project, and I would like to flesh out a little more, identify how they overlap and are related&amp;mdash;then work to actually push them forward without me doing all of the work. I feel like with some assistance from the wider API community, and some investment from the OAI, AsyncAPI, JSON Schema, and Postman, these projects could make a pretty significant impact on what is going on across the API landscapes. My objective with this post is to show how all of these projects can feed each other, and see what I can convince the community, and each specification to help move forward. Providing me with the words I am going to need to sell these ideas to anyone who will listen, and potentially help make things actually happen. Mapping The Landscape I feel this area is one of the cornerstone deficiencies that slows the forward motion of the specifications, services, and tooling. In my opinion, everything is dependent on these four areas, meaning if we can clearly articulate the services, tooling, and people involved with these API specifications, and understand how they are extending the specification, all of these specifications and resulting tooling will lurch forward without any clear vision or coherency. As a community, we need to be able to efficiently profile and publish directories of services, tooling, people, and extensions, and do it in a way that can paint a full picture of what is going on. These are the four core projects I feel are needed to map the API specification landscape. Service Providers #19 - Identifying, profiling, and publishing a directory of...]]></content>
    <id>http://apievangelist.com/2020/11/12/some-api-specification-toolbox-projects-that-will-make-an-impact/</id>
  </entry><entry>
    <title>An API Lifecycle Collection Playbook</title>
    <link href="http://apievangelist.com/2020/11/11/an-api-lifecycle-collection-playbook/"/>
    <updated>2020-11-11T00:00:00Z</updated>
    <content><![CDATA[I have a single API request that is becoming the first call I make on a growing number of Postman ccollections. It is a call to the Postman API to pull the OpenAPI for any API I am managing using Postman. This gives me the OpenAPI contract for an API so that I can move forward as part of a variety of stops along the lifecycle, starting with mocking, documentation, and testing as part of an API-first approach, but then also potentially monitoring, securing, generate client code, or even deployment and management of an API. I am working with a number of API service providers to define Postman collections that go well beyond the common APIs you will find in the Postman API Network, helping develop entirely new categories of collections that are designed to deliver different stops along the API lifecycle, so I am looking to develop a playbook for how you create one of these new types of collections, baking your API services into the Postman platform. Publish a Team Page Any partnership with an API service provider and the Postman platform begins with publishing of a team profile to the Postman network. Providing a logo, name, and description for your company, creating your official team profile on the Postman platform&amp;mdash;here is my reference API implementation team page from the Postman API network.&amp;nbsp; You can manage your team profile under your team settings in your Postman dashboard. You can upload a logo, choose a name, and provide a description. When ready, you can choose to make your profile public, choosing a subdomain for your company on the Postman platform.&amp;nbsp; This is the profile for your API services on the Postman platform, accessible by 13 million developers via their desktop application and on the web. All the collections and template you publish for your services will show up here, and be discoverable via Postman and Google search, providing more exposure for the services you are making available to API providers. API Lifecycle Collections Most of the Postman collections available in the API Network are from API providers like Twitter and Salesforce, but as we are ramping up our partnering across the API lifecycle, we are looking to get a lot more DevOps, DevSecOps, and APIOps collections available that push the API network beyond just SaaS and product APIs. As Postman is expanding to become a full lifecycle API management provider it is partnering for many of these stops along the API lifecycle. Postman&amp;rsquo;s roots as an HTTP client, debugging, and testing tool provides a base, and we&amp;rsquo;ve rolled out the builder, documentation, mocking, code generation, and other portions of the lifecycle over the years. But, we aren&amp;rsquo;t about to reinvent the wheel when it comes to API deployment, management, security, and other more established portions of the API lifecycle, and we are depending on you to deliver these capabilities for us. So, let&amp;rsquo;s walk through the anatomy of an API lifecycle collection that can help you deliver API lifecycle...]]></content>
    <id>http://apievangelist.com/2020/11/11/an-api-lifecycle-collection-playbook/</id>
  </entry><entry>
    <title>A Lifecycle for the API Factory Floor</title>
    <link href="http://apievangelist.com/2020/11/10/a-lifecycle-for-the-api-factory-floor/"/>
    <updated>2020-11-10T00:00:00Z</updated>
    <content><![CDATA[I am pushing forward a handful of conversations with enterprise organizations about how to better formalize their API lifecycle workflow. To help me load up my talking points in my head I wanted to publish a post here on the blog. Using Postman I am finally able to actually execute on my API lifecycle visions in the most tangible way since I started doing all of this in 2010. Postman is a Swiss Army Knife that allows me to approach the API lifecycle in a variety of ways depending on the situation I find myself in. While there are a lot of unknowns when it comes to doing APIs, there are also a lot of common patterns to use, and this is an exploration of these standardized approaches, allowing me to articulate them tomorrow during some discussions. Workspace It may seem obvious, but I am finding that having a well defined workspace to define, design, and manage APIs is essential to doing APIs well. Having a single place where you can find the contract and supporting artifacts that define each of the stops along the API lifecycle is needed to do all of this at scale, and consistently collaborate and move APIs forward. There are a handful of elements needed to define an API workspace when you are using Postman. Name - You'd be surprised at how important the name of an API can be when it comes to making it discoverable and usable by consumers--how you name your API will define a lot about it. Description - A well written description for an API is your first impression when it comes to onboarding consumers. They shouldn't be a novel, but it should provide enough information for a consumer to understand what it does. Administrative Team Members - Have your leadership team identified, make sure they are plugged in and know what needs to be done, giving them the control and observability they need. Collaborator Team Members - Define all the other stakeholders who should have direct access to the workspace, and be able to provide feedback, and iterate upon each of the APIs being delivered. Do not underestimate the importance of a dedicated workspace that is designed for iterating upon your APIs. You should be able to access your OpenAPI, and the collections driving docs, mocks, tests, as well as all of the orchestration applied using runners and monitors via a single shareable URL. You'd be surprised at how much a workspace can anchor the evolution of your APIs, providing the cornerstone needed to move things forward in a logical, coherent, and collaborative manner. Machine Readable Contracts The centerpiece of any workspace should be one or many OpenAPI contracts defining what is possible with an API. Providing the details of each request and response as a single human and machine readable contract, that can be versioned, evolved, and used across the API lifecycle. Postman allows you to place the contract for your APIs at the center of your workspace,...]]></content>
    <id>http://apievangelist.com/2020/11/10/a-lifecycle-for-the-api-factory-floor/</id>
  </entry><entry>
    <title>Shifting How API Providers Define What An Application Is When Onboarding and Integrating With Their APIs</title>
    <link href="http://apievangelist.com/2020/10/28/shifting-how-api-providers-define-what-an-application-is-when-onboarding-and-integrating-with-their-apis/"/>
    <updated>2020-10-28T00:00:00Z</updated>
    <content><![CDATA[When you sign up to access most APIs you will have to sign up for an account, create an application, and retrieve a set of keys and / or tokens before you will be able to use the API. This is standard practice that is baked into the home grown as well as Commercial API management solutions available across the landscape. This is a concept that was introduced back in 2005 by Mashery, and is something that hasn&amp;rsquo;t changed much over the years, despite what we build on top of APIs, and use APIs for having changed significantly over the last decade. In 2020, this relic of API management past needs to evolve if API providers and consumers are going to use APIs to their fullest potential&amp;mdash;something API management service providers are going to have to take the lead on, and get back to work innovating and not just being a commodity. When I sign up for Twitter&amp;rsquo;s API I have to create an application before I can get the tokens I need to begin using the application. I have to provide a name, purpose, and other details about what that application is&amp;mdash;even if I do not fully understand what that is. Most API provider&amp;rsquo;s notion of an application means web or mobile application, but in reality it can be the &amp;ldquo;application&amp;rdquo; of the data, content, and algorithms being made available via an API in a variety of ways from just pulling data to integrating in real-time with other systems. As an API analyst and storyteller I rarely am building an application, but just looking to kick the tires and understand what is going on&amp;mdash;being forced to define an application is nothing but a road block for me. I may be a small group of API consumers, but there are many other edge cases which are similar to my situation in that we represent the long tail of API consumption in the unknown unknown API usage quadrant&amp;mdash;meaning we are still figuring out why we need an API.&amp;nbsp; The most significant breakdown in the concept of defining an application is that it is designed for use by developers. In an iPaaS, BPM, and API automated business world, the legacy API management application definition doesn&amp;rsquo;t work. It is bad enough that an application stands in between a regular user of a platform and getting access to their data, content, and the useful algorithms that exist, but we often also hide all of this in some other completely separate developer area, excluding them from the conversation&amp;mdash;instead of just making the API, and access to the API a natural part of the platform account management and settings. This separation between business and integration interfaces reflect decades of division between business and IT groups that needs to be done away with as we move forward in an API-driven business landscape. There is no reason that as a user of an &amp;ldquo;application&amp;rdquo;, that I need to venture to another separate section of a platform and create...]]></content>
    <id>http://apievangelist.com/2020/10/28/shifting-how-api-providers-define-what-an-application-is-when-onboarding-and-integrating-with-their-apis/</id>
  </entry>
</feed>
