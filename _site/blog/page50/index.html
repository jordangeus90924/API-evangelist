<!DOCTYPE html>
<html xmlns="https://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
  <html>
  <title>API Evangelist </title>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
  <!--[if lte IE 8]><script src="/assets/js/ie/html5shiv.js"></script><![endif]-->
  <link rel="stylesheet" href="/assets/css/main.css" />
  <link rel="stylesheet" href="/assets/css/bootstrap.min.css" />
  <!--[if lte IE 9]><link rel="stylesheet" href="/assets/css/ie9.css" /><![endif]-->
  <!--[if lte IE 8]><link rel="stylesheet" href="/assets/css/ie8.css" /><![endif]-->

  <!-- Icons -->
  <link rel="shortcut icon" type="image/x-icon" href="https://apievangelist.com/favicon.ico">
	<link rel="icon" type="image/x-icon" href="https://apievangelist.com/favicon.ico">

  <link rel="alternate" type="application/rss+xml" title="API Evangelist Blog - RSS 2.0" href="https://apievangelist.com/blog.xml" />
  <link rel="alternate" type="application/atom+xml" title="API Evangelist Blog - Atom" href="https://apievangelist.com/atom.xml">

  <!-- JQuery -->
  <script src="/js/jquery-latest.min.js" type="text/javascript" charset="utf-8"></script>
  <script src="/js/bootstrap.min.js" type="text/javascript" charset="utf-8"></script>
  <script src="/js/utility.js" type="text/javascript" charset="utf-8"></script>

  <!-- Github.js - http://github.com/michael/github -->
  <script src="/js/github.js" type="text/javascript" charset="utf-8"></script>

  <!-- Cookies.js - http://github.com/ScottHamper/Cookies -->
  <script src="/js/cookies.js"></script>

  <!-- D3.js http://github.com/d3/d3 -->
  <script src="/js/d3.v3.min.js"></script>

  <!-- js-yaml - http://github.com/nodeca/js-yaml -->
  <script src="/js/js-yaml.min.js"></script>

  <script src="/js/subway-map-1.js" type="text/javascript"></script>

  <style type="text/css">

    .gist {width:100% !important;}
    .gist-file
    .gist-data {max-height: 500px;}

    /* The main DIV for the map */
    .subway-map
    {
        margin: 0;
        width: 110px;
        height: 5000px;
        background-color: white;
    }

    /* Text labels */
    .text
    {
        text-decoration: none;
        color: black;
    }

    #legend
    {
    	border: 1px solid #000;
        float: left;
        width: 250px;
        height:400px;
    }

    #legend div
    {
        height: 25px;
    }

    #legend span
    {
        margin: 5px 5px 5px 0;
    }
    .subway-map span
    {
        margin: 5px 5px 5px 0;
    }

    </style>

    <meta property="og:url" content="">
    <meta property="og:type" content="website">
    <meta property="og:title" content="API Evangelist">
    <meta property="og:site_name" content="API Evangelist">
    <meta property="og:description" content="A network of research sites dedicated to the technology, business, and politics of APIs.">
    <meta property="og:image" content="http://s3.amazonaws.com/kinlane-productions/api-evangelist/t-shirts/KL_InApiWeTrust-1000.png">

    <meta name="twitter:url" content="">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="API Evangelist">
    <meta name="twitter:site" content="API Evangelist">
    <meta name="twitter:description" content="A network of research sites dedicated to the technology, business, and politics of APIs.">
    
      <meta name="twitter:creator" content="@apievangelist">
    
    <meta property="twitter:image" content="http://s3.amazonaws.com/kinlane-productions/api-evangelist/t-shirts/KL_InApiWeTrust-1000.png">


</head>

  <body>

			<div id="wrapper">
					<div id="main">
						<div class="inner">

              <header id="header">
  <a href="http://apievangelist.com" class="logo"><img src="https://kinlane-productions.s3.amazonaws.com/api-evangelist/api-evangelist-logo-400.png" width="75%" /></a>
  <ul class="icons">
    <li><a href="https://twitter.com/apievangelist" class="icon fa-twitter"><span class="label">Twitter</span></a></li>
    <li><a href="https://github.com/api-evangelist" class="icon fa-github"><span class="label">Github</span></a></li>
    <li><a href="https://www.linkedin.com/organization/1500316/" class="icon fa-linkedin"><span class="label">LinkedIn</span></a></li>
    <li><a href="http://apievangelist.com/atom.xml" class="icon fa-rss"><span class="label">RSS</span></a></li>
  </ul>
</header>

    	        <section>
	<div class="content">

	<h3>The API Evangelist Blog</h3>
	<p>This blog is dedicated to understanding the world of APIs, exploring a wide range of topics from design to deprecation, and spanning the technology, business, and politics of APIs. <a href="https://github.com/kinlane/api-evangelist" target="_blank">All of this runs on Github, so if you see a mistake, you can either fix by submitting a pull request, or let us know by submitting a Github issue for the repository</a>.</p>
	<center><hr style="width: 75%;" /></center>
	
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/11/12/9-essential-languages-for-your-api-code-libraries/">9 Essential Languages For Your API Code Libraries</a></h3>
        <span class="post-date">12 Nov 2013</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/google-drive/bw-google-drive-icon.png" alt="" width="100" align="right" /></p>
<p>I was working with Google APIs over the last couple days while building <a href="http://apievangelist.com/2013/11/12/deploy-api-private-google-spreadsheet-to-api/">Google Spreadsheet to API tools</a>. It gave me a chance to look around the <a href="https://developers.google.com">Google Developers Area</a> and rediscover some of the positive approaches the API pioneer brings to the table.</p>
<p>In this post I wanted to highlight the <a title="Google Drive Code Libraries" href="https://developers.google.com/drive/downloads">Google Drive Code Libraries</a>. While the Google approach isn't perfect, I think it sets a good bar for what can be achieved by API providers when delivering their own API code libraries.</p>
<p><a title="Google Drive Code Libraries" href="https://developers.google.com/drive/downloads"><img style="display: block; margin-left: auto; margin-right: auto;" src="https://s3.amazonaws.com/kinlane-productions/google-drive/google-drive-code-samples-2.png" alt="" width="550" /></a></p>
<p>I think the languages represented are the baseline for any modern API, and all API providers should consider providing the following languages:</p>
<ul class="mainlist">
<li>.NET</li>
<li>Go</li>
<li>Java</li>
<li>JavaScript</li>
<li>Node.js</li>
<li>Objective-C</li>
<li>PHP</li>
<li>Python</li>
<li>Ruby</li>
</ul>
<p>Languages like Go and Node.js are definitely forward leaning, but represent very fast growing areas of the API integration space.</p>
<p>Java and Objective-C represent the mobile space, something API providers can't be ignoring in 2013.</p>
<p>If your target audience is the enterprise, you have to have .NET and Java as part of your API library.</p>
<p>PHP, Python and Ruby are the web staples, that are default for any API that is catering to general web developers.</p>
<p>It should get easier to generate code libraries automatically for API providers who have developed some sort of API definition for their APIs, but for others you will still have eto hand-roll your own code lbiraries.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/11/12/9-essential-languages-for-your-api-code-libraries/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/11/08/dwolla-open-sources-mobile-payment-app/">Dwolla Open Sources Mobile Payment App</a></h3>
        <span class="post-date">08 Nov 2013</span>
        <p><a href="http://blog.dwolla.com/for-developers-an-open-source-mobile-wallet-built-on-the-dwolla-network/"><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/api-evangelist/dwolla/dwolla-open-source-iphone-app.png" alt="" width="175" align="right" /></a></p>
<p>Every API provider should provide code samples in a variety of languages, helping developers get up and running as fast as possible.</p>
<p>Dwolla is taking this one step further and <a href="http://blog.dwolla.com/for-developers-an-open-source-mobile-wallet-built-on-the-dwolla-network/">providing a fully functional iOS app that developers can fork, tweak and use</a> as they wish.</p>
<p>I've talked about what I call "starter kits" before, when I <a href="http://apievangelist.com/2011/09/17/providing-code-libraries-is-not-enough-for-your-api/">showcased Google+ sample social applications in a variety of languages</a>, but it is still something I don't see from very many API providers.</p>
<p>Complete mobile applications is a great way to showcase what a complete API integration will look like, helping developers see the end goal clearly, while also teaching them best practices.</p>
<p>Do you have any applications you could open source and allow developers to reverse engineer? Or maybe an app you could developer to show developers what is possible!</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/11/08/dwolla-open-sources-mobile-payment-app/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/11/08/automatic-rest-api-for-databases-as-complete-amazon-machine-image/">Automatic REST API for Databases As Complete Amazon Machine Image</a></h3>
        <span class="post-date">08 Nov 2013</span>
        <p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/api-service-providers/slashdb/slashdb-logo.png" alt="" width="125" align="right" /></p>
<p><a title="SlashDB" href="http://www.slashdb.com/">SlashDB</a> aka /db, has recently been added to the Amazon Marketplace, providing a <a title="complete database to API solution as an Amazon Machine Image (AMI)" href="https://aws.amazon.com/marketplace/pp/B00FFKW0GC/ref=vdr_rf#product-details">complete database to API solution as an Amazon Machine Image (AMI)</a>.</p>
<p>Companies can use the /db Amazon image to automatically <a title="generate REST APIs from common relational databases" href="http://apievangelist.com/2013/03/18/database-to-api-with-slashdb/">generate REST APIs from common relational databases</a> like Microsoft SQL Server, Oracle, MySQL, PostGreSQL, which includes Amazon RDS.</p>
<p>/db charges based upon the number of databases you launch and the number of users that are using the API for the database, and you will have to pay for the regular charges for any Amazon EC2 instances.</p>
<p>I like the idea of building API solutions and launching as Amazon Machine Images. I think ready-to-go platform solutions like this for AWS, Google, Heroku and other top cloud platforms are good for potential API providers.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/11/08/automatic-rest-api-for-databases-as-complete-amazon-machine-image/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/11/07/apis-ongithub/">APIs Ongithub</a></h3>
        <span class="post-date">07 Nov 2013</span>
        <p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/api-on-github/api-on-github-logo.png" alt="" width="250" align="right" /></p>
<p>I've created a new playground for some of my work. Pretty much everything at <a title="API Evangelist" href="http://apievangelist.com">API Evangelist</a> runs on Github, and each new project I produce starts its life as a Github repository.  To support this work I established a new domain called ongithub.</p>
<p>My first series in the ongithub realm is based upon an approach I'm using to deploy very simple APIs, while also introducing and educating people about APIs. I have a handful of simple API designs from working in the government, so I married them with data models derived from <a href="http://schema.org">schema.org</a>, and publish over 10 very simple API design patterns.</p>
<p>Every one of these demo APIs began as a simple <a title="swagger" href="https://developers.helloreverb.com/swagger/">Swagger specification</a>, which I quickly spun into a web API using the <a title="SLIM REST Framework" href="http://www.slimframework.com/">Slim REST Framework</a>, then generated a simple API microsite complete with interactive documentation.</p>
<p>These Swagger specifications were the seed of the recent <a href="http://techcrunch.com/2013/11/05/3scale-launches-api-commons-to-allow-developers-to-share-apis-under-creative-commons-licenses/">API Commons that 3Scale and API Evangelist just launched</a>. I have plenty of other API designs laying around, but this seemed like a good way to seed the <a title="API Commons" href="http://apicommons.org">API Commons</a> with some simple and common designs.</p>
<p>You can find the following 11 designs at <a title="api.ongithub.com" href="http://api.ongithub.com">api.ongithub.com</a>:</p>
<p>&nbsp;</p>
<table id="api-listing" style="padding-left: 25px;" width="100%">
<tbody>
<tr>
<td width="15%" align="center"><a href="http://ongithub.github.io/businesses/" target="_blank"><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-business-icon.png" alt="" width="50" align="left" /></a></td>
<td align="left"><a href="http://ongithub.github.io/businesses/" target="_blank"><strong>Businesses</strong></a></td>
<td align="left">This is a simple API specification for a listing of businesses.</td>
</tr>
<tr>
<td width="15%" align="center"><a href="http://ongithub.github.io/events/" target="_blank"><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-calendar.png" alt="" width="50" align="left" /></a></td>
<td align="left"><a href="http://ongithub.github.io/events/" target="_blank"><strong>Events</strong></a></td>
<td align="left">This is a simple API specification for a listing of events.</td>
</tr>
<tr>
<td width="15%" align="center"><a href="http://ongithub.github.io/images/" target="_blank"><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-camera.jpg" alt="" width="50" align="left" /></a></td>
<td align="left"><a href="http://ongithub.github.io/images/" target="_blank"><strong>Images</strong></a></td>
<td align="left">This is a simple API specification for a listing of photos and images.</td>
</tr>
<tr>
<td width="15%" align="center"><a href="http://ongithub.github.io/jobs/" target="_blank"><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-job.jpg" alt="" width="50" align="left" /></a></td>
<td align="left"><a href="http://ongithub.github.io/jobs/" target="_blank"><strong>Jobs</strong></a></td>
<td align="left">This is a simple API specification for a listing of jobs.</td>
</tr>
<tr>
<td width="15%" align="center"><a href="http://ongithub.github.io/offices/" target="_blank"><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-office.png" alt="" width="50" align="left" /></a></td>
<td align="left"><a href="http://ongithub.github.io/offices/" target="_blank"><strong>Offices</strong></a></td>
<td align="left">This is a simple API specification for a listing of offices.</td>
</tr>
<tr>
<td width="15%" align="center"><a href="http://ongithub.github.io/places/" target="_blank"><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-places.png" alt="" width="50" align="left" /></a></td>
<td align="left"><a href="http://ongithub.github.io/places/" target="_blank"><strong>Places</strong></a></td>
<td align="left">This is a simple API specification for a listing of places.</td>
</tr>
<tr>
<td width="15%" align="center"><a href="http://ongithub.github.io/people/" target="_blank"><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-people.png" alt="" width="50" align="left" /></a></td>
<td align="left"><a href="http://ongithub.github.io/people/" target="_blank"><strong>People</strong></a></td>
<td align="left">This is a simple API specification for a listing of people.</td>
</tr>
<tr>
<td width="15%" align="center"><a href="http://ongithub.github.io/press/" target="_blank"><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-news-icon.png" alt="" width="50" align="left" /></a></td>
<td align="left"><a href="http://ongithub.github.io/press/" target="_blank"><strong>Press</strong></a></td>
<td align="left">This is a simple API specification for a listing of news and press releases.</td>
</tr>
<tr>
<td width="15%" align="center"><a href="http://ongithub.github.io/products/" target="_blank"><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-products.png" alt="" width="50" align="left" /></a></td>
<td align="left"><a href="http://ongithub.github.io/products/" target="_blank"><strong>Products</strong></a></td>
<td align="left">This is a simple API specification for a listing of products.</td>
</tr>
<tr>
<td width="15%" align="center"><a href="http://ongithub.github.io/programs/" target="_blank"><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-programs.png" alt="" width="50" align="left" /></a></td>
<td align="left"><a href="http://ongithub.github.io/programs/" target="_blank"><strong>Programs</strong></a></td>
<td align="left">This is a simple API specification for a listing of programs.</td>
</tr>
<tr>
<td width="15%" align="center"><a href="http://ongithub.github.io/videos/" target="_blank"><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-video.png" alt="" width="50" align="left" /></a></td>
<td align="left"><a href="http://ongithub.github.io/videos/" target="_blank"><strong>Videos</strong></a></td>
<td align="left">This is a simple API specification for a listing of videos.</td>
</tr>
</tbody>
</table>
<p>&nbsp;</p>
<p>If there are any API designs you'd like to see published to api.ongithub.com, let me know.  If you'd prefer a Ruby, Python or Node.js API backend, also let me know.</p>
<p>I will be playing with as many API design patterns here as I can fit in. I encourage you to fork any of my work and make sure to submit any of your own work to API Commons.  If you have a design you think would fit in well with api.ongithub.com let me know, and I am happy to list.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/11/07/apis-ongithub/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/11/06/putting-the-open-in-api-with-the-api-commons/">Putting The Open In API With The API Commons</a></h3>
        <span class="post-date">06 Nov 2013</span>
        <p><a href="http://apicommons.org"><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/api-commons/api-commons-logo.png" alt="" width="275" align="right" /></a></p>
<p>Steve Willmott(<a href="https://twitter.com/njyx">@njyx</a>) from API infrastructure provider <a title="API infrastructure provider" href="http://3scale.net">3Scale</a> and API Evangelist launched a new partner project yesterday at <a href="http://defragcon.com/">Defrag</a>, that we are calling <a href="http://apicommons.org">API Commons</a>.  The mission with API commons is to provide a simple and transparent mechanism for the copyright free sharing and collaborative design of API specifications, interfaces and data models.</p>
<p>For a space that is about open access and interoperability the API industry has been very closed about their API designs, and after <a href="http://apievangelist.com/2013/06/02/helping-eff-urge-the-courts-to-block-copyright-claims-in-oracle-v-google-api-fight/">helping the EFF urge the courts to block copyright claims in the Oracle v. Google API fight</a>, Steve and I thought it would be a good idea to introduce an API commons that would help put the "open" into API designs and data models, and back into the API space in gernal.</p>
<p>API Commons is build entirely on Github and is meant to act as a common index of API definitions and data models that <a href="http://apicommons.org/add-apis.html">anyone can add by generating what we are calling an API Commons Manifest</a> that points to your API definition(s). Using the existing layers of Github, anyone can fork, favorite or follow the best API design patterns and eventually help establish some clear best practices across any government or business sector.</p>
<p>Everything you need to get going is on the site at <a title="apicommons.org" href="http://apicommons.org">apicommons.org</a>. You can join the discussion on the <a href="https://groups.google.com/forum/?hl=en#!forum/api-commons">Google Group</a> or by <a href="https://twitter.com/apicommons">following us on Twitter</a>. We are in early stages, but will be dedicating a great deal of time over the holidays to get more API definitions in the commons.</p>
<p>3Scale and I strongly believe that API Commons is what the API industry needs to help deal with some of the clutter in the number of API designs, incentivize the development of open and common tooling around the best API designs and bring reuse, collaboration and copyright concerns out into the open.</p>
<p>Also check out some of the great news coverage of API Commons over the last 24 hours:</p>
<ul class="mainlist">
<li><a href="http://techcrunch.com/2013/11/05/3scale-launches-api-commons-to-allow-developers-to-share-apis-under-creative-commons-licenses/">New API Commons Platform Allows Developers To Share APIs Under Creative Commons Licenses</a></li>
<li><a href="http://blog.programmableweb.com/2013/11/05/api-commons-launched-share-your-api-code/">API Commons Launched: Share Your API Code</a></li>
<li><a href="http://www.zdnet.com/at-last-an-api-commons-7000022849/">At last, an API Commons</a></li>
<li><a href="http://www.forbes.com/sites/benkepes/2013/11/05/solving-the-tragedy-of-the-api-commons/">Solving The Tragedy Of The API Commons</a></li>
<li><a href="http://www.wired.com/wiredenterprise/2013/11/api-commons/">Oracle Sued Google Over Android. But There&rsquo;s Hope For the Future</a></li>
</ul>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/11/06/putting-the-open-in-api-with-the-api-commons/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/11/06/open-data-and-api-efforts-rendered-useless-when-privacy-is-ignored/">Open Data And API Efforts Rendered Useless When Privacy Is Ignored</a></h3>
        <span class="post-date">06 Nov 2013</span>
        <p><a href="http://www.opengovpartnership.org/"><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/federal-government/open-government-partnership.png" alt="" width="150" align="right" /></a></p>
<p><a href="http://www.opengovpartnership.org/"> </a></p>
<p><a href="http://www.opengovpartnership.org/">On the second anniversary of the </a><a href="http://www.opengovpartnership.org/">Open Government Partnership (OGP)</a>, where we are celebrating a "<a href="http://www.whitehouse.gov/the-press-office/2013/10/31/fact-sheet-marking-progress-second-anniversary-open-government-partnersh">global effort to encourage transparent, effective, and accountable governance</a>", and that:</p>
<p style="padding-left: 30px;"><em>OGP has grown to 60 countries that have made more than 1000 commitments to improve the governance of more than two billion people around the globe.  OGP is now a global community of government reformers, civil society leaders, and business innovators working together to develop and implement ambitious open government reforms and advance good governance.</em></p>
<p>That is some pretty significant platform growth! While reading this I'm reminded of how any amount of perceived growth and value delivered via an "open data or API platform" can be immediately muted by the omission of very fundamental building blocks like privacy.</p>
<p>Let's review the building blocks of the Open Government Alliance:</p>
<ul class="mainlist">
<li><strong>Expand Open Data -&nbsp;</strong>Open Data fuels innovation that grows the economy and advances government transparency and accountability.  Government data has been used by journalists to uncover variations in hospital billings, by citizens to learn more about the social services provided by charities in their communities, and by entrepreneurs building new software tools to help farmers plan and manage their crops.  Building upon the successful implementation of open data commitments in the first U.S. National Action Plan, the new Plan will include commitments to make government data more accessible and useful for the public, such as reforming how Federal agencies manage government data as a strategic asset, launching a new version of Data.gov, and expanding agriculture and nutrition data to help farmers and communities.</li>
<li><strong>Modernize the Freedom of Information Act (FOIA) -&nbsp;</strong>The FOIA encourages accountability through transparency and represents a profound national commitment to open government principles.  Improving FOIA administration is one of the most effective ways to make the U.S. Government more open and accountable.  Today, the United States announced a series of commitments to further modernize FOIA processes, including launching a consolidated online FOIA service to improve customers&rsquo; experience and making training resources available to FOIA professionals and other Federal employees.</li>
<li><strong>Increase Fiscal Transparency -&nbsp;</strong>The Administration will further increase the transparency of where Federal tax dollars are spent by making federal spending data more easily available on USASpending.gov; facilitating the publication of currently unavailable procurement contract information; and enabling Americans to more easily identify who is receiving tax dollars, where those entities or individuals are located, and how much they receive.</li>
<li><strong>Increase Corporate Transparency -&nbsp;</strong>Preventing criminal organizations from concealing the true ownership and control of businesses they operate is a critical element in safeguarding U.S. and international financial markets, addressing tax avoidance, and combatting corruption in the United States and abroad.  Today we committed to take further steps to enhance transparency of legal entities formed in the United States.</li>
<li><strong>Advance Citizen Engagement and Empowerment -&nbsp;</strong>OGP was founded on the principle that an active and robust civil society is critical to open and accountable governance.  In the next year, the Administration will intensify its efforts to roll back and prevent new restrictions on civil society around the world in partnership with other governments, multilateral institutions, the philanthropy community, the private sector, and civil society.  This effort will focus on improving the legal and regulatory framework for civil society, promoting best practices for government-civil society collaboration, and conceiving of new and innovative ways to support civil society globally.</li>
<li><strong>More Effectively Manage Public Resources -&nbsp;</strong>Two years ago, the Administration committed to ensuring that American taxpayers receive every dollar due for the extraction of the nation&rsquo;s natural resources by committing to join the Extractive Industries Transparency Initiative (EITI).  We continue to work toward achieving full EITI compliance in 2016.  Additionally, the U.S. Government will disclose revenues on geothermal and renewable energy and discuss future disclosure of timber revenues.</li>
</ul>
<p>How can you argue with that? Its very sensible set of open government platform building blocks right? However, when you look at the bigger picture you realize there is a significant building block, that us in the tech sector have realized is essential to a healthy platform ecosystem missing:</p>
<ul class="mainlist">
<li><strong>Citizen Data Privacy -</strong> Ensuring that government respects the online privacy of each and every U.S. citizen, preventing unwanted harvesting of private data or meta data that exists in cloud environments, computer and mobile devices as well as transported across telecommunications infrastructure locally or abroad. When privacy is compromised in the name of law enforcement or national security, the laws, rules and procedures around these accepted situations are made publicly accessible.</li>
</ul>
<p>It is great that our government is committed to expanding open data, increasing transparency and efficiently engaging citizens, and sensibly manage public resources. However if our government wants to act as an open platform, just like any private sector platform, they must respect user privacy.</p>
<p>Without ensuring privacy for users, it doesn't matter how forward thinking your open data, information and API strategy is. Privacy and security are essential building blocks any private or public sector entity looking to build an open platform.</p>
<p>Nice work around the Open Government Partnership, but without addressing the privacy of citizens it is rendered pretty useless.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/11/06/open-data-and-api-efforts-rendered-useless-when-privacy-is-ignored/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/10/22/deploy-api-public-google-spreadsheet-to-api/">Deploy API: Public Google Spreadsheet to API</a></h3>
        <span class="post-date">22 Oct 2013</span>
        <p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-google-docs.png" alt="" width="150" align="right" /></p>
<p>I'm working on a series of simple scripts that help people deploy APIs from some of the most common data sources. I'm starting with a series of PHP scripts, and next up is a public Google Spreadsheet to API, using JSON stored in Github.</p>
<p>For this PHP implementation, I'm using the <a href="http://www.slimframework.com/">SLIM framework</a>, which provides a dead simple REST framework you can use to deploy an API from a variety of data sources.   To begin deploying an API from your Google Spreadsheet datastore, download the REST library and upload to your server that runs PHP.</p>
<p>Slim is pretty straightforward to work with, to add each API endpoint you just add a single PHP file under methods. For this how-to guide we are going to add a simple endpoint from our JSON products data store.</p>
<script src="https://gist.github.com/kinlane/7104824.js"></script>
<p>Next you just add an include reference in the index page for your slim implementation:</p>
<script src="https://gist.github.com/kinlane/7104830.js"></script>
<p>This API just uses ID, Name, Price and Description of the product, and queries by a simple query parameter. You can use this as a template for your own product database, adding and removing fields as you need, or completely retrofitting for any database table.  That is it, now you have a simple product API that pulls a list of products from a Google Spreadsheet data store.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/10/22/deploy-api-public-google-spreadsheet-to-api/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/10/22/deploy-api-github-json-to-api/">Deploy API: Github JSON to API</a></h3>
        <span class="post-date">22 Oct 2013</span>
        <p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-github.jpg" alt="" width="150" align="right" /></p>
<p>I'm working on a series of simple scripts that help people deploy APIs from some of the most common data sources. I'm starting with a series of PHP scripts, and next up is JSON to API, using JSON stored in Github.</p>
<p>For this PHP implementation, I'm using the <a href="http://www.slimframework.com/">SLIM framework</a>, which provides a dead simple REST framework you can use to deploy an API from a variety of data sources.   To begin deploying an API from your JSON datastore located at Github, download the REST library and upload to your server that runs PHP.</p>
<p>Slim is pretty straightforward to work with, to add each API endpoint you just add a single PHP file under methods. For this how-to guide we are going to add a simple endpoint from our JSON products data store.</p>
<script src="https://gist.github.com/kinlane/7102861.js"></script>
<p>Next you just add an include reference in the index page for your slim implementation:</p>
<script src="https://gist.github.com/kinlane/7102885.js"></script>
<p>This API just uses ID, Name, Price and Description of the product, and queries by a simple query parameter. You can use this as a template for your own product database, adding and removing fields as you need, or completely retrofitting for any database table.  That is it, now you have a simple product API that pulls a list of products from a JSON data store stored at Github.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/10/22/deploy-api-github-json-to-api/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/10/22/api-deployment-from-mysql-json-github-and-google-spreadsheets/">API Deployment From MySQL, JSON, Github and Google Spreadsheets</a></h3>
        <span class="post-date">22 Oct 2013</span>
        <p><a href="https://github.com/kinlane/api-deploy-toolkit" target="_blank"><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-toolbox.jpg" alt="" width="225" align="right" /></a></p>
<p>I'm doing a lot more API deployments from dead simple data sources since I started working in the federal government. As part of these efforts I'm working to put together a simple toolkit that newbies to the API world can use to rapidly deploy APIs as well.</p>
<p>Currently I have four separate deployment blueprints done:</p>
<ul class="mainlist">
<li><a href="http://apievangelist.com/2013/10/21/deploy-api-mysql-to-api">MySQL to API</a></li>
<li><a href="http://apievangelist.com/2013/10/21/deploy-api-json-to-api">Local JSON to API</a></li>
<li><a href="http://apievangelist.com/2013/10/22/deploy-api-github-json-to-api">Github JSON to API</a></li>
<li><a href="http://apievangelist.com/2013/10/22/deploy-api-public-google-spreadsheet-to-api">Google Spreadsheet to API</a></li>
</ul>
<p>All of these samples are in PHP and uses the Slim PHP REST framework. They are meant to be working examples that you can use to seed your own API deployment.</p>
<p>I'm also including these in my government API workshop at #APIStrat this week, hoping to get other people equipped with the necessary skills and tools they need to get APIs in the wild.</p>
<p>You can find the entire <a href="https://github.com/kinlane/api-deploy-toolkit">working repository</a>, including Slim framework at Github.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/10/22/api-deployment-from-mysql-json-github-and-google-spreadsheets/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/10/21/deploy-api-mysql-to-api/">Deploy API: MySQL to API</a></h3>
        <span class="post-date">21 Oct 2013</span>
        <p><img style="padding: 15px;" src="http://kinlane-productions.s3.amazonaws.com/api-evangelist-site/company/bw-mysql.png" alt="" width="150" align="right" /></p>
<p>I'm working on a series of simple scripts that help people deploy APIs from some of the most common data sources. I'm starting with a series of PHP scripts, and first up is MySQL to API.</p>
<p>For this PHP implementation, I'm using the <a href="http://www.slimframework.com/">SLIM framework</a>, which provides a dead simple REST framework you can use to deploy an API from a variety of data sources.   To begin deploying an API from your MySQL database, download the REST library and upload to your server that runs PHP.</p>
<p>Slim is pretty straightforward to work with, to add each API endpoint you just add a single PHP file under methods. For this how-to guide we are going to add a simple endpoint from our products database.</p>
<script src="https://gist.github.com/kinlane/7094940.js"></script>
<p>Next you just add an include reference in the index page for your slim implementation:</p>
<script src="https://gist.github.com/kinlane/7094951.js"></script>
<p>This API just uses ID, Name, Price and Description of the product, and queries by a simple query parameter. You can use this as a template for your own product database, adding and removing fields as you need, or completely retrofitting for any database table.  That is it, now you have a simple product API that pulls a list of products from a MySQL database.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/10/21/deploy-api-mysql-to-api/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/10/21/deploy-api-json-to-api/">Deploy API: JSON to API</a></h3>
        <span class="post-date">21 Oct 2013</span>
        <p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-json-data-store.png" alt="" width="150" align="right" /></p>
<p>I'm working on a series of simple scripts that help people deploy APIs from some of the most common data sources. I'm starting with a series of PHP scripts, and next up is JSON to API.</p>
<p>For this PHP implementation, I'm using the <a href="http://www.slimframework.com/">SLIM framework</a>, which provides a dead simple REST framework you can use to deploy an API from a variety of data sources.   To begin deploying an API from your JSON datastore, download the REST library and upload to your server that runs PHP.</p>
<p>Slim is pretty straightforward to work with, to add each API endpoint you just add a single PHP file under methods. For this how-to guide we are going to add a simple endpoint from our JSON products data store.</p>
<script src="https://gist.github.com/kinlane/7095348.js"></script>
<p>Next you just add an include reference in the index page for your slim implementation:</p>
<script src="https://gist.github.com/kinlane/7095362.js"></script>
<p>This API just uses ID, Name, Price and Description of the product, and queries by a simple query parameter. You can use this as a template for your own product database, adding and removing fields as you need, or completely retrofitting for any database table.  That is it, now you have a simple product API that pulls a list of products from a JSON data store.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/10/21/deploy-api-json-to-api/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/10/19/government-api-opportunities-bureau-of-labor-statistics/">Government API Opportunities: Bureau of Labor Statistics</a></h3>
        <span class="post-date">19 Oct 2013</span>
        <p><a href="http://www.bls.gov/developers/home.htm"><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/federal-government/bureau-of-labor-statistics/bureau-of-labor-statistics-logo.png" alt="" width="250" align="right" /></a></p>
<p>I'm working to expand my awareness of APIs in our federal government by spending time each week discovering, reviewing and trying to brainstorm ways to expand and evolve existing government API efforts.</p>
<p>Today I was reviewing the <a href="http://www.bls.gov/developers/home.htm">Bureau of Labor Statistics API</a>, where I was pleased to find this valuable labor data available via single series, multiple series, one or more series specifying years.  The API is a pretty straightforward web API, which could use some polishing, but overall it provides machine readable access to this very important data as I would expect.</p>
<p>When I look at federal government APIs I'm trying to find at least one or two ways to help move the API forward, either as constructive criticism for the API providers or ways that the public (me included) can help evolve the community or the API itself from the outside.</p>
<p>My current contributions to the Bureau of Labor Statistics is to add support for the Series ID to the API stack. The Series ID is the single, central parameter you pass to each of the API endpoints, but nowhere does it link to or help the users understand the Series ID, which plays a central role in API operations.</p>
<p>This type of omission by API providers is common. You have the domain expertise in your area, you know the Series ID is the central character, but to people stumbling across or intentionally pulling up the Bureau of Labor Statistics API, this might not be common knowledge.</p>
<p>With this in mind, the roadmap of the Bureau of Labor Statics API should include an API for all of the building blocks and meta data for the Series ID. <a href="http://www.bls.gov/help/hlpforma.htm">There is a lot of rich data available on a Series ID</a>, and while it would take a significant amount of work to develop additional APIs around this data, I think it would significantly add value to the Bureau of Labor Statistics API and increase adoption.</p>
<p>I'm adding this to my list of potential future projects, which could be done external to the Bureau of Labor Statistics, but also could be something they may consider doing internally as well.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/10/19/government-api-opportunities-bureau-of-labor-statistics/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/10/17/shutdown-of-government-open-data-and-apis-is-not-government-services-business-as-usual/">Shutdown of Government Open Data and APIs Is NOT Government Services Business As Usual</a></h3>
        <span class="post-date">17 Oct 2013</span>
        <p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-government.jpg" alt="" width="250" align="right" /></p>
<p>During the recent federal government shutdown many sources of open data and APIs were suddenly rendered unavailable, including the flagship <a href="http://www.data.gov/">Data.gov</a>. As government workers went home and lights were turned off at federal agencies, so too were the servers that hosted much of the open data and APIs that have been opened up in the last couple years.</p>
<p>Across the web I've encountered discussions from many individuals who state this is how government services work. When government funding disappears, the government services go away, suck it up.</p>
<p>I'm sorry, but this is unacceptable in the Internet age. If you see things this way, you are part of the machine that allows government services to be used as a political tool. I agree, that human powered government services go away when funding disappears, but in the age of open data, APIs and the cloud, services are designed and deployed to be self-service and highly available.</p>
<p>When you launch APIs in the cloud, you bundle your budget, service level agreement and the tech into a single package. My funding went away this month and couldn't afford my AWS bill on 10/1, but my server didn't shut down the minute the shutdown happened. I had until the end of the month. Ideally the federal government could go with reserved instances annually or at least quarterly, securing the funding needed to outlast any shutdown.</p>
<p>Even with my heavy usage of AWS for much of my infrastructure, the majority of my world runs on open repositories on Github. I have carefully crafted my public presence using open formats like HTML, CSS, JavaScript and JSON and host these as openly licensed, public repositories that I can operate as no cost the social coding platform.</p>
<p>There is no excuse for government open data data and API services to go away during a shutdown like we just experienced. Open data and APIs represent a new, self-service future for government services. This model won't ever completely replace vital government services, but augment the physical services we depend on every day.</p>
<p>The fact that open data and API driven services are bundled with legacy web and physical government services represents a lack of vision, passion and drive to push government services into the digital age. If an agency is <span style="text-decoration: underline;">not</span> making assets available via open data or APIs, or is bundling them along with other legacy services, they are allowing these services to be used political tool in the current Washington D.C. game.</p>
<p>Let's make sure that open data and APIs are not federal government services business as usual in DC. C'mon it is 2013!</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/10/17/shutdown-of-government-open-data-and-apis-is-not-government-services-business-as-usual/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/10/17/api-and-oauth-literacy-is-as-important-as-financial-literacy-in-the-api-economy/">API and OAuth Literacy Is As Important As Financial Literacy in the API Economy</a></h3>
        <span class="post-date">17 Oct 2013</span>
        <p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/api-evangelist/att/universal-library-sign.png" alt="" width="250" align="right" /></p>
<p>The primary mission of API Evangelist is to spread awareness of APIs amongst the masses, expanding the audience beyond just the IT crowd, and developer community. Initially I wanted to make sure business leaders understood the potential of APis, so that they funded API initiatives within their companies. In 2012 I feel that APIs have hit a critical mass, and while I still evangelize APIs to business leaders I'm shifting a portion of my focus to the average Internet user.</p>
<p>APIs impact almost every aspect of our daily lives from logging into Facebook on our mobile phones to purchasing gasoline at the corner gas station. As API usage spreads across business, the government and the Internet of Things (IoT), the everyday citizen will be using APIs more and more each day. While many of these citizens will never hack on an API at the code level, I'm seeing a need emerge for everyone individual to be aware of APIs, much like they need a certain level of economic and financial awareness in every day life.</p>
<p>When it comes to our world of finances, every single adult must have a certain level of awareness of how our financial system operates. You don't need to understand the inner workings of banking and global markets, but you need to know how to setup a bank account, apply for credit or debit cards, balance your checkbook and pay your taxes. As our lives move online and the API economy grows, our data is fast becoming the online currency on Internet platforms like Facebook, Twitter and Pinterest, the need for us to understand the mechanisms at play in this new digital economy increases.</p>
<p>Virtually every platform we use online employs APIs in some capacity. These platforms use APIs and often an open authentication standard called oAuth to allow us to give access to our data that resides on platforms to the applications and other systems we use daily. We login to news and media sites using our Facebook login, we give access to our Instagram photos to scrapbooking applications using oAuth and APIs and much more. If you use Facebook or Pinterest on your cell phone, you are using APIs daily.</p>
<p>Much like your bank accounts, you are giving access to your Facebook or Pinterest accounts to 3rd parties, and you don't want just any companies application to make deposits or withdrawals of information without your knowledge. This is where a certain level of awareness around APIs and oAuth comes into play. As an average user you may not need to actually handle an oAuth token or parse JSON, but you will initiate the oAuth flow regularly and potentially import and export JSON data between systems regularly.</p>
<p>In the API economy users will initiate potentially thousands of transactions daily, in contrast to the handful of transactions you may initiate via your credit cards and bank accounts. Yet we have less literacy around APIs than we do about these financial systems. We are giving financial management courses in high school and college, and are required to take them as part of debt management, divorce and bankruptcy cases. Similar awareness around APIs, security and privacy is needed for the average citizen in the Internet age.</p>
<p>When I tell developers or the technically savvy user that I'm educating the masses about APIs, they often state that there is no reason the average person will ever need to know about APIs. Consciously or subconsciously this is part of the current climate of Internet technology and the exploitative stance Silicon Valley investors have set into motion. The Facebooks and Twitters of the world do not want you understanding how your data is being accessed and transacted, because behind the curtain they are profiting from your information, which is the lifeblood, currency and value of the API economy.</p>
<p>I will continue to work for more API and oAuth literacy amongst the "normals", establishing at least a high level awareness of how the API economy works within in every online citizen, helping evolve toward a more web literate society, which will benefit everyone, even Silicon Valley--whether they like it or not.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/10/17/api-and-oauth-literacy-is-as-important-as-financial-literacy-in-the-api-economy/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/10/16/foundry-group-makes-investment-in-the-open-standards-api-driven-javascript-approach-of-mapbox/">Foundry Group Makes Investment In The Open Standards, API Driven, JavaScript Approach Of MapBox</a></h3>
        <span class="post-date">16 Oct 2013</span>
        <p><a href="https://www.mapbox.com"><img style="padding: 20px;" src="https://s3.amazonaws.com/kinlane-productions/api-evangelist/mapbox/mapbox-logo.png" alt="" width="200" align="right" /></a></p>
<p>On June 29th, 2006, Google launched Google Maps API allowing developers to put Google Maps on their own sites using JavaScript. The API launch was just shy of 6 months after the release of Google Maps as an application, and was in direct response to the number of rogue apps developed that were hacking the application--demonstrating the demand for a JavaScript based, API driven mapping solution for developers.</p>
<p>Fast-forward 7 years, and maps are a central fixture of virtually every web and mobile application we depend on daily. While Google Maps is still the heavyweight in the space, their now classic map interface, proprietary tooling and search centric mindset leaves a huge opportunity for disruption in the app economy, and the venture capital firm <a href="http://www.foundrygroup.com/wp/">Foundry Group</a> is betting that startup mapping provider <a href="https://www.mapbox.com/">MapBox</a> is the solution that will de-throne Google, with a <a href="https://www.mapbox.com/blog/10million-funding-foundry-group/">10M investment in MapBox</a>&nbsp;earlier today.</p>
<p>What makes MapBox such a good investment? At first look, it is clear that MapBox is winning over developers and existing players like Foursquare and Evernote by providing very clean, attractive mapping solutions that contain street, terrain and satellite layers, but when you take a closer look at the platform, you see the MapBox allure isn't just about maps. The value of MapBox is also about their approach to delivering a platform that begins with a heavy focus on open specifications, embracing of APIs, heavy investment in JavaScript, and a knowledge of modern cloud architecture, with strong support for mobile apps.</p>
<p><strong>Open Specifications</strong><br />In 2013, when you are looking to deploy a true platform, you have to shed your self-centered approach to technology, do your homework on what are the best practices and standards that exist across your industry, and don't re-invent the wheel or try to keep things closed and proprietary, making everything you do a two-way street that benefits the entire ecosystem. This is how you establish a true platform ecossytem, one that developers will believe in and embrace. This is what MapBox has done by building their platform around four very critical open mapping specifications:</p>
<ul class="mainlist">
<li><strong><a href="http://github.com/mapbox/tilejson-spec">TileJSON</a></strong> - TileJSON is a standard format for describing various aspects of a map and makes for an easy entry point for loading, showing, and describing maps, allowing developers to keep track of information about maps,where their tiles are stored, their centerpoints, bounds, supported zoom levels, markers data, attribution, and more.</li>
<li><strong><a href="http://github.com/mapbox/simplestyle-spec">simplestyle-spec</a> </strong>- The simplestyle spec is a practical approach to describing visual markers on a map, for styling markers and maintaining a distinction between content and visual styling can be tricky when annotating maps.&nbsp;</li>
<li><strong><a href="http://github.com/mapbox/mbtiles-spec">mbtiles-spec</a></strong> - The mbtiles specification is an open approach to storing<span>&nbsp;tiled map data in&nbsp;</span><a href="http://sqlite.org/">SQLite</a><span>&nbsp;databases for immediate usage and for transfer, making invidual tiles portable and easily migrated between apps and systems.</span></li>
<li><strong><a href="http://github.com/mapbox/utfgrid-spec">utfgrid-spec</a></strong> - UTFGrid is a format for interactive data that uses JSON and can be transferred tile-by-tile to fit maps of any scale, allowing scalable interaction of maps within applications.</li>
</ul>
<p><a href="https://www.mapbox.com"><img style="padding: 20px;" src="https://s3.amazonaws.com/kinlane-productions/api-evangelist/openstreetmaps/openstreetmap-logo.png" alt="" width="125" align="right" /></a></p>
<p>Open standards help provide grounding anchors for any platform, and MapBox is going all in, by not just employing these four open specifications--MapBox is also entirely powered by <a title="OpenStreetMap" href="http://www.openstreetmap.org/#map=5/51.500/-0.100">OpenStreetMap</a>, an active community of tens of thousands of dedicated open source mappers who keep MapBox maps up to date and accurate in a real-time, crowdsourced way.</p>
<p>The approach MapBox is taking to building their platform on top of an existing open platform, and embracing the best of breed open standards, sends a signal to its fast evolving ecosystem, that MapBox is not just about building out their own intellectual property like Google, Bing, Apple and other providers are. MapBox is  about investing in an open ecosystem of maps, standards, tools and resources that benefit the entire world of mapping.</p>
<p><strong>API Driven Integration </strong><br />MapBox provides static and REST API access to all aspects of the mapping platform providing developers with programmatic interfaces for all aspects of the mapping ecosystem. Developers can work with maps, tiles, markers and geocoding services directly via API interface, and use SSL to secure integration, and JSONP to integrate with mapping services across any domain.</p>
<p><strong>Custom Layers</strong><br /> The ability to customize every layer of a map, making it as meaningful as possible to each application is the future of mapping. MapBox allows for the development of custom maps, markers and related data, allowing developers to define mapping layers as containers of rich context that will benefit the end-user experience and establish millions of virtual map tiles and layers as rich stores of geo and context relevant information.</p>
<p><img style="display: block; margin-left: auto; margin-right: auto;" src="https://s3.amazonaws.com/kinlane-productions/api-evangelist/mapbox/mapbox-streets.png" alt="" width="600" /></p>
<p><strong>Next Generation Architecture</strong> <br />MapBox reflects the latest approaches to scalable, real-time platform development using Node.js, a JavaScript driven approach that delivers high input / output throughput which naturally scales on top of a redundant, distributed cloud infrastructure deployed using Amazon Web Services. The MapBox approach to architecture is fast becoming the standard for API driven, scalable platforms, something that developers and companies are recognizing provide the elastic base that web and mobile applications are demanding.</p>
<p><strong>Ubiquitous JavaScript </strong><br />The use of JavaScript is present across all aspects of MapBox, from the server-side Node.js platform to client-side MapBox.js JavaScript API. MapBox has developed MapBox.js as a plugin that leverages Leaflet, an existing, leading open-source JavaScript library that provides the basic ability to embed a map into a page, and handles the fundamental operation of map interaction. MapBox employs JavaScript to provide a resilient back-end, the embeddable and client side tools developers have grown used to, while also extending its embrace of existing open standards, by integrating with the existing mapping frameworks like Leaflet.</p>
<p><strong>Mobile Focused </strong><br />MapBox identifies that mobile is a major driver of the growing role maps are playing in our daily lives, with a GPS in all of our pockets, and providing realtime location data to applications. MapBox has invested in providing iOS SDKs for developing rich mapping solutions for the iPhone, including native mapping based upon Apple's MapKit with their MapBox MBXMapkit. Beyond mobile specific SDKs, the MapBox API provides many mobile focused resources including the ability to optimize resolution of mapping images and overall access via modern, mobile friendly web APIs.</p>
<p><img style="display: block; margin-left: auto; margin-right: auto;" src="https://s3.amazonaws.com/kinlane-productions/api-evangelist/mapbox/mapbox-mobile.png" alt="" width="600" /></p>
<p><strong>Simplicity Rules </strong><br />The simple, attractive approach to mapping that MapBox introduces goes being just the visual, with simplicity being a key aspect in the deployment and management of MapBox integrations. MapBox has expanded the opportunity within map layers for developers with many advanced features, but MapBox also provides a suite of ready-to-go HTML, CSS and JavaScript bundles for rapid copy / paste of maps by publishers and hackers who only know enough tech to be dangerous. MapBox also provides an add-on script for Google Docs Spreadsheets called Geo, that lets anyone geocode arbitrary addresses and export spreadsheets as GeoJSON that works fluently with MapBox maps.</p>
<p><strong>Priced to Scale&nbsp;</strong><br />The pricing of cloud platforms are always an immediate signal of the potential of an ecosystem, and developers have been trained to be weary and avoid deeply integrating with platforms who do not have a clear business model. MapBox has a four tier pricing framework starting at $5 a month, then stepping up to $49, $149 and up to $499 a month. MapBox base pricing is derived from map views and storage with an additional rate for any overage charges. MapBox pricing reflects modern cloud utility pricing that provide developers with an essential pay-as-you-go model, ensuring a healthy approach to monetization that is doable for developers, covers MapBox operating costs while also generating sensible revenue for the company.</p>
<p><strong>Serious Client Portfolio</strong><br /> MapBox isn't just a favorite for the usual alpha tech developer community. The existing portfolio of MapBox users includes tech heavyweights like Foursquare, Evernote, Github and Uber including leading news and media groups like NPR, US Today, Financial Times and National Geographic. This is just a sampling of some of the best known brands who have embraced MapBox, and understand the importance of custom, open attractive maps that compliment their brand, while also providing the best user experience possible.</p>
<p><img style="display: block; margin-left: auto; margin-right: auto;" src="https://s3.amazonaws.com/kinlane-productions/api-evangelist/mapbox/mapbox-foursquare.png" alt="" width="600" /></p>
<p><strong>A Platform Blueprint </strong><br />The MapBox approach to delivering their platform by building it on top of existing open standards, baking in APIs access to all resources, while embracing the latest architectural design patterns that focus on lightweight JavaScript and JSON, and having a mobile focus that operates in the cloud, is more than just a blueprint for a successful mapping platform. MapBox is a model that other cloud platforms can follow in their own operations, focusing on simplicity, customization and all the vital features that make a platform truly an open, vibrant ecosystem, while still employing a viable business model.</p>
<p>The opportunity for mapping solutions in the new app economy makes Foundry Group's investment in MapBox a wise one, but it is the embracing of open standards, APIs, JavaScript, the cloud and mobile that will make that investment return at a scale that I think will surprise even the Foundry Group, and deliver similiar to that of existing platforms like Github.</p>
<p>MapBox is a model of how successful technology ecosystems will deliver the resources developers will need to build the next generation of web and mobile applications.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/10/16/foundry-group-makes-investment-in-the-open-standards-api-driven-javascript-approach-of-mapbox/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/10/15/visual-notes-from-my-talk-on-apis-and-the-future-of-education-at-openva/">Visual Notes From My Talk On APIs And The Future of Education At OpenVA</a></h3>
        <span class="post-date">15 Oct 2013</span>
        <p>Audrey and I went up to University of Mary Washington yesterday and participated in the #OpenVa discussion, where I gave a presentation on the importance of APIs and how they will play a significant role in the future of education.</p>
<p>During the talk Giulia Forsythe (<a href="https://twitter.com/giuliaforsythe">@giuliaforsythe</a>) sketched some visual notes that I think are pretty damn cool!</p>
<p><img style="display: block; margin-left: auto; margin-right: auto;" src="https://s3.amazonaws.com/kinlane-productions/api-evangelist/kinlane-openva-api-visual-notes.jpg" alt="" width="600" /></p>
<p>You can view <a href="http://gforsythe.ca/minding-the-future-visual-notes-openva/" target="_blank">her blog post and other sketches on her blog at Minding the Future [Visual Notes} #OpenVA</a>.  You can also find the slides for my talk on Github under <a href="/admin/blog/kinlane.github.io/talks/open-va/future-of-edu/index.html">OpenVA - The Future of Educaiton</a>.</p>
<p>I had a great time brainstorming with everyone up at UMW, and will have more posts in the near future about the other plotting and scheming we did regarding the future of education and APIs.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/10/15/visual-notes-from-my-talk-on-apis-and-the-future-of-education-at-openva/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/10/12/two-weeks-until-api-strategy-practice-in-san-francisco/">Two Weeks Until API Strategy &amp; Practice in San Francisco</a></h3>
        <span class="post-date">12 Oct 2013</span>
        <p><a href="http://www.apistrategyconference.com/2013SF/index.php" target="_blank"><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/events/api-strategy-practice-sf/APIStrat-Home-Page-Slice-2.png" alt="" width="275" align="right" /></a></p>
<p>I'm working through the schedule for <a href="http://www.apistrategyconference.com/2013SF/index.php" target="_blank">API Strategy &amp; Practice Conference (#APIStrat) in San Francisco</a>, preparing for the 3Scale / API Evangelist produced event October 23rd through 25th.</p>
<p>I'm pretty excited about the lineup we've managed to assemble including keynotes from Pamela Fox (<a href="https://twitter.com/pamelafox">@pamelafox</a>) from Khan Academy, Daniel Jacobson (<a href="https://twitter.com/daniel_jacobson">@daniel_jacobson</a>) of Netflix, Wynn Netherland (<a href="https://twitter.com/pengwynn">@pengwynn</a>) from Github and Kristin Calhoun (<a href="https://twitter.com/KCalhoun">@KCalhoun</a>) the director of the Public Media Platform, just to name a few of them.</p>
<p>We've worked hard to put together <a href="http://www.apistrategyconference.com/2013SF/schedule.php">sessions that would speak to all aspects of the API spac</a>e including creation, design and documentation of APIs, API discovery, hypermedia APIs, API testing &amp; debugging, API marketing &amp; evangelism and business models. The goal was to cover topics from basic to advanced, while covering APIs from start to finish.</p>
<p>I'm particularly stoked about the location of the conference. It is right downtown at the <a href="http://www.parc55hotel.com/">Parc55 Hotel</a>, easy walking distance to and from anything.  I always hate conferences that are off the beaten path, and Parc55 will make it easy to hang out and eat, drink and network around the event before and after.</p>
<p>The <a href="http://www.apistrategyconference.com/2013NYC/">New York City edition of #APIStrat back in February</a> was sold out with over 350 people in attendance. San Francisco is also on track to be sold out, this time with over 600 people in attendance.  Steve Willmott(<a href="https://twitter.com/njyx">@njyx</a>) of 3Scale and I have a blast MC'ing the entire event and facilitating the API conversations, both business and technology, and gearing up to make sure #APIStrat flows.</p>
<p>Make sure and <strong><a href="http://www.apistrategyconference.com/2013SF/register.php">GET REGISTERED</a></strong>. It was painful to turn away everyone last time, and I'd hate for you to not be able to get in. It is going to be an informative three days with the people who make the API space move forward. I look forward to seeing you there.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/10/12/two-weeks-until-api-strategy-practice-in-san-francisco/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/10/12/from-extract-transform-load-to-input-process-and-output-with-delray/">From Extract, Transform &amp; Load To Input, Process and Output With Delray</a></h3>
        <span class="post-date">12 Oct 2013</span>
        <p><a href="http://delray.io/" target="_blank"><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/api-evangelist/seabourne-inc/delray-logo.png" alt="" width="250" align="right" /></a></p>
<p>I spend a lot of time finding valuable data sets and manually converting, processing and outputting into more usable formats, so that they can be used in APIs that drive mobile and web applications.</p>
<p>I am always on the lookout for new tools that will help me be more efficient in to my work. I'm currently test driving a new platform called <a href="http://delray.io/">Delray</a> that focuses on taking an older concept of extract, transform and load (ETL) and bringing it into the API age by allowing me to define common data resources as inputs, process them one time or on schedule and output data in a cleaner, more usable format.</p>
<p><a href="http://delray.io/" target="_blank"><img style="padding: 15px; display: block; margin-left: auto; margin-right: auto;" src="https://s3.amazonaws.com/kinlane-productions/api-evangelist/seabourne/delray/DelRay-Inputs-Processors-Outputs.png" alt="" width="550" /></a></p>
<p>Using Delray I can define an input from CSV, JSON, MSSQL and other common formats, and save this as the input for my workflow.</p>
<p><a href="http://delray.io/" target="_blank"><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/api-evangelist/seabourne/delray/DelRay-Inputs.png" alt="" width="250" /></a></p>
<p>Next I can setup a configure a cleansing stage to process the data, allowing me to trim whitespace, replace space, make lowercase and other common things I tend to do manually with my data sets.</p>
<p><a href="http://delray.io/" target="_blank"><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/api-evangelist/seabourne/delray/DelRay-Processor.png" alt="" width="250" /></a></p>
<p>Finally I can output the CSV inputed data as a JSON file for use in my APIs and other open data efforts.</p>
<p><a href="http://delray.io/" target="_blank"><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/api-evangelist/seabourne/delray/DelRay-Output.png" alt="" width="250" /></a></p>
<p>Delray represents the next generation of tools that will turn anyone into a data steward, allowing non-developers to take control of critical data flows within your business, organization or government agency.</p>
<p>Opening up data in machine readable format is not just for IT and developers anymore.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/10/12/from-extract-transform-load-to-input-process-and-output-with-delray/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/10/12/access-interoperability-privacy-and-security-of-technology-will-set-the-stage-for-the-future-of-education/">Access, Interoperability, Privacy and Security Of Technology Will Set The Stage For The Future of Education</a></h3>
        <span class="post-date">12 Oct 2013</span>
        <p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/api-evangelist/att/tag-cloud-education.png" alt="" width="325" align="right" /></p>
<p>In 2010 when I started API Evangelist I saw the technological potential of APIs, but while the rest of the online space was focused on what APis could do for developers, I was focused on what APIs could do for the average person.  APIs don't just open up access for developers, they open up access for end-users, introducing interoperability, data portability and ultimately tools that give them control over their own data, content and other valuable resources.</p>
<p>This realization has been central to my mission at API Evangelist, which is about educating the masses about APIs. What is an API? Why are APIs important? I strongly feel that APIs empower end-users to make better decisions about which platforms they use, which applications they adopt, and gives them more ownership, control and agency in their own worlds. When you help an individual understand they can host their own Wordpress blog and migrate from the cloud hosted version of Wordpress, or migrate their blog from Blogger to Wordpress via APIs, you are giving the gift of web literacy.</p>
<p>Leading technology platforms like Amazon, Google, eBay and Flickr have long realized the potential of opening up APIs and empowering end-users. Since then, thousands of platform providers have also realized that opening up APIs enables developers and end-users to innovate around their platform and services, and that there is much more opportunity for growth, expansion and revenue when end-users are API literate. Users are much more likely to adopt a platform and deeply integrate it into their personal or business lives, if they are able to connect it with their other cloud services, taking control and optimizing their information and work flow.</p>
<p>Helping business owners, developers and end-users understand the potential that APIs introduce is essential to the future of education, and will be the heart of a healthy and thriving economy. There is a key piece of technology that reflects this new paradign and is currently operating and thriving across the web, called oAuth. This open authentication (oAuth) standard provides the ability for platforms to open up access to content and data that enables developers to build web and mobile applications, but in a way that gives the control to end-users, who are ulimately the owners of a platforms content and data, and are the target of the applications that developers are building.</p>
<p>oAuth has introduced a new online dance, that is widely known as three-legged authentication, and is being used across common platforms from Google to Facebook, allowing end-users, developers and platforms to interact in a way that makes the Internet go round.  If any of these three legs are out of balance and security or privacy is compromised, or one of the players is not educated and exploitation occurs, the cycle quickly breaks down. This delicate balance encourages all three legs to be educated, empowered and in control over their role in this critical supply chain of the Internet.</p>
<p>Online platforms, and the web and mobile applications that are built on them, are playing an ever increasing role in every aspect of our personal, professional and public lives, from turning in class assignments in high school to paying our taxes as adults.  APIs and oAuth are being used as the pipes and gatekeepers for everything from photos and location data to our vital healthcare records. These online platforms will play a central role in our education from infancy to retirement, and being educated, aware and literate in how these platforms operate is essential to it all working--for everyone involved.</p>
<p><a href="http://openva.org/2013/10/09/minding-the-future-program-at-a-glance/"><img style="display: block; margin-left: auto; margin-right: auto;" src="http://openva.org/wp-content/uploads/2013/09/cropped-openva_header.jpg" alt="" width="600" /></a></p>
<p>The future of education depends on <span style="text-decoration: underline;">all online platforms</span> providing access, interoperability and data portability, while also fully respecting end-users privacy and security and investing in their education about these features and the opportunities they open up.  Education will continue to exist within traditional institutions, but will persist throughout our lives in this new online environment. It is imperative that every citizen possesses a certain level of web literacy to be able to learn, grow and evolve as a human being in this increasingly digital society.</p>
<p>I will be speaking at <a href="http://openva.org/2013/10/09/minding-the-future-program-at-a-glance/">OpenVA, Virginia&rsquo;s First Annual Open and Digital Learning Resources Conference</a> on this topic and continue to work this message into my overall API Evangelist message. The link between APIs, the access they provide, and education is critical. It is something that I feel provides just as many opportunity for exploitation as it does for benefiting end-users, developers and platforms--requiring a great deal of transparency and scrutiny.</p>
<p>Lots to think about, and discuss. &nbsp;I look forward to seeing you at University of Mary Washington for OpenVA.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/10/12/access-interoperability-privacy-and-security-of-technology-will-set-the-stage-for-the-future-of-education/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/10/11/how-to-defrag-your-brain-and-tech-career-in-november/">How To Defrag Your Brain and Tech Career In November</a></h3>
        <span class="post-date">11 Oct 2013</span>
        <p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/events/defrag-2013/DEFRAG-2013-2.png" alt="" width="325" align="right" /></p>
<p>I spend the year going from city to city, attending conferences, meet-ups and hackathons--speakng, networking and doing the things that makes my world go around. Every November I find myself a little spun out from the year and need to Defrag my brain, re-organize what I know and re-enforce the most meaningful relationships across my professional career.  This is is done in Broomfield Colorado each November at the <a href="http://defragcon.com/2013/">Defrag Conference</a>.</p>
<p>I arrive the evening before the conference at the Omni Interlocken Resort. It is late at night, the lobby is empty and I walk up to the counter and quickly get my room from the young lady running the desk. I turn around to head to the elevators and notice Brad Feld(<a href="https://twitter.com/bfeld">@bfeld</a>) sitting on the couch, lost in his phone. I spend some time engaging him about the latest trends in technology and investing and the current political climate in the country before I head off to bed.  Where else do you get casual focus time with folks like Brad, then at Defrag?</p>
<p>In the morning I wake up, grab some coffee and pastries and head for the main stage. As I walk in I feel like I've walked into a 1980's rock concert as I'm blasted a classic rock soundtrack from Tom Petty to AC/DC.  I grab a seat in the dark and as I'm waiting for keynotes to start I notice I've accidently joined a table of the cloud computing mafia ranging from Alex Williams(<a href="https://twitter.com/alexwilliams">@alexwilliams</a>)&nbsp;of TechCrunch to cloud pundit Ben Kepes (<a href="https://twitter.com/benkepes">@benkepes</a>) of <a href="http://diversity.net.nz/">Diversity.net.nz</a>.</p>
<p>The morning moves by fast with a engaging array of talks from Amber Case of Esri, to Paul Kedrosky of Bloomber and Kauffman Foundation. After they are done, I roll out of the main stage and get in line for some lunch, which is the only conference lunch I will actually eat, as the Omni Interlocken catering is not the normal fare.</p>
<p>As soon as I'm done I weave in and out of the session stages absorbing talks ranging from business and tech investing, to developer marketing as well as deep dives into data architecture, but I notice one growing trend this year--APIs. Defag's sister event GlueCon was the OG(Original Gangster) API event, but as APIs move from the future of technology into reality across all aspects of the business world, APIs become part of every session at Defrag as well.</p>
<p>After the sessions I go back to main stage for another mind blowing assortment of talks around identity, security, privacy and of course some more APIs, and a very important talk on imperative of women in technology.  Just at the point where I feel like my brain can't absorb any more, the doors open and Eric Norlin, our host, let's us go for the evening.</p>
<p>Before the official reception begins, I need to get some nourishment, so I run over to the Tap Room and devour an assortment of sliders and enjoy an IPA to wash down the enormous amount of API knowledge I had to absorb today. Alright, now I'm ready for some networking at the reception.</p>
<p>I quickly realize the Defrag reception is just an appetizer for a long evening of meaningful conversations with the who's who in the technology space. I spend the next 7 hours bouncing from table to table, toasting with the likes of Mike Maney(<a href="https://twitter.com/the_spinmd">@the_spinmd</a>) the Spin Dr himself, Andy Thurai of Intel and Uri Sarid of <a href="http://mulesoft.com">Mulesoft</a>, to name just a few. Drink after drink I re-enforce existing relationships and make numerous other new connections with faces I might know from their Twitter photos, but haven't actually had the chance to meet in person and take the connection to the next level.</p>
<p>Its 2 AM. With a head full of IPAs and APIs I head off to bed, knowing I have another full two days of this! When I'm done I know I can head home for the holidays, finish off the year properly with the one event I will never miss, because I know my year will not be complete and properly closed out if I miss it.</p>
<p>I hope to see you at <a href="http://defragcon.com/2013/">Defrag</a>, and have a chance to buy you a beer!</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/10/11/how-to-defrag-your-brain-and-tech-career-in-november/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/10/09/the-backend-as-a-service-space-is-maturing/">The Backend As A Service Space Is Maturing</a></h3>
        <span class="post-date">09 Oct 2013</span>
        <p><a href="http://baas.apievangelist.com/" target="_blank"><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/api-evangelist/trends/baas-trends.png" alt="" width="200" align="right" /></a></p>
<p>I just got off the phone with a new Backend as a Service provider <a href="http://bizmobify.com/">BizMobify</a>, who is looking to deliver BaaS services to the enterprise.  The timing for the call couldn't be better, as I'm updating up my <a href="http://apievangelist.com/2013/05/08/overview-of-backend-as-a-service-baas-white-paper/">BaaS white paper</a> this week, and one thing I'm expanding is looking at it through the enterprise lens.</p>
<p>As I dust off my research on BaaS I'm re-visiting my <a href="http://apievangelist.com/2013/05/08/overview-of-backend-as-a-service-baas-white-paper/">BaaS research site</a> and re-watching the <a href="http://www.infoq.com/presentations/Mobile-Back-end-Service">BaaS Panel from API Strategy &amp; Practice in NYC</a> last February. This is helping me understand where the space what last winter and early spring.</p>
<p>As we move into the last quarter of 2013 I'm reminded of how fast the BaaS space is maturing. There are new providers continuing to enter the space, but I also see continued energy and releases from the BaaS leaders like Parse and Kinvey.</p>
<p>Kinvey, AnyPresence and StackMob will all be at <a href="http://www.apistrategyconference.com/2013SF/index.php">#APIStrat on October 24th and 25th in San Francisco</a>. While we won't be having another BaaS focused panel, they will be sharing their insight on the space in separate sessions.</p>
<p>From my vantage point I see BaaS providers being a key channel for API providers to reach developers in 2014, and definitely an area I will keep tracking on and working to understand.</p>
<p>If you are an API provider, you should be paying attention to BaaS providers, because they offer a channel for your API resources to reach developers. Developers may not care about your resource all by itself, but when bundled with the best of breed BaaS tools as well as other API resources, it may look much more appealing.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/10/09/the-backend-as-a-service-space-is-maturing/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/10/01/can-we-depend-on-federal-government-apis/">Can We Depend On Federal Government APIs?</a></h3>
        <span class="post-date">01 Oct 2013</span>
        <p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/federal-government/data-gov/data-gov-shutdown.png" alt="" width="325" align="right" /></p>
<p>The federal government shutdown today. At the Department of Veterans Affairs we are still working through next monday, so it was business as usual today for me.</p>
<p>One of my projects is preparing a list of APIs and data assets for a hackathon in NYC that is focusing on developing apps for veterans, called <a href="http://feastongood.com/2013/conference/hackathon">The Feast</a>. My goal is to aggregate a list of as many usable assets as possible so developers don't have to go to multiple locations to locate them.</p>
<p>Many of the assets are available at <a title="VA.gov" href="http://www.va.gov/">VA.Gov</a>, but there are others that I knew were on <a title="Data.gov" href="http://data.gov">Data.Gov</a>. As soon as the page loaded at Data.Gov, I got a friendly message:</p>
<blockquote><em>Due to the lapse in federal government funding, this website is not available. We sincerely regret this inconvenience.</em></blockquote>
<p>Basically, no data for me. No datasets for download, no APIs allowing me access information.  Which leaves me questioning the entire reason I'm in government. I came here to open up data and build APIs, then convince you to use them in your applications, widgets, visualizations and other innovation projects.</p>
<p>It is my way to find a way around <span style="text-decoration: underline;">ANY</span> obstacle. There is nothing that will stop me. I will keep working no matter what. However, this is a pretty big obstacle, something that makes me question my faith in APIs in government. I can deal with just about anything, but if I evangelize APIs, that can be turned off at any point, for an unknown amount of time? Ummm&hellip;WTF? Unnacceptable!!</p>
<p>There is always a work-around. I will find a solution that will work for me(and you), but it leaves me questioning quite a bit about this API evangelism from within the federal government.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/10/01/can-we-depend-on-federal-government-apis/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/09/29/providing-access-to-services-that-help-americans-with-their-food-security-using-apis/">Providing Access To Services That Help Americans With Their Food Security Using APIs</a></h3>
        <span class="post-date">29 Sep 2013</span>
        <p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/code-for-america/the-ohana-api.png" alt="" width="325" align="right" /></p>
<p>I had the pleasure to connect with the talented Code for America fellow, Moncef Belyamani(<a href="https://twitter.com/monfresh">@monfresh</a>)&nbsp;this week and talk about a very meaningful API project, called the <a title="The Ohana API" href="http://ohanapi.org/">Ohana API</a>.</p>
<p style="padding-left: 30px;"><em>"The Ohana API is a project from the San Mateo County team of Code for America fellows that is aiming to create open access to community social services, with an initial emphasis on food security."</em></p>
<p>I couldn't' think of a more important use of APIs, than making sure people can find the soical services they need--especially services that ensure people are fed.</p>
<p>I'm also impressed with the approach of <a href="http://www.codeforamerica.org/&lrm;">Code for America</a> in giving Github a central role in the project. The <a href="https://github.com/codeforamerica/ohana-api/">API project</a>, the <a href="https://github.com/codeforamerica/ohanakapa-ruby/">API wrapper in Ruby</a> and a cool <a href="https://github.com/codeforamerica/ohana-pdf/">API to PDF generator</a> are all available on Github.</p>
<p>The Oahana API is only in alpha, they are looking for people to help the Code for America team take it to the next level with approaches to keep the data current and developing an SMS interface.</p>
<p>The Ohana API project itself, and the model used by Code for America, provides an important blueprint for how technology can be applied, and make a difference in our daily lives in a scalable way.</p>
<p>This type of work keeps me coming back back and working on API Evangelist, even after three years of covering a space that often leaves me pretty discouraged.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/09/29/providing-access-to-services-that-help-americans-with-their-food-security-using-apis/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/09/25/start-with-your-public-website-when-you-begin-your-inventory-for-data-apis/">Start With Your Public Website When You Begin Your Inventory For Data APIs</a></h3>
        <span class="post-date">25 Sep 2013</span>
        <p>I'm working on taking inventory of data assets at the Department of Veterans Affairs. While eventually this will include private data assets, in the beginning we are focusing on data that can be made public without being worried about personally identifiable information or health information.</p>
<p>There are a lot of hurdles to get over, including educating people about what is a data asset, as well as the process of identifying, preparing, publishing and listing the data assets in a publicly available marketplace.</p>
<p>We are at the point where everyone is looking around for potential data assets that can be included in the current open data inventory cycle.  It is proving to be a challenge for folks to find datasets they can include. To help the process along I've set my focus on the public website, va.gov, and finding data that has already been published in various formats on the site.</p>
<p>Data and content is already available on the public web site represents the low hanging fruit when it comes to identifying open data that should be made available in machine readable formats like JSON and XML as well as available in APIs.</p>
<p>This approach works in both the public and private sector. If you feel it is valuable enough to have on your already, it is a perfect candidate to make available as open data or API.  Once you get the hang of identifying, processing and publishing this open data and APIs, you can start the much more difficult process of looking for harder to identify data sets and resources.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/09/25/start-with-your-public-website-when-you-begin-your-inventory-for-data-apis/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/09/25/github-can-be-the-post-and-put-layer-for-federal-government-apis/">Github Can Be the POST and PUT Layer For Federal Government APIs</a></h3>
        <span class="post-date">25 Sep 2013</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/api-evangelist/augmented-post.png" alt="" width="250" align="right" /></p>
<p>I'm playing with different approaches to rapidly design, develop, deploy and manage APIs using Github. While about 90% of what I'm building runs on Github, there is still about 10% that runs on Amazon EC2.</p>
<p>There are just some aspects of a proper API interface that I can't do on Github. My recent prototypes use swagger and allow for much of the API interactions to occur via Github. I a working to carve off any elements I can from the architecture, including using JSON files stored at Github as the database backend for the API.</p>
<p><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-government.jpg" alt="" width="250" align="right" /></p>
<p>If you look at my recent <a href="http://kinlane.github.io/dev-hub/index.html">Dev Hub</a> prototype, you can browse the API interface, thanks to <a href="https://developers.helloreverb.com/swagger/">Swagger</a>, and when you make API calls to the endpoints via Amazon EC2, the REST interface is just acting as a search, filter and REST facade for the JSON files that are actually stored on Github--eliminating the need for a database backend.</p>
<p>This approach allows me to develop light-weight REST facades for JSON data stores as well as for other APIs. I'm playing around with different ways that I can use this thought process to push government APIs to the next level, and building on my earlier thoughts today on the <a href="http://apievangelist.com/2013/09/25/a-huge-need-for-writeable-apis-in-government/">need for writable APIs in federal government</a>.</p>
<p>I'm evolving earlier designs I have in my archives of <a href="http://apievangelist.com/2013/03/17/beyondget-or-otherverbs-an-augmented-api-platform-/">BeyondGET or OtherVerbs, an Augmented API Platform</a>, where I'm looking to provide an augmented layer that makes existing APIs writable.  Marrying these legacy thoughts with my current approaches using Github plus EC2 APIs, I strongly feel that Github has huge potential for being a POST, PUT and DELETE layer for federal government APIs.</p>
<p>Using a REST facade on EC2 I can easily proxy existing government APIs, then using a swagger definition I could seamlessly weave in a POST, PUT and DELETE layer that would write to JSON files hosted at Github using the Github API.</p>
<p>I'm in early thoughts on this work, and will start playing with examples of how this can work with real, live government APIs.  I think it has legs though. I'm not very confident that we can get the government to allow users to write and update data via APIs without demonstrating the value of this. Which means we need to make it happen externally of government, show the value and then get buy in from key decision makers.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/09/25/github-can-be-the-post-and-put-layer-for-federal-government-apis/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/09/25/a-huge-need-for-writeable-apis-in-government/">A Huge Need for Writeable APIs in Government</a></h3>
        <span class="post-date">25 Sep 2013</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-pen-hand.png" alt="" width="250" align="right" /></p>
<p>I asked a question on Twitter last night: <a href="https://twitter.com/kinlane/status/382685108014428160">Any examples of government APIs that allow for write (POST, PUT, PATCH) capabilities? I'm looking for existing agencies who have implemented already</a>. While I was asking for examples of APIs, by motivations were specifically about finding an example of terms of use for a government writable API.</p>
<p>After spending some time looking and listening to peoples responses, there isn't much in the wild when it comes to writable government APIs, however it is clear that there is a huge demand for writable APIs, and a lot of opinion that this could be the thing that changes how government operates for the better.</p>
<p>The best examples that my followers pointed me to was with the <a href="http://open311.org/">Open 311</a> iniative:</p>
<ul class="mainlist">
<li><a href="http://dc.gov/DC/About+DC.Gov/Terms+and+Conditions#1">Washington, DC</a></li>
<li><a href="http://dev.cityofchicago.org/docs/api/tos">Chicago, IL</a></li>
<li><a href="http://www.montgomerycountymd.gov/mcg/user_rights.html">Montgomery County MD</a></li>
</ul>
<p>There was another DoD API that allows users to POST information, and then only allows them to only update their own information, but wasn't exaclty the open write I was looking for.</p>
<ul class="mainlist">
<li><a href="https://clauselogic.altess.army.mil/banner">Clause Logic Service</a></li>
</ul>
<p>Clay Johnson (<a href="https://twitter.com/cjoh">@cjoh</a>), the author of <a href="http://www.informationdiet.com/">The Information Diet</a>, has a great <a href="http://dobtco.github.io/fixing-procurement-ebook/final/fixing-procurement-ebook/#how-to-fix-procurement-2-up-the-api-game">post on how writable APIs can help fix the government procurement process</a>. Demonstrating one solid example of how government could be more efficient through the sensible use of APIs.</p>
<p>The biggest <a title="case study I can find of writable APIs in federal government was the IRS Modernized e-File system" href="http://apievangelist.com/2013/09/15/irs-modernized-efile-mef-a-blueprint-for-public--private-sector-partnerships-in-a-21st-century-digital-economy-draft/">case study I can find of writable APIs in federal government was the IRS Modernized e-File (MeF) system</a>, but the goal of this research is to find an existing example of terms of use for writable APIs in the federal government, and after looking through all the e-File documentation I couldn't find any terms of use that covered developers submitting tax forms to the IRS via MeF web services.  I will spend more time looking, I'm sure they are in there somewhere.</p>
<p>If you know of any examples of of the federal government using APIs and allowing the public to to submit data, content or forms through APIs, please let me know.  It is something I will keep researching, writing about and advocating for.</p>
<p>Executing APIs as a two-way street is essential to successful API and open data strategies in both the public and private sector.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/09/25/a-huge-need-for-writeable-apis-in-government/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/09/24/excel-and-csv-conversion-to-json-and-xml-in-javascript-that-runs-100-on-github/">Excel and CSV Conversion to JSON and XML in JavaScript That Runs 100% on Github</a></h3>
        <span class="post-date">24 Sep 2013</span>
        <p><a href="http://kinlane.github.io/csv-converter/"><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/csv-converter-github.png" alt="" width="325" align="right" /></a></p>
<p>When it comes to building applications within the federal government, there are numerous road-blocks to innovation. I'm currently assisting with the inventorying of open data assets at the Department of Veterans Affairs, as well as across numerous other federal agencies.</p>
<p>The two biggest bottlenecks of this process are:</p>
<ul class="mainlist">
<li><strong>File Conversion</strong> - Converting Excel and CSV data assets into JSON and XML</li>
<li><strong>File Storage</strong> - Where do you put data assets once you have available in CSV, JSON and XML</li>
</ul>
<p>When I hit these road-blocks, it is my nature to find quick and dirty technical solutions (hacks) to get around these obstacles, and do it in a way that can be taught to others, allowing them to overcome these challenges in their own worlds.</p>
<p>The solution I've employed involved discovering and forking of a kick ass data conversion tool called <a href="https://github.com/shancarter/Mr-Data-Converter">Mr. Data Converter</a>, and quickly the tool retrofitted with some of my own enhancements:</p>
<ul class="mainlist">
<li><a href="http://www.w3.org/TR/FileAPI/">HTML5 File API</a> - Allows me to acces file content without server side technology.</li>
<li><a title="oAuth" href="https://oauth.io/">oAuth.io</a> - Dead simple, client side oAuth for Github and other platforms.</li>
<li><a href="https://github.com/michael/github">Github.js</a> - A JavaScript API wrapper for Github, enabling client-side interaction.</li>
</ul>
<p>I quickly stripped down Mr. Data Converter to have only the features I desired, added a file upload capabilities that used the File API to access CSV files without a server side layer, then after authenticating with oAuth.io via Github, I used Github.js to post the original CSV and converted JSON or XML files directly to the same Github repo that the file conversion application runs in.</p>
<p>This approach allows me to run the Excel / CSV conversion app 100% on Github using Github Pages--an blueprint that allows anyone to fork and run within their own Github accounts.  I'll spend more time hardening the code, and documenting it, to make it easier to use, and empower anyone to use in their own open data inventorying initiatives.</p>
<p>You can <a href="http://kinlane.github.io/csv-converter/">see it in action live on Github Pages</a>, and get at the <a href="https://github.com/kinlane/csv-converter/tree/gh-pages">code behind in the Github repository</a>.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/09/24/excel-and-csv-conversion-to-json-and-xml-in-javascript-that-runs-100-on-github/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/09/22/html-to-markdown-api/">HTML to Markdown API</a></h3>
        <span class="post-date">22 Sep 2013</span>
        <p><a href="http://fuckyeahmarkdown.com/#api"><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/api-evangelist/fuck-yeah-markdown/fuck-yeah-markdown-api.png" alt="" width="275" align="right" /></a></p>
<p>I'm slowly getting my blog world in order after the move from my own proprietary blogging platform to using Github + Jekyll hosted using Github Pages.</p>
<p>I've been using HTML pages for blog posts at <a title="API Evangelist" href="http://apievangelist.com">API Evangelist</a>, <a href="http://kinlane.com">Kin Lane</a> and other blogs, with 3 years of blog posts at API Evangelist and about 6 years at Kin Lane. There is a lot of legacy content to move from my EC2 driven blogs to Github.</p>
<p>Every time I would try and publish the posts as is, Github would reject my commit when it hit posts that didn't have compliant HTML, making it near impossible to publish everything.  I was trying to clean up as much of it as I could, but it wasn't good enough.  I needed a way to convert to markdown and clean house.</p>
<p>Thankfully, Ben Balter(<a href="/admin/blog/BenBalter">@BenBalter</a>) from Github recommend a very cool API called <a href="http://fuckyeahmarkdown.com/#api">Fuck Yeah Markdown</a>, which takes my legacy HTML pages and converts it to much cleaner markdown.</p>
<p>When I first started using Jekyll I wasn't really sold on markdown, in my mind I didn't mind hand rolling my HTML tags--I have been doing it for years. After Ben suggested I use markdown in my newly minted Github Jekyll projects I started to see the benefits.  It is way easier to manage content that is being published as a blog, page or otherwise when it is markdown.</p>
<p>I am just finishing up converting all of API Evangelist and Kin Lane to use markdown, and will be using the <a href="http://fuckyeahmarkdown.com/#api">Fuck Yeah Markdown API</a> to convert blog posts from HTML generated in my blog editor to markdown before publishing to Github.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/09/22/html-to-markdown-api/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/09/15/irs-modernized-efile-mef-a-blueprint-for-public-private-sector-partnerships-in-a-21st-century-digital-economy-draft/">IRS Modernized e-File (MeF): A Blueprint For Public &amp; Private Sector Partnerships In A 21st Century Digital Economy (DRAFT)</a></h3>
        <span class="post-date">15 Sep 2013</span>
        <p><a href="http://bit.ly/147BfVv">Download as PDF</a></p>
<p><a href="https://s3.amazonaws.com/kinlane-productions/federal-government/irs/bw-irs-logo.jpg" target="_blank"><img src="https://s3.amazonaws.com/kinlane-productions/federal-government/irs/bw-irs-logo.jpg" alt="" width="225" align="right" /></a>The Internal Revenue Service is the revenue arm of the United States federal government, responsible for collecting taxes, the interpretation and enforcement of the Internal Revenue code.</p>
<p>The first income tax was assessed in 1862 to raise funds for the American Civil War, and over the years the agency has grown and evolved into a massive federal entity that collects over $2.4 trillion each year from approximately 234 million tax returns.</p>
<p>While the the IRS has faced many challenges in its 150 years of operations, the last 40 years have demanded some of the agency's biggest transformations at the hands of technology, more than any time since its creation.</p>
<p>In the 1970s, the IRS began wrestling with the challenge of modernizing itself using the latest computer technology. This eventually led to a pilot program in 1986 of an new Electronic Filing System (EFS), which aimed in part to gauge the acceptance of such a concept by tax preparers and taxpayers.</p>
<p>By the 1980s, tax collection had become very complex, time-consuming, costly, and riddled with errors, due to what had become a dual process of managing paper forms while also converting these into a digital form so that they could be processed by machines. The IRS despereatly needed to establish a solid approach that would enable the electronic submission of tax forms.</p>
<p>It was a rocky start for the EFS, and Eileen McCrady, systems development branch and later marketing branch chief, remembers, &ldquo;Tax preparers were not buying any of it--most people figured it was a plot to capture additional information for audits." But by 1990, IRS e-file operated nationwide, and 4.2 million returns were filed electronically. This proved that EFS offered a legitimate approach to evolving beyond a tax collection process dominated by paper forms and manual filings.</p>
<h3><a class="anchor" name="even-federal-agencies-cant-do-it-alone" href="https://github.com/kinlane/irs-modernized-efile-blueprint/blob/master/README.md#even-federal-agencies-cant-do-it-alone"></a>Even Federal Agencies Can't Do It Alone</h3>
<p>Even with the success of early e-file technology, the program did not get the momentum it needed without the support of two major tax preparation partnerships--H&amp;R Block and Jackson-Hewitt. These helped change the tone of EFS efforts, making it more acceptable and appealing to tax professionals. It was clear that e-File needed to focus on empowering a trusted network of partners to submit tax forms electronically, sharing the load of tax preparation and filing with 3rd party providers. And this included not just the filing technology, but a network of evangelists spreading the word that e-File was a trustworthy and viable way to work with the IRS.</p>
<p><a href="https://s3.amazonaws.com/kinlane-productions/federal-government/irs/irs-efile-logo.jpeg" target="_blank"><img src="https://s3.amazonaws.com/kinlane-productions/federal-government/irs/irs-efile-logo.jpeg" alt="" width="300" align="right" /></a></p>
<h3><a class="anchor" name="bringing-e-file-into-the-internet-age" href="https://github.com/kinlane/irs-modernized-efile-blueprint/blob/master/README.md#bringing-e-file-into-the-internet-age"></a>Bringing e-File Into The Internet Age</h3>
<p>By 2000, Congress had passed IRS RRA 98, which contained a provision setting a goal of an 80% e-file rate for all federal tax and information returns. This, in effect, forced the IRS to upgrade the e-File system for the Internet age, otherwise they would not be able meet this mandate. A working group was formed, comprised of tax professionals and software vendors that would work with the IRS to design, develop and implement the&nbsp;<a href="http://www.irs.gov/uac/Modernized-e-File-(MeF">Modernized e-File(MeF)</a>-Program-Information) system which employed the latest Internet technologies, including a new approach to web services which used XML that would allow 3rd party providers to submit tax forms in a real-time, transactional approach (this differed from the batch submissions required in a previous version of the EFS).</p>
<h3><a class="anchor" name="moving-beyond-paper-one-form-at-a-time" href="https://github.com/kinlane/irs-modernized-efile-blueprint/blob/master/README.md#moving-beyond-paper-one-form-at-a-time"></a>Moving Beyond Paper One Form At A Time</h3>
<p>Evolving beyond a 100 years of paper process doesn't happen overnight. Even with the deployment of the latest Internet technologies, you have to incrementally bridge the legacy paper processes to a new online, digital world. After the deployment of the MeF, the IRS worked year by year to add the myriad of IRS forms to the e-File web service, allowing software companies, tax preparers, and corporations to digitally submit forms into IRS systems over the Internet. Form by form, the IRS was being transformed from a physical document organization to a distributed network of partners that could submit digital forms through a secure, online web service.</p>
<h2><a class="anchor" name="technological-building-blocks" href="https://github.com/kinlane/irs-modernized-efile-blueprint/blob/master/README.md#technological-building-blocks"></a>Technological Building Blocks</h2>
<p>The IRS MeF solution represents a new approach to using modern technology by the federal government in the 21st century Internet age. In the last 15 years, a new breed of Internet enabled software standards have emerged that enable the government to partner with the private sector, as well as other government agencies, in ways that were unimaginable just a decade ago.</p>
<h3><a class="anchor" name="web-services" href="https://github.com/kinlane/irs-modernized-efile-blueprint/blob/master/README.md#web-services"></a>Web Services</h3>
<p>Websites and applications are meant for humans. Web services, also known as APIs, are meant for other computers and applications. Web services has allowed the IRS to open up the submission of forms and data into central IRS systems, while also transmitting data back to trusted partners regarding errors and the status of form submissions. Web services allow the IRS to stick with what it does best, receiving, filing and auditing of tax filings, while trusted partners can use web services to deliver e-Filing services to customers via custom developed software applications.</p>
<p>Web services are designed to utilize existing Internet infrastructure used for everyday web operations as a channel for delivering trusted services to consumers around the country, via the web.</p>
<h3><a class="anchor" name="an-xml-driven-communication-flow" href="https://github.com/kinlane/irs-modernized-efile-blueprint/blob/master/README.md#an-xml-driven-communication-flow"></a>An XML Driven Communication Flow</h3>
<p>XML is a way to describe each element of IRS forms, and its supporting data. XML makes paper forms machine readable so that the IRS and 3rd party systems can communicate using a common language, allowing IRS to share a common set of logic around each form, then use what is known as schemas, to validate the XML submitted by trusted partners against a set of established business rules that provide enforcement of the IRS code. XML gives the ability for IRS to communicate with 3rd party systems using digital forms, applying business rules to reject or accept the submitted forms, which then can be stored in an official IRS repository in a way that can be viewed and audited by IRS employees (using stylesheets which make the XML easily readable by humans).</p>
<h3><a class="anchor" name="identity-and-access-management-iam" href="https://github.com/kinlane/irs-modernized-efile-blueprint/blob/master/README.md#identity-and-access-management-iam"></a>Identity and Access Management (IAM)</h3>
<p>When you expose web services publicly over the Internet, secure authentication is essential. The IRS MeF system is a model for securing the electronic transmission of data between the government and 3rd party systems. The IRS has employed a design of the Internet Filing Application (IFA) and Application to Application (A2A) which are features of the Web Services-Interoperability (WS-I) security standards. Security of the MeF system is overseen by the IRS MITS Cyber Security organization which ensures all IRS systems receive, process, and store tax return data in a secure manner. MeF security involves an OMB mandated Certification and Accreditation (C&amp;A) Process, requiring a formal review and testing of security safeguards to determine whether the system is adequately secured.</p>
<h2><a class="anchor" name="business-building-blocks" href="https://github.com/kinlane/irs-modernized-efile-blueprint/blob/master/README.md#business-building-blocks"></a>Business Building Blocks</h2>
<p>To properly extend e-File web services to partners isn't just a matter of technology. There are numerous building blocks required that are more business than technical, ensuring a healthy ecosystem of web service partners. With a sensible strategy, web services need to be translated from tech to business, allowing partners to properly translate IRS MeF into e-filing products that will deliver required services to consumers.</p>
<h3><a class="anchor" name="four-separate-e-filing-options" href="https://github.com/kinlane/irs-modernized-efile-blueprint/blob/master/README.md#four-separate-e-filing-options"></a>Four Separate e-Filing Options</h3>
<p>MeF provided the IRS with a way to share the burden of filing taxes with a wide variety of trusted partners, software developers and corporations who have their own software systems. However MeF is just one tool in a&nbsp;<a href="http://www.irs.gov/Filing">suite of e-File tools</a>. These include Free File software that any individual can use to submit their own taxes, as well as free fillable digital forms that individuals can use if they do not wish to employ a software solution.</p>
<p>Even with these simple options, the greatest opportunities for individuals and companies is to use commercial tax software that walks one through what can be a complex process, or to depend on a paid tax preparer who employ their own commercial versions of tax software. The programmatic web service version of e-file is just one option, but it is the heart of an entire toolkit of software that anyone can put to use.</p>
<h3><a class="anchor" name="delivering-beyond-technology" href="https://github.com/kinlane/irs-modernized-efile-blueprint/blob/master/README.md#delivering-beyond-technology"></a>Delivering Beyond Technology</h3>
<p>The latest evolution of the e-file platform has technology at heart, but it delivers much more than just the transmission of digital forms from 3rd party providers, in ways that also make good business sense:</p>
<ul>
<li>Faster Filing Acknowledgements - Transmissions are processed upon receipt and acknowledgements are returned in near real-time, unlike the once or twice daily system processing cycles in earlier versions</li>
<li>Integrated Payment Option - Tax-payers can e-file a balance due return and, at the same time, authorize an electronic funds withdrawal from their bank accounts, with payments being subject to limitations of the Federal Tax Deposit rules</li>
<li>Brand Trust - Allowing MeF to evolve beyond just the IRS brand, allowing new trusted commercial brands to step up and deliver value to consumer, like TurboTax and TaxAct.</li>
</ul>
<p>Without improved filing results for providers and customers, easier payment options and an overall set of expectations and trust, MeF would not reach the levels of e-Filing rates mandated by Congress. Technology might be the underpinning of e-File, but improved service delivery is the thing that will seal the deal with both providers and consumers.</p>
<h3><a class="anchor" name="multiple-options-for-provider-involvement" href="https://github.com/kinlane/irs-modernized-efile-blueprint/blob/master/README.md#multiple-options-for-provider-involvement"></a>Multiple Options for Provider Involvement</h3>
<p>Much like the multiple options available for tax filers, the IRS has established tiers of involvement for partners to be involved with the e-File ecosystem. Depending on the model and capabilities, e-File providers can step up and be participate in multiple ways:</p>
<ul>
<li>Electronic Return Originators (EROs) - ERO prepare returns for clients or have collected returns from taxpayers who have prepared their own, then begin the electronic transmission of returns to the IRS</li>
<li>Intermediate Service Providers - These providers process tax return data, that originate from an ERO or an individual taxpayer, and forward to a transmitter.</li>
<li>Transmitters - Transmitters are authorized to send tax return data directly to the IRS, from custom software that connect directly with the IRS computers</li>
<li>Online Providers - Online providers are a type of transmitter that sends returns filed from home by taxpayers using tax preparation software to file common forms</li>
<li>Software Developers - write the e-file software programs that follow IRS specifications for e-file.</li>
<li>Reporting Agents - An accounting service, franchiser, bank or other person that is authorized to e-file Form 940/941 for a taxpayer.</li>
</ul>
<p>The IRS has identified the multiple ways it needed help from an existing, evolving base of companies and organizations. The IRS has been able to design its partner framework to best serve its mission, while also delivering the best value to consumers, in a way that also recognizes the incentives needed to solicit participation from the private sector and ensure efforts are commercially viable.</p>
<h3><a class="anchor" name="software-approval-process" href="https://github.com/kinlane/irs-modernized-efile-blueprint/blob/master/README.md#software-approval-process"></a>Software Approval Process</h3>
<p>IRS requires all tax preparation software used for preparing electronic returns to pass the requirements for Modernized e-File Assurance Testing (ATS). As part of the process software vendors notify IRS via an e-help Desk, that they plan to commence testing, then provide a list of all forms that they plan to include in their tax preparation software, but do not require that vendors support all forms. MeF integrators are allowed to develop their tax preparation software based on the needs of their clients, while using pre-defined test scenarios to create test returns that are formatted in the specified XML format. Software integrators then transmit the XML formatted test tax returns to IRS, where an e-help Desk assister checks data entry fields on the submitted return. When IRS determines the software correctly performs all required functions, the software is approved for electronic filing. Only then are software vendors allowed to publicly market their tax preparation software as approved for electronic filing -- whether for usage by corporations, tax professionals and individual users.</p>
<h3><a class="anchor" name="state-participation" href="https://github.com/kinlane/irs-modernized-efile-blueprint/blob/master/README.md#state-participation"></a>State Participation</h3>
<p>Another significant part of the MeF partnership equation is providing seamless interaction with the electronic filing of both federal and state income tax returns at the same time. MeF provides the ability for partners to submit both federal and state tax returns in the same "taxpayer envelope", allowing the IRS to function as an "electronic post office" for participating state revenue services -- certainly better meeting the demands of the taxpaying citizen. The IRS model provides an important aspect of a public / private sector partnership with the inclusion of state participation. Without state level participation, any federal platform will be limited in adoption and severely fragmented in integration.</p>
<h3><a class="anchor" name="resources" href="https://github.com/kinlane/irs-modernized-efile-blueprint/blob/master/README.md#resources"></a>Resources</h3>
<p>To nurture an ecosystem of partners, it takes a wealth of resources. Providing technical, how-to, guides, templates and other resources for MeF providers is essential to the success of the platform. Without proper support, MeF developers and companies are unable to keep up with the complexities and changes of the system. The IRS has provided the resources needed for each step of the e-Filing process, from on-boarding, to how to understanding the addition of the latest forms, and changes to the tax code.</p>
<h3><a class="anchor" name="market-research-data" href="https://github.com/kinlane/irs-modernized-efile-blueprint/blob/master/README.md#market-research-data"></a>Market Research Data</h3>
<p>Transparency of the MeF platform goes beyond individual platform operations, and the IRS acknowledges this important aspect of building an ecosystem of web service partners. The IRS provides valuable e-File market research data to partners by making available e-file demographic data and related research and surveys. This important data provides valuable insight for MeF partners to use in their own decision making process, but also provides the necessary information partners need to educate their own consumers as well as the general public about the value the e-File process delivers. Market research is not just something the IRS needs for its own purposes; this research needs to be disseminated and shared downstream providing the right amount of transparency that will ensure healthy ecosystem operations.</p>
<h2><a class="anchor" name="political-building-blocks" href="https://github.com/kinlane/irs-modernized-efile-blueprint/blob/master/README.md#political-building-blocks"></a>Political Building Blocks</h2>
<p>Beyond the technology and business of the MeF web services platform, there are plenty of political activities that will make sure everything operates as intended. The politics of web service operations can be as simple as communicating properly with partners, providing transparency, or all the way up to security, proper governance of web service, and enforcement of federal laws.</p>
<h3><a class="anchor" name="status" href="https://github.com/kinlane/irs-modernized-efile-blueprint/blob/master/README.md#status"></a>Status</h3>
<p>The submission of over 230 million tax filings annually requires a significant amount of architecture and connectivity. The IRS provides real-time status of the MeF platform for the public and partners, as they work to support their own clients. Real-time status updates of system availability keeps partners and providers in tune with the availability of the overall system, allowing them to adjust availability with the reality of supporting such a large operation. Status of availability is an essential aspect of MeF operations and overall partner ecosystem harmony.</p>
<h3><a class="anchor" name="updates" href="https://github.com/kinlane/irs-modernized-efile-blueprint/blob/master/README.md#updates"></a>Updates</h3>
<p>An extension of MeF platform status is the ability to keep MeF integrators up-to-date on everything to do with ongoing operations. This includes providing alerts when the platform needs to tune-in platform partners to specific changes with tax law, resource additions, or other relevant news of operations. The IRS also provides updates via an e-newsletter, providing a more asynchronous way for the IRS MeF platform to keep partners informed about ongoing operations.</p>
<p>Updates over the optimal partner channels are an essential addition to real-time status and other resources that are available to platform partners.</p>
<h3><a class="anchor" name="roadmap" href="https://github.com/kinlane/irs-modernized-efile-blueprint/blob/master/README.md#roadmap"></a>Roadmap</h3>
<p>In addition to resources, status and regular updates of platform status of the overall MeF system, the IRS provides insight into where the platform is going next, keeping providers apprised with what is next for the e-File program. Establishing and maintaining the trust of MeF partners in the private sector is constant work, and requires a certain amount of transparency -- allowing partners to anticipate what is next and make adjustments on their end of operations. Without insight into what is happening in the near and long term future, trust with partners will erode and overall belief in the MeF system will be disrupted, unraveling over 30 years of hard work.</p>
<h3><a class="anchor" name="governance" href="https://github.com/kinlane/irs-modernized-efile-blueprint/blob/master/README.md#governance"></a>Governance</h3>
<p>The Modernized e-File (MeF) programs go through several stages of review and testing before they are used to process live returns. When new requirements and functionality are added to the system, testing is performed by IRS's software developers and by IRS's independent testing organization. These important activities ensure that the electronic return data can be received and accurately processed by MeF systems. Every time an IRS tax form is changed and affects the XML schema, the entire development and testing processes are repeated to ensure quality and proper governance.</p>
<h3><a class="anchor" name="security" href="https://github.com/kinlane/irs-modernized-efile-blueprint/blob/master/README.md#security"></a>Security</h3>
<p>Secure transmissions by 3rd parties with the MeF platform is handled by the Internet Filing Application (IFA) and Application to Application (A2A), which are part of the IRS Modernized System Infrastructure, providing access to trusted partners through the Registered User Portal (RUP). Transmitters using IFA are required to use their designated e-Services user name and password in order to log into the RUP. Each transmitter also establishes a Electronic Transmitter Identification Number (ETIN) prior to transmitting returns. Once the transmitter successfully logs into the RUP, a Secure Socket Layer (SSL) Handshake Protocol allows the RUP and transmitter to authenticate each other, and negotiate an encryption algorithm, including cryptographic keys before any return data is transmitted. The transmitter&rsquo;s and the RUP negotiate a secret encryption key for encrypted communication between the transmitter and the MeF system. As part of this exchange, MeF will only accommodate one type of user credentials for authentication and validation of A2A transmitters; username and X.509 digital security certificate. Users must have a valid X.509 digital security certificate obtained from an IRS authorized Certificate Authority (CA), such as like VeriSign or IdenTrust, then have their certificates stored in the IRS directory using an Automated Enrollment process.</p>
<p>The entire platform is accredited by the Executive Level Business Owner, who is responsible for the operation of the MeF system, with guidance provided by the National Institute of Standards (NIST). The IRS MITS Cyber Security organization and the business system owner are jointly responsible and actively involved in completing the IRS C&amp;A Process for MeF, ensuring complete security of all transmissions with MeF over the public Internet.</p>
<h3><a class="anchor" name="a-blueprint-for-public--private-sector-partnerships-in-a-21st-century-digital-economy" href="https://github.com/kinlane/irs-modernized-efile-blueprint/blob/master/README.md#a-blueprint-for-public--private-sector-partnerships-in-a-21st-century-digital-economy"></a>A Blueprint For Public &amp; Private Sector Partnerships In A 21st Century Digital Economy</h3>
<p>The IRS MeF platform provides a technological blueprint that other federal agencies can look to when exposing valuable data and resources to other agencies as well as the private sector. Web services, XML, and proper authentication can open up access and interactions between trusted partners and the public in ways that were never possible prior to the Internet age.</p>
<p>While this web services approach is unique within the federal government, it is a common way to conduct business operations in the private sector -- something widely known as Service Oriented Architecture (SOA), an approach that is central to a healthy enterprise architecture. A services oriented approach allows organizations to decouple resources and data and open up very wide or granular levels of access to trusted partners. The SOA approach makes it possible to submit forms, data, and other digital assets to government, using XML as a way to communicate and validate information in a way that supports proper business rules, wider governance, and the federal law.</p>
<p>SOA provides three essential ingredients for public and private sector partnership:</p>
<ul>
<li>Technology - Secure usage of modern approaches to using compute, storage and Internet networking technology in a distributed manner</li>
<li>Business - Adherence to government lines of business, while also acknowledging the business needs and interest of 3rd party private sector partners</li>
<li>Politics - A flexible understanding and execution of activities involved in establishing a distributed ecosystem of partners, and maintaining an overall healthy balance of operation</li>
</ul>
<p>The IRS MeF platform employs this balance at a scale that is unmatched in federal government currently. MeF provides a working blueprint can be applied across federal government, in areas ranging from the veterans claims process to the financial regulatory process.</p>
<p>The United States federal government faces numerous budgetary challenges and must find new ways to share the load with other federal and state agencies as well as the private sector. A SOA approach like MeF allows the federal government to better interact with existing contractors, as well as future contractors, in a way that provides better governance, while also allowing for partnership with the private sector in ways that goes beyond simply contracting. The IRS MeF platform encourages federal investment in a self-service platform that enable trusted and proven private sector partners to access IRS resources in predefined ways -- all of which support the IRS mission, but provide enough incentive that 3rd party companies will invest their own money and time into building software solutions that can be fairly sold to US citizens.</p>
<p>When an agency builds an SOA platform, it is planting the seeds for a new type of public / private partnership whereby government and companies can work together to deliver software solutions that meet a federal agency's mission and the market needs of companies. This also delivers value and critical services to US citizens, all the while reducing the size of government operations, increasing efficiencies, and saving the government and taxpayers money.</p>
<p>The IRS MeF platform represents 27 years of the laying of a digital foundation, building the trust of companies and individual citizens, and properly adjusting the agency's strategy to work with private sector partners. It has done so by employing the best of breed enterprise practices from the private sector. MeF is a blueprint that cannot be ignored and deserves more study, modeling, and evangelism across the federal government. This could greatly help other agencies understand how they too can employ an SOA strategy, one that will help them better serve their constituents.</p>
<p style="text-align: center;"><a href="https://github.com/kinlane/irs-modernized-efile-blueprint/blob/master/README.md"><strong>You Can View, Edit, Contribute Feedback To This Research On Github</strong></a></p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/09/15/irs-modernized-efile-mef-a-blueprint-for-public-private-sector-partnerships-in-a-21st-century-digital-economy-draft/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/09/14/api-monetization-in-the-internet-of-things-nordic-apis/">API Monetization In The Internet of Things @ Nordic APIs</a></h3>
        <span class="post-date">14 Sep 2013</span>
        <p><a href="http://nordicapis.com/events/stockholm-sep-2013/" target="_blank"><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/events/nordic-apis/nordic-apis-logo.png" alt="" width="175" align="right" /></a></p>
<p>I have a panel this week at <a href="http://nordicapis.com/events/stockholm-sep-2013/" target="_blank">Nordic APIs</a> called Business Models in an Internet of Things, with Ellen Sundh (<a href="https://twitter.com/ellensundh">@ellensundh</a>) of <a href="http://codacollective.com/">Coda Collective</a>, David Henricson Briggs of <a href="http://www.playbackenergy.se/">Playback Energy</a>, Bradford Stephens of <a href="https://www.pingidentity.com/">Ping Identity</a> and Ronnie Mitra(<a href="https://twitter.com/mitraman">@mitraman/a&gt;) of </a><a href="http://www.layer7tech.com/">Layer 7 Technologies</a>. My current abstract for the panel is:</p>
<blockquote><em>As we just begin getting a hold on monetization strategies and business models for APIs delivering data and resources for mobile development. How will we begin to understand how to apply what we have learned for the Internet of Things across our homes, vehicles, sensors and other Internet enabled objects that are being integrating with our lives.</em></blockquote>
<p>In preparation for the event I am working through my thoughts around potential monetization strategies and business models that will emerge in this fascinating adn scary new world where everything can be connected to the Internet---creating an Internet of Things (IoT).</p>
<p><strong>Where Is The Value In The IoT?</strong><br /> When it comes to monetizing APIs of any type, there first has to be value. When it comes IoT where is the value for end-users? Is it the device themselves, is it the ecosystem of applications built around a device or will it be about the insight derived from the data exhaust generated from these Internet connected devices?</p>
<p><strong>Evolving From What We Know</strong><br /> After almost 10 years of operating web APIs, we are getting a handle on some of the best approaches to monetization and building business models in this new API economy.  How much of this existing knowledge will transfer directly to the IoT? Freemium, tiered plans, paid API access and advertising--which of these existing models will work, and which won't.</p>
<p>Another existing model to borrow from when it comes to IoT is the telco space. The world of cellphone and smart phones are the seeds of IoT and one of the biggest drivers of the API economy. How will existing telco business models be applied to the world of IoT? Device subsidies, contracts, data plans, message volumes are all possible things that could be borrowed from the existing telco world, but we have to ask ourselves, what will work and what won't?</p>
<p><strong>Will Developers Carry the Burden?</strong><br /> When it comes to API access, developers often pay for access and the privilege of building applications on top of API driven platforms. Will this be the case in the IoT? Will the monetization of IoT platforms involve charging developers for API usage, number of users and features? Is this a primary channel for IoT device makers to make money off their products? In the beginning this may not be the case, with providers needing to incentivize developers to build apps and crunch data, but it is likely that eventually developers will have to carry at least some of the burden.</p>
<p><strong>Micro-Payment Opportunities</strong><br /> The payment industry is booming in the API Economy, but micro-payments are still getting their footing, doing better in some areas than others. Certain areas of IoT may lend itself to applying micro-payment approaches to monetization.  When you pass through toll booths or parking, there are clear opportunities for micro-payments to engage with Internet connected automobiles. Beyond the obvious, think of the opportunities for traffic prioritization--do you want intelligence on where you should drive to avoid traffic or possibly pay per mile to be in a preferred lane? Another area is in entertainment, in generating revenue from delivering music, audiobooks and other entertainment to drivers or passengers in IoT vehicles and public transportation.</p>
<p><img src="https://s3.amazonaws.com/kinlane-productions/api-evangelist/tag-cloud-internet-of-things.png" alt="" width="325" align="right" /></p>
<p><strong>Will IoT Be All About The Data</strong><br /> As we sit at the beginning of the era of big data, driven from mobile, social and the cloud, what will big data look like in the IoT era. Will the money be all about the data exhaust that comes from a world of Internet connected device, not just at the individual device and the insight delivered to users, but at the aggregate level and understand parking patterns for entire cities or the electricity consumption for a region.</p>
<p><strong>Security Will Be Of High Value In IoT</strong><br /> We are already beginning to see the importance of security in the IoT world, with <a href="http://apievangelist.com/2013/09/13/the-perils-of-api-transport-over-the-public-internet/">missteps by Tesla</a> and <a href="http://apievangelist.com/2013/09/05/building-internet-of-things-products-you-better-secure-it-says-the-ftc/">camera maker <span>TRENDnet</span></a>. Will security around IoT be a monetization opportunity in itself?  Device manufacturers will be focused on doing what they do best, and often times will overlook security, leaving open huge opportunities for companies to step up and deliver b2b and b2c security options and layers for IoT. How much will we value security? Will we pay extra to ensure the devices in our lives are truly secure?</p>
<p><strong>I Will Pay For My Privacy In An IoT World</strong><br /> When all devices in my life are connected to the Internet, but also the world around me is filled with cameras, sensors and tracking mechanisms, how will privacy change? Will we have the opportunity to buy privacy in an IoT world? Will the wealthy be able to pay for the privilege of being lost in a sea of devices, not showing up on cameras, passed by when sensors are logging data? Privacy may not be a right in an IoT world it by be purely something you get if you can afford it. Will companies establish IoT business models and drive monetization through privacy layers and opportunities?</p>
<p><strong>A IoT Las Vegas for Venture Capital</strong><br /> With IoT centered around costly physical devices, and potentially large platforms and networks, will anything in the IoT space be able to be bootstrapped like the web 2.0 and mobile space was? Or will all IoT companies require venture capital? At first glance IoT looks like a huge opportunity for VC firms, allowing them to specialize for the win, or gamble on the space like they would in Las Vegas.</p>
<p><strong>Will We Plan For Monetization Early On In IoT?</strong><br /> When it comes to IoT, it is easy to focus on the monetization the physical device, either leaving money on the table with new an innovative ways of generating revenue, or possibly having monetization strategies that are behind the scenes and not obvious to users--something that could be damaging to security, privacy and overall trust in the IoT space.</p>
<p>We learned a lot from mistakes made in early social, cloud and mobile API monetization. We need to make sure and have open conversation around healthy IoT business models and monetization strategies. Generating revenue from IoT needs to be a 3-legged endeavor that includes not just IoT platform providers, but sensibly includes ecosystem developers as well as end-users.</p>
<p>The world of IoT is just getting going, but is picking up momentum very quickly. We are seeing IoT devices enter our homes, cars, clothing, bodies and will become ubiquitous in the world around us, embedded in signs, doorways, roadways, products in rural and metropolitan areas.  It is clear there is huge opportunities to make money in this new Internet connected world, but let's make sure and have open conversations about how this can be done in sensible ways to make sure the IoT space grows in a healthy and vibrat way.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/09/14/api-monetization-in-the-internet-of-things-nordic-apis/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/09/13/using-excel-for-crowdsourced-data-gathering-and-reporting/">Using Excel For Crowdsourced Data Gathering And Reporting</a></h3>
        <span class="post-date">13 Sep 2013</span>
        <p><a href="http://apps.npr.org/playgrounds/#playground-help" target="_blank"><img src="https://s3.amazonaws.com/kinlane-productions/npr/accessible-playgrounds/ramps-to-play-components-600.jpg" alt="" width="250" align="right" /></a></p>
<p>I was impressed with some of the data journalism behind the recent NPR story, <a href="http://apps.npr.org/playgrounds/#playground-help" target="_blank">Playgrounds For Everyone, a community-edited guide to accessible playgrounds</a>.</p>
<p>The story is definitely an important one, but it is the data behind it I think is significant to highlight. You can download the data of the 1700 playgrounds in 20 different cities in a CSV and JSON format. Something I think is ripe for an API, by the way.</p>
<p>Another interesting aspect is they are asking for submissions from the public, and they even provide a template Google spreadsheet, providing a framework for how the public should gather and organize data into a standard way, that NPR can import.</p>
<p>While I think this project could go further, I think it is an excellent example of using data journalism in public reporting.  The only suggestions I have is making the project a Github repository so the story, JSON and CSV can be versioned, forked and downloaded much more easily.</p>
<p>I think Google Spreadsheets and Excel templates are a perfectly acceptable way to gather data from the public and 3rd party sources. It allows you to solicit data from others in a format that they understand, while still making sure it is structured enough to easily merge with a master database.</p>
<p>Additionaly, it would be pretty easy to add the ability for users to email their spreadsheets to a central email address, and programmatically convert to JSON, and CSV, then commit to the Github repository that contains the master JSON and CSV files.  This way the repository administrator could accept or deny submissions as a pull request.</p>
<p>I'm enjoying seeing these scrappy spreadsheet, CSV and JSON solutions to data storytelling. Even if they aren't perfect I like seeing people play with different approaches, in hopes of finding an approach that works for them.</p>
<p>Lots to learn from. Nice work NPR.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/09/13/using-excel-for-crowdsourced-data-gathering-and-reporting/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/09/13/the-perils-of-api-transport-over-the-public-internet/">The Perils Of API Transport Over The Public Internet</a></h3>
        <span class="post-date">13 Sep 2013</span>
        <p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-danger.png" alt="" width="250" align="right" /></p>
<p>George Reese has a very interesting post from last week over at O'Reilly. It is about an earlier post he did on the unpublished <a href="http://programming.oreilly.com/2013/08/tesla-model-s-rest-api-authentication-flaws.html">Tesla REST API</a>.&nbsp;I'll let you read the post, "T<a href="http://programming.oreilly.com/2013/09/the-myth-of-the-private-api.html">he Myth of the Private API</a>"--I highly recommend it.</p>
<p>Reese talks about the mistakes made by Tesla, Phillips and other Internet of Things companies, when they take advantage of the power of web APIs, intending them to be private, but do not put any thought into what happens when you deploy APIs using the public without securing your API endpoints from unintended use.</p>
<p>I find a particular statement he made, fascinating:</p>
<blockquote><em>I sincerely believe that ultimately there is no such thing as a private API for consumption over the public Internet.</em></blockquote>
<p>After reading his post, I have to agree. I think many technology companies are just considering the Internet to be some sort of constant, magic transport layer for anything we want to use it for. I think this can be true to a point, but as the Intenret matures, we have slow down a bit and consider deeply the impact of our actions, and the way we use Internet enabled technology.</p>
<p>I wrote about a piece last week, which was about the <a href="http://apievangelist.com/2013/09/05/building-internet-of-things-products-you-better-secure-it-says-the-ftc/">first FTC case against an Internet of Things manufactuer</a>, camera maker TrendNet--where much like Tesla, they took no considerations for the fact they were using the open Internet to drive their technology, and more importantly no thought regarding the privacy of their consumers.</p>
<p>The world of APIs fascinates me. It reminds me of the bug zappers, where we are attracted by the openness and power of web APIs, but as you get closer and closer to the API light, you can easily get burned or zapped by the very thing that drew you in.</p>
<p>I strongly believe in the power of web APIs, but I think there will be a lot of unintended consequences from opening up data, resources and the devices that surround us, over the public Internet.  Make sure you are being thoughtful, and seriously considering security, privacy and the other potential repercussions of web APis before jumping in.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/09/13/the-perils-of-api-transport-over-the-public-internet/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/09/13/a-masking-scrubbing-anonymizing-api/">A Masking, Scrubbing, Anonymizing API</a></h3>
        <span class="post-date">13 Sep 2013</span>
        <p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-question-mark.png" alt="" width="250" align="right" /></p>
<p>In government there is a fear of exposing public data via APIs--rightfully so. This is not just a government concern, it exists in all industries within each an every business and organization.  We all possess private data, and when opening up API driven resources, we need to make sure none of this is exposed in un-desired ways.</p>
<p>I find it hard to believe, that after almost 10 years of public APIs, there isn't a reasonable solution to masking, scrubbing and anonymizing data that is made available via APIs.  I wrote about r<a href="http://apievangelist.com/2013/03/13/an-api-that-scrubs-personally-identifiable-information-from-other-apis/">esearch into finding a solution at UC Berkeley</a> a while back, but to date I have not seen any real solutions to this problem yet.</p>
<p>I was talking with another Presidential Innovation Fellow (PIF) the other day about possible solutions for making sure Personally Identifiable Information (PII) doesn't get exposed via government APIs. Afterwards, I got to thinking about possible API options, and I don't think it would be that difficult to get started with a basic solution.</p>
<p>My thoughts are, that you could provide a simple API proxy, that would terminate requests from any <a href="https://developers.helloreverb.com/swagger/">Swagger</a> defined APIs and easily iterate through each value and apply a series of regular expressions against it to look for common PII or other data that shouldn't be exposed.  The proxy could automatically replace with template values like John or Jane Doe for names, 1234 Street for addresses, etc.</p>
<p>API providers could set a list of areas they are concerned about exposing with the API proxy configuration, and it would enforce all filtering required. The proxy could also look for other common patterns, and make recommendations of other areas that could be masked, scrubbed or anonymized that the API provider didn't consider.</p>
<p>Technically it sounds like a pretty simple solution, that could get smarter and faster over time at identifying sensitive information, to better serve API providers.  This type of proxy could be default in healthcare, education and in other sensitive environments and be default in development environments, or in production environments that are accessible to non-trusted consumers.</p>
<p>Of course this is something I'd love to explore, but I just don't have the time to build it. This is something that wouldn't be too hard to build and evolve, and could have potentially huge impacts across many important industries, and go far to protect all of our sensitive data from potential privacy violations.</p>
<p>As with all of my ideas, I just want to share it publicly, in hopes someone will build it.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/09/13/a-masking-scrubbing-anonymizing-api/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/09/09/the-spreadsheet-will-play-a-central-role-in-the-api-space/">The Spreadsheet Will Play A Central Role In The API Space</a></h3>
        <span class="post-date">09 Sep 2013</span>
        <p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/spreadsheet-basic.gif" alt="" width="300" align="right" /></p>
<p>The more I immerse myself in government, I'm reminded of the central role that the spreadsheet plays in our business and government operations--primarily Microsoft Excel, but also in some circles, the Google Docs Spreadsheet.</p>
<p>While it is government that is bringing the spreadsheet front and center for me again, I'm reminded of days while working on SAP events and working on budgets, sessions and registrations lists that were past around in complex series of spreadsheets. After this I go further back in time, to the early 2000s when I worked in the non-profit sector, where database management was completely done in a myriad of group and individual spreadsheets.</p>
<p>Beyond the spreadsheet being the <a href="http://www.breakingviews.com/is-microsoft-the-quiet-villain-of-global-finance?/21081118.article">central villain in global operations</a>, I'm seeing it emerge as a character across the API landscape with <a href="http://octopart.com/blog/archives/2013/7/octopart-in-excel">Octobpart Electronics providing bill of materials management in Microsoft Excel that is driven from their API</a>, <a href="http://info.crunchbase.com/2013/06/06/crunchbase-excel-update/">CrunchBase adding 13,689 Companies and 1,462 venture rounds as an Excel download</a>, and <a href="https://www.twilio.com/blog/2013/08/twilio-from-excel-and-access.html">Twilio allowing users to make calls and send SMSs from spreadsheets</a>.</p>
<p>As much as us API geeks would love for people to deploy clean, sensibly designed APIs, that meet our visions of the future of APIs--the reality is that much of the worlds data is managed via the spreadsheet.  If we are truly going to deliver on the API economy, we have to consider the spreadsheet.</p>
<p>This spreadsheet bridge is not just about allowing users to publish data via APIs from spreadsheets, but also enabling every day users to cosume valuable API driven data and resources from their native spreadsheet. It has to be a two way street.</p>
<p>Whether we like it or not, the spreadsheet will continue to play a central role in the API space, and represents the future of acessing valuable corporate, non-profit and government resources for everyone.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/09/09/the-spreadsheet-will-play-a-central-role-in-the-api-space/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/09/07/loosely-coupled-services/">Loosely Coupled Services</a></h3>
        <span class="post-date">07 Sep 2013</span>
        <p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-gears.png" alt="" width="200" align="right" /></p>
<p>Building off a similar topic this week, I was asked to dumb down or explain what I meant by "Loosely Coupled Services", alongside a "<a href="http://apievangelist.com/2013/09/07/library-of-modular-services/">Library of Modular Services</a>". In this case, loosely couple means independent technical and data services, in the same way you would access services that people are familar with in the mainstream business world.</p>
<p>Think of the services you would access and put to use around your home. Common household services like electrician, plumber, tile layer and sheet rocker. These each represent independent services you would access to tackle a home improvement project. While there is some overlap in these services, generally each service technician specializes in one area, doing one thing and doing it well. The slight overlap between an electrician and plumber would be considered the "loosely coupled" part, where there are dependencies between each specialized service, ie. the plumber needs an electrician to wire the dishwasher after he /she plumbs it.</p>
<p>The concept of loosely coupled services works well when it comes to APIs. The goal is to define APIs to do one thing and do it well, establishing a library of modular services that can be used across a company and organization, its partners as well as provide public access to the most commonly requested resources.  A simple example might be product catalog. You can deliver a web service that allows for accessing, searching and pulling details of products a company offers. All the web service knows how to do is find, list and provide info on products, nothing else. This product catalog will have loosely coupled dependencies with other inventory, shopping cart and coupon services, but in the end its very specialized.</p>
<p>Any organization or company will have a wide variety of potential services that can be defined. It is best to define these in as granular of a way as possible, keeping them entirely independent of other services, except for slightly coupling that allow them to consider certain interactions and facilitate interoperability. A loosely coupled services approach will allow you to mix and match different services for different project, minimizing dependencies and introducing complexity that down the road can be very hard to untangle.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/09/07/loosely-coupled-services/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/09/07/library-of-modular-services/">Library of Modular Services</a></h3>
        <span class="post-date">07 Sep 2013</span>
        <p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/api-evangelist/att/universal-library-sign.png" alt="" width="200" align="right" /></p>
<p>I'm always looking for simpler and more concise language to describe API, while writing stories and white papers for my audience. I recently used the phrase "library of modular web services", in a presentation outline at the Department of Veterans Affairs (VA). This white paper was intended for a non-technical, state government audience, and my collaborator on the presentation asked if I could dumb this phrase down a little for the audience, providing a simpler explanation.</p>
<p>In this case, I think certain phrases get co-opted by the developer and IT crowd, borrowing from the physical world, resulting in them having a perceived technical meaning, but when in reality they are still very rooted in their past, and can be easily explained by taking users back to their previous meanings. One perfect example of this is the phrase, a "Library of Modular Services".</p>
<p>Think of each book, in a physical library as an analogy of a single API service. Much like when building an application on top of API services, when you are developing a research paper in a library, you need a multitude of resources to bring your paper together. When you visit the library to conduct your research you can browse the library directory, find a wide variety of books you will need. Early on you will be testing out many of these books, then setting aside the books that do not deliver the value and information you are looking for.</p>
<p>When you find the specific resources you need, this is when the modular approach comes into play. For example, if you need a book on a specific artist from history, you aren't required to check-out the entire art history section, or even check-out all impressionists artists, you can go for a very specific artist like Monet or pick and choose from the impressionist resources you need.</p>
<p>Using this library analogy for API services works very well. As a company or organization, instead of just going to IT to get technical services, you can visit your library of modular services to find exactly the resources you need for your project.  Maybe your project is just creating a quarterly report, or maybe you want to create a visualization of product sales, all the way to launching a new mobile application.</p>
<p>To support employess in their work, each company should have a library where anyone in the can visit, browse, search and discovery the resources they will need for any project. This library can then be extended to have more marketplace features allowing external partners or even the public to come and browse the library of modular resources, just like they would the public library--allowing them to find just the services they need.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/09/07/library-of-modular-services/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/09/05/i-am-always-amazed-at-how-little-people-understand-about-github/">I Am Always Amazed At How Little People Understand About Github</a></h3>
        <span class="post-date">05 Sep 2013</span>
        <p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-github.jpg" alt="" width="175" align="right" /></p>
<p>I work with some seriously smart people on a day to day basis, virtually across the web, and in person on some of the projects I'm working on in federal government. Much like APIs, Github is fast becoming a ubiquitous technology that people are using to manage their community, code, documents and much more.</p>
<p>Several times each week I encounter situations where Github is referenced as a potential platform for managing a new project, or cited wen talking about how to solicit feedback, engagement and participation across existing projects. I'm always amazed that in about 75% of these Github conversations, someone chimes in about how Github wouldn't be appropriate because of the barrier to entry for many users.</p>
<p>I find this barrier to entry perspective very interesting. Many of the uses of Github require no knowledge of, or the need to touch code. One meeting in particular, was about providing feedback on the next steps of <a href="http://data.gov">data.gov</a>, when a participant referenced that for users who weren't technical, but wanted to provide feedback, they should use a separate forum to submit feedback.</p>
<p>To understand this I pulled up the data.gov site, clicked on link to Github repository behind the project, clicked on issues tab, then submit new issue. A text box came up much like it would on Facebook or the proposed forum. In reality there are no technical hurdles for these users, except their own perception that Github is a social coding site for programming.</p>
<p>This type of perception is a holdover from the last 30 years of IT and developers making sure they were keepers of the knowledge and instilling fear in users, that treading in this realm is only for the brave, often male world of developers, database and IT folk. In the world of software as a service (SaaS) and APIs, this is no longer a reality, but the perception is still there.</p>
<p>As I work hard to evangelize API tools and resource, in which Github is a huge part of, one of my primary directives is to educate everyday business users about how easy it is to use some of these tools. You don't need to be a developer to use Github. You can sign up for an account, create repositories of HTML, markdown, text, PDF, images and other documents, and even participate, and contribute to other people's projects--without touching code.</p>
<p>In the last year I've seen numerous, very tech savvy users, who are exposed to Github managed projects daily, who have made their first commit, submit their first issue and realize how easily all of this is. I'm always amazed at how little people truly understand about Github, when in reality with a little education, it is a very powerful platform that anyone can use--no coding knowledge required.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/09/05/i-am-always-amazed-at-how-little-people-understand-about-github/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/09/05/building-internet-of-things-products-you-better-secure-it-says-the-ftc/">Building Internet of Things Products? You Better Secure It, Says the FTC</a></h3>
        <span class="post-date">05 Sep 2013</span>
        <p><a href="http://www.trendnet.com/?todo=home"><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/trendnet-camera.jpg" alt="" width="200" align="right" /></a></p>
<p>The <a href="http://www.ftc.gov/opa/2013/09/trendnet.shtm">Federal Trade Commission(FTC) just settled a case with web-enabled camera maker TRENDnet</a>, signaling the government agency's first action against an Internet of Thing's company.</p>
<p>The FTC's complaint alleges that <a href="http://www.trendnet.com/?todo=home">TRENDnet</a> was labeling their cameras as secure, when in reality the camera had faulty software that left them open to online viewing and audio access to anyone who had the Internet address of the camera.</p>
<p>The FTC / TRENDnet case is the first, in what I predict is a future filled with security and privacy violations by Internet of Things products and companies.  As we blindly race forward with the exciting Internet of Things, many companies will disregard the security of their hardware and software, just like TRENDnet did.</p>
<p>Hopefully as an industry we can help make sure this doesn't get out of hand, and don't require the federal government to police the situation. As technology providers, we need to make sure the software, hardware and APIs that drive the Internet of Things is properly secured, protecting our customers and the industry.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/09/05/building-internet-of-things-products-you-better-secure-it-says-the-ftc/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/09/05/api-of-api-keyword-searches/">API of API Keyword Searches</a></h3>
        <span class="post-date">05 Sep 2013</span>
        <p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-magnifying-glass.png" alt="" width="150" align="right" /></p>
<p>I was working on series of API endpoints this week, each of them had a basic search parameter, allowing you pass a keyword to filter your API request.  Pretty standard stuff.</p>
<p>After deploying the APIs I wanted to make sure I tracked what people were searching for, so I could use in reporting and other tools. Then I got to thinking, that it would make sense to go ahead and launch an API of API search queries, allowing other users to be able to discover and benefit from insights derived from other API users searches.</p>
<p>Just a random thought as I'm playing around more with APIs in government. I definitely like the stimulation I get from designing, deploying and evolving APIs at my new gig, in addition to my existing monitoring of the API space.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/09/05/api-of-api-keyword-searches/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/09/04/am-i-going-to-see-you-nordicapis-in-sweden-september-18th-19th/">Am I Going to See You @NordicAPIs in Sweden, September 18th &amp; 19th?</a></h3>
        <span class="post-date">04 Sep 2013</span>
        <p><a href="http://nordicapis.com/" target="_blank"><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/events/nordic-apis/nordic-apis-logo.png" alt="" width="200" align="right" /></a></p>
<p>There is a growing number of API conferences going on this year in the US, but the hunger for API knowledge isn't just something going on in this country, we are seeing a demand for API information and conversation growing internationally.</p>
<p>One place that is exploding is in Europe and specifically in the Scandinavian region, and there is one must-go-to event that is driving the API conversation--the <a href="http://nordicapis.com/" target="_blank">Nordic API Conference</a>, September 18th and 19th in Stockholm, Sweden.</p>
<p>I will be heading out for the conference and giving a talk I'm calling "The Politics of APIs is the Future", my current abstract is:</p>
<blockquote><em>We have found the right balance of technology for APIs, using simple lightweight protocols, built on HTTP. The business of APIs around good documentation, marketing and support to developers and monetization strategies are being proven. The next challenge we face in the API space will be around terms of use, privacy, deprecation and security.</em></blockquote>
<p>In addition to my talk, I will be moderating a panel on the Internet of Things, but specifically on business models, with Ronnie Mitra, Bradford Stephens, David Henricson Briggs and Ellen Sundh:</p>
<p><a href="http://nordicapis.com/" target="_blank"><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/events/nordic-apis/stockholm-image.jpeg" alt="" width="200" align="right" /></a></p>
<blockquote><em>As we just begin getting a hold on monetization strategies and business models for APIs delivering data and resources for mobile development.  How will we begin to understand how to apply what we have learned for the Internet of Things across our homes, vehicles, sensors and other Internet enabled objects that are being integrating with our lives.</em></blockquote>
<p>The Nordic APIs is exactly two weeks away, so its not too late to buy a plane ticket and engage in API conversations with global thought leaders fromt the space, in beautiful Stockholm. I've never been to Sweden and looking forward to going.  I get really pumped by the passion and energy for APIs, interoperability and opening up government businesses outside the United States.</p>
<p>If you can make time, and afford the trip, I look forward to seeing you in Stockholm and having a conversation about the business and politics of the fast unfolding API driven world.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/09/04/am-i-going-to-see-you-nordicapis-in-sweden-september-18th-19th/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/09/02/private-sector-sharing-the-load-through-government-apis/">Private Sector Sharing The Load Through Government APis</a></h3>
        <span class="post-date">02 Sep 2013</span>
        <p><a href="/admin/blog/" target="_blank"><img src="https://s3.amazonaws.com/kinlane-productions/federal-government/irs/bw-irs-logo.jpg" alt="" width="200" align="right" /></a></p>
<p>When it comes to APIs, people respond to stories about real world examples, even more than solid technological implementations. If you can demonstrate how APIs are actually providing a solution, you can reach more people than just talking about the technological nuts and bolts. With this in mind I'm working through telling stories around how the IRS leveraged web services to incentivize private sector to develop applications that would provide tax solutions for the every day tax payer.</p>
<p>In my short year and half working for government I've heard the example of "TurboTax" used to describe an example of how the federal government can leverage technology to deliver partner driven solutions, and better serve the public. Obviously this is an example that resonates with leaders in government, but one that I think needs a lot more work to actually flush out the model more deeply, while keeping it as something that anyone can understand and is able to repeat in their own circles.</p>
<p>The story of the IRS e-File program for developers is a important blueprint for how a forms driven federal government system, can deploy APIs and share the burden of delivering important civic services with the private sector. Describing this as a "Turbo Tax Solution", is an extremely simplified analogy, whereTurbo Tax is just one application within an ecosystem of private sector, trusted IRS partners.</p>
<p>As with every other federal agency, the IRS faced the problem of modernizing its systems to keep up with current technologies, while also continuing to improve the US tax process, so that it would better serve americans, and make the massive federal agency more efficient, which resulted in the design of an e-File system, where tax professionals could submit electronic tax form filings via IRS systems. While a web-based approach to modernizing the IRS tax process is a large part of the evolution of the US tax process, it wasn't enough. The IRS isn't in the business of being a software developer, and needed more help when building the next generation of tax solutions--setting the stage for development of web services.</p>
<p>Web services, also widely called Application Programming Interfaces (APIs), provide the ability to submit traditional IRS forms over the Internet, directly from existing or new software platforms that are developed by 3rd party, public and private sector partners. These web services don't just speak in terms of IRS forms, they also understand the myriad of business rules that surround the submission of these forms, adhering to not just the legacy IRS forms process, but allow developers to follow the IRS tax code without fully understanding the intricacies of the complex tax system.</p>
<p><a href="/admin/blog/" target="_blank"><img style="padding: 20px;" src="https://s3.amazonaws.com/kinlane-productions/federal-government/irs/irs-efile-logo.jpeg" alt="" width="325" align="right" /></a></p>
<p>This new set of APIs provides the foundation for what is known as the <a href="http://www.irs.gov/pub/irs-pdf/p4164.pdf" target="_blank">modernized e-File system for software developers and transmitters</a>. By employing APIs, the IRS is securely opening up access to the digital filing of IRS tax forms and supporting business rules, to trusted 3rd party partners from the public and private sector.  This API driven approach allows the IRS to stick with what they do best, and not worry about being the sole developer of online, desktop and mobile applications that interface with the US tax process--giving birth to not just TurboTax, but a whole ecosystem of API driven technology solutions from the prviate sector.</p>
<p>The IRS Modernized e-File (MeF) system provides a blueprint for how the federal government can leverage APIs to establish and evolve a public / private sector partnerships that allows government to more intelligently deliver services. This API driven approach is not purely a technical solution, it is one that acknowledges there are business drivers needed that provide incentives for 3rd party organizations and companies to participate. There are also political considerations in the form of terms of services, privacy policy and security, as well as adhering to the nuances and forward motion of the federal lawmaking process.</p>
<p>This post is just the first in a series of stories and white papers working to better clarify the API driven approach the IRS has taken to better collaborate with trusted private and public sector partners. My goal is to eventually provide a working blueprint that other government agencies can follow when embarking on their own API initiatives, and better serve their constituents.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/09/02/private-sector-sharing-the-load-through-government-apis/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/09/02/baseline-for-federal-government-open-data-and-api-portals/">Baseline for Federal Government Open Data and API Portals</a></h3>
        <span class="post-date">02 Sep 2013</span>
        <p><a href="http://kinlane.github.io/va-developer/"><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-portal.jpg" alt="" width="200" align="right" /></a></p>
<p>I have a whole list of projects around open data and APIs at the Department of Veterans Affairs (VA). Additionally I have numerous other open data and API projects I'd like to tackle across other federal agencies. As I do with other areas of my work, I needed a standardized way to stabilize the datasets and APis I will need for my projects, in the same way any open data and API provider should do for their consumers.</p>
<p>To help support my work, and hopefully the work of others I wanted to create a baseline portal that I could use at the VA, for showing what is possible when hanging open datasets and APIs, in a full featured portal. The success of any open data and / or API portal starts with the technical building blocks, like data and APIs, but have a set of business and political building blocks that are essential to their adoption and growth.</p>
<p>I've spent the last three years studying the business and politics of APIs. During these three years I've looked at almost 10,000 API developer portals, and I've established a <a href="http://management.apievangelist.com/building-blocks.html">base set of what I consider the building blocks</a> of successful API portals, with a handful in which I consider essential to success. I've always wanted a simple API portal template that would reflect this research, and my new <a href="http://kinlane.github.io/va-developer/">Developer @ VA</a>&nbsp;portal&nbsp;is the first step towards achieving this.</p>
<p><a href="http://kinlane.github.io/va-developer/">Developer @ VA</a> is an early stage prototype, whcih I've built to satisfy this need of mine, specifically for my VA projects. I will be polishing this portal and replicating it as a single template that can be used for any API and / or open data portal. This portal exists purely as a <a href="https://github.com/">Github repository</a> and runs on <a href="http://pages.github.com/">Github Pages</a>, using a <a href="http://jekyllrb.com/">Jekyll for managing its pages and blog</a>.  Everything else is HTML, CSS, Javascript and JSON, allowing it to be able to run on any server, including other cloud services like Dropbox or Amazon S3.</p>
<p>To start with I've included 20 of what I consider essential API building blocks:</p>
<ul class="mainlist">
<li>Landing Page</li>
<li>Getting Started</li>
<li>APIs</li>
<li>Data</li>
<li>Interactive Docs</li>
<li>Code</li>
<li>Gallery</li>
<li>Support  
<ul>
<li>Self-Service  
<ul>
<li>Stack Exchange</li>
<li>Quora</li>
</ul>
</li>
<li>Direct Support  
<ul>
<li>Issue Management</li>
<li>Twitter</li>
<li>LinkedIn</li>
<li>Facebook</li>
<li>Google+</li>
</ul>
</li>
</ul>
</li>
<li>Roadmap</li>
<li>Changelog</li>
<li>Blog</li>
<li>Terms of Use</li>
<li>Privacy Policy</li>
<li>Branding Guidelines</li>
</ul>
<p>Beyond this project running using open formats and standards, and being deployable in common cloud environments like Github, Dropbox and Amazon S3, everything is machine readable by default. The portal starts with a <a href="http://kinlane.github.io/va-developer/sitemap.json">sitemap.json</a>, which links &nbsp;to other building blocks that make up the open data and API portal, including a data.json and api.json which provide programmatic access to all resources included in the site:</p>
<ul class="mainlist">
<li><a href="http://kinlane.github.io/va-developer/api.json">data.json</a> - Machine readable JSON file of all data assets using common core metadata for easy access to all data stored in the portal</li>
<li><a href="http://kinlane.github.io/va-developer/data.json">api.json</a> - Machine readable JSON, using the Swagger format describing all API resources available within the portal</li>
</ul>
<p>Next I wanted all essential building blocks of the portal to also be machine readable by default:</p>
<ul class="mainlist">
<li><a href="http://kinlane.github.io/va-developer/code/code.json">Code</a> - JSON library of all code available for use when integrating with datasets and APIs</li>
<li><a href="http://kinlane.github.io/va-developer/gallery/gallery.json">Gallery</a> - A JSON gallery of web, mobile apps and visualizations, widgets, excel and other integrations on data and APis</li>
<li><a href="http://kinlane.github.io/va-developer/support/support.json">Support</a>&nbsp;- A JSON listing of self-service and direct support channels for the portal</li>
<li><a href="http://kinlane.github.io/va-developer/roadmap/roadmap.json">Roadmap</a> - JSON listings of both the future with a roadmap, providing transparency into portal operations</li>
<li><a href="http://kinlane.github.io/va-developer/roadmap/changelog.json">Changelog</a> - A JSON listing documenting the past with all changes made to the portal</li>
<li><a href="http://kinlane.github.io/va-developer/legal/legal.json">Legal</a> - A directory of the legal building blocks of the portal with links to terms of use, privacy and branding guidelines</li>
</ul>
<p>This project is the product of 3 years of research, and 3 days worth of work. So it is rough. I was able to capture my initial vision in 3 days, but still a lot of work to do. I need to let it simmer a little bit, and round off some of the rough edges and apply some polish. Then the next step is to generate a generic template from it, that will become the baseline for any other portal I derive from this work.</p>
<p>If there is anything you'd like to see in the future, go ahead and use any of the <a href="http://kinlane.github.io/va-developer/support/">support channels available </a>on the site. Once I get the base template set up, I will use that as a top level project to guide the future of this baseline for open data and API portals.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/09/02/baseline-for-federal-government-open-data-and-api-portals/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/08/28/pick-your-head-up-regularly-heads-down-is-good-but-being-aware-cannot-be-ignored/">Pick Your Head Up Regularly, Heads Down is Good, But Being Aware Cannot Be Ignored</a></h3>
        <span class="post-date">28 Aug 2013</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/y-u-no-guy-why-u-no-pay-attention.png" alt="" width="250" align="right" /></p>
<p>One important thing I've learned while running API Evangelist, is the importance of picking your head up from your work on a regular basis, and tuning into the world around me.  When you are running your API initiative it can be also be easy to go heads down coding, addressing technical issues, managing support channels and dealing with the general day-to-day, internal activity of running a company.</p>
<p>Don't get me wrong, I'm big on going radio silent, closing the Gmail tab, shutting down TweetDeck, LinkedIn, Facebook, Google+, Skype and my other communication channels. Since I stopped using Google Reader to monitor feeds, and setup my own internal curation, I can easily tune out my API industry monitoring and curation for days sometimes. This is all intended to get shit done and reduce distractions.</p>
<p>Even with my regular tuning out of the world and focusing on work, I make sure and pick my head up, turn on communication channels, read and curate blog posts and generally take a good look at the world around me.  I've worked too hard, building up momentum with my content creation, search engine optimization and social media presence to let it all slide. I can coast for days, or even weeks, but if I drop the ball for too long, I will not only stop any forward motion and growth--I risk losing traction and quickly becoming irrelevant.</p>
<p>My number one mission with the <a title="API Evangelist Network" href="http://apievangelist.com/network.html">API Evangelist Network</a> is to educate myself, then secondarily educate the masses about the API space. If I don't pick my head up regularly, tune into the API space and understand the latest trends, technologies and players--I'm doing myself a disservice, as well as the greater interest of the API industry, and whoever I work for.</p>
<p>When running your company, make sure you find time to go heads down, focusing on your work, but make sure you pick your head up regularly and tune into your community, your audience and the wider industry you exist within. Without this engagement you will never achieve your goals.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/08/28/pick-your-head-up-regularly-heads-down-is-good-but-being-aware-cannot-be-ignored/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/08/28/kicking-the-api-strategy-practice-conference-into-full-gear/">Kicking The API Strategy &amp; Practice Conference Into Full Gear</a></h3>
        <span class="post-date">28 Aug 2013</span>
        <p><a href="http://www.apistrategyconference.com/2013SF/index.php" target="_blank"><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/events/api-strategy-practice-sf/api-strategy-and-practice-san-francisco-october-23-24-25-half.png" alt="" width="250" align="right" /></a></p>
<p><a href="http://www.apistrategyconference.com/2013SF/index.php" target="_blank">While we officially launched </a><a href="http://www.apistrategyconference.com/2013SF/index.php" target="_blank">API Strategy &amp; Practice, San Francisco edition</a> back in May, we've been pretty quiet during the summer months. Well, now summer is coming to a close, and we are now less than 60 days away from the API community conversation that is #APIStrat.</p>
<p>To start ramping things up, I'm going to start showcasing the <a href="http://www.apistrategyconference.com/2013SF/speakers.php">amazing line-up of speakers</a> we have for the event, and giving the <a title="kick-ass sponsors" href="http://www.apistrategyconference.com/2013SF/sponsors.php">kick-ass sponsors</a> who have stepped up to support the event, the "love" they deserve.</p>
<p>Early bird pricing has ended, but you have less than a month to get in on the mid range pricing. Don't miss out like so many did in February when #APIStrat New York City sold out--<a href="http://www.apistrategyconference.com/2013SF/register.php">buy your tickets</a> now.</p>
<p>Even with large number of speakers we have lined up, we still have some slots left open, and will be making some announcements of other big names to the lineup-so stay tuned.</p>
<p>I will be exploring the wide range of topics and tracks we have planned here on API Evangelist as well as the <a title="APIStrat Blog" href="http://www.apistrategyconference.com/2013SF/blog.php">#APIStrat blog</a>, so subscribe to our RSS feeds and tune in on Twitter for more details.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/08/28/kicking-the-api-strategy-practice-conference-into-full-gear/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/08/27/the-api-space-often-seems-to-more-about-money-intellectual-property-and-competition-than-interoperability-sometimes/">The API Space Often Seems To More About Money, Intellectual Property and Competition, Than Interoperability Sometimes</a></h3>
        <span class="post-date">27 Aug 2013</span>
        <p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-greed.png" alt="" width="200" align="right" /></p>
<p>I used to think that the API space is resistant to defining standards around REST, data formats, webhooks, hypermedia, api definitions and other key areas of the space, because after the top down, strict structure of SOA, the community just wanted to let the space organically define the best approaches.</p>
<p>The API world just seemed like a wild west of strong minded individuals, who had a sort of "markets will work it out" approach, and the best approach will win in the end. You know, kind of like the Amazon cloud API battle?</p>
<p>By 2013, the only thing we've come to agreement on is around oAuth, and by many accounts that was a failure. I used to think that many of the bitter battles by the RESTafarians about API design, RESTfulness and Hypermedia were because these were very smart, stubborn folks trying to craft the best approach possible.</p>
<p>After many years of advocating for open source tooling, open events in the space and sharing of common API design patterns, I don't think there is much goodwill for any of it, because companies are more interested in their intellectual property(IP), seeming competitive and ultimately making the most money and pleasing their VCs.</p>
<p>Now don't get me wrong, there are some very fine companies, do good in the space. I'm not saying the entire sector has lots its way. However the majority of the vibe from major players is, we don't want to share design patterns, open tooling, work together to support industry events and gatherings, we will just do it all ourselves, keeping the IP and value for themselves.</p>
<p>I understand I'm less interested in the whole business and VC aspect of this than many of you are, but I think APIs got their start in openness, collaboration and sharing in the spirit of transparency and interoperability. It seems like like after 10 years and finally getting some traction in the space, we are starting to lose our way.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/08/27/the-api-space-often-seems-to-more-about-money-intellectual-property-and-competition-than-interoperability-sometimes/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/08/27/sitemap-for-apis/">Sitemap for APIs</a></h3>
        <span class="post-date">27 Aug 2013</span>
        <p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-telescope.png" alt="" width="175" align="right" /></p>
<p>When it comes to API discovery, as an industry we haven't been able to find a satisfactory technological solution yet. While I often feel the right approach hasn't emerged yet, I think we are just overlooking "good enough" solutions, because we are waiting for the holy grail of API discovery.</p>
<p>I can't imagine that indexing, search and discovery of the myriad of web APIs out there is that much harder than indexing, search and discovery of the billions of HTML documents available online.  Sure, when you are talking about programmatic interfaces, you need a little more precision, but I think us technologists are caught up our own beliefs that APIs should be perfect.</p>
<p>It would make sense that we adopt some evolution of the common <a href="http://www.sitemaps.org/protocol.html">sitemaps format</a>, retrofit it to be JSON, accommodate open data catalogs, and allow for various API definitions in <a href="https://developers.helloreverb.com/swagger/">Swagger</a>, <a href="https://github.com/mashery/iodocs">I/O Docs</a> or even <a title="API Blueprint" href="http://apiblueprint.org/">API blueprint</a>.  Sure these formats won't have the precision of an evolution of the precious WSDL, or some actually agreed upon standard, but it will get us over the hump we are in.</p>
<p><a title="ProgrammableWeb" href="http://programmableweb.com">ProgrammableWeb</a> is 8 years old now, and in 2013, we still don't have any next step, let lone an actual usable solution for API discovery? I just have a hard time believing this is a technological problem, that it is more the stubbornness of the leaders in the space to just take any meaningful step towards API discovery, and lead.</p>
<p>There isn't going to be any money in API discovery, so this isn't something a single startup can emerge to solve. It is something we will all have to discuss and play with until we can find something will get us to the next step, together.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/08/27/sitemap-for-apis/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/08/27/oauth-101/">OAuth 101</a></h3>
        <span class="post-date">27 Aug 2013</span>
        <p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/api-evangelist/oauth/OAuth2.png" alt="" width="200" align="right" /></p>
<p>With APIs beginning to enter the mainstream consciousness, it is time to spend more time educating the masses about OAuth. We've had plenty of conversations between two of the OAuth legs, provider and developer, but we now need to <a title="3 legged conversations" href="http://apievangelist.com/2013/02/26/which-of-the-three-oauth-legs-is-the-most-important/">bring the third leg into the conversation</a>--the user.</p>
<p>First, what is OAuth? - An open protocol to allow secure authorization in a simple and standard method from web, mobile and desktop applications.</p>
<p>Whether you like it or not, OAuth has become the industry standard for accessing resources, being served up via APIs, that are being consumed through desktop, web and the fast growing mobile space.</p>
<p><strong>OAuth Platforms &amp; Data Providers</strong><br /> If you are an online platform, OAuth is something you need to understand. At a minimum, if you require users to establish an account, you need to consider allowing users to create their accounts and login in the future using other popular OAuth providers like Facebook, Twitter and Google. Next if you want to provide access to your platform user's data via an API, you need to take a deeper dive into OAuth, and consider establishing yourself as an OAuth provider.</p>
<p><strong>OAuth for Desktop, Web and Mobile Developers</strong><br /> In 2013, if you are a developer, you are probably using APIs. OAuth has been very intimidating for developers for quite some time, but with the increased availability of quality OAuth clients, better implementations and educational materials from API providers, and standardized approaches by startups like <a title="OAuth.io" href="http://apievangelist.com/2013/08/13/simplifying-oauth-with-oauthio/">OAuth.io</a>--OAuth is something you shouldn't fear anymore. You need OAuth as a default tool in your developer toolbox.</p>
<p><strong>Everyday Online User</strong><br /> Like the term API, OAuth is something that should be added to the vocabulary of every tech savvy user. You should understand that OAuth exists, and that it gives you the ability to create accounts and login to your favorite platforms without filling out endless new forms and sharing your passwords unnecessarily. The platforms you use daily, like Facebook, Twitter, LinkedIn and Google all are OAuth providers, and you should leverage these providers to manage your online presence. The control is in your hands to securely manage your online persona using OAuth, and with a little education and maintenance you can ensure you profile(s) are secure, and only the providers you trust have access to your important data.</p>
<p>This is a first post in series of OAuth related information that is looking to educate the masses about the importance of OAuth. Hopefully increasing the number of quality OAuth providers, knowledgeable developers and OAuth aware online users--making OAuth something that is ubiquitous across the web, and enabling meaningful 3 legged conversations that make data accessible, incentivizes developers while protecting end-user's privacy.</p>
<p>I will be deploying an entirely new research project dedicated to OAuth, where I will work on stories about OAuth that hopefully resonate with the masses. As with my other research, it will take me a while to dial in. As I work to do this, I will curate the best stories and tools in the OAuth space, eventually trying to create a polished repository of OAuth resources that providers, developers and users will find valuable.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/08/27/oauth-101/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/08/25/api-testing-and-monitoring-finding-a-home-in-your-companies-existing-qa-process/">API Testing and Monitoring Finding A Home In Your Companies Existing QA Process</a></h3>
        <span class="post-date">25 Aug 2013</span>
        <p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-qa.jpeg" alt="" width="200" align="right" /></p>
<p>I've been doing API Evangelist for three years now, a world where selling APIs to existing companies outside of Silicon Valley, and often venture capital firms is a serious challenge. While APis have been around for a while in many different forms, this new, more open and collaborative approach to APis seems very foreign, new and scary for some companies and investors--resulting in them often very resistant to it.</p>
<p>As part of my storytelling process, I'm always looking for ways to dovetail API tools and services into existing business needs and operations, making them much more palatable to companies across many business sectors.  Once part of the API space I'm just getting a handle on is the area&nbsp;<a title="API Integration" href="http://integration.apievangelist.com">API integration</a>, which includes testing, monitoring, debugging, scheduling, authentication and other key challenges developers face when building applications that depend on APIs.</p>
<p>I was having a great conversation with Roger Guess of <a title="TheRightAPI" href="http://therightapi.com">TheRightAPI</a> the other day, which I try to do regularly. We are always brainstorming ideas on where the space is going and the best way to tell stories around API integration, that will resonate with existing companies. Roger was talking about the success they are finding dovetailing their testing, monitoring and other web API integration services with a company's existing QA process--something that I can see will resonate with many companies.</p>
<p>Hopefully your company already has a full developed QA cycle for your development team(s), including, but not limited to, automated, unit and regression testing--something where API tests, monitoring, scheduling and other emerging API integration building blocks will fit in nicely. This new breed of APi integration tools don't have to be some entirely new approach to development, chances are you are already using APIs in your development and API testing and monitoring can just be added to your existing QA toolbox.</p>
<p>I will spend more time looking for stories that help relate some of these new approaches to your existing QA processes, hopefully finding news ways you can put tools and services like TheRightAPI to use, helping you better manage the API integration aspect of your web and mobile application development.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/08/25/api-testing-and-monitoring-finding-a-home-in-your-companies-existing-qa-process/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/08/24/with-apis-in-your-company-start-small-and-read-api-evangelist/">With APIs In Your Company, Start Small And Read API Evangelist</a></h3>
        <span class="post-date">24 Aug 2013</span>
        <p><img src="https://s3.amazonaws.com/kinlane-productions/bw-icons/bw-start.jpeg" alt="" width="175" align="right" /></p>
<p>I thoroughly enjoy the assortment of emails, LinkedIn messages and phone calls I get from people in the SMB and enterprise, letting me know the role my blog plays in them starting, cultivating and evolving their own API initiatives.</p>
<p>I received once such call this week, from an unnamed individual, at an unnamed company, letting me know the role API Evangelist played in providing the information they needed to find success. Like many other companies who reach out to me, their efforts aren't to the point where they feel comfortable telling stories publicly, so I'm happy to keep anonymous, until they are ready.</p>
<p>The stories that come out of these companies are all very similar.  The API initiatives were started by single person, or small group of passionate individuals who start small, find safe and sensible wins, while keeping risk and failures to a minimum.  They start with data and resources that are not mission critical, but still offer value to either internal, partner or public developers.</p>
<p>These innovators usually start with a handful of trusted partners, keeping the experimentation very controlled in a safe environment, before opening up to a wider base of partners, and then when ready, to a self-service public audience.  This approach allows API innovators to find small successes and report these wins to business leaders and stakeholders, before moving forward with other efforts.</p>
<p>Taking this approach in small, iterative cycles, providing decision makers with the necessary reporting and education, allows for you to slowly change internal culture. API change does not happen overnight, and it is easy to fail if you try to go big in companies who aren't quite ready.</p>
<p>I can't get enough of these stories, I can't wait until these program mature, where I can tell them publicly on the blog. Until then, remember that when you are starting with a brand new API initiative within your company, start small, find success, minimize risk, repeat and tell stories of your efforts to everyone you can. You will be surprised what can happen in six months to a year, with the right environment you can find your culture changing and becoming much more open to API experimentation.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/08/24/with-apis-in-your-company-start-small-and-read-api-evangelist/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2013/08/22/view-csv-and-tsv-data-files-in-table-views-directly-on-github/">View CSV and TSV Data Files In Table Views Directly On Github</a></h3>
        <span class="post-date">22 Aug 2013</span>
        <p><a href="https://github.com/blog/1601-see-your-csvs" target="_blank"><img style="kpadding: 15px;" src="https://s3.amazonaws.com/kinlane-productions/api-evangelist/github/github-csv-table-view.png" alt="" width="250" align="right" /></a></p>
<p>Github is really doing some cool stuff to help open data folks manage and share their data.</p>
<p>They just launched the ability to <a href="https://github.com/blog/1601-see-your-csvs" target="_blank">render data from .csv (comma-separated) and .tsv (tab-separated) files as an interactive table</a>, including headers and row numbering.  They even let you link to a specific row for sharing specific data from the file.</p>
<p>As I'm working on opening up government data, I'm pushing for agencies to use Github when publishing and sharing CSV, TSV, XML and JSON files. These kind of features really go a long way in helping me achieve my goals.</p>
<p>Make sure and also check out what Github has done around <a href="https://github.com/blog/1465-stl-file-viewing">3D models</a> and <a href="https://github.com/blog/1528-there-s-a-map-for-that">geographic data</a>, pretty cool stuff.</p>
        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2013/08/22/view-csv-and-tsv-data-files-in-table-views-directly-on-github/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  

	<table width="100%" border="1" style="background-color:#FFF; border: 0px #FFF;">
		<tr style="background-color:#FFF; border: 0px #FFF;">
			<td align="left">
				<a href="/blog/page49" class="button"><< Prev</a></li>
			</td>
			<td></td>
			<td align="right">
				<a href="/blog/page51" class="button">Next >></a>
			</td>
		</tr>
	</table>

  </div>
</section>

              
<footer>
  <hr>
  <div class="features">
    
    
      
      <article>
        <div class="content">
          <p align="center"><a href="https://www.getpostman.com/" target="_blank"><img src="https://apievangelist.com/images/postman-logo.png" width="75%" style="padding: 15px; border: 1px solid #000;" /></a></p>
        </div>
      </article>
      
    
      
      <article>
        <div class="content">
          <p align="center"><a href="https://tyk.io/" target="_blank"><img src="https://apievangelist.com/images/tyk-logo.png" width="75%" style="padding: 15px; border: 1px solid #000;" /></a></p>
        </div>
      </article>
      
    
  </div>
  <hr>
  <p align="center">
    relevant work:
    <a href="http://apievangelist.com">apievangelist.com</a> |
    <a href="http://adopta.agency">adopta.agency</a>
  </p>
</footer>


            </div>
          </div>

          <div id="sidebar">
            <div class="inner">

              <nav id="menu">
  <header class="major">
    <h2>Menu</h2>
  </header>
  <ul>
    <li><a href="/">Homepage</a></li>
    <li><a href="http://101.apievangelist.com/">101</a></li>
    <li><a href="/blog/">Blog</a></li>
    <li><a href="http://history.apievangelist.com/">History of APIs</a></li>
    <li><a href="/#api-lifecycle">API Lifecycle</a></li>
    <li><a href="/search/">Search</a></li>
    <li><a href="/newsletters/">Newsletters</a></li>
    <li><a href="/images/">Images</a></li>
    <li><a href="/archive/">Archive</a></li>
  </ul>
</nav>

              <section>
  <div class="mini-posts">
    <header>
			<h2 style="text-align: center;"><i>API Evangelist Sponsors</i></h2>
		</header>
    
    
      
        <article style="display: inline;">
          <a href="https://www.getpostman.com/" class="image"><img src="https://apievangelist.com/images/postman-logo.png" alt="" width="50%" style="padding: 15px; border: 1px solid #000;" /></a>
        </article>
      
    
      
        <article style="display: inline;">
          <a href="https://tyk.io/" class="image"><img src="https://apievangelist.com/images/tyk-logo.png" alt="" width="50%" style="padding: 15px; border: 1px solid #000;" /></a>
        </article>
      
    
  </div>
</section>


            </div>
          </div>

      </div>

<script src="/assets/js/skel.min.js"></script>
<script src="/assets/js/util.js"></script>
<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
<script src="/assets/js/main.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-1119465-51"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-1119465-51');
</script>


</body>
</html>
