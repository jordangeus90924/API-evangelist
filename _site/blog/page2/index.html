<!DOCTYPE html>
<html xmlns="https://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
  <html>
  <title>API Evangelist </title>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
  <!--[if lte IE 8]><script src="/assets/js/ie/html5shiv.js"></script><![endif]-->
  <link rel="stylesheet" href="/assets/css/main.css" />
  <link rel="stylesheet" href="/assets/css/bootstrap.min.css" />
  <!--[if lte IE 9]><link rel="stylesheet" href="/assets/css/ie9.css" /><![endif]-->
  <!--[if lte IE 8]><link rel="stylesheet" href="/assets/css/ie8.css" /><![endif]-->

  <!-- Icons -->
  <link rel="shortcut icon" type="image/x-icon" href="https://apievangelist.com/favicon.ico">
	<link rel="icon" type="image/x-icon" href="https://apievangelist.com/favicon.ico">

  <link rel="alternate" type="application/rss+xml" title="API Evangelist Blog - RSS 2.0" href="https://apievangelist.com/blog.xml" />
  <link rel="alternate" type="application/atom+xml" title="API Evangelist Blog - Atom" href="https://apievangelist.com/atom.xml">

  <!-- JQuery -->
  <script src="/js/jquery-latest.min.js" type="text/javascript" charset="utf-8"></script>
  <script src="/js/bootstrap.min.js" type="text/javascript" charset="utf-8"></script>
  <script src="/js/utility.js" type="text/javascript" charset="utf-8"></script>

  <!-- Github.js - http://github.com/michael/github -->
  <script src="/js/github.js" type="text/javascript" charset="utf-8"></script>

  <!-- Cookies.js - http://github.com/ScottHamper/Cookies -->
  <script src="/js/cookies.js"></script>

  <!-- D3.js http://github.com/d3/d3 -->
  <script src="/js/d3.v3.min.js"></script>

  <!-- js-yaml - http://github.com/nodeca/js-yaml -->
  <script src="/js/js-yaml.min.js"></script>

  <script src="/js/subway-map-1.js" type="text/javascript"></script>

  <style type="text/css">

    .gist {width:100% !important;}
    .gist-file
    .gist-data {max-height: 500px;}

    /* The main DIV for the map */
    .subway-map
    {
        margin: 0;
        width: 110px;
        height: 5000px;
        background-color: white;
    }

    /* Text labels */
    .text
    {
        text-decoration: none;
        color: black;
    }

    #legend
    {
    	border: 1px solid #000;
        float: left;
        width: 250px;
        height:400px;
    }

    #legend div
    {
        height: 25px;
    }

    #legend span
    {
        margin: 5px 5px 5px 0;
    }
    .subway-map span
    {
        margin: 5px 5px 5px 0;
    }

    </style>

    <meta property="og:url" content="">
    <meta property="og:type" content="website">
    <meta property="og:title" content="API Evangelist">
    <meta property="og:site_name" content="API Evangelist">
    <meta property="og:description" content="A network of research sites dedicated to the technology, business, and politics of APIs.">
    <meta property="og:image" content="http://s3.amazonaws.com/kinlane-productions/api-evangelist/t-shirts/KL_InApiWeTrust-1000.png">

    <meta name="twitter:url" content="">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="API Evangelist">
    <meta name="twitter:site" content="API Evangelist">
    <meta name="twitter:description" content="A network of research sites dedicated to the technology, business, and politics of APIs.">
    
      <meta name="twitter:creator" content="@apievangelist">
    
    <meta property="twitter:image" content="http://s3.amazonaws.com/kinlane-productions/api-evangelist/t-shirts/KL_InApiWeTrust-1000.png">


</head>

  <body>

			<div id="wrapper">
					<div id="main">
						<div class="inner">

              <header id="header">
	<a href="http://apievangelist.com" class="logo"><img src="https://kinlane-productions2.s3.amazonaws.com/api-evangelist/api-evangelist-logo-400.png" width="75%" /></a>
	<ul class="icons">
		<li><a href="https://twitter.com/apievangelist" class="icon fa-twitter"><span class="label">Twitter</span></a></li>
		<li><a href="https://github.com/api-evangelist" class="icon fa-github"><span class="label">Github</span></a></li>
		<li><a href="https://www.linkedin.com/company/api-evangelist/" class="icon fa-linkedin"><span class="label">LinkedIn</span></a></li>
		<li><a href="http://apievangelist.com/atom.xml" class="icon fa-rss"><span class="label">RSS</span></a></li>
	</ul>
</header>

    	        <section>
	<div class="content">

	<h3>The API Evangelist Blog</h3>
	<p>This blog is dedicated to understanding the world of APIs, exploring a wide range of topics from design to deprecation, and spanning the technology, business, and politics of APIs. <a href="https://github.com/kinlane/api-evangelist" target="_blank">All of this runs on Github, so if you see a mistake, you can either fix by submitting a pull request, or let us know by submitting a Github issue for the repository</a>.</p>
	<center><hr style="width: 75%;" /></center>
	
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/04/06/establishing-an-apifirst-reference-implementation/">Establishing An Apifirst Reference Implementation</a></h3>
        <span class="post-date">06 Apr 2020</span>
        ---
published: true
layout: post
title: 'Establishing an API-First Reference Implementation'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/aws-s3-stories-christianity-under-construction-copper-circuit.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/aws-s3-stories-christianity-under-construction-copper-circuit.jpg" alt="" width="40%" align="right" /></p>
<p>I do a lot of API blah blah blah&rsquo;ing about abstract technical concepts. Sometimes I am able to craft a coherent narratives around some complex technology goings on, but most of the time I am just practicing. Workshopping different concepts until I find one that will make an impact on the way folks see APIs. One of the challenges I face in my storytelling is that I operate too far into the abstract, and not making the rubber meet the road enough. Another challenger I face is going too far down the rabbit hole with a particular companies implementation, which usually turns down the volume significantly on my storytelling, because most companies, organizations, institutions, and government agencies aren&rsquo;t equipped to be 100% transparent about what they are doing. After a decade of storytelling exploration I find that operating somewhere in between the abstract and the real world is the best place to be, resulting in me desiring a reference implementation that I could use as an anchor for my storytelling, helping keep me grounded when it comes to how I talk about APIs.</p>
<h3>Welcome Union Fashion</h3>
<p>One of my co-workers at Postman had created a fictional company called Union Fashion when he started working on our solutions engineering team, but hadn&rsquo;t put much more work into the project since. When I heard about it sounded exactly like what I was looking for. An e-commerce reference implementation that a wide audience could relate with, providing us with a model API implementation that we could use across webinars, workshops, and other storytelling channels. I&rsquo;m big on building on the work of others, so I adopted Union Fashion, and I am working to define the fictional company as an API-First approach to operating a common real world business.</p>
<p><img src="https://kinlane-productions2.s3.amazonaws.com/union-fashion/union-fashion-logo.png" alt="" width="255'&gt;&#10;&lt;h3&gt;An API-First E-Commerce Reference Implementation&lt;/h3&gt;&#10;&lt;p&gt;Union Fashion provides me with the opportunity to design, deploy, and operate a simple set of APIs. Moving them from idea to sustainment in a way that I can share with Postman customers and API Evangelist readers. Beyond setting up a fictional e-commerce company including organizational structure and teams, complete with roles, we are beginning with the development of a handful of simple APIs that will make sense to a large audience, beginning with these five APIs:&lt;/p&gt;&#10;&lt;ul&gt;&#10;&lt;li&gt;&lt;strong&gt;Products&lt;/strong&gt;&nbsp;- (&lt;a href=" align="right" />Repo) (<a href="https://documenter.postman.com/view/10394726/SzS2xojt?version=latest">Docs</a>) - Defining all of the products that Union Fashion offers.</p>
<li><strong>Orders</strong>&nbsp;- (<a href="https://github.com/union-fashion/orders">Repo</a>) (<a href="https://documenter.postman.com/view/10394726/SzYXXzLu?version=latest">Docs</a>) - Allows for the ordering of Union Fashion products online.</li>
<li><strong>Baskets</strong>&nbsp;- (<a href="https://github.com/union-fashion/baskets">Repo</a>) (<a href="https://documenter.postman.com/view/10394726/SzYXXzVh?version=latest">Docs</a>) - Allows for the ordering of Union Fashion products online.</li>
<li><strong>Users</strong>&nbsp;- (<a href="https://github.com/union-fashion/users">Repo</a>) (<a href="https://documenter.postman.com/view/10394726/SzYXXzaC?version=latest">Docs</a>) - Defines users who engage with the Union Fashion platform.</li>
<li><strong>Search</strong>&nbsp;- (<a href="https://github.com/union-fashion/search">Repo</a>) (<a href="https://documenter.postman.com/view/10394726/SzYXXza6?version=latest">Docs</a>) - Provides a universal search for products, orders, and users.</li>
<p>Each API will get fully fleshed out as part of an API-First design effort, where I am guessing there will be other APIs added along the way. The goal of this is to come out of the other end with some fully functioning APIs that I can actually use as part of selling products online, which I can simultaneously also use for workshops and training on how APIs can be done well using a consistent API life cycle and set of governance practices.</p>
<h3>Planning For The Reference Implementation Out In the Open</h3>
<p>I was given an &ldquo;enterprise webinar&rdquo; to do back in February, shortly after I learned about Union Fashion. Before I thought much about it I declared that I would plan the Union Fashion API out in the open on GitHub using Postman, and make it center of my webinar, and eventually turn it into a series of webinars showing how to deliver APIs using an API-first approach. Proposing the following outline when it came to planning for how to deliver APIs for Union Fashion, shaping each part of the webinar series alongside building our reference e-commerce implementation.</p>
<ul>
<li><a href="https://github.com/union-fashion/home/blob/master/planning/initial-planning.md"><strong>Initial Planning</strong></a>&nbsp;(<a href="https://www.youtube.com/watch?v=iq3ZMQ6f_Vg&amp;list=PLM-7VG-sgbtAR_Z2q_a2hAT4St7nU9SoQ&amp;index=4&amp;t=0s">Webinar Video</a>)- Getting the ball rolling with an API-first approach to development.           
<ul>
<li><a href="https://github.com/union-fashion/home/blob/master/planning/build-and-test-planning.md"><strong>Build &amp; Test Planning</strong></a>&nbsp;(<a href="https://www.youtube.com/watch?v=Op1Xep0j5s0&amp;list=PLM-7VG-sgbtAR_Z2q_a2hAT4St7nU9SoQ&amp;index=5&amp;t=117s">Webnar Video</a>) - In planning phase currently, determining the process for how we will be building and testing our infrastructure.</li>
<li><a href="https://github.com/union-fashion/home/blob/master/planning/deploy-and-monitor-planning.md"><strong>Deploy &amp; Monitor Planning</strong></a>&nbsp;- In planning phase currently, shaping how each team will be delivering their API infrastructure across the organization.</li>
<li><a href="https://github.com/union-fashion/home/blob/master/planning/go-to-market-and-sustainment.md"><strong>GTM &amp; Sustainment</strong></a>&nbsp;-In planning phase currently, and helping make sure we have a formal approach to how we are going living with our infrastructure.</li>
</ul>
</li>
<li><a href="http://developer.union.fashion/"><strong>Developer Portal</strong></a>&nbsp;- Publishing a portal for Union Fashion, providing a dedicated area for developers to find all the essential building blocks of an API platform.</li>
</ul>
<p>I added the developer portal portion just now. I haven&rsquo;t scheduled that one, but Deploy &amp; Monitor and GTM &amp; Sustainment are both scheduled for end of April and beginning of May. With the initial planning and Build &amp; Test having already occurred&mdash;with videos published to YouTube. My intention is to keep planning Union Fashion out in the open, while telling the story of it all via a series of webinars, and posts here on this blog, and eventually on the Postman blog. Right now I am just looking to get a handle on the overall tone for the project, and hammer out some of the technical details of my implementation. Since it is a reference implementation I am particularly eager to keep it simple, standardized, and reflecting the best of what I have to offer&mdash;while still being perpetually under construction.</p>
<h3>The Infrastructure Behind Union Fashion</h3>
<p>I am looking for Union Fashion to be a real world implementation that others can actually implement using common infrastructure. I am beginning with a mostly AWS focused stack to help me get the Union Fashion APIs stood up, leveraging Postman and GitHub as the backbone of the implementation, while also relying on a handful of AWS APIs to make the Union Fashion API factory operate.</p>
<ul>
<li><strong>Postman</strong>&nbsp;(<a href="https://documenter.postman.com/view/631643/JsLs/?version=latest">API</a>) (<a href="https://documenter.postman.com/view/631643/JsLs/?version=latest">Docs</a>) - We use Postman as our API life cycle manager, helping deliver on a variety of stops along the life cycle for each API, and orchestrate how everything works using APIs.</li>
<li><strong>GitHub</strong>&nbsp;(<a href="https://developer.github.com/v3/">API</a>) (<a href="https://documenter.postman.com/view/10394726/SzYbxHEo?version=latest">Docs</a>) - We use GitHub as the underlying workspace for each API, working in sync with Postman workspaces to make the core definition of each API available across the entire life cycle.</li>
<li><strong>AWS API Gateway</strong>&nbsp;(<a href="https://docs.aws.amazon.com/apigatewayv2/latest/api-reference/api-reference.html">API</a>) (<a href="https://documenter.postman.com/view/10394726/SzYbxHAM?version=latest">Docs</a>) - All internal, partner, and public APIs are published using the AWS API Gateway, providing a content management layer across all APIs being delivered.</li>
<li><strong>AWS DynamoDB</strong>&nbsp;(<a href="https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/Welcome.html">API</a>) (<a href="https://documenter.postman.com/view/10394726/SzYbxHAK?version=latest">Docs</a>) - For simpler data APIs we are using AWS DynamoDB for the persistent data storage behind APIs, allowing for simple NoSQL data storage for each individual APIs.</li>
<li><strong>AWS RDS Aurora</strong>&nbsp;(<a href="https://docs.aws.amazon.com/AmazonRDS/latest/APIReference/Welcome.html">API</a>) (<a href="https://documenter.postman.com/view/10394726/SzYbxHAP?version=latest">Docs</a>) - For more complex data APIs we are using AWS RDS Aurora for persistent storage behind APIs, allowing for more complex relational data storage for each API.</li>
<li><strong>AWS Lambda</strong>&nbsp;(<a href="https://docs.aws.amazon.com/lambda/latest/dg/API_Reference.html">API</a>) (<a href="https://documenter.postman.com/view/10394726/SzYbxHAQ?version=latest">Docs</a>) - For the serverless compute layer for many APIs we are using Lambda as the scalable power behind each API, allowing us to scale APIs at the most atopic level.</li>
<li><strong>AWS S3</strong>&nbsp;(<a href="https://docs.aws.amazon.com/AmazonS3/latest/API/Welcome.html">API</a>) (<a href="https://documenter.postman.com/view/10394726/SzYbxHEf?version=latest">Docs</a>) - Using AWS S3 for the storage of all images, videos, documents, and other heavy objects that are made available via Union Fashion APIs, giving each API it's own object store.</li>
<li><strong>AWS Cloudtrail</strong>&nbsp;(<a href="https://docs.aws.amazon.com/awscloudtrail/latest/APIReference/Welcome.html">API</a>) (<a href="https://documenter.postman.com/view/10394726/SzYbxHEg?version=latest">Docs</a>) - We are using AWS CloudTrail for the logging layer behind each API, gathering the exhaust of the database, storage, compute, and gateway layers of the APIs.</li>
<li><strong>AWS Identity &amp; Access Management (IAM)</strong>&nbsp;(<a href="https://docs.aws.amazon.com/IAM/latest/APIReference/Welcome.html">API</a>) (<a href="https://documenter.postman.com/view/10394726/SzYbxHEh?version=latest">Docs</a>) - AWS IAM is used to provide access to APIs for all the underlying services they are using across the AWS platform.</li>
<li><strong>CloudFlare</strong>&nbsp;(<a href="https://api.cloudflare.com/">API</a>) (<a href="https://documenter.postman.com/view/10394726/SzYbxHEm?version=latest">Docs</a>) - We are using CloudFlare as the DNS and certificate provider behind Union Fashion, providing addressing and encryption for all of the APIs being delivered.</li>
<li><strong>Twitter</strong>&nbsp;(<a href="https://developer.twitter.com/en">API</a>) (<a href="https://documenter.postman.com/view/10394726/SzYbxHEn?version=latest">Docs</a>) - We are using the Twitter API for updates, support, and other communication with the Union Square community.</li>
</ul>
<p>I almost have the entire AWS stack up and running, minus some Lambda and DNS work, and once I am done I will be extending this to use Azure. Expanding the Union Fashion approach to delivering APIs to include a multi-cloud view of the landscape, allowing us to deploy APIs in two separate clouds. Something we&rsquo;ll expand to Google and beyond down the road. Expanding the infrastructure we are using to deploy and operate APIs, while always keeping a strong, well documented list of API-driven infrastructure to help deliver APIs throughout the entire API life cycle.</p>
<h3>A Well Defined API Life Cycle for Union Fashion</h3>
<p>Union Fashion was my opportunity to move my very abstract narrative around the API life cycle from a bulleted list to something you can actually apply on the ground. Using the APIs of the infrastructure providers listed above I actually crafted a single API life cycle collection that would help me not just quantify the API life cycle for Union Fashion, it would let me actually execute upon it. Resulting in the following outline for the Union Fashion API life cycle, helping guide each API forward in a standardized way.</p>
<ul>
<li><strong>Define</strong>&nbsp;(<a href="https://documenter.postman.com/view/10394726/SzYbxGrc?version=latest#3c968356-0064-43ce-a16e-56c8ab6d5916">Docs</a>) - Providing guidelines for how APIs should be defined.</li>
<li><strong>Design</strong>&nbsp;(<a href="https://documenter.postman.com/view/10394726/SzYbxGrc?version=latest#a8242433-c788-4c22-a432-035f2c7ce952">Docs</a>) - Training and guidance about how to design APIs.</li>
<li><strong>Mocking</strong>&nbsp;(<a href="https://documenter.postman.com/view/10394726/SzYbxGrc?version=latest#5fe06cfd-8462-4089-ab79-65fabebd5f16">Docs</a>) - The ability to mock an API to assist in it's delivery.</li>
<li><strong>Documentation</strong>&nbsp;(<a href="https://github.com/union-fashion/home/blob/master">Docs</a>) - Always having consistent up to date documentation.</li>
<li><strong>Database (NoSQL)</strong>&nbsp;(<a href="https://documenter.postman.com/view/10394726/SzYbxGrc?version=latest#111634f5-cdf5-455a-8205-80fbd8597b89">Docs</a>) - Ensuring there is always persistent data storage.</li>
<li><strong>Database (SQL)</strong>&nbsp;(<a href="https://documenter.postman.com/view/10394726/SzYbxGrc?version=latest#05420759-44d9-46e3-9c22-a9f09a73338a">Docs</a>) - Ensuring there is always persistent data storage.</li>
<li><strong>Storage</strong>&nbsp;(<a href="https://documenter.postman.com/view/10394726/SzYbxGrc?version=latest#d329e0d2-0176-4c8a-a73e-d9906d71267f">Docs</a>) - Providing a place to put objects as part of API operations.</li>
<li><strong>Compute</strong>&nbsp;(<a href="https://documenter.postman.com/view/10394726/SzYbxGrc?version=latest#7d081afe-1b11-444d-b43a-d497b1eb24db">Docs</a>) - Having the appropriate amount of compute behind each API.</li>
<li><strong>Pipeline</strong>&nbsp;(<a href="https://documenter.postman.com/view/10394726/SzYbxGrc?version=latest#7ba011e4-a9a7-4b25-910c-1f102430bb49">Docs</a>) - Making the delivery of code behind each API repeatable.</li>
<li><strong>Deployment</strong>&nbsp;(<a href="https://documenter.postman.com/view/10394726/SzYbxGrc?version=latest#fd958817-4c85-447a-856b-8d5745ba484c">Docs</a>) - Making sure that APIs are deployed in repeatable ways.</li>
<li><strong>Management</strong>&nbsp;(<a href="https://documenter.postman.com/view/10394726/SzYbxGrc?version=latest#1394eea4-59a1-4c76-bb82-01fa99e8a663">Docs</a>) - Ensuring that every API is being managed consistently.</li>
<li><strong>Logging</strong>&nbsp;(<a href="https://documenter.postman.com/view/10394726/SzYbxGrc?version=latest#ea51db44-c8ab-402c-9234-824d128f6424">Docs</a>) - Establishing a centralized logging strategy across APIs.</li>
<li><strong>Encryption</strong>&nbsp;(<a href="https://documenter.postman.com/view/10394726/SzYbxGrc?version=latest#24cd0f73-c2de-4e0e-884a-7f77d8c49fbe">Docs</a>) - Always making encryption the default response across APIs.</li>
<li><strong>DNS</strong>&nbsp;(<a href="https://documenter.postman.com/view/10394726/SzYbxGrc?version=latest#b3b87c21-1814-4bcb-83f3-73d6afae8669">Docs</a>) - Having a strategy for how DNS is handled across groups and APIs.</li>
<li><strong>Portal</strong>&nbsp;(<a href="https://documenter.postman.com/view/10394726/SzYbxGrc?version=latest#c3c525bc-f028-43cf-835d-a922e33a7bd9">Docs</a>) - Ensuring there is always a doorway to get at all APIs.</li>
<li><strong>Testing</strong>&nbsp;(<a href="https://documenter.postman.com/view/10394726/SzYbxGrc?version=latest#a12b8298-b530-4792-a9df-1095bee2806c">Docs</a>) - Providing a consistent approach to testing all APIs.</li>
<li><strong>Security</strong>&nbsp;(<a href="https://documenter.postman.com/view/10394726/SzYbxGrc?version=latest#8091e28b-210e-4d4c-8295-2a60631ca01d">Docs</a>) - Scanning and auditing the security landscape for each API.</li>
<li><strong>Monitoring</strong>&nbsp;(<a href="https://documenter.postman.com/view/10394726/SzYbxGrc?version=latest#f5afa22d-84c1-4c0f-9350-06fe98b10154">Docs</a>) - Having monitors on a schedule ensuring the quality of APIs.</li>
<li><strong>Support</strong>&nbsp;(<a href="https://documenter.postman.com/view/10394726/SzYbxGrc?version=latest#4057e585-c8b0-4eaa-8246-844789bb1370">Docs</a>) - Requiring there be support for every API being operated.</li>
<li><strong>Communications</strong>&nbsp;(<a href="https://documenter.postman.com/view/10394726/SzYbxGrc?version=latest#96a779e8-49f8-49f9-bf0b-b71dbcced85b">Docs</a>) - Having consistent communication in place for APIs.</li>
<li><strong>Analytics</strong>&nbsp;(<a href="https://documenter.postman.com/view/10394726/SzYbxGrc?version=latest#a08dc26e-3c28-496a-b2bc-45f3b5ff2a23">Docs</a>) - Establishing a layer for understanding what is happening.</li>
<li><strong>Deprecation</strong>&nbsp;(<a href="https://documenter.postman.com/view/10394726/SzYbxGrc?version=latest#50938295-1a99-4e88-a147-f0bfd52a09fc">Docs</a>) - Making sure there is a plan for how all APIs will be sunset.</li>
</ul>
<p>It is all a work in progress, and many of the requests in the collection are just relying on hacked together scripts, but it demonstrates the actual API life cycle I am using to design, deploy, and sustain APIs as part of Union Fashion in a well documented, executable, and machine readable way. I am actually using each of these steps to define, design, and move forward each API across a consistent life cycle. There are a lot of steps missing, and lots of edges to grind down and make smooth, but it goes further than any other API life cycle project I&rsquo;ve developed to date, getting me closer to a fully automated series of API life cycle outcomes.</p>
<h3>Governing The API Life Cycle For APIs at Union Fashion</h3>
<p>Complimenting the guard rails that a standardized API life cycle collection bring to the table I wanted to be able to similarly govern how each of the APIs were moving along across the API life cycle. Not just understanding the design of each of the APIs, but actually understand important other stops required for consistently delivering APIs at scale across an organization. So I got to work creating a Postman collection that would help me govern each API I was developing, helping keep an eye on the following areas:</p>
<ul>
<li><strong>Definition</strong>&nbsp;(<a href="https://documenter.postman.com/view/10394726/SzYUagbA?version=latest#17bdb429-32dd-4ecb-9924-6c4f596461e0">Docs</a>) - The guidelines in place when it comes to defining each API.</li>
<li><strong>Design</strong>&nbsp;(<a href="https://documenter.postman.com/view/10394726/SzYUagbA?version=latest#7de484dd-ce0a-4d94-a1c9-4596efe18eae">Docs</a>) - The guidelines in place for helping design better APIs.</li>
<li><strong>Mocks</strong>&nbsp;(<a href="https://documenter.postman.com/view/10394726/SzYUagbA?version=latest#a3f9418e-d98d-4a40-a061-c69fe2becc8c">Docs</a>) - Looking at how mocking is used across the API life cycle.</li>
<li><strong>Development</strong>&nbsp;(<a href="https://documenter.postman.com/view/10394726/SzYUagbA?version=latest#0aba84b5-ae05-41a3-9fb2-d6acda41b55e">Docs</a>)- Helping standardize how APIs are being developed.</li>
<li><strong>Production</strong>&nbsp;(<a href="https://documenter.postman.com/view/10394726/SzYUagbA?version=latest#004ccfb8-f6b6-4599-a55a-ebae98a635db">Docs</a>) - Standardizing how APIs are made available in live environment.</li>
<li><strong>Management</strong>&nbsp;(<a href="https://documenter.postman.com/view/10394726/SzYUagbA?version=latest#d39cfd83-65b4-463a-92a6-200832e57dcc">Docs</a>) - Using a consistent way to manage access and usage of all APIs.</li>
<li><strong>Testing</strong>&nbsp;(<a href="https://documenter.postman.com/view/10394726/SzYUagbA?version=latest#ee2a5dc1-7071-4e66-b6d6-41080e677751">Docs</a>) - Establishing a common approach to delivering testing across APIs</li>
<li><strong>Monitoring</strong>&nbsp;(<a href="https://documenter.postman.com/view/10394726/SzYUagbA?version=latest#1189c6b7-df4b-47b6-a859-de19c5381534">Docs</a>) - Making sure there are monitors for some of the key collections.</li>
<li><strong>Support</strong>&nbsp;(<a href="https://documenter.postman.com/view/10394726/SzYUagbA?version=latest#a84a5d65-9699-4080-9465-52c3c9baff91">Docs</a>) - Being consistent in how each of the APIs are being supported.</li>
<li><strong>Licensing</strong>&nbsp;(<a href="https://documenter.postman.com/view/10394726/SzYUagbA?version=latest#3b52cb12-f718-4c1a-9c90-fc8e006162ea">Docs</a>) - Looking at the licensing of each API and its support resources.</li>
<li><strong>Reporting</strong>&nbsp;(<a href="https://documenter.postman.com/view/10394726/SzYUagbA?version=latest#54e3af5f-35f8-4d6f-afb5-ecc44e536c60">Docs</a>) - Reporting on governance for each API, providing an overview.</li>
</ul>
<p>My work on this collection began with defining not just the API, but defining all of the artifacts and infrastructure that would be used across the governance process. Then I started with API design, which is the stop along the API life cycle most people associate with API governance, but I wanted to quickly move on to also service other stops along the API life cycle.<span>&nbsp; There are definitely many more stops I can service, but the API governance collection is a pretty good start when it comes demonstrating how Postman, collections, and environments can be used to test more than just the surface area of the API&mdash;you can also govern the entire API life cycle.</span></p>
<h3>A Dance Between APIs, Collections, Environments, and Workspaces</h3>
<p>My goal with <a href="https://github.com/union-fashion/home">Union Fashion</a> is to push the boundaries of how Postman is used. Helping folks realize it can be used to do more than just making calls to APIs or testing APIs, and that it can be applied as a complete API life cycle solution. What makes it all possible is a dance that is occuring between the central OpenAPI definition as well as the collections and environments that exist within workspaces for each API. There is a lot more work to be done to polish the rough edges and make it easier for new users to on-board with these concepts but it is a damn good start. It is the most polished version of what I see in my head when it comes to the API life cycle and governance, but have only been just talking about. I am hoping eventually this will become a dance choreography that others can follow when it comes to crafting their own approach to doing APIs. Going well beyond what I am doing here.</p>
<h3>An Exercise In Self-Service API-First Training and Storytelling</h3>
<p>I feel like Union Fashion is allowing me to anchor my vision of how to realize the API life cycle and governance, making it more tangible. However, one of my biggest challenges here is doing all of this out in the open, and keep everything I am doing accessible to the widest possible audience. My goal is to make Union Fashion be a self-service reference implementation that anyone can reverse engineer and apply in their world. I am not saying that my approach to the life cycle and governance will work for every organization, but I am hoping it will provide a new way of thinking about your API life cycle and governance through a series of self-service material, and storytelling via blog posts, webinars, videos, and other formats, with the following currently in play.</p>
<ul>
<li><strong><a href="https://www.youtube.com/watch?v=E2_r1jrZ2Ec">Overview</a></strong> - A quick video walk through of the Union Fashion project.</li>
<li><strong><a href="https://www.youtube.com/watch?v=5fLepBVFDiU">Life Cycle</a></strong> - A quick video walk through of the Union Fashion API life cycle.</li>
<li><strong><a href="https://www.youtube.com/watch?v=eFYgmMbOLnc">Governance</a></strong> - A quick video walk through of the Union Fashion API life cycle.</li>
</ul>
<p>I will be re-recording this screen capture videos as I move each area forward. I am also hopeful I will get better at recording them in the future, as I am pretty stiff at the moment. I am looking to develop more of a flow between the actual work I am doing on Union Fashion APIs, while also telling the story of how I did it. Evolving the Union Fashion APIs, how I deliver APIs, as well as how I tell stories and help others learn about Union Fashion and doing APIs in a consistent way using Postman, GitHub, and a variety of other services.</p>
<h3>Why Does This Even Matter in the First Place?</h3>
<p>It is always important for me to step back and look at my work through the lens of the average person who may not be aware of why APIs matter in the first place. There is a lot here to consider when it comes to shaping the future of your own API operations, and it always helps to step back and sell folks on why APIs matter in the first place, and why doing APIs in a consistent way also counts. Union Fashion is doing APIs in order to realize the following outcomes that will help the (fictitious) company better meet its business objectives as a fashion provider in the e-commerce space.<span>&nbsp;</span></p>
<ul class="ul2">
<li>Allow for more easier publishing of data, content, and algorithms to known web and mobile applications.</li>
<li>Ensure that data content, and algorithms are immediately available for publishing to unknown applications.</li>
<li>More easily integrate all data, content, and algorithms into external 3rd party and partner systems.</li>
<li>Reduce overall overhead and costs involved with delivering new web, mobile, device, and network applications.</li>
<li>Increase the overall quality and velocity of new features and functionality being delivered across applications.</li>
</ul>
<p>There are many more benefits of doing APIs, and going API first, but these reflect the areas can will make a significant change in how businesses, organizations, institutions, and government agencies do what they do. Helping them more effectively utilize Internet connected applications, and iterate upon the technology that they have in place. Helping be more consistent and efficient in how API infrastructure, and the applications that rely on it, ensuring that technology meets the needs of the organizations putting them to work.</p>
<h3>An API-First E-Commerce Reference Implementation</h3>
<p>I am looking to come out of this work with a real world API implementation that I can reference across my storytelling. I am looking to establish an open source set of blueprints that anyone can pick up, learn from, reverse engineer and apply the parts and pieces that are relevant to them in their world. I don&rsquo;t expect Union Fashion to be perfect, but I do expect that it should be thoughtful, observable, and teachable. Helping show how to do APIs right and wrong, and learn from our mistakes out in the open. Working real hard to make sure Union Fashion is accessible to the API curious all the way to the API expert, and helps provide a solid set of blueprints that others can follow.</p>
<p><a href="https://github.com/union-fashion/home">Union Fashion is just getting started and is being planned out in the open on GitHub</a>. If you see a mistake, something incomplete, or a feature you&rsquo;d like to see covered, <a href="https://github.com/union-fashion/home/issues">feel free to submit a GitHub issue for the overall project</a>, or for a specific API. It is all published to GitHub, and I am using GitHub issues as the task list and road map for the project. With every step forward I will be stepping back to better understand how I can document, and tell stories about what is happening on the blog (once I have one), and via video walk-throughs and webinars which will all be published to YouTube. I am hoping to make it a familiar reference implementation that the community can learn from and contribute to, helping push forward and stabilize how we talk about and deliver APIs across our organizations.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/04/06/establishing-an-apifirst-reference-implementation/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/04/03/crowdsourcing-covid19-testing-location-data/">Crowdsourcing Covid19 Testing Location Data</a></h3>
        <span class="post-date">03 Apr 2020</span>
        ---
published: true
layout: post
title: 'Crowdsourcing COVID-19 Testing Location Data'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/postman_data_api_blueprint_multiple_google_sheets.jpg
---
<img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/postman_data_api_blueprint_multiple_google_sheets.jpg" width="40%" align="right" style="padding: 15px;" /><p>I have been heads down working on <a href="https://covid-19-apis.postman.com/">resources for Postman's COVID-19 response</a>, pulling together a variety of <a href="http://apievangelist.com/2020/03/26/covid19-data-and-information/">COVID-19 data and information</a> that developers (and non-developers) can put to use when trying to make sense of what is going on around us. Identifying existing API resources that were available, while shining a light on the hard work of others was the first wave of our response, but along the way we identified some areas where there were no existing APIs, and felt there was an opportunity to step in. So I got to work on developing a couple of proof of concepts (POCs) that we could rally around as a company, and further contribute to the COVID-19 / Coronavirus fight. One of the POCs that came out of this work was an idea for crowdsourcing COVID-19 testing location data, resulting in a pretty interesting blueprint for making data available as APIs, which could be used for a variety of open data efforts—not just COVID-API testing locations.</p>
<h3>Framing the COVID-19 Testing Location Problem</h3>
<p>Before I dive into what I built, let me talk a little about how I landed on this being a problem in the first place, which is an important first step in any technological response to a real world problem. I was listening to the regular highlighting of drive-through COVID-19 testing locations during the press conferences coming out of this administration, and I was seeing or hearing it on the news I am digesting each day. Recognizing that the availability of COVID-19 testing locations was a politically charged topic, I wanted to better understand where we could or should go if we had Corona symptoms. I don’t have a doctor, event though I have health insurance, so I really have no idea where to go if I came down with it. I have anxiety about where I would go in my community if I came down with symptoms, and I can imagine that other people are feeling the same, but more importantly I don’t feel like the official federal response about drive-thru COVID-19 esting locations was adequate, honest, or satisfactory in any way.</p>
<h3>Finding he COVID-19 Testing Location Data</h3>
<p>With a real world problem of finding COVID-19 testing locations identified I moved on to defining where the data might actually be. I couldn’t find any specific announcement out of the federal government agencies leading the COVID-19 fight, so I set out to find other possible locations where I could find authoritative information about where testing locations were—tuning into the following channels:</p>
<ul>
<li><strong>Web Search via Google & Bing - </strong>Manually using Google, and pulling from the Bing API using a Postman collection I am able to find quite a few links to news stories about COVID-19 testing locations.</li>
<li><strong><a href="https://documenter.postman.com/view/8854915/SzYT5MzW?version=latest">State Health Departments via Twitter</a> </strong>- I have crowdsourced all of the state health departments and I am pulling their tweets and looking for mentions of COVID-19 testing locations.</li>
<li><strong><a href="https://documenter.postman.com/view/8854915/SzYXVdyQ?version=latest">County Health Departments via Twitter</a> -</strong> I have crowdsourced all of the county health departments and I am pulling their tweets and looking for mentions of COVID-19 testing locations.</li>
<li><strong>Television Stations via Twitter -</strong> I am crowdsourcing television states for different states and I am pulling their tweets and looking for mentions of COVID-19 testing locations.</li>
</ul>
<p>There was no shortage of chatter about COVID-19 testing locations, but there wasn’t any actually data being made available. In order to establish a structured data set for COVID-19 testing locations, humans would have to get involved. To find, filter, and extract a standard set of data from each of the news pages, blog posts, and other page it would need a human touch to do it right, and there is no better interface for sucking data out of humans than a spreadsheet, and in this situation Google Sheets. I set out to engineer a Google Sheet driven approach to efficiently crowdsourcing COVID-19 testing locations across all 50 US states, and maybe eventually a global dataset.<span> </span></p>
<h3>Managing COVID-19 Testing Location Data Using Google Sheets</h3>
<p>To mange the crowdsourcing of COVID-19 testing location data I looked to Google Sheets, which is the quickest free way to stand up a data store that most individual will know how to work with. To lay the foundation for managing the COVID-19 testing location data I opted to setup 50 separate sheets, which was pretty easy to do using a simple script that uses the Google Drive and Sheets API. I opted for 50 separate sheets to help isolate users working on different states into different buckets, sharding out the potentially large amount of data, management, and user access using Google accounts. Something that allows me to quickly use the Google sharing and publishing features to manage a<span> </span>group of evolving individuals who are helping crowdsource the COVID-19 testing location data across all 50 states, and maybe wider.</p>
<p><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/google_sheets_covid_testing_locations.png" alt="" width="98%" align="center" /></p>
<h3>Managing COVID-19 Testing Location Data Syndication Using Postman</h3>
<p>After creating 50 separate Google Sheets and populating them with some data I wanted to get to work making the data available via an API, so that the data could be used in other applications. You can access the data via the Google Sheets API, but the data isn’t available in the most intuitive format, and I wanted to be able to use Postman to not just pull the data, but also refactor the data to make it available in a more thoughtful way. I opted to structure the Google Sheets and the resulting API using the <a href="http://docs.openreferral.org/en/latest/">Open Referral specification</a>, which is an open source open data and API format for making health and human services data available to the public. Postman would help me pull from the Google Sheets then transform the data for publishing as valid Open Referral API endpoints, with a standardized underlying schema driven by Google Sheets. The resulting Postman collection for managing COVID-19 testing locations has the following outline:</p>
<ol>
<li><strong>Configuration</strong> -<span> Defining the base settings the collection needs to run.</span></li>
<li><strong>Google Sheets </strong>-<span> Pulling of the data from the Google Sheet(s).</span></li>
<li><strong>Publish to GitHub </strong>-<span> Publishing the data to GitHub as JSON and CSV files.</span></li>
<li><strong>Build Collection -</strong><span> Generate a separate collection for making calls to the API.</span></li>
<li><strong>Call APIs -</strong><span> Default endpoints for call the endpoints of each state being managed.</span></li>
</ol>
<p><a href="https://covid-19-apis.postman.com/covid-19-testing-locations/">You can view the documentation for my COVID-19 testing location data management collection</a>, and use the Run in Postman button to import into your own Postman client. The code isn’t the most beautiful or well documented, but it gets the job done and accomplishes what I am looking to do. The Postman collection comes with a starter environment which I have duplicated to create 50 separate environments for each state, providing me with my local data store for pulling COVID-19 testing location data and refactoring for then making available through API syndication. I have already improved upon this model for another crowdsourcing model I am building, but the collection provides an interesting look at how to work with data in Google sheets, but also how to leverage Postman to pull, aggregate, and transform data, but also auto-generate Postman collections for pulling the data.</p>
<p><a href="https://documenter.postman.com/view/8854915/SzS7P5VZ?version=latest"><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/covid_19_testing_locations_management.png" alt="" width="98%" align="center" /></a></p>
<h3>Publishing COVID-19 Testing Location to GitHub for Wider Access</h3>
<p>While Postman can work a lot of magic, it doesn’t have a scalable way to publish an API. Earlier on I had includedf a request where I would automatically publish a mock API using the collection, but I quickly realized I would need a better way of quickly publishing JSON and CSV data that would be receiving a significant amount of traffic. For me, the quickest, cheapest, and APIi-driven way to publish JSON and CSV data for high volume access by other applications is GitHub. So I added a set of requests to the collection for publishing individual JSON and CSV files for the COVID-19 testing location data to GitHub, as well as a single complete JSON endpoint that rolls it all up into a single JSON file for each state. It is important to keep the data as flat as possible so that consumers can work with in spreadsheets, this is why I publish as CSV. But then it is also important to publish as JSON, which allows for more complex data structures, going beyond what spreadsheets can handle.<span> </span></p>
<p><a href="https://github.com/covid-19-testing/locations"><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/covid_19_github.png" alt="" width="98%" align="center" /></a></p>
<p>GItHub is designed for quickly making public data available in a machine readable format. I use the GitHub API to publish the data to GitHub, and consumers can make calls to the variety of JSON and CSV files publicly via GitHub using the URL. I also added a request to the COVID-19 testing location collection above for automatically generating another collection for accessing and consuming the 50 individual JSON files published to GitHub. Making for <a href="https://documenter.postman.com/view/8854915/SzS7PR3t?version=latest">a single set of documentation and Run in Postman button for viewing, processing, and syndicating of COVID-19 testing location data</a> across other systems and applications. Adding another dimension for how Postman can be used, publishing two separate collections, 1) for managing the COVID-19 testing location data, and 2) for accessing the resulting data aggregated from Google Sheets, converted to a more usable <a href="http://docs.openreferral.org/en/latest/">Open Referral specification</a>, and then publishing to Github so that the APIs can handle a large volume of calls, while being updated on a regular basis.</p>
<h3>Aggregating, Refactoring, and Publishing Using Postman Monitors</h3>
<p>With a Postman collection for managing the crowdsourced COVID-19 testing location data, and separate Postman environments for each of the 50 US states, I am able to schedule the pulling, refactoring, and publishing of testing location data across all 50 states using Postman monitors. To automate this process I schedule separate Postman monitors for each of the 50 states, applying the collection above to a specific states environment, resulting in the same process being executed for all 50 US states. Leveraging the Postman platform as the engine for making COVID-19 testing location data more accessible using a low-cost crowdsourced way to solve this problem.</p>
<p><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/postman_monitoring_covid_test.png" alt="" width="98%" align="center" /></p>
<h3>Browsing COVID-19 Testing Locations and Accessing via API</h3>
<p>You can <a href="https://covid-19-apis.postman.com/covid-19-testing-locations/">browse the COVID-19 testing locations using the microsite setup by Postman</a>, and you can access <a href="https://documenter.postman.com/view/8854915/SzS7PR3t?version=latest">the COVID-19 testing location API using the documentation and Run in Postman button</a>. If you want to help work on adding COVID-19 testing locations for any of the states—there is an email to hit, and we’ll plug you in. If you want to build something on top of the API, you can grab any of the URLs from the Postman collection for accessing the COVID-19 testing location API published as part of this work.</p>
<p><a href="https://covid-19-apis.postman.com/covid-19-testing-locations/"><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/postman_covid_19_testing_locations.png" alt="" width="98%" align="center" /></a></p>
<p>If you want to learn more about the overall model I am using for crowdsourcing this data, feel free to ping us as well. I am still honing the overall approach. As I said earlier, I have an improved version of this data management collection driving a separate project, which I will talk about in a future post. Postman is also looking for other interesting projects involving public data, APIs, and the COVID-19 fight. I’ll end this post with an overview diagram of this process, which I hope can provide an open blueprint that could easily be replicated to serve other project that also use multiple Google Sheets as the data store.</p>
<p><a href="https://covid-19-apis.postman.com/covid-19-testing-locations/how-it-works/"><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/postman_data_api_blueprint_multiple_google_sheets.jpg" alt="" width="98%" align="center" /></a></p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/04/03/crowdsourcing-covid19-testing-location-data/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/03/26/covid19-data-and-information/">Covid19 Data And Information</a></h3>
        <span class="post-date">26 Mar 2020</span>
        ---
published: true
layout: post
title: 'COVID-19 Data and Information'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/postman_covid_response_1.png
---
<p><a href="https://covid-19-apis.postman.com/"><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/postman_covid_response_1.png" alt="" width="40%" align="right" /></a></p>
<p class="p1">When it comes to coping with the stressful world unfolding around us I like to lose myself in my work. Data and APIs is a great way to tune out the world and keep myself busy while in isolation. Like most other technosolutionists I want to do some good in this crazy time, even if I don&rsquo;t quite fully know what that means. So, to help me define what that means I sat down and began scratching at what was already occuring across the landscape. Identifying what sources of data were available out there, and what types of information was available which would truly make a difference in everyones world--not make it worse.</p>
<p class="p3"><strong>Informational API Collections</strong></p>
<p class="p3">To begin I wanted to better understand where the top sources of information were, so I began documenting who the most relevant government agencies were in the COVID-19 conversation, going directly to the source of information at the highest levels.</p>
<ul class="ul1">
<li class="li3"><strong>Center for Disease Control (CDC)</strong>&nbsp;(<a href="https://www.cdc.gov/">Website</a>) (<a href="https://documenter.postman.com/view/8854915/SzS7NkAL?version=latest">Collection</a>) - A simple collection for pulling information from the CDC.</li>
<li class="li3"><strong>European Centre for Disease Prevention and Control (ECDC)&nbsp;</strong>(<a href="https://www.ecdc.europa.eu/en">Website</a>) (<a href="https://documenter.postman.com/view/8854915/SzS7NkAQ?version=latest">Collection</a>)&nbsp;- A simple collection for pulling information from the ECDC.</li>
<li class="li3"><strong>World Health Organization (WHO)</strong>&nbsp;(<a href="https://www.who.int/">Website</a>) (<a href="https://documenter.postman.com/view/8854915/SzS7NkAS?version=latest">Collection</a>)&nbsp;- A simple collection for pulling information from the WHO.</li>
</ul>
<p class="p3">This seemed to reflect the authoritative resources available to me, so I got to work defining how each of these agencies shares information, mapping out the top channels I could profile as a Postman collection, aggregating relevant information, and then allowing it to be pulled manually or in some automated way.</p>
<ul class="ul1">
<li class="li3"><strong>Twitter</strong>&nbsp;- Each agency uses Twitter as a way of providing updates.</li>
<li class="li3"><strong>YouTube</strong>&nbsp;- Each agency uses YouTube to publish video resources.</li>
<li class="li3"><strong>RSS / Atom Feeds</strong>&nbsp;- Each of the agency provides RSS feeds of info.</li>
</ul>
<p class="p2">I created a Postman collection for each agency, all someone has to do is enter their Twitter and YouTube API authentication, and they are up and running pulling data from across each of the agencies. My goal is to help expedite the pulling, aggregation and publishing of information from these sources, while demonstrating how this type of information gathering across many APIs can be done using Postman. For now, I have only done CDC, ECDC, and WHO, but the model can easily be applied to any source of information, and I have a number of other government agenices I am working on currently.</p>
<p class="p3"><strong>Tapping Twitter API Collections</strong></p>
<p class="p3">Once I saw that the Twitter API would be a valuable source of information, I wanted to work on some other collections that would help the pulling, aggregation, and publishing. So I got to work on a handful of collections that developers, and even non-developers could put to work to pull information, and help make sense of what is going on using the Twitter API.&nbsp;</p>
<ul class="ul1">
<li class="li3"><strong>COVID-19 Twitter Searches </strong>(<a href="https://documenter.postman.com/view/8854915/SzS7NkEt?version=latest">Collection</a>) - Some of the most common searches for uncovering COVID-19 related conversations.</li>
<li class="li3"><strong>State Government Twitter Accounts&nbsp;</strong>&nbsp;(<a href="https://documenter.postman.com/view/8854915/SzYT5MzV?version=latest">Collection</a>) - Official government Twitter accounts for each state in the US.</li>
<li class="li3"><strong>Statte Governor Twitter Accounts&nbsp;</strong>(<a href="https://documenter.postman.com/view/8854915/SzYT5MzU?version=latest">Collection</a>) -The Twitter accounts for all the governors of the 50 US states.</li>
<li class="li3"><strong>State Health Department Twitter Accounts</strong> (<a href="https://documenter.postman.com/view/8854915/SzYT5MzW?version=latest">Collection</a>) - The Twitter accounts for all of the state health departments.</li>
</ul>
<p>After working on this more general, state centered Postman collections I began seeing the need to focus more on the local levels and understanding what is going on down on the ground in each county, resulting in two collections for the State of California.</p>
<ul>
<li><strong>California County Health Department Twitter Accounts </strong>(<a href="https://documenter.postman.com/view/8854915/SzYT5Mv5?version=latest">Collection</a>) - A single collection for aggregating Tweets across all of Californias county health departments.</li>
<li><strong>Calfironia Television News Stations (<a href="https://documenter.postman.com/view/8854915/SzYT5h6P?version=latest">Collection</a></strong>) A single collection for aggregating Tweets across all of the Calfiornia television stations.</li>
</ul>
<p class="p3">These API collections are designed to reduce friction when getting up and running with pulling of data across many different Twitter accounts. All you need is to create your own Twitter application, get you some API keys, and you run each of the collections. I am looking. There is a lot of information available across those Twitter collections, making it easier to automate the processing of information being made available about the pandemic. I have things broken into such small collections beause it helps with the separation of concerns, but also helps spread out the API calls to the Twitter API, allow for the running of collections as Postman monitors across a balanced 24 hour schedule.</p>
<p class="p3"><strong>COVID-19 API Collections</strong></p>
<p class="p3">After that I paused for a bit and then zoomed out a bit. I wanted to step back and see what else might be going on around COVID-19 data and API specifically. There was a handful of APIs emerging, coming out of primarily data from Johns Hopkins University, and other known and unknown data sources, producing a variety of approaches to making sense of the spread of COVID-19 and its impact on the ground.&nbsp;</p>
<p><a href="https://covid-19-apis.postman.com/"><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/postman_covid_response_2.png" alt="" width="40%" align="right" /></a></p>
<ul>
<li><strong>The COVID Tracking Project&nbsp;</strong>(<a href="https://documenter.postman.com/view/8854915/SzS8rjHv?version=latest">Collection</a>) - The COVID Tracking Project collects information from 50 US states, the District of Columbia, and 5 other US territories to provide the most comprehensive testing data we can collect for the novel coronavirus, SARS-CoV-2.</li>
<li><strong>Covid19API&nbsp;</strong>(<a href="https://documenter.postman.com/view/10808728/SzS8rjbc?version=latest">Collection</a>) - A free API for data on the Coronavirus Access data on COVID19 through an easy API for free.</li>
<li><strong>COVID19-Tracker-REST API&nbsp;-</strong> (<a href="https://documenter.postman.com/view/4074074/SzS7Pkup?version=latest">Collection</a>) - Provides global and country level statistics on the Coronavirus.</li>
<li><span><strong>NovelCOVID AP</strong>I</span>&nbsp;(<a href="https://documenter.postman.com/view/8854915/SzS7R6uu?version=latest">Collection</a>) - API for Current cases and more stuff about COVID-19 or the Novel Coronavirus Strain.</li>
<li><span><strong>COVID-19 AP</strong>I</span>&nbsp;(<a href="https://documenter.postman.com/view/8854915/SzS7R74j?version=latest">Collection</a>) - The COVID-19 API provides information related with the case of pneumonia associated with the COVID-19 coronavirus.</li>
<li><strong>Coronavirus Data API</strong>&nbsp;(<a href="https://documenter.postman.com/view/8854915/SzS7R74n?version=latest">Collection</a>) - Provides global stats, country stats, full timeline, and country timeline for the coronavirus.</li>
<li><strong>Health API - COVID-19&nbsp;</strong>(<a href="https://documenter.postman.com/view/8854915/SzS7R74s?version=latest">Collection</a>) - Global Coronavirus statistics by country and state.</li>
<li><strong>Coronavirus Smartable</strong>&nbsp;(<a href="https://documenter.postman.com/view/8854915/SzS7R74q?version=latest">Collection</a>) - The coronavirus stats and news API offers latest and historic COVID-19 stats and news information per country or state.</li>
</ul>
<p class="p2">&nbsp;Each of these APIs provide their own take on the COVID-19 pandemic. I have created a Postman collection for each of these APIs, and encouraged their owners to publish as well. Next, I&rsquo;ll study the provenance of the data behind, and do a little diff on the schema behind each one. To help me better understand what is being offered by each API provider, in an effort to make sense of the benefits each bring to the table.&nbsp;</p>
<p class="p3"><strong>ScrAPI Collections</strong></p>
<p class="p3">Before I found <a href="https://covidtracking.com/">the COVID Tracking Project</a> I was looking to establish my own source of state and county counts for the cases by pulling data from the state health department websites. To help me tackle the work I created a handful of what I am calling Postman ScrAPI collections, that help pull some data from a website, and publish as a mock or real API. Making for a handful of useful collections that can be adapted to target, scrape, process, and publish web data as an API.</p>
<ul class="ul1">
<li class="li3"><strong>CDC Cases &amp; Deaths </strong>(Collection) - Scraping the COVID-19 cases and deaths from CDC home page, converting to JSON, and saving within an environment.</li>
<li class="li3"><strong>CDC Testing</strong>&nbsp;(<a href="https://documenter.postman.com/view/8854915/SzS7R6gm?version=latest">Collection</a>) - Scraping the number of specimens tested for SARS CoV-2 by CDC labs and U.S. public health laboratories from the CDC website.</li>
</ul>
<p class="p3">I find these little ScrAPI collections provide me with reusable requests that I can duplicate and customize to pull almost any single piece of data, lists, or tables from a website. Providing me with very useful set of utilities when it comes to gathering the data I need to publish a variety of APIs, acknowledging that not all of the data I need will be available via a straightforward data source.</p>
<p class="p3"><strong>Data API Templates</strong></p>
<p class="p3">As I was working on mapping out the world of COVID-19 APIs I began seeing two specific approaches to producing valuable sets of data with accompanying APIs. I saw a significant amount of data spread across many domains in need of aggregation. I also saw a need for a light weight, easy to use, crowdsourced approach to aggregating data, refining, managing, and then redistributing it using APIs. So I got to work defining two distinct blueprints for data APIs that might be used to help reduce friction when it comes to more accurate data sharing across the COVID-19 pandemic.</p>
<ul class="ul1">
<li class="li3"><strong>Google Sheets -</strong> Provide a Postman collection that allows any data stored within a Google Sheet to be pulled and published as an API using Postman, GitHub, AWS, or other service.</li>
<li class="li3"><strong>Web Scraping </strong>- Provide a postman collection that harvests data stored on any website, aggregates and publishes it as an API using Postman, GitHub, AWS, or other service.</li>
</ul>
<p class="p3">I am trying to push myself to be more consistent in how I aggregate, define, refine, store, and syndicate data. I am also looking to share share these patterns with others so that they can do the same. I have thse blueprints established, but I do not have them properly narrated, and complete with instructions, so that someone else could pick up and put to work. I will be working on polishing them more as replicable collections that anyone can reverse engineer and apply to a specific data problem they have, hopefully helping folks be more collaborative and efficient at making COVID-19 related (and other) data available to the public.</p>
<p class="p3"><strong>What Is Next?</strong></p>
<p class="p3">I am not 100% sure what is next. I am going to step back a bit and work on my regular work for a while, and let the ideas I&rsquo;ve put forth simmer. Like any data project I have learned a lot along the way. I want to simmer for a bit on what I have learned. I think I have my process really honde for how I am deploying data APIs using Google Sheets, Postman, and GitHub. I&rsquo;m just not convinced that I have the right ideas when it comes to what is needed when it comes to data sharing in support of the COVID-19 fight. I have jotted down some ideas about what I think I should tackle, but at this point I&rsquo;m not 100% sure I have my finger on the pulse of what is needed&mdash;here is a short list.</p>
<p><a href="https://covid-19-apis.postman.com/"><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/postman_covid_response_3.png" alt="" width="40%" align="right" /></a></p>
<ul class="ul1">
<li class="li3"><strong>Federal Agencies Twitter &amp; RSS &amp; Data </strong>- Create the same collections I have for WHO, CDC, and others for the leading federal agencies making an impact.</li>
<li class="li3"><strong>State Health Departments -</strong> Pull together a collection of the websites, Twitter accounts, and RSS feeds for the state health departments for all 50 states.</li>
<li class="li3"><strong>County Health Departments -</strong> Pull together a collection of the websites, Twitter accounts, and RSS feeds for the county health departments for all 50 states.</li>
<li class="li3"><strong>Corporate Statements / Announcements - </strong>Pull together a list of Fortune 500 companies, and where they announcement pages, feeds, and Twitter accounts are.</li>
<li class="li3"><strong>K-12 / Higher Education School Statements / Announcements </strong>- Pull together a list of school distracts and their COVID-19 update pages and feeds.</li>
<li class="li3"><strong>State Laws Being Passed </strong>- Pull lists of all laws being enacted by states in response to the COVID-19 pandemic, providing details on what is being done.</li>
<li class="li3"><strong>Federal Laws Being Passed - </strong>Pull lists of all laws being enacted by the federal government in response to the COVID-19 pandemic, providing details on what is being done.</li>
<li class="li3"><strong>Food Banks - </strong>Pull together lists of available food banks within local areas &mdash; this is most likely just a template that others can easily fork and put to work on their own.</li>
<li class="li3">Restaurant Open for Pickup - Pull together a list of local restaurants available for pickup &mdash; this is most likely just a template that others can easily fork and put to work on their own.</li>
<li class="li3"><strong>Delivery APIs -</strong> Pull together a list of the delivery APIs, or other service economy APIs that can help with services on the ground within communities.</li>
<li class="li3"><strong>Zapier, IFTTT -</strong> Brainstorm and develop lists of recipes and formulas that people can put together to help reduce friction in their lives, providing some useful API-driven solutions.</li>
</ul>
<p class="p3">I am adding to this list almost daily, but being pretty picky about what I actually tackle. It is pretty easy to fall prey to building something that isn&rsquo;t needed, but on the other hand if it keeps me busy and distracted, there still might be value in doing. Beyond the prices, templates, and the different types of data I still have other areas I need to think about before moving to fast on any project. I have concerns around the provenance and trust of data being published, my own included. I have concerns around data always being publicly accessible, so I&rsquo;m thinking about how to easily secure this data and allow for easier management of private spreadsheets, and other data sources. As always there are a lot of questions to be asked before I dive head first into new data project, despite the urgency we are al feeling in any particular moment.</p>
<p class="p3">All of this work is being funded by Postman, as part of <a href="https://covid-19-apis.postman.com/">their&nbsp;COVID-19 API Resource Center</a>. Our CEO Abhinav Asthana (<a href="https://twitter.com/a85?lang=en">@a85</a>), and my boss Nick Tran (<a href="https://twitter.com/tranmanyo?lang=en">@tranmanyo</a>) have given me space to work on all of these collections, and my amazing design, front-end, and marketing teams are working daily to help shape the Postman response to COVID-19. Currently I'm working to crowdsource the Twitter accounts for all the county health depeartments across the US, which I am almost done with. Then I will publish 50 separate collections like the California County Healthy Department collection listed above. Beyond that, I'm not sure what is next. These collections are shaping how we are responding to the COVID-19 pandemic in real-time. Tuning into things via the Twitter API at the ground level is shaping what data we think is relevant to the conversation. Aggregating more information and data on testing locations, equipment and foot shortages, the availability of food banks and other resources seem like they are priorities. We'll just keep tuning in to what we are hearing, and engaging with other technology service providers and non-profits to understand what type of data projects are really needed. Then I will focus my efforts based upon this response. If you have any ideas for projects, or need help on a data API project for your non-profit, <a href="https://covid-19-apis.postman.com/">feel free to reach out</a>.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/03/26/covid19-data-and-information/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/03/12/the-official-cloudflare-api-postman-collection/">The Official Cloudflare Api Postman Collection</a></h3>
        <span class="post-date">12 Mar 2020</span>
        ---
published: true
layout: post
title: 'The Official Cloudflare API Postman Collection'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/clouidflare_logo.png
---
<p><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/clouidflare_logo.png" alt="" width="40%" align="right" /></p>
<p class="p1">I use <a href="https://www.cloudflare.com/">Cloudflare</a> for my DNS. I like the threat protection they offer, the dead simple DNS management, and their robust API. I automate the management of a handful of my domains. Providing maintenance on <a href="http://apievangelist.com/#API-Lifecycle">100 of my API life cycle</a>, couple hundred <a href="http://apievangelist.com/#API-Lifecycle">API landscape sites</a>, and the range of tooling, APIs, and other side projects I have. I&rsquo;ve written several times about how Cloudlare weaves their API into their UI, so I am happy to write about their <a href="https://support.cloudflare.com/hc/en-us/articles/115002323852-Using-Cloudflare-API-with-Postman-Collections">new Postman collection for the complete Cloudflare API</a>.</p>
<p class="p1">The Clouflare API Postman collection provides 447 individual API requests organized into different folders, making the entire surface area of the API much easier to navigation and make sense of what is going on. The Cloudflare API Postman collections gives you quick access to working with Users, Accounts, Organizations, Zones, DNS, Certificates, Workers, Firewalls, Load Balancer, Logs, and other essential infrastructure assets. I use about 1/20th of the valuable API resources Cloudflare provides, but I couldn&rsquo;t operate my infrastructure like I do with out it.<span>&nbsp;</span></p>
<p class="p1">I have added the Cloudflare API Postman collection to internal Postman workspaces, allowing me to automate more of API infrastructure work. I haven&rsquo;t expanded my usage of the Cloudflare API because I haven&rsquo;t had time to kick the tires and learn about what is going on. With the Cloudflare API Postman collection I am able to quickly play around with different APIs and learn more about what is possible. I&rsquo;ve been wanted to play with Cloudlfare workers for sometime, and think more about how I can use them to deliver or consume APIs at the edge, and the Cloudflare API Postman collection makes it easier for me to make the time to learn more about how it all works.</p>
<p class="p1">I&rsquo;d love to see <a href="https://support.cloudflare.com/hc/en-us/articles/115002323852-Using-Cloudflare-API-with-Postman-Collections">the Cloudflare API Postman collection</a> get added to <a href="https://explore.postman.com/">the Postman API Network</a>. If you work at Cloudflare and are in charge of maintaining the Postman collection, all you have to do is click on the three dots no the bottom right corner of your collection in Postman, select Publish Docs, and choose to make available for discovery under the Postman network. It will make the collection more accessible to the 10M users across the Postman network, introducing them to the collection, and the Cloudflare API. It is a pretty powerful API collection, and it is something that should get more attention&mdash;which is why I am writing up this post. ;-)<span>&nbsp;</span></p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/03/12/the-official-cloudflare-api-postman-collection/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/03/12/a-proof-of-concept-api-service-tier/">A Proof Of Concept Api Service Tier</a></h3>
        <span class="post-date">12 Mar 2020</span>
        ---
published: true
layout: post
title: 'A Proof of Concept API Service Tier'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/tyk_poc_access_tier.png
---
<p class="p1">If you<span>&nbsp; </span>have followed me over the years you know that I get very frustrated by the access or lack of access to APIs, as well as the services and tooling that target the sector. As someone who is perpetually kicking the tires of API providers and service providers, not being able to on-board at all, on-board without my credit card, or one of the many other ways companies introduce friction, I find myself regularly pissed off. So anytime someone makes my world easier, and accommodates my need, desire, and obsession with playing with every damn API tool out there I have to say something. Today&rsquo;s example is from <a href="https://tyk.io/price-comparison/">my partner in crime Tyk</a>, with their proof of concept option<span>&nbsp;</span></p>
<p class="p1"><a href="https://tyk.io/price-comparison/"><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/tyk_poc_access_tier.png" alt="" width="95%" align="center" /></a></p>
<p class="p1">Tyk acknowledges that most of us might not be ready for pro status&mdash;we just need to kick the tires a bit. I love this approach. It&rsquo;s an evolution of the freemium model that I think is more honest and acknowledges the need to play around before entering in the credit card. This isn&rsquo;t all about getting something for free or always being ready to pay for a service. This is about me getting access to your service, be able to develop my proof af concept (<a href="http://apievangelist.com/2020/01/08/dead-simple-real-world-api-management/">which I was able to do in &lt; 10 minutes with Tyk</a>), and then justify the cost of going pro with other stakeholders. Nice work Tyk&mdash;definitely what I like to see when playing with any API solution.<span>&nbsp;</span></p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/03/12/a-proof-of-concept-api-service-tier/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/03/10/apifirst-business/">Apifirst Business</a></h3>
        <span class="post-date">10 Mar 2020</span>
        ---
published: true
layout: post
title: 'API-First [Business]'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/long-factory-uncle-sam.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/long-factory-uncle-sam.jpg" alt="" width="40%" align="right" /></p>
<p>I am working my way through defining a more precise definition of what API-first means which I can use across my API storytelling and conversations. <a href="http://apievangelist.com/2020/03/09/what-is-api-first/">I workshopped the widest definition possible of what API-First means to me yesterday</a>, and be the end of the day <a href="http://apievangelist.com/2020/03/09/apifirst-design--code/">I posted another more precise definition of what API-First means to a more technical crowd which I dubbed API-First [Design || Code]</a>. Today, I&rsquo;m once again thinking more about the business side of the conversation, and focusing on what I would like to eventually be a more precise definition of what API-First means to business stakeholders, which I am dubbing as API-First [Business].</p>
<p>As I said in my broader definition of API-First, if these conversations aren&rsquo;t including business stakeholders we are doing it wrong. These people are making many of the decisions around the why and how of the desktop, web, mobile, device, and network applications we are delivering on top of our API infrastructure, so we can&rsquo;t argue that API-First is a developer or technical only concept. We need business stakeholders also thinking API-First, otherwise our projects will never have the resources they need, and are more likely to fall short in meeting real world business objectives. API-First is not a developer concept, it is a concept that business and developer audiences should both be aware of, and then there are separate inner cores to the definition of API-First, one API-First[Design || Code], and the other API-First[Business], <span id="docs-internal-guid-e8ece19a-7fff-a07f-c55b-7fbb55b115e6"><span>which can help bring a more precise definition to the table for each dimension of our operations.</span></span></p>
<h3>Some Common Business Productivity APIs</h3>
<p>To help make this definition a little more real I wanted to actually apply it against a handful of services I am currently working with business stakeholders at Postman. I am working with some very smart technically savvy folks who aren&rsquo;t programmers to understand how I can help them be more effective and efficient in their daily work. Working together, we&rsquo;ve come up with a short list of applications in use which also have APIs (cause we don&rsquo;t adopt services that have APIs, right? right?).<span>&nbsp;</span></p>
<ul>
<li><strong><a href="https://iterable.com/">Iterable</a></strong> - Defining marketing automation.</li>
<li><strong><a href="https://www.eventbrite.com/">Eventbrite</a></strong> - Working across multiple events.</li>
<li><strong><a href="https://www.atlassian.com/software/jira">JIRA</a></strong> - Staying in tune with engineering.</li>
<li><strong><a href="https://wordpress.org/">WordPress</a></strong> - Making a bigger impact with blog.</li>
<li><strong><a href="https://www.zerobounce.net/">Zero Bounce</a></strong> - Being more effective with email.</li>
<li><strong><a href="https://hunter.io/">Hunter</a></strong> - Profiling of our customers and audience.</li>
<li><strong><a href="https://clearbit.com/">Clearbit</a></strong> - Profiling of our customers and audience.</li>
<li><strong><a href="https://www.fullcontact.com/">FullContact</a></strong> - Profiling of our customers and audience.</li>
<li><strong><a href="https://www.google.com/sheets/about/">Google Sheets</a> -</strong> Ubiquious data storage and management.</li>
</ul>
<p>Each of these services have APIs. Each of them are being used in different ways internally at Postman. There are other services in use that also have APIs, but this provides me with a nice sampling of services to think through as part of my API-First [Business] definition. They bring a suite of resources with varying business objectives to help me better understand how I can incentivize business stakeholders to better understand what APIs are, how they can be applied to their work, and of course how Postman can help them do all of this.</p>
<h3>The API-First [Business] Definition Dimensions</h3>
<p>Next, I want to think about the different dimensions how business users can think about not just APIs, but how they work with each of these services. I am not expecting people to always do APIs, but I am expecting people consider the existence of an API, and have a discussion about how it might be used&mdash;first. Here is how I feel like the dimensions of this conversation should be approached, offering up four distinct ways that business users can be thinking about API-First [Business].</p>
<p><strong>Application</strong> - When should a business user be using the web or desktop application for a platform?</p>
<ul class="ul1">
<li class="li1">Need to manage account, billing, and core features.</li>
<li class="li1">Need to accomplish individual tasks without friction.</li>
<li class="li1">Need to consume existing data, content, and visuals.</li>
<li class="li1">When functionality only exists within the user interface.</li>
<li class="li1">When technical or developer resources aren&rsquo;t available.</li>
<li class="li1">The application does everything you need it to.</li>
</ul>
<p><strong>No-Code</strong> - When should a business user be looking for a no-code option like IFTTT or Zapier?</p>
<ul class="ul1">
<li class="li1">When a no-code option from a service provider exists.</li>
<li class="li1">When authorization for an API is available for use by a user.</li>
<li class="li1">When a feature exists in API, but not in the user interface (UI).</li>
<li class="li1">When data needs to be accessed from another service.</li>
<li class="li1">When data needs to be synced from another service.</li>
<li class="li1">When data needs to be backed up from a service.</li>
<li class="li1">When bulk data needs to be updated from a service.</li>
<li class="li1">When orchestration needs be conducted across many services.</li>
<li class="li1">When actions need to happen on a designated schedule.</li>
<li class="li1">When actions need to run in response to an event or change.</li>
</ul>
<p><strong>Low-Code</strong> - When should a business user be looking for a low-code option like Postman?</p>
<ul class="ul1">
<li class="li1">When a low-code option from service provider exists.</li>
<li class="li1">When technical skills are available to implement.</li>
<li class="li1">When a feature exists in API, but not in the user interface (UI).</li>
<li class="li1">When authorization for an API is available for use by a user.</li>
<li class="li1">When data needs to be accessed from another service.</li>
<li class="li1">When data needs to be synced from another service.</li>
<li class="li1">When data needs to be backed up from a service.</li>
<li class="li1">When bulk data needs to be updated from a service.</li>
<li class="li1">When orchestration needs be conducted across many services.</li>
<li class="li1">When actions need to happen on a designated schedule.</li>
<li class="li1">When actions need to run in response to an event or change.</li>
</ul>
<p><strong>API</strong> - When should a business user be looking to use the API for a platform?</p>
<ul class="ul1">
<li class="li1">When an API is available from service being used.</li>
<li class="li1">When programming skills are available to implement.</li>
<li class="li1">When feature exists in API, but may not in the user interface (UI).</li>
<li class="li1">When authorization for an API is available for use by user.</li>
<li class="li1">When data needs to be accessed from another service.</li>
<li class="li1">When data needs to be synced from another service.</li>
<li class="li1">When data needs to be backed up from a service.</li>
<li class="li1">When bulk data needs to be updated from a service.</li>
<li class="li1">When orchestration needs be conducted across many services.</li>
<li class="li1">When actions need to happen on a designated schedule.</li>
<li class="li1">When actions need to run in response to an event or change.</li>
<li class="li1">When the complexity of tasks becomes much more complex.</li>
</ul>
<p>I am sure there are other elements to consider here, but this provides me with a base definition of what API-First [Business] might mean to a business user. Helping folks think about why and when you should be using an application, an API, or other low code or no code opportunities that may exist in the cracks. I wanted to highlight that this isn't just about API vs App, and that the low code / no code movement is building up a pretty strong middle ground for brave tech savvy business users to consider. Crafting a definition of API-First [Business] is fraught with challenges, because as many API developers understand, not all APIs are created equal, and there are plenty of business and political elements at play when it comes to the opportunities that exist between any platforms application and API.</p>
<p><strong>The Business and Politics of APIs</strong></p>
<p>When to use an application or an API is rarely straightforward and consistent. Why a platform has an API, and what features are available in the application or API are usually business and political in nature. Some APIs are more read only, where others allow you to add, update, and delete data. What features are made exclusively available within the application or it's API will vary from platform to platform. All of these characteristics will influence the decisions that a business user will have to make. Developers and business users both will have to navigate these differences between APIs, and have to learn to live with a certain amount of uncertainty, while also working to make informed tactical decisions with confidence when it comes to whether you should use an application, API, or low-code and no-code alternative for your situation.</p>
<h3>Including Business Users in the API-First Conversation</h3>
<p>I am adamant that API-first isn&rsquo;t something that should just roll of the lips of technically inclined folks. If business users aren&rsquo;t equipped to understand why APIs matter, and that they should have a role in their development, then we should just give up on this whole API thing. I am not saying that business users should understand the nuts and bolts of everything that is occurring throughout the API life cycle, but we shouldn&rsquo;t be hiding things from them, and we should be working hard to regularly educate and equip them with the ability to ask.</p>
<ul>
<li>Before any service or software solution is used or purchased, ask if it has an API first.</li>
<li>Before developing a web application, develop an API first.</li>
<li>Before developing a mobile application, develop an API first.</li>
<li>Before developing a device application, develop an API first.</li>
<li>Before you open a ticket with a service provider that the UI can&rsquo;t do something, look for an API first.</li>
<li>Before custom programming a migration between systems, look for an API first.</li>
<li>Before manually attempting a bulk process, look for an API first.</li>
</ul>
<p>If someone at a company, organization, institution, or government agency is going to be in a leadership position involving the development, delivery, operation, sustainment, and support around any desktop, web, mobile, device, or network application, then they should be equipped to ask these questions. They should not be require to understand all the technical details of what is happening, but they should have a seat at the table, be able to ask questions, and be equipped always ask if an effort has considered being API-first.</p>
<h3>Why API-First for Business Folks?</h3>
<p>It is natural for folks to ask why. APIs are not the solution to every problem, and there are pros and cons to doing APIs, so asking why is essential. There are numerous reasons why business folks should be asking about API-first when starting a new project, or looking to evolve upon an existing application. I&rsquo;ll keep iterating upon these reasons, but here are a few of the reasons why business should be learning about API-first and injecting it into conversations with other business and technical groups.</p>
<ul>
<li>APIs allow all stakeholders to communicate about what is needed before applications are actually build.</li>
<li>APIs will reduce redundancy across multiple types of applications&nbsp;and integrations.</li>
<li>APIs will allow for reuse across multiple types of applications&nbsp;and integrations.</li>
<li>APIs will allow for increased efficiency across multiple types of applications and integrations.</li>
<li>APIs will allow for centralization of observability across applications and integrations.</li>
<li>APIs will allow for meeting needs of the known knowns, known unknowns, and help address unknown unknowns.</li>
<li>APIs the same reasons as for technical folks, but a few more things to consider.</li>
<li>APIs in some cases will allow you to bypass the need for more technical stakeholders.</li>
<li>User interfaces are meant for narrow audiences and APIs cater to as wide as possible audience.</li>
<li>The more eyeballs on the pipes behind the applications we depend on the better.</li>
<li>Help demystify API technology, and force technical stakeholders to simply and make more accessible.</li>
</ul>
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/two-sattelite-dishes-uncle-sam.jpg" alt="" width="45%" align="right" /></p>
<p>As you can see, this really isn&rsquo;t about API. It is about people, communication, and planning. APIs are just a convenient vehicle for introducing healthier approaches to these areas, and better define the human-machine relationship that exists throughout our personal and professional lives. APIs aren&rsquo;t purely technical. They also have the human meaning and behavioral outcomes coded into their endpoints. APIs are both human and machine readable when they are designed well. This reflects the API-first mandate. APIs aren&rsquo;t new. Really, the most recent innovation in the development and delivery of APIs that has made a significant impact in how business gets done using APIs, is that they have become simpler, and more accessible to non-developers. Invoking more conversations around the business value of doing APIs, which honestly is the primary driver of why we are not just doing APIs, but also the desktop, web, mobile, device, and network applications that use them.</p>
<h3>API-First Needs To Be More Inclusive</h3>
<p>API-first is important. Not because of some un-defined, superficial way of thinking about technology. API-first is important because it causes us to pause for a moment and think about the bigger picture. Who should be involved. What types of applications are going to need access to this data, content, and algorithms in the near or longer term future. API-first forces us technologists to tap the breaks before diving in, which is one of the reasons us developers are resisting API-first so much. We just want to dive in and get coding, without much thought to the long term consequences, or the unintended side effects. Someone else will have to deal with those consequences. API-first won&rsquo;t solve all of the challenges we face in the technology sector, and the business sectors who find themselves delivering more technology, but they can help us be more thoughtful and inclusive in how we deliver technology, while also allowing us to move faster, be more agile, nimble, and flexible when it comes to operating in a digital world.</p>
<p>This post helps me further round off my big tent definition for API-First, but it also allows me to address the more precise API-First [Design || Code], and API-First [Business] dimensions of the conversation. I don&rsquo;t think I&rsquo;ve answered everything about what API-First means, but I do feel like I&rsquo;ve put myself on firmer ground when it comes to implementing API-First in a more meaningful way across projects, and speak more precisely in my online and offline storytelling. I&rsquo;d say that my definitions are still pretty verbose and need a lot more refinement to make it more accessible by developer and business users. Ultimately I am looking to establish a one pager that anyone can look at and use to help them make more informed decisions about engaging in an API-First conversation within their organization. Helping set the ground rules for what people are talking about when they say API-First, helping bring more alignment to teams when it comes to moving the conversation forward.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/03/10/apifirst-business/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/03/09/what-is-api-first/">What Is Api First</a></h3>
        <span class="post-date">09 Mar 2020</span>
        ---
published: true
layout: post
title: 'What Is API First?'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/braceros-domingo-ulloa-docks-water-front-ships-containers.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/braceros-domingo-ulloa-docks-water-front-ships-containers.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">I really struggled with this piece on API-first. It is one of those holistic API advice pieces I am very conflicted about. API-first feels like yet another marketing phrase or latest trend like microservices. So as I am writing down my thoughts over the last couple weeks on this, my bullshit-o-meter kept going off. Honestly it still is, but I still feel like there is enough value here that I can move forward with a story. As my co-worker Joyce rightfully pointed out in a meeting recently, API-first is one of those phrases we regularly throw out there without much assessment, agreement, or real definition of what it means. That is one reason it feels so wrong at times, because I feel like it is one of those feel good things we throw out there, but never really think too deeply about while doing, or after it fails and we&rsquo;ve moved on to the next thing.</p>
<p class="p1">With all of that said, I still believe that API-first can matter, if we, as Joyce points out, actually define what we mean by it. I think there is a lot of misconception about what we mean by API-firsat, and I&rsquo;d like to stimulate conversation around what it means, if not just get more precise around how I talk about it. One concern I have about the API-first discussion is that once again it is something that only concerns developers when delivering APIs, and that it is something that business folks shouldn&rsquo;t worry their pretty little heads about. This is a classic historical technique for dividing and conquering the technology-human paradigm that is spreading across society, and is something I am not interested in perpetuating. So I have broken down API-first discussion into two main parts, one through the technical lens, and another through how business folks will need to be made aware of as they continue to employ technology as part of their everyday work.</p>
<p class="p1"><strong>Looking Through the Technical Lens of an Organization</strong></p>
<p class="p1">What does API-first mean to technically mind folks, including architects, developers, and other roles? When leadership, all the way down to the individual developer on teams, begin any new project, why should API-first be the first thing on the table. Not that everything is an API, or gets solved by an API, but we should be thinking about the following.</p>
<ul class="ul1">
<li class="li1">Before developing a web application, develop an API first.</li>
<li class="li1">Before developing a mobile application, develop an API first.</li>
<li class="li1">Before developing a device application, develop an API first.</li>
<li class="li1">Before attempting any system integration, develop an API first.</li>
<li class="li1">Before directly connecting to a databases, develop an API first.</li>
</ul>
<p class="p1">I am not saying that APIs are always the solution. I am just saying they are too often presented as a solution to everyone involved very late in the game. Before you consider doing anything with the web, or any of the other applications the web enables, you should be bringing up API-first. It is less about the API, and more about widening the conversation around how we use technology, and being more thoughtful, organized, and strategic about how we deliver technology. It really isn&rsquo;t just about APIs.</p>
<p class="p1"><strong>Why API-First for Technical Folks?</strong></p>
<p class="p1">Naturally folks are going to ask me why? Why should we be brining up API-first before we get to work developing any single application. It isn&rsquo;t that APIs are always the right or superior choice, it is that the API-first discussion brings up many things that need consideration, and help us break down who should have a seat at the table. Providing me with a handful of definitions I&rsquo;m going to go to when it comes to answer why API-first as part of discussions with technical folks.</p>
<ul class="ul1">
<li class="li1">Allow potential stakeholders to communicate about what is needed before applications are actually build.</li>
<li class="li1">API will reduce redundancy across multiple types of applications&nbsp;and integrations.</li>
<li class="li1">API will allow for reuse across multiple types of applications&nbsp;and integrations.</li>
<li class="li1">API will allow for increased efficiency across multiple types of applications and integrations.</li>
<li class="li1">API will allow for centralization of observability across applications and integrations.</li>
<li class="li1">API will allow for meeting needs of the known knowns, known unknowns, and help address unknown unknowns.</li>
</ul>
<p class="p1">Again, it isn&rsquo;t really about APIs. API-first is more of a vehicle for making sure we zoom out and consider the bigger picture. Which is one of the main reasons why it is so important that this isn&rsquo;t just a technical discussion held amongst the usual set of wizards that have guided application and infrastructure development of the past. For API to really work this can&rsquo;t just be about architects and developers, it has to be inclusive to the business people who are usually pulling the strings and making the business decisions that decide whether or not an application lives or dies in the first place.</p>
<p class="p1"><strong>Looking Through the Business Lens of an Organization</strong></p>
<p class="p1">I am adamant that API-first isn&rsquo;t something that should just roll of the lips of technically inclined folks. If business users aren&rsquo;t equipped to understand why APIs matter, and that they should have a role in their development, then we should just give up on this whole API thing. I am not saying that business users should understand the nuts and bolts of everything that is occurring throughout the API life cycle, but we shouldn&rsquo;t be hiding things from them, and we should be working hard to regularly educate and equipping them with the ability to ask&hellip;</p>
<ul class="ul1">
<li class="li1">Before any service or software solution is used or purchased, ask if it has an API first.</li>
<li class="li1">Before developing a web application, develop an API first.</li>
<li class="li1">Before developing a mobile application, develop an API first.</li>
<li class="li1">Before developing a device application, develop an API first.</li>
<li class="li1">Before you open ticket with service provider that the UI can&rsquo;t do something, look for an API first.</li>
<li class="li1">Before custom programming a migration between systems, look for an API first.</li>
<li class="li1">Before manually attempting a bulk process, look for an API first.</li>
</ul>
<p class="p1">If someone at a company, organization, institution, or government agency is going to be in a leadership position involving the development, delivery, operation, sustainment, and support around any desktop, web, mobile, device, or network application, then they should be equipped to ask these questions. They should not be require to understand all the technical details of what is happening, but they should have a seat at the table, be able to ask questions, and be equipped always ask if an effort has considered being API-first.</p>
<p class="p1"><strong>Why API-First for Business Folks?</strong></p>
<p class="p1">As with discussion amongst a more technical crowd, it is natural for folks to ask why. APIs are not the solution to every problem, and there are pros and cons to doing APIs, so asking why is essential. There are numerous reasons why business folks should be asking about API-first when starting a new project, or looking to evolve upon an existing application. I&rsquo;ll keep iterating upon these reasons, but here are a few of the reasons why business should be learning about API-first and injecting it into conversations with other business and technical groups.</p>
<ul class="ul1">
<li class="li1">All the same reasons as for technical folks, but a few more to things to consider.</li>
<li class="li1">APIs in some cases will allow you to bypass the need for more technical stakeholders.</li>
<li class="li1">There are low code / no code options for business users to put APIs to work.</li>
<li class="li1">User interfaces are meant for narrow audience and APIs cater to as wide as possible audience.</li>
<li class="li1">The more eyeballs on the pipes behind the applications we depend on the better.</li>
<li class="li1">Help demystify API technology, and force technical stakeholders to simply and make more accessible.</li>
</ul>
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/braceros-domingo-ulloa-docks-big-cosco-ship.jpg" alt="" width="45%" align="right" /></p>
<p class="p1">As you can see, this really isn&rsquo;t about API. It is about people, communication, and planning. APIs are just a convenient vehicle for introducing healthier approaches to these areas, and better define the human-machine relationship that exists throughout our personal and professional lives. APIs aren&rsquo;t purely technical. They also have the human meaning and behavioral outcomes coded into their endpoints. APIs are both human and machine readable when they are designed well. This reflects the API-first mandate. APIs aren&rsquo;t new. Really, the most recent innovation in the development and delivery of APIs that has made a significant impact in how business gets done using APIs, is that they have become simpler, and more accessible to non-developers. Invoking more conversations around the business value of doing APIs, which honestly is the primary driver of why we are not just doing APIs, but also the desktop, web, mobile, device, and network applications that use them.</p>
<p class="p1">API-first is important. Not because of some un-defined, superficial way at thinking about technology. API-first is important because it causes us to pause for a moment and think about the bigger picture. Who should be involved. What types of applications are going to need access to this data, content, and algorithms in the near or longer term future. API-first forces us technologists to tap the breaks before diving in, which is one of the reasons us developers are resisting API-first so much. We just want to dive in and get coding, without much thought to the long term consequences, or the unintended side effects. Someone else will have to deal with those consequences. API-first won&rsquo;t solve all of the challenges we face in the technology sector, and the business sectors who find themselves delivering more technology, but they can help us be more thoughtful and inclusive in how we deliver technology, while also allowing us to move faster, be more agile, nimble, and flexible when it comes to operating in a digital world.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/03/09/what-is-api-first/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/03/09/apifirst-design-code/">Apifirst Design  Code</a></h3>
        <span class="post-date">09 Mar 2020</span>
        ---
published: true
layout: post
title: 'API-First [Design || Code]'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/la_muse-alan-turing-side.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/la_muse-alan-turing-side.jpg" alt="" width="40%" align="right" /></p>
<p class="p1"><a href="http://apievangelist.com/2020/03/09/what-is-api-first/">I worked through my thoughts on what API first is</a>, which I consider to be the outer layers of what is going on when we use this phrase. I wanted to focus on the technical and business rift that exists in this discussion first, now I want to dive into the more technical core of this phrase, and get to the heart of how developers are going to see this phrase. Depending on the type of developer you are, and your exposure to different aspects of the API industry or API operations within your organization you are going to make different assumptions about what API first is or isn&rsquo;t. Some will feel it is more just about doing APIs before you build applications, while others are going to see it as being more about going API design first, before you ever write any code. Ultimately I want to establish a definition of API first that is inclusive, and not pushing people out, while also helping me ground how I use the phrase.</p>
<h3>Let&rsquo;s Recap, What Is API-First?</h3>
<p class="p1">From the previous post, let&rsquo;s take a fresh look at what is API-First from the vantage point of a more technically included stakeholder like architect, developer, or other IT actors. Setting the stage for how API-First [Code] can be approached.</p>
<ul class="ul1">
<li class="li1">Before developing a web application, develop an API first</li>
<li class="li1">Before developing a mobile application, develop an API first</li>
<li class="li1">Before developing a device application, develop an API first</li>
<li class="li1">Before attempting any system integration, develop an API first</li>
<li class="li1">Before directly connecting to a databases, develop an API first</li>
</ul>
<h3>Also, Why do API-First?</h3>
<p class="p1">Naturally people will ask why? To help flesh out why API-First matters, before we help separate API-First [Code] from API-First [Design], let&rsquo;s look at the benefits of going API-First, then separate code from design approaches might make a little more sense.</p>
<ul class="ul1">
<li class="li1">Allow potential stakeholders to communicate about what is needed before applications are actually build.</li>
<li class="li1">API will reduce redundancy across multiple types of applications</li>
<li class="li1">API will allow for reuse across multiple types of applications</li>
<li class="li1">API will allow for increased efficiency across multiple types of applications.</li>
<li class="li1">API will allow for centralization of observability across applications</li>
<li class="li1">API will allow for meeting needs of the known knowns, known unknowns, and help with unknown unknowns.</li>
</ul>
<h3>API-First [Code]</h3>
<p class="p1">This is the most common approach to API first that I see, because it is the next step towards being API-First from a historically API-last approach. Going API-First by writing code is a perfectly valid way to develop an API, if it doesn&rsquo;t occur in isolation, and a machine readable artifact is produced from the process. I wanted to consider what an API-First [Code] approach might look like, if approached in a general sense across potentially different platforms and programming languages.<span>&nbsp;</span></p>
<ul class="ul1">
<li class="li1"><strong>Requirements</strong> - Hopefully you aren&rsquo;t just diving straight into writing code and there are some requirements dictating what is going on.</li>
<li class="li1"><strong>Database</strong> - Setting up the database that will exist behind each API, providing a persistent data store for each individual service.</li>
<li class="li1"><strong>Storage</strong> - You will also need persistent or ephemeral object storage for each API, ensuring that you places to put your heavy objects as well.</li>
<li class="li1"><strong>Compute</strong> - Establishing where you will run the code you are using to define and develop an API as part of this process.</li>
<li class="li1"><strong>Scaffolding</strong> - Often times developers are using frameworks, libraries, and other scaffolding for helping deliver common elements of APIs.</li>
<li class="li1"><strong>Code</strong> - Then within the framework provided, developers are often times writing custom code to do the heavy lifting of each API.</li>
<li class="li1"><strong>Pipeline</strong> - Modern API delivery systems are leveraging CI/CD processes to help establish reproducible pipelines for the delivery of APIs.</li>
<li class="li1"><strong>Tests</strong> - Develop tests that ensure the surface area of the API is properly defined, and operates as expected meeting requirements defined.</li>
<li class="li1"><strong>Definition</strong> - Generation of an OpenAPI, RAML, or other API definition that represents the surface area of the API defined through development.</li>
<li class="li1"><strong>Collection</strong>&nbsp;- Producing a Postman collection from the generated API definition, enabling users to make calls to the API using the Postman client.</li>
<li class="li1"><strong>Documentation</strong> - Publishing of up to date and complete documentation for an API using the API definition that was generated from code.</li>
<li class="li1"><strong>Sharing</strong> - Once you have the API definition, documentation, and collection you can share the link with other stakeholders to get feedback.</li>
<li class="li1"><strong>Feedback</strong> - Stakeholders can leave feedback by forking definitions or collections, commenting within Postman, or using GitHub / GitLab issues.</li>
</ul>
<p class="p1">There are benefits to being code-first in an API-First world. Once you are done iterating upon the API, there is no development needed to move towards actual deployment. I would say there is additional overhead with setting up the development environment and pipeline in an API-First [Code] approach, but I think you also can offset that because it is a process more developers are going to be familiar with over having to learn a new API-First [Design] process. This is why&nbsp;API-First [Code] still has such a strong foothold, because it is what is familiar and working currently.</p>
<h3>API-First [Design]</h3>
<p class="p1">This is the API-First approach that progressive API believers and developers picture in their minds eye. Where you can define, design, and iterate upon the design of an API and its underlying schema without ever writing code. Simplifying how APIs are designed, leveraging mock servers, and modern tooling and services to bring an API to life in a collaborative way, without writing any code. This is what many organizations are talking about, but few are actually able to achieve due to a variety of concerns from developers.</p>
<ul class="ul1">
<li class="li1"><strong>Assumptions</strong> - Outlining the assumptions being made about what each API should do, providing a simple list of what all stakeholders expect.</li>
<li class="li1"><strong>Definitions</strong> -<span>&nbsp; </span>Designing of an OpenAPI or RAML definition describing all details of the surface area of an API, ensuring it meets the assumptions of stakeholders.</li>
<li class="li1"><strong>Collections</strong> - Generating a Postman collection from the API definition, providing an executable runtime to drive mocks, tests, and docs, as well as manual use in Postman as a client.</li>
<li class="li1"><strong>Mocks</strong> - Generating mock servers from the Postman collection, mocking all the API paths using example responses defined as part each API definition.</li>
<li class="li1"><strong>Tests</strong> - Develop tests for each of the assumptions put forth as part of the design process, ensuring there is a check for business and technical assumption.</li>
<li class="li1"><strong>Documentation</strong> - Publishing of up to date and complete documentation for an API using the collection that was generated from the OpenAPI or RAML.</li>
<li class="li1"><strong>Sharing</strong> - Once you have the API definition, documentation, and collection you can share the link with other stakeholders to get feedback.</li>
<li class="li1"><strong>Feedback</strong> - Stakeholders can leave feedback by forking definitions or collections, commenting within Postman, or using GitHub / GitLab issues.</li>
</ul>
<p class="p1">API-First [Design] is the preferred approach being peddled across the API sector today. If you believe in the importance of OpenAPI and RAML you feel that you can define a more complete and consistent API than you can with an API-First [Code] approach. If you are coming at API development from a more engineering focused background you are more likely to believe the API-First [Code] is faster and superior. Really it comes down your comfort level and understanding of API definitions, and whether you place value on code over the API definitions, but in the end, regardless of how you feel on the subject, API-First [Code] is still the primary approach to delivering APIs on the ground across enterprise organizations.</p>
<h3>Changing Behavior Is Hard</h3>
<p class="p1">I firmly believe API-First [Design] is a faster and more consistent way to deliver APIs. You can iterate upon them faster, and reduce the length of time for the feedback loop between each version. Code and pipelines aren&rsquo;t necessary at the design stage. An API-First [Design] approach is less intimidating to business users, making the process more inclusive, and not just something that happens in isolation with developers. However, changing<span>&nbsp; </span>behavior is hard and takes time. The efficiency gains on API-First [Design] is mostly likely lost when throwing inexperienced developers into the process, but it is a cost of doing business that will pay off at other stops along the API life cycle like documentation, testing, monitoring, security, and overall governance. API-First [Design] will produce more consistent APIs in the end, but again, changing behavior is hard, costly, and takes time, so teams will have to weigh the overall cost.</p>
<h3>Infrastructure Is Costly</h3>
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/la-muse-blechlety-old-racks.jpg" alt="" width="45%" align="right" /></p>
<p class="p1">It takes time, resources, and know-how to setup the infrastructure needed to deliver an API. If you are looking to just design and iterate upon each API amongst stakeholders you don&rsquo;t really need a database, storage, compute, code, and pipelines to get things done. Sure, you&rsquo;ll need these things before you can move an API from design to production, but you really don&rsquo;t need these things to iterate upon the design of an API. So I wouldn&rsquo;t say they aren&rsquo;t unnecessary, but they are extra costs and potential friction when you are just trying to iterate upon the design of an API. As I stated in the previous paragraph, each organization will have to weigh what is more costly based upon their own infrastructure costs, as well as the cultural and organizational costs of an API-First [Design] shift. Even if API-First [Design] is more efficient I do not think we can expect every organization will make the shift, and I am not in the business of shaming folks for their practices. We need to acknowledge, and equip API-First [Code] teams with what they need to be successful, and work to ensure the API contract produced from all approaches are in alignment.</p>
<h3>API-First [Design || Code]</h3>
<p class="p1">I do not think this is about API-First [Code] vs API-First [Design]. It should be API-First [Design || Code]. Honestly, I&rsquo;m weighing making it API-First [Design || Code || Gateway], because I have seen groups who are defining an API using AWS API Gateway, then exporting an OpenAPI to document, monitor, test, secure, and govern. So I am more concerned with continueing to define what API-First is in a meaningful and pragmatic way that includes as many people as possible in the conversation. This whole series of posts is all about me being able to better articulate what I mean by API-First when discussing APIs with enterprise organizations and within Postman. I am looking to root what I mean with API-First in some solid beliefs and practices that actually match what is going on across the industry. I am not completely convinced that API-First is as well defined as it could / should be, but I feel like I am on a better path when it comes to talking about it in detail.</p>
<p class="p1">API-First isn&rsquo;t as squishy as it was just a couple days ago. I can see the outer layer of meaning with just API-First, and I can see the inner layer with API-First [Design || Code]. It has helped me be more precise in what I say, which will hopefully reduce some confusion in at least the conversations I am having. I don&rsquo;t have much faith that everyone in the API sector will immediately be enlightened, but it will help me produce better stories, tutorials, talks, and webinars that show what is possible with an API-First mindset, even if you are API-First [Code], aspiring to be API-First [Design], or already made the conversion to API-First [Design]. I am on firmer ground, but my API-First storytelling journey is only beginning, and I predict I will be telling some of the same stories over and over the next couple years to help others realize the state of their API delivery process, and further optimize, and move towards a more efficient and effective way of doing things no matter which approach they end up choosing.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/03/09/apifirst-design-code/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/03/06/what-is-my-api-network/">What Is My Api Network</a></h3>
        <span class="post-date">06 Mar 2020</span>
        ---
published: true
layout: post
title: 'What Is My API Network'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/bf-skinner-satellite-with-sunset.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/bf-skinner-satellite-with-sunset.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">I am working on the vision for the Postman Network. As I do with everything, I want to start with the basics human aspects of what is going on, and then relate them to the more technical and then business aspects of it all. Right now, the Postman Network is a listing of teams and individuals who have published Postman collections under a handful of categories. While visiting the network you can browse collections by category or search by keyword, and view the team or individual profile, select the &ldquo;Run in Postman&rdquo; button, or view the documentation. My goal is to brainstorm what is next for the Postman network, but also help define what network means in a world of API collaboration.</p>
<p class="p1">When it comes to my API network, I like to focus on the meaningful elements, the &ldquo;person, place, or thing&rdquo; that makes my world go around. I am not interested in nouns that do not enrich my world, and I am keen on emphasis of the humanity of all of this over purely the tech for the sake of tech. So what are the nouns that make up my world?</p>
<ul class="ul1">
<li class="li1"><strong>People</strong> - While I don&rsquo;t always like people, because I am one, they tend to be the center of my world. People are the most important building block of my network, and drive what I truly care about when it comes to APIs.</li>
<li class="li1"><strong>Teams</strong> - I engage with a variety of teams as part of my job, both internal to Postman, but also externally across the many different enterprise organizations I am working with. While I have relationships with individuals on the team, I find myself regularly thinking about how to add value to the entire team, and influence how and why they are doing APIs.</li>
<li class="li1"><strong>Projects</strong> - My world is littered with projects. Some projects move forward, while others simmer, and sometimes whither on the vine. Projects usually involve one or many APIs, as well as one or many people. While people are the center of my world, my network is usually in service of moving a specific project forward with a specific purpose in mind.</li>
<li class="li1"><strong>Workspaces</strong> - There are a number of places where I get work one. These include, but are not limited to local folders, cloud folders, repositories, and other constructs that help me organize the artifacts that are most important to my network. These are the places where my network meats and gets work done on a regular basis.<span>&nbsp;</span></li>
<li class="li1"><strong>Specifications</strong> - There are a handful of API and data specifications that rule my world, and define my network. OpenAPI, JSON Schema, Postman, are a few of the specifications that define how I communicate, collaborate, and interact with my network in a human as well as machine readable way, helping me automate and govern how I do what Id o on a daily basis.<span>&nbsp;</span></li>
<li class="li1"><strong>Definitions</strong> - From the specifications I use I produce a wealth of definitions that reflect specific projects and APIs I am working on. These definitions are the life blood of my network, helping me articulate some pretty abstract concepts to the people in my network, helping me move forward a variety of projects with different objectives.</li>
<li class="li1"><strong>Organizations</strong> - The people I engage with are always part of a larger organization. While they tend to have their own personalities, an team or project objective, they belong to a larger organization and have the vision and brand of that organization to consider&mdash;something that always influences how I network with them.</li>
<li class="li1"><strong>Domains</strong> - One of the defining areas of my world are domains. Not just areas of knowledge, but actual online domains governed by DNS. These tend to go hand in hand and reflect the different areas of work that are occurring across my network, and provide the bounded context for how I conduct work and publish the result of that work.<span>&nbsp;</span></li>
<li class="li1"><strong>Industries</strong> - Since my network has such a large public face to it, there are many considerations for the industries I am targeting with specific APIs, messages, and storytelling. This is the 100K view of my network, allowing me to see things at the highest level, spanning my individuals, teams, specifications, definitions, and organizations.</li>
</ul>
<p class="p1">I am ending the noun discussion there, although I am going to continue describing many more in the coming section, but I&rsquo;d say these are closer to the meaningful network actions I&rsquo;m looking to highlight than the actual person, place, or thing that are central. These are many of the actions I am thinking about when it comes to what occurs across my network. The things that make it a living, active, and useful network to many people, teams, and organizations.</p>
<ul class="ul1">
<li class="li1"><strong>Create</strong> - How I create teams, projects, workspaces, definitions, and relate those to organizations, domains, industries, and people.</li>
<li class="li1"><strong>Message</strong> - I need to send public and private messages to people on my network about the different areas of operation.</li>
<li class="li1"><strong>Comment</strong> - Beyond basic messaging I need to leave comments in different areas of my network, providing more context to stakeholders.</li>
<li class="li1"><strong>Annotate</strong> - I also need to add specific details to individual objects, or pieces of objects that exist across my network.</li>
<li class="li1"><strong>Questions</strong> - I need to be able to ask questions, as well as answer questions from others on my network.</li>
<li class="li1"><strong>Invites</strong> - I will need to be able to invite people to different teams, projects, workspaces, and other contexts of my network.</li>
<li class="li1"><strong>Roles</strong> - I need to apply roles to different people who participate in activity across my network, governing who is able to do what.</li>
<li class="li1"><strong>Relationship</strong> - Establish the connection between people, teams, and organizations across my network spheres.<span>&nbsp;</span></li>
<li class="li1"><strong>Mentor</strong> - I will need to mentor some individuals on my network when it comes to projects, specifications, definitions, and other concepts.</li>
<li class="li1"><strong>Edits</strong> - Everything on my network will need editing, allowing me to perpetually changing the core element I am moving forward.</li>
<li class="li1"><strong>Publish</strong> - Specifications and definitions need regular publishing to workspaces, domains, and other dimensions of my network.</li>
<li class="li1"><strong>Version</strong> - Artifacts all need to be versioned, allowing them to be evolved, helping manage both major, minor, and fixes to objects.</li>
<li class="li1"><strong>Fork</strong> - Artifacts need to be forked, allowing derivatives to be established and evolved separate from the core definition.</li>
<li class="li1"><strong>Merge</strong> - Any artifacts that have been merged need to also have the ability to be merged back into the master version of each definition.</li>
<li class="li1"><strong>Search</strong> - Any element on my network should be searchable, allowing me to find what is going on across every network element.</li>
<li class="li1"><strong>Sync</strong> - Artifacts and the activity around them should be sinkable to other workspaces, organizations, and areas they are needed.</li>
<li class="li1"><strong>Integrate</strong> - I want to be able to expand my network by integrating different aspects of it to other platforms and systems using APIs.</li>
<li class="li1"><strong>Issues</strong> - I want to be able to report, identify, and work with issues in context of different artifacts and elements of my network.</li>
<li class="li1"><strong>Share</strong> - Everything on my network should be able to be shared with users, with a consideration for what should be public or private.</li>
<li class="li1"><strong>Browse</strong> - I should be able to browse my network, and explore what is happening across teams, workspaces, and other elements.</li>
<li class="li1"><strong>Notify</strong> - I should be able to tune into or tune out of notifications around events that are occurring across my network.</li>
<li class="li1"><strong>Script</strong> - There should be opportunities for scripting to help me automate, orchestrate, and work with different elements of my network.</li>
<li class="li1"><strong>Run</strong> - I should able to run scripts, definitions, and other elements of my network, providing me with a runtime layer to my network.</li>
<li class="li1"><strong>Store</strong> - I should be able to store data as part of my network operations, organizing the exhaust and output from network operations.</li>
<li class="li1"><strong>Monitor</strong> - I should be able to monitor any aspect of what is happening across my network, allowing me to tune into what is going on.</li>
<li class="li1"><strong>Test</strong> - I want to be able to create, manage, execute, and report upon tests established as part of artifacts on my network.</li>
<li class="li1"><strong>Automate</strong> - I should be able to schedule and automate how and when things run on my network, expanding on what I am capable of.</li>
<li class="li1"><strong>Validate</strong> - There should be mechanisms for me to validate specifications, definitions, and data in motion across my network.</li>
<li class="li1"><strong>Document</strong> - I want to be able to document different aspects of my network, publishing a view of each area for others to consume.</li>
<li class="li1"><strong>History</strong> - There should be a history of everything that is occurring across my network, allowing for observability into network operations.</li>
<li class="li1"><strong>Activity</strong> - History should be able to be seen as it is happening, allowing for visibility into events that are occurring across my network.</li>
<li class="li1"><strong>Analyze</strong> - I want to be able to analyze and report upon what is happening across the network, at the highest and lowest levels.</li>
<li class="li1"><strong>Visualize</strong> - I want to be able to visualize the outputs from various aspects of my network, and see what is going on in different places.</li>
<li class="li1"><strong>Observe</strong> - I want to have observability across my network, consistently providing me visibility into everything that is happening.</li>
<li class="li1"><strong>Duplicate</strong> - Artifacts and other elements should be able to be duplicated, allowing for easy replication across my network.</li>
<li class="li1"><strong>Mock</strong> - I want to be able to mock interfaces and data that is in motion across my network, and share as a mock interface.</li>
<li class="li1"><strong>Import</strong> - Artifacts should be able to be imported into different areas of my network, allowing me to easily bring in new artifacts.</li>
<li class="li1"><strong>Export</strong> - Artifacts should also be able to be exported from different areas of my network, allowing me to easily get artifacts out.</li>
<li class="li1"><strong>Remove</strong> - I should be able to remove any part of my network, allowing me to curate my network as I see fit, across every area.</li>
</ul>
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/bf-skinner-satellite-dish-pointing-upwards.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">There are several actions here that clearly have objects associated with them, but my intend here is to understand what they enable, and what action is being taken as part of my network&mdash;not be hard about what is a noun vs verb. I see my network as made up of people, teams, projects, workspaces, specifications, definitions, organizations, domains, and industries. These are the defining lines of my network, and this list of actions I take will produce data, content, and other artifacts as part of my network, but they provide me with a way to map out the intent, incentives, and meaningful value that gets delivered across my network. These are the things that make my network remain viable and something that helps me accomplish what I am looking to do as a professional within an organization, and across multiple industries.<span>&nbsp;</span></p>
<p class="p1">Across my network, things like code are rapidly becoming more ephemeral. In a serverless, runtime, test-driven wold, code is becoming lighter weight, and act as ephemeral gears throughout my network. Something that is easily replace and removed as needed, acting much like mocks, docs, and other elements of operations. Scripting is more of an action, then an actual thing. Specifications and definitions are the most meaningful constant, actions being taken against them by people across many different projects, workspaces, organizations, domains, and industries. This is an initial attempt at quantifying my network so that I can provide more coherent and thoughtful feedback on how other people define their own networks, helping drive a variety of conversations I am in when it comes to how we structure our operations. This is my view of my network, but the building blocks provide me with some lego blocks I can use when mapping out the landscape of other networks I&rsquo;m providing input on. Hopefully influencing the future of the Postman network, as well as the other enterprise organizations i am working with.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/03/06/what-is-my-api-network/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/03/04/the-building-blocks-of-api-partner-programs/">The Building Blocks Of Api Partner Programs</a></h3>
        <span class="post-date">04 Mar 2020</span>
        ---
published: true
layout: post
title: 'The Building Blocks of API Partner Programs'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/braceros-domingo-ulloa-adam-smith-edinburgh.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/braceros-domingo-ulloa-adam-smith-edinburgh.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">I&rsquo;m doing a deep dive into partner API research, taking a fresh look at how API providers and service providers are operating their partner programs. I looked through around a hundred partner programs I have indexed, and listed a few of the notable ones below. It can be difficult to study partner API programs because many organizations consider their API program a type of partner program by itself, and then there are also a lot of partner APIs, providing actual services involving partners, providing programmatic access to a variety of partner resources. I&rsquo;ll be rolling up this research into several other more formal strategies and guides that I will publish as part of API Evangelist, but like I do with all my work I wanted to publish my notes and research here as I&rsquo;m working through.</p>
<h3>Purpose</h3>
<p class="p1">The reasons behind having a partner program, and what value it brings to an organization and its partners. Providing a list of reasons why you will want to invest in a partner program, and use to sell the concept to other stakeholders.</p>
<ul class="ul1">
<li><strong>Increase Exposure</strong> - Providing more exposure opportunities for platform partners.</li>
<li><strong>Increase Skills</strong> - Expand upon the skills of partners who are putting a platform to work.</li>
<li><strong>Increase Awareness</strong> - Grow the awareness amongst partners about what is possible.</li>
<li><strong>Increase Sales</strong> - Making it about the money, and expanding the sales intake for partners.</li>
<li><strong>Drive Communications</strong> - Push the platform and its partners to communicate more.</li>
<li><strong>Increase Collaboration</strong> - Pushing partners to work together, and with the platform more.</li>
<li><strong>Encourage Usage</strong> - Incentivize more usage of the platform and its products and services.</li>
<li><strong>Encourage Adoption</strong> - Drive adoption of the platform, pushing partners to depend on it more.</li>
<li><strong>Encourage Syndication</strong> - Increase the syndication of content and other branded assets.</li>
<li><strong>Opportunity for Growth</strong> - Allow partners to grow by using the platform more.</li>
<li><strong>Protect Users From Unwanted Behavior</strong> - Solicit partner assistance to help keep users safe.</li>
<li><strong>Protect Platform From Unwanted Behavior</strong> - Solicit partner assistance to police bad behavior.</li>
<li><strong>Strengthen Brand</strong> - Leverage partners to strengthen the platform brand, while building their own.</li>
<li><strong>Increase Reciprocity</strong> - Thoughtfully balance the value created between platform and partner.</li>
<li><strong>Expand Network Reach</strong> - Use partners to extend the reach of the platform, and build up each partner.</li>
<li><strong>Increase SEO</strong> - Work with partners to optimize platform and partner properties on search engines.</li>
<li><strong>Standardize Engagements</strong> - Keep platform engagements with partners consistent and bearing fruit.<span>&nbsp;</span></li>
</ul>
<p class="p1">It helps to establish the purpose of why a platform would want to formalize their partner offering, and investment more in a focused group of API developers. Defining the bar at which developers will need to reach before they can take advantage of more resources and opportunities when it comes to putting a platform to work.<span>&nbsp;</span></p>
<h3>On-Boarding</h3>
<p class="p1">There were some pretty clear building blocks for on-boarding partners as part of a formal API partner program, helping educate interested parties in what the program is all about, and how you can go from learning about it to participating in as few steps as possible.</p>
<ul class="ul1">
<li><strong>Subdomain</strong> - Use a dedicated domain or sub-domain for partner program.</li>
<li><strong>Overview</strong> - Provide a concise and simple overview of what the partner program is.</li>
<li><strong>Getting Started</strong> - Offer up simple steps for how someone can sign up for the program.</li>
<li><strong>Sign-Up Form</strong> - Have an easy to find form available for signing up for the program.</li>
<li><strong>Contact Info</strong> - Make contact information for the partner program easy to find.</li>
</ul>
<p class="p1">Making it easy for interested parties to on-board with as little friction as possible, while standardizing the information and process around the partner program helps ensure an API partner program offering value to both the platform and the partners, ensuring everyone is happy.</p>
<h3>Access</h3>
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/braceros-domingo-ulloa-satellite-dishes-pointing-up.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">Some API partner programs are just one level of access, but there are numerous examples of multi-tiered partner programs, and specialty types of access associated with leading API partner platforms. Demonstrating there isn&rsquo;t one way of defining partnerships, and platforms should consider what the proper levels of access for their platforms, meeting the needs of their organization and partners.</p>
<ul class="ul1">
<li><strong>Program Tiers</strong> - Offering multiple levels of access with details of each tier.</li>
<li><strong>Early Access to APIs</strong> - Providing early access to APIs being developed.</li>
<li><strong>Early Access to New Features</strong> - Offering up early access to new features.</li>
<li><strong>Early Access to Road Map</strong> - Giving partners early look at what is on the road map.</li>
<li><strong>Partner Only APIs</strong> - Providing APIs that are specifically available for partners.</li>
<li><strong>Community</strong> - Allowing different levels of access to the platform community for partners.</li>
<li><strong>Demo Accounts</strong> - Making demo accounts available for partners to put to use.</li>
<li><strong>Sandbox</strong> - Dedicated sandboxes available for partners to develop against.</li>
</ul>
<p class="p1">Different levels of access allow for multiple bars to exist for API developers to rise to, allowing them to determine where they fit into the operations of a platform. While providing a common template and processes for how partnerships are handled, ensuring consistency and reliability across how partner relationships are managed.</p>
<h3>Education<span>&nbsp;</span></h3>
<p class="p1">Taking a look at what is needed to help educate interested parties about what the partner program is, helping them make sense of the value that is available when they step up and work with a platform. Making sure there are self-service, and other educational resources available for all partners, and potential partners.</p>
<ul class="ul1">
<li><strong>Guide</strong> - A PDF guide to the partner program, providing a portable overview of how the platform works.</li>
<li><strong>Benefits</strong> - Providing the details about the benefits to partners, as well as the platform, for easy consumption.</li>
<li><strong>Training</strong> - Invest in the proper amount of training resources to ensure partner learn what is needed when partnering.</li>
</ul>
<p class="p1">Crafting education materials helps platforms work through the details of a program, and make it available in a way that can be easily accessed and consumed by interested parties. Carefully crafted education materials helps further stabilize the relationship between platform and partners, laying a good foundation for what can be expected.</p>
<h3>Business</h3>
<p class="p1">Moving beyond the purpose, on-boarding, access, and education, these are some of the more business elements of doing an API partner program. Defining the direct business elements that can define and incentivize the desired behavior across platform partners, and not missing a beat when it comes to the real world value behind doing an API partner program.</p>
<ul class="ul1">
<li><strong>Fees</strong> - Require partners to pay feeds for applying, processing, certification, and other partner costs.</li>
<li><strong>Discounts</strong> - Offering discounts to partners when it comes to purchasing products and services.</li>
<li><strong>Deals</strong> - Making business deals available to partners, bringing businesses to their doorstep.</li>
<li><strong>Funding</strong> - Providing funding and investment for partners to take advantage of when it comes to their projects.</li>
<li><strong>Grants</strong> - Offering grant funds for certain types of educational, research, and non-profit platform projects.</li>
<li><strong>Incubator</strong> - Establishing an incubator program that is available for partners to enter their projects into.</li>
<li><strong>Accelerator</strong> - Making an accelerator program available for helping increase the momentum of partner projects.</li>
<li><strong>Resell</strong> - Allowing partners to resell products and services and generate revenue when purchases are made.</li>
<li><strong>Affiliate</strong> - Offering a percentage a sale to customers when traffic generates engagement that leads to sales.</li>
</ul>
<p class="p1">Every API partner program ultimately is in service of increasing the bottom line of both the platform and partners, so it makes sense to have a clear definition for how revenue opportunities are providing both directions. Making it obvious the real world value that can be created for everyone involved with making an API partner platform work.</p>
<h3>Innovation</h3>
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/braceros-domingo-ulloa-seattle-shipping-people-walking.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">Building on the business of an API platform, there are several ways API providers are injecting innovation into the partner discussion via their platforms. Providing additional building blocks for other API providers to consider when they are crafting and expanding on their API partner programs, making sure they help a platform quickly innovate.</p>
<ul class="ul1">
<li><strong>Innovation Ideas</strong> - Publishing a list of ideas that partners can consider when it comes to putting a platform to work.</li>
<li><strong>Labs Environment</strong> - Providing a lab that partners can use to help stimulate their usage of the platform and resources.</li>
<li><strong>Proof of Concept (POC) Program</strong> - Providing an official program for giving birth to POC, and possibly moving them ahead.</li>
</ul>
<p class="p1">Innovation is the life blood of API-driven platforms, and should also be partner of the partner layers of a platform, providing ways in which partners can do new and interesting things. Ensuring there is resources, investment, and support from the platform when it comes to lighting the fire under the imagination of platform partners.</p>
<h3>Exposure</h3>
<p class="p1">Most partners are looking for exposure as part of the operations of a platform, extending their reach, and expanding the potential customers they have access to. There are a number of building blocks that API providers are using to increase the surface area of their API partner programs, and give partners more opportunities to be seen.</p>
<ul class="ul1">
<li><strong>Showcase</strong> - Regularly showcasing partners across a website, developer area, and other platform properties.</li>
<li><strong>Directory</strong> - Providing a directory of partners for other platform stakeholders to use to find trusted resources.</li>
<li><strong>Integrations</strong> - Publishing a list of partner integrations available for platform consumers to put to work.</li>
<li><strong>Marketplace</strong> - Having a marketplace of applications that are relevant to a platform, showcasing partner apps.</li>
</ul>
<p class="p1">Exposure is critical to the success of an API platform. Partners need exposure to feel they are getting value from the relationship, and it helps strengthen the overall awareness and perception of what a platform&rsquo;s API partner program is all about&mdash;elevating the presence of the partner program, and the partners who are participating in the program.<span>&nbsp;</span></p>
<h3>Marketing</h3>
<p class="p1">There are a handful of marketing centered building blocks present across many API partner programs. Helping bring alignment between the platform and partner marketing efforts by providing resources that partners can take advantage of. Providing consistency of message and outreach when it comes to how a platform, and the applications integrations are marketed across an industry.</p>
<ul class="ul1">
<li><strong>Co-Marketing</strong> - Offering co-marketing services and resources for partners to take advantage of.</li>
<li><strong>Marketing Toolkit</strong> - Deliver self-service marketing resources in the form of a toolkit for partners.</li>
<li><strong>Go To Market Kits</strong> - Establishing an official go to market strategy for partner to use when launching apps and integrations.</li>
<li><strong>Representative</strong> - providing a dedicated marketing representative for a platform to help guide partner efforts.</li>
</ul>
<p class="p1">Providing marketing resources is a critical set of alignment dials that an API provider can turn to dial in the marketing of the platform, and the apps and integrations that partner provides. Extending the reach of platform marketing while also giving partners a stronger voice when it comes to marketing their own solutions built on top of a platform.</p>
<h3>Branding</h3>
<p>Augmenting marketing it is important to provide API partners with a wealth of assets they can use to reflect the platform&rsquo;s brand in a healthy way. There are a number of building blocks employed by API providers when it comes to standardizing that partners represent a platform in their own content, marketing, and outreach&mdash;helping keep things consistent.</p>
<ul class="ul1">
<li><strong>Images / Logos</strong> - Providing an official set of images and logos for use by partners.</li>
<li><strong>Content</strong> - Publishing partner specific content that helps them represent the platform.</li>
<li><strong>Embeddable</strong> - Providing a suite of embeddable buttons, badges, and widgets for a platform.</li>
<li><strong>Toolkit</strong> - Crafting a complete branding toolkit that walks partners through platform branding.</li>
</ul>
<p class="p1">Offering standardized partner branding resources for a platform helps consistently represent a platform across many domains, but also helps make the program more precise in how it reaches and speaks to consumers. Establishing a common way to represent apps, integrations, and other solutions that are developed on top of a platform.</p>
<h3>Communications</h3>
<p class="p1">Turning up the volume on communications, both on platform and off, is an essential nutrient of any API partner platform. Leveraging a pretty large list of channels in which a platform can communicate about partners, and partners can communicate about the applications and integrations they have developed using a platform&mdash;amplifying everyone involved, and bringing more attention to the interesting things going on.</p>
<ul class="ul1">
<li><strong>News</strong> - Publishing of news that involves a platform and what a partner is delivering.</li>
<li><strong>Blog</strong> - Publishing of blog posts that involves a platform and what a partner is delivering.</li>
<li><strong>Newsletter</strong> - Including details of a platform and partner activity via existing newsletters.</li>
<li><strong>Webinars</strong> - Providing webinars that involves a platform and what a partner is delivering.</li>
<li><strong>Videos</strong> - Publishing videos that showcase a platform and what a partner is delivering.</li>
<li><strong>Slack Channel</strong> - Establishing a dedicated slack channel for platform and partner communication.</li>
<li><strong>Twitter</strong> - Tweeting about what is happening on a platform, and the cool things partners build.</li>
<li><strong>Facebook</strong> - Publishing to Facebook when interesting things occur on a platform involving partners.</li>
<li><strong>YouTube</strong> - Providing a regular stream of videos via Youtube about a platform and partner activity.</li>
<li><strong>Instagram</strong> - Publishing images and stories to Instagram about a platform and partner activity.</li>
<li><strong>LinkedIn</strong> - Publishing to LinkedIn when interesting things occur on a platform involving partners.</li>
<li><strong>GitHub</strong> - Making partner platform projects available via GitHub as open source offerings.</li>
<li><strong>Interviews</strong> - Conducting regular interviews with platform partners and sharing them with the community.</li>
<li><strong>Case Studies</strong> - Crafting case studies that highlight what partners are building on top of a platform.</li>
<li><strong>Testimonials</strong> - Capturing regular testimonials from partners helping gather the experience of partners.</li>
<li><strong>Office Hours</strong> - Holding office hours for partners, allowing for further discussions around the platform.</li>
</ul>
<p class="p1">Healthy communication as part of platform partner activity is essential to a successful API partner platform. Without it, both sides will not receive value from the relationship. The number of channels available will depend on the resources a platform has, but every API provider should consider at least a handful of these communication channels when it comes to defining their API partner program.</p>
<h3>Events</h3>
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/braceros-domingo-ulloa-steam-engine-iceland.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">Events are a great way to get partners involved, and providing them with additional exposure opportunities as part of regular platform gatherings. There are a few building blocks employed by leading API providers when it comes to sweetie the partner pot with opportunities to participate in events, strengthening the platform and partner relationship.</p>
<ul class="ul1">
<li><strong>Speaking</strong> - Offering partners opportunities to speak at events, and be part of the in-person conversation.</li>
<li><strong>Sponsorship</strong> - Establishing event sponsorship opportunities for partners to invest in platform events.</li>
<li><strong>Exhibition</strong> - Expanding to offer up exhibit opportunities for partners to showcase their wares at an event.</li>
</ul>
<p class="p1">Events are an opportunity for the platform partner relationship to move offline and establish more trust, while expanding the exposure partners will get. Helping strengthen how partners engage with a platform, and expanding the value being generated for the end customer, but also partners and the platform that is the foundation for everything that is occurring.</p>
<h3>Support</h3>
<p class="p1">Partners will need support as part of their on-boarding process, and throughout their platform journey. There are numerous proven support channels that API providers are using that can be easily extended to partners, providing them with preferred support channels. Ensuring that partners have what they need, and can get assistance whenever it is needed.</p>
<ul class="ul1">
<li><strong>Email</strong> - Making sure there is an email for partners to use to get support.</li>
<li><strong>Phone</strong> - Publishing a phone number that partners can call to get help.</li>
<li><strong>Paid</strong> - Allowing partners to pay for premium support via a platform.</li>
<li><strong>Ticketing</strong> - Provide the ability for partners to submit a ticket to get help.</li>
<li><strong>Representative</strong> - Provide a dedicated support representative for partners.</li>
<li><strong>Executive Sponsor</strong> - Offer a dedicated executive sponsor for partners.</li>
<li><strong>FAQ</strong> - Publish a list of FAQs to answer many of the common questions.</li>
<li><strong>Road Map Review</strong> - Provide dedicated resources to help partners with their road map.</li>
<li><strong>Community</strong> - Provide dedicated community support for partners needs.</li>
</ul>
<p class="p1">Support will define the partner experience. If partners feel supported they will continue to generate value for a platform. If partners feel alone in their platform journey, the partnership won&rsquo;t mean much to them. The strength of these support mechanisms will set the tone for partnership on any platform, revealing the strength or weakness of everyone involved.</p>
<h3>Platform</h3>
<p class="p1">Partners need a dedicated layer of the platform tailored to their needs, providing the building blocks they will need to manage their applications, integrations, and quantify their overall engagement. There are common ways to extend personalized platform resources for partners to take advantage of, offering up tailored services and features via dedicated private spaces.</p>
<ul class="ul1">
<li><strong>Portal</strong> - Providing a dedicated portal for partners to access information and resources.</li>
<li><strong>Login</strong> - Requiring partners to login and fully access the resources being made available.</li>
<li><strong>Account</strong> - Allow partners to manage the details of their account via a platform login.</li>
<li><strong>Dashboard</strong> - Providing a dashboard that gives partners visibility into their engagement.<span>&nbsp;</span></li>
<li><strong>Analytics</strong> - Make meaningful analytics available to help partners understand their activity.</li>
<li><strong>Sandbox</strong> - Establish a dedicated API sandbox for partners to take advantage of.</li>
</ul>
<p class="p1">The amount of resources available to partners, combined with real time visibility into their platform engagement will keep partners coming back and staying active and engaged. This section is about giving partners their own little slice of a platform to make them feel like they are part of the action, incentivizing them along the way to always do more.</p>
<h3>Observability</h3>
<p class="p1">Measuring the activity of an API partner program using available outputs is a critical part of providing the observability needed to understand, drive, and direct partner activity and engagement. There are a handful of ways in which API providers are making their platforms more observable to all stakeholders involved in moving the platform, and the integrations and applications are built on them forward.</p>
<ul class="ul1">
<li><strong>Activity Reports</strong> - Publish regular activity reports about all the partner actions that are occurring.</li>
<li><strong>Progress Reports</strong> - Provide progress reports for partners, as well as the platform when it comes to meeting obligations.</li>
<li><strong>Ranking</strong> - Establish a ranking system for partners, helping understand the scope and quality of engagement.</li>
<li><strong>Governance</strong> - Ensure that the partner program is regularly being measured, audited, and understood for value.</li>
</ul>
<p class="p1">Observability is all about being aware of what is happening with partner activity. Ensuring that everyone can see what is going on, and the activity that is occurring is in alignment with the purpose of the partner program, and making sure that there is reciprocity between the platform and the partners who have stepped up to participate in the program.</p>
<h3>Accreditation:</h3>
<p class="p1">Once a partner is on-boarded, there should be additional tracks for further ensuring the quality and intent of partners. Helping establish solid benchmarks for what is expected of partners, and making sure it is clear to the platform and the community that partners are of a higher quality when it comes to providing applications, integrations, and other services.</p>
<ul class="ul1">
<li><strong>Verification</strong> - Formally verifying that partners are real, and have the best interests of the platform in mind.</li>
<li><strong>Certification</strong> - Establish a certification process around specific platform needs, certifying partners deliver value.</li>
<li><strong>Badging</strong> - Offer up an official badge for partners to display on their website and applications built on a platform.</li>
</ul>
<p class="p1">Accreditation provides a process and mechanisms for the platform community to understand who the sanctioned partners are, providing a wealth of services, tooling, and other resources they can confidently put to work. Raising the quality of engagements beyond the partner program, making sure end-user&rsquo;s needs are met, while keeping everything in alignment with platform objectives.</p>
<h3>Types of Partners</h3>
<p class="p1">While reviewing different API provider partner programs there were a number of different types of partners present4ed. Offering a look at different ways in which APIs are partnering with their community. Demonstrating that there isn&rsquo;t just one way in which you can partner with other companies, organizations, institutions, and government agencies.</p>
<ul class="ul1">
<li><strong>Developer</strong> - The most common layer of developer engagement, while still raising the quality bar.</li>
<li><strong>Agency</strong> - Providing an opportunity for agencies to partner and deliver value to platform users.</li>
<li><strong>Consulting</strong> - Encouraging consultants to become partners and fulfill services the platforms needs.</li>
<li><strong>Technology</strong> - Allow technology providers to offer their solutions as part of a platform.</li>
<li><strong>Integration</strong> - Showcasing partners who have established platform integration that offer users value.</li>
<li><strong>Franchises</strong> - Allow partners to franchise the API platform model and offer as part of their business.</li>
<li><strong>Reseller</strong> - Allow partners to resell products and services to generate revenue as part of their operations.</li>
<li><strong>Affiliates</strong> - Allow partners to generate revenue from inbound traffic they send which converts into sales.</li>
<li><strong>White Label</strong> - Offer white or private label offerings that partners can offer seamlessly as part of their operations.</li>
<li><strong>Academic</strong> - Establish partner opportunities for academic institutions, offering them tailored engagements.</li>
<li><strong>Non-Profit</strong> - Establish partner opportunities for non-profit and NGO groups to put the platform to work.</li>
<li><strong>Government</strong> - Establish partnership opportunities that offer platform resources to government agencies.</li>
</ul>
<p class="p1">Many API providers just have a single type of partner, but these additional types offer a look at the opportunities to expand in the future as a platform gets its footing with its partner program. Depending on the type of services being offered, each of these areas can represent a new way to look at how services can be made available to an entirely new audience.</p>
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/braceros-domingo-ulloa-electric-tower-sun-behind.jpg" alt=" alt=" width="40%" align="right" /></p>
<h3>Requirements</h3>
<p class="p1">There were also some requirements present for a handful of the API providers I looked at as part of this research. I thought it was an interesting way to set the bar for partners, ensuring the quality of the partner program, and what is offered to the community. There were some really interesting ways in which platforms governed who could step up and achieve partner status for a platform.</p>
<ul class="ul1">
<li><strong>Plan</strong> - Partners must have a plan in place that outlines what they will be doing on a platform.</li>
<li><strong>Dedicated Human Resources</strong> - Partners must provide a dedicated person to manage relationships.</li>
<li><strong>Dedicated Training Resources</strong> - Partners must be ready to offer dedicated training resources.</li>
<li><strong>Managed Service Offering</strong> - Partners will be required to offer a managed service as part of their engagement.</li>
<li><strong>Lead Requirements</strong> - Partners must generate a certain amount of leads to maintain their partner status.</li>
<li><strong>Revenue Requirements</strong> - Partners must generate a certain amount of revenue for their platform to maintain status.</li>
</ul>
<p class="p1">Partner program requirements are a great way to raise the bar when it comes to what is expected of partners. Ensuring that partners are of the highest quality, filtering out the organizations who might not be ready to meet platform standards. Requiring everyone involved in the partner program take its engagement with the platform more seriously.<span>&nbsp;</span></p>
<h3><span>Leading API Partner Programs</span></h3>
<p>I looked through well over a hundred API provider partner programs and I filtered the less than exciting examples, leaving a list of API providers who are at least doing something worthwhile as part of their official partner offerings. Providing me with all the building blocks I extracted as part of this research. Building upon what is already occurring across the sector, and providing a list of building blocks that other API providers might want to consider as part of their partner strategy.</p>
<table width="100%">
<tbody>
<tr>
<td width="50%" valign="top">
<ul>
<li><strong><a href="https://www.twilio.com/partners">Twilio</a></strong></li>
<li><strong><a href="https://partners.salesforce.com/">Salesforce</a></strong></li>
<li><strong><a href="https://stripe.com/docs/partners">Stipe</a></strong></li>
<li><strong><a href="https://www.facebook.com/business/marketing-partners/">Facebook</a></strong></li>
<li><strong><a href="http://developer.xero.com/partner/">Xero</a></strong></li>
<li><strong><a href="https://www.mailjet.com/partners/">Mailjet</a></strong></li>
<li><strong><a href="http://www.constantcontact.com/partners/technology">Constant Contact</a></strong></li>
<li><strong><a href="https://www.docusign.com/partners">Docusign</a></strong></li>
<li><strong><a href="https://www.cloudflare.com/partners/">CloudFlare</a></strong></li>
<li><strong><a href="https://www.assuresign.com/resource-center/partner-program/">Assure Sign</a></strong></li>
<li><strong><a href="http://www.verticalresponse.com/partner">Vertical Response</a></strong></li>
<li><strong><a href="https://www.shopify.com/partners">Shopify</a></strong></li>
<li><strong><a href="https://bitly.com/pages/partners">Bitly</a></strong></li>
<li><strong><a href="http://www.freeagent.com/partners/">Free Agent</a></strong></li>
<li><strong><a href="https://www.visual-paradigm.com/partner/academic/">Visual Paradigm</a></strong></li>
<li><strong><a href="http://www.fiorano.com/partners/partners.php">Fiorana</a></strong></li>
<li><strong><a href="https://www.digicert.com/digital-certificate-reseller-program.htm">Digitcert</a></strong></li>
<li><strong><a href="https://www.2checkout.com/partner">2Checkout</a></strong></li>
<li><strong><a href="https://aws.amazon.com/api-gateway/partners/">Amazon API Gateway</a></strong></li>
<li><strong><a href="https://aws.amazon.com/solutions/partners/dev-ops/">Amazon Dev Ops</a></strong></li>
<li><strong><a href="https://aws.amazon.com/config/partners/">Amazon Config</a></strong></li>
<li><strong><a href="https://aws.amazon.com/dms/partners/">Amazon Database Migration</a></strong></li>
<li><strong><a href="https://aws.amazon.com/directconnect/partners/">Amazon Direct Connect</a></strong></li>
<li><strong><a href="https://aws.amazon.com/dynamodb/partners/">Amazon DynamoDB</a></strong></li>
<li><strong><a href="https://aws.amazon.com/emr/partners/">Amazon Elastic Map Reduce</a></strong></li>
<li><strong><a href="https://aws.amazon.com/iam/partners/">Amazon Identity and Access Management</a></strong></li>
<li><strong><a href="https://aws.amazon.com/inspector/partners/">Amazon Inspector</a></strong></li>
<li><strong><a href="https://aws.amazon.com/iot/partner-solutions/">Amazon Internet of Things</a></strong></li>
<li><strong><a href="https://aws.amazon.com/lambda/partners/">Amazon Lambda</a></strong></li>
<li><strong><a href="https://aws.amazon.com/rds/partners/">Amazon Relational Database Services</a></strong></li>
<li><strong><a href="https://aws.amazon.com/redshift/partners/">Amazon Redshit</a></strong></li>
<li><strong><a href="https://aws.amazon.com/server-migration-service/partners/">Amazon Server Migration Service</a></strong></li>
<li><strong><a href="https://aws.amazon.com/waf/partners/">Amazon Web Application Firewall</a></strong></li>
<li><strong><a href="https://cloud.google.com/partners">Google</a></strong></li>
<li><strong><a href="https://developers.google.com/analytics/program/">Google Analytics</a></strong></li>
<li><strong><a href="https://cloud.google.com/bigquery/partners/">Google BigQuery</a></strong></li>
<li><strong><a href="https://cloud.google.com/dataproc/docs/resources/partners">Google Data Analytics</a></strong></li>
<li><strong><a href="https://developer.yammer.com/v1.0/docs/yammer-partners">Yammer</a></strong></li>
<li><strong><a href="https://intrinio.com/partners">Intrinio</a></strong></li>
</ul>
</td>
<td width="50%" valign="top">
<ul>
<li><strong><a href="https://developer.starlingbank.com/partner">Starling Bank</a></strong></li>
<li><strong><a href="https://www.versapay.com/partners/">Versapay</a></strong></li>
<li><strong><a href="https://www.appsflyer.com/partners/">AppsFlyer</a></strong></li>
<li><strong><a href="https://www.bizimply.com/partner/">Bizimply</a></strong></li>
<li><strong><a href="https://www.fraudlabspro.com/reseller-program">Fraud Labs</a></strong></li>
<li><strong><a href="https://www.shipstation.com/partners/">Ship Station</a></strong></li>
<li><strong><a href="https://www.bookeo.com/affiliate/">Bookeo</a></strong></li>
<li><strong><a href="https://forge.autodesk.com/systemsintegrators">Autodesk</a></strong></li>
<li><strong><a href="https://kenticocloud.com/partners">Kentico Cloud</a></strong></li>
<li><strong><a href="https://developers.idxbroker.com/partnership/">IDX Broker</a></strong></li>
<li><strong><a href="https://www.coupa.com/partner-connect-program/">Coupa</a></strong></li>
<li><strong><a href="https://www.3dcart.com/ecommerce-partners.html">3D Cart</a></strong></li>
<li><strong><a href="https://www.net2phone.com/partners/">Net2Phone</a></strong></li>
<li><strong><a href="https://www.authorize.net/resources/find-a-partner/">Authorize.net</a></strong></li>
<li><strong><a href="https://www.evosnap.com/partner-with-us/">Evo Snap</a></strong></li>
<li><strong><a href="https://www.adp.com/who-we-serve/by-partner.aspx">ADP</a></strong></li>
<li><strong><a href="https://www.actility.com/partners/">Activity</a></strong></li>
<li><strong><a href="https://www.cardknox.com/partners/">CardKnox</a></strong></li>
<li><strong><a href="https://www.acxiom.com/partners/">Acxiom</a></strong></li>
<li><strong><a href="https://www.checkpoint.com/partners/opsec/">Checkpoint</a></strong></li>
<li><strong><a href="https://www.blackbaud.com/partners/become-a-partner">Blackbaud</a></strong></li>
<li><strong><a href="https://curity.io/company/partners/">Curity</a></strong></li>
<li><strong><a href="https://www.ecwid.com/partners">Ecwid</a></strong></li>
<li><strong><a href="https://www.fxspotstream.com/partners/">FX Spotstream</a></strong></li>
<li><strong><a href="https://www.formstack.com/partners">Formstack</a></strong></li>
<li><strong><a href="https://www.gainsight.com/partners/">Gainsight</a></strong></li>
<li><strong><a href="https://511.org/about/partners">SF 511</a></strong></li>
<li><strong><a href="https://solace.com/company/partners/">Solace</a></strong></li>
<li><strong><a href="https://partners.typeform.com/">Typeform</a></strong></li>
<li><strong><a href="https://algorithmia.com/partners">Algorithmia</a></strong></li>
<li><strong><a href="https://developers.shutterstock.com/partners">Shutterstock</a></strong></li>
<li><strong><a href="https://www.airbnb.com/partner">Airbnb</a></strong></li>
<li><strong><a href="https://www.prodatakey.com/partner-portal-new">PDK</a></strong></li>
<li><strong><a href="https://apifortress.com/partners/">API Fortress</a></strong></li>
<li><strong><a href="https://cloudinary.com/partners">Cloudinary</a></strong></li>
<li><strong><a href="https://www.digitalocean.com/partners/solutions-partners/">Digital Ocean</a></strong></li>
<li><strong><a href="https://www.everbridge.com/about/partner-program/">Everbridge</a></strong></li>
<li><strong><a href="https://segment.com/partners/">Segment</a></strong></li>
</ul>
</td>
</tr>
</tbody>
</table>
<h3>Crafting the Most Effective API Partner Program</h3>
<p>I am taking this research and weaving it into my work at Postman. Like the other stops along the API life cycle I am looking to learn from what is happening across the API space, find the common building blocks and patterns, and load them up in my brain for use in workshops, strategy, and conversation I am having with enterprise groups looking to expand their platforms. While not every API provider should be applying all of these building blocks, the list does provide a comprehensive view at the building blocks in use across providers. Allowing anyone to cherry pick what would work for their platform. I will take this list and use it across my other work, offering up more refined strategies for API providers based upon their needs and objectives, regularly using this list to refine what I'm proposing, but also help remind me to regularly pause and take a look at what other API providers are doing when it comes to their partner programs.</p>
<p>API providers who have an established partner program as part of their API offerings demonstrate that they are further along in their API journey. They have identified that they need more quality control gates on their API program, allowing developers till up the intake funnel for their platform, while ensuring you identify what is required of developers before they can receive more investment, exposure, and reach when it comes to what is happening on a platform. Establishing a process for raising the bar for what gets built on a platform, and the overall value of the applications and integrations developers are delivering. Increasing not just the availability of high quality services, applications, tooling, and integrations, but also the overall reach and scope of what a platform can do. Leveraging partners to help join in ensuring an API platform is living up to its full potential and meeting the needs of its users.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/03/04/the-building-blocks-of-api-partner-programs/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/03/04/postman-api-reference-and-capability-collections/">Postman Api Reference And Capability Collections</a></h3>
        <span class="post-date">04 Mar 2020</span>
        ---
published: true
layout: post
title: 'Postman API Reference and Capability Collections'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/bf-skinner-docks-water-front-ships-containers.jpg
---
<img src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/bf-skinner-docks-water-front-ships-containers.jpg" width="40%" align="right" style="padding: 15px;" /><p>Postman collections are a great way to document every detail of an API, defining the host, path, parameters, headers, and body of each API request. Allowing any single API request to be captured as a machine and human readable Postman collection that can be shared and used by any technical or non-technical user. The most common approach to defining a Postman API collection is to document the requests across all available APIs, providing a complete collection of all API requests that can be made, then using that reference to mock, document, test, monitor, and execute individual requests manually or as part of any automated process.<span>  </span>However, there are other ways to evolve these requests to ensure that they more closely resemble common business tasks, accomplishing everyday activities that technical and non-technical individual need to accomplish.</p>
<h3>An AWS EC2 Reference Collection</h3>
<p>An example of a Postman reference API collection can be found in <a href="https://github.com/api-evangelist/aws">the collections I worked on leading up to AWS re:Invent last December</a>. One of the reference API collections I have been crafting is for the <a href="https://aws.amazon.com/ec2/"><span class="s1">Amazon EC2</span></a>, providing a portable and executable collection of all API requests possible for the cloud compute platform. The AWS EC2 reference collection has over 350 individual requests possible in, providing a dizzying amount of control over delivering, operating, and evolving compute capacity across AWS regions. While this collection a robust representation of all the available AWS EC2 resources, it will take additional work to understand what is possible, find the specific request needed for any particular integration or application, and populate the request with relevant values to realize any specific business need. It is a great start when it comes to putting AWS EC2 to work, but to make things more usable, it will take a little more work.</p>
<h3>An Amazon EC2 Capability Collection</h3>
<p>This AWS EC2 reference collection provides a foundation for delivering integrations and applications, and can be used as a seed for a different type of API collection I like to call "capability collections". These capability collections involve further populating individual API requests with specific parameters, headers, and body payload values that accomplish a specific business task. An example of this could be <a href="https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_RunInstances.html"><span class="s1">taking the run instance request</span></a> and pre-populate it with a specific EC2 instance type and pre-built base image for deployment, accomplishing a more precise goal when it comes to deploying and running a specific type of AWS EC2 instance. Establishing a single collection with one or more precise API requests that can deliver on a single organizational capability which any individual with the proper access can execute. Keeping the collection very focused on a single or suite of complimentary capabilities that make the AWS EC2 Run Instance action more about representing business capabilities, then just being a generic technical interface for use in many different scenarios.</p>
<h3>Collections Defining Organizational Capabilities</h3>
<p>This is just one example of the evolutionary difference between reference Postman API collections and capability Postman API collections. Both play a significant role in making API integration as frictionless as possible, but the capability Postman collections go the extra difference to define and enable specific organizational capabilities. Defining a single digital capability of an organization, then grouping complimentary capabilities into meaningful folders, collections, and workspaces, making them available across technical and non-technical teams. Defining organizational capabilities as portable sharable units of compute that can be made accessible and discoverable across distributed groups, and put to work manually via the Postman platform, 3rd party tools, or automated as part of scheduled and CI/CD pipelines. Properly defining what an organization is capable of, and further defining that down to each line of business, department, and team—ensuring that an organization has firm grasp on what it is capable of at any moment.</p>
<p>Postman collections exist to help developers keep track of the growing number of API requests they will need to make on any given day, across each of the projects they are working on. Reference collections are all about making sure enterprise API infrastructure is properly defined, versioned, and made available across teams. Capability Postman API collections are about atomically defining what each individual API resource is capable of doing in a way that makes sense, is accessible, and executable by both developer and business users. Postman reference API collections represent what is possible across operations, and Postman capability API collections represents going beyond what is possible, and actually putting each individual capability to work—manually by running a collection within Postman client, scheduled as a monitor, or integrated into existing CI/CD workflows by using the Postman runner. Defining what organizations are capable of as they continue to invest in their digital transformation, and get more organized about how they do business within the expanding and shifting global API economy.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/03/04/postman-api-reference-and-capability-collections/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/03/03/peeling-the-openapidriven-api-life-cycle-collaboration-onion/">Peeling The Openapidriven Api Life Cycle Collaboration Onion</a></h3>
        <span class="post-date">03 Mar 2020</span>
        ---
published: true
layout: post
title: 'Peeling the OpenAPI-Driven API Life Cycle Collaboration Onion'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/stalin-time-working-on-railroad-2.jpg
---
<p><img src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/stalin-time-working-on-railroad-2.jpg" alt="" width="47%" align="right" /></p>
<p>I am trying to better understand how we all work together to deliver and consume APIs. Fleshing out more meaning behind some of the common words we use in the space such as collaboration, platform, hubs, workspaces, feedback looks, comments, sharing, notifications, and other communication channels. I want push my thoughts forward on what the gears of API collaboration are, and how we can better work together to move many different APIs forward as provider and consumer.</p>
<p>API collaboration isn&rsquo;t very straightforward, and in my mind there are several layers to how things actually are playing out across the API landscape. This is my best attempt at breaking things out into different buckets for helping us make sense of how we are working together to move API infrastructure forward at the organizational and industry level.</p>
<h3>Layer One - Single OpenAPI Management</h3>
<p>In 2020, OpenAPI has won the great API specification wars of the previous decade. OpenAPI is helping individual developers and architects more efficiently define and design OpenAPI definitions, using the core objects of the API specification as our guide. Providing us with a box of gears we can assemble to define the floor of our digital factories putting out the digital products and services we provide to our customers each day.</p>
<ul>
<li><strong>Info</strong> - Helping manage the name and description for OpenAPI definitions</li>
<li><strong>Contact</strong> - Helping integrate and manage contact info as part of wider team management.</li>
<li><strong>License</strong> - Helping manage the4 licensing for the APIs being defined.</li>
<li><strong>Server</strong> - More management for available servers (ie. mock, development, production, etc)</li>
<li><strong>Server Variables </strong>- Helping manage server variables as part of environment management.</li>
<li><strong>Paths</strong> - Help managing the design and definition of API paths.</li>
<li><strong>Operation</strong> - Better operation management (verbs, summary, description, operationIds, etc.)</li>
<li><strong>Parameter</strong> - Help more consistently name and define query and path parameters.</li>
<li><strong>Headers</strong> - Be more deliberate and aware about how headed are defined and used.</li>
<li><strong>Request Body </strong>- More tools for managing the schema that is used as part of the API body.</li>
<li><strong>Media Type</strong> - Make it easier to define and manage multiple media types, encoring negotiation.</li>
<li><strong>Responses</strong> - More tools for helping define and manage the responses for each API method.</li>
<li><strong>Examples</strong> - Better tools for creation, management, and organizing of examples for each method.</li>
<li><strong>Callback</strong> - Defining callbacks that are in use across APIs, making APIs outbound as well.</li>
<li><strong>Links</strong> - More hypermedia controls with better link management for each method response.</li>
<li><strong>Tags</strong> - Better management of tags that are applied to each API and individual API methods.</li>
<li><strong>Overlays (new)</strong> - Management of additions, augmentations, and overlays beyond the spec.</li>
<li><strong>Schema</strong> - More tools for helping manage, create, and validate schema for responses, and from examples.</li>
<li><strong>Documentation</strong> - Automatically linkage of external Postman generated documentation</li>
<li><strong>Security</strong> - More management of security scheme in use across OpenAPI definitions.</li>
</ul>
<p>These are the moving parts of each individual API, but also collectively the APIs we are putting to work across our digital factory floors.<span>&nbsp; </span>Whether we are hand-crafting our OpenAPI definitions, or generating from code, they represent the moving parts of what we are looking to move forward and orchestrate throughout the numerous API life cycles. Now, we just have to further expand our OpenAPI management gears to ensure we can consistently deliver and orchestrate across many different API resources.</p>
<h3>Layer Two - Multiple API Management</h3>
<p>This layer is all about acknowledging that organizations aren&rsquo;t just defining a single API in isolation and they will be delivering multiple APIs across teams and organizations, and a consistent approach is being defined by OpenAPI. Teams are increasingly using OpenAPI to define each API, but there is a significant amount of work ahead of us when it comes to how we wield OpenAPI consistently across multiple APIs, across multiple teams, organizations, and industries. Here is how I&rsquo;m looking at the gears for consistently applying across many different APIs.</p>
<p><strong>Components</strong> - Again, we should be building on core of the OpenAPI specification. The components object was central to the evolution from 2.0 to 3.0 of the specification, acknowledging that reusable components is not just important to API governance, but to the API design process. The OpenAPI 3.0 components spec centralizes the following components:</p>
<ul>
<li><strong>Schemas</strong> - Centralization, recuse, and evolution of schema across all APIs in motion.</li>
<li><strong>Responses</strong> - Standardizing the responses across resources, standardizing how APIs respond.</li>
<li><strong>Parameters</strong> - Centralizing the management of parameters used across the API request surface.</li>
<li><strong>Examples</strong> - Standardizing how examples are created, stored, managed, and refreshed.</li>
<li><strong>RequestBodies</strong> - Having a common strategy for managing how request bodies work for APIs.</li>
<li><strong>Headers</strong> - Providing a platform wide header management approach, fully leveraging the web.</li>
<li><strong>SecuritySchema</strong> - Centralizing how APIs are secured, and resting the same authentication patterns.</li>
<li><strong>Links</strong> - API wide management of links between APIs, and the different resources and capabilities they enable.</li>
<li><strong>Callbacks</strong> - Defining the callback and event structure that exists across the request / response API network.</li>
</ul>
<p>I think standardization, reuse, and modularization of the API design process is something OpenAPI excels at, and something all API service should embrace as part of their adoption of OpenAPI as the central truth for APIs. Providing users with the ability to generate, aggregate, manage, share, and collaborate around healthy API patterns across API operations. Many API developers are beginning to think about API components across a single API thanks to the OpenAPI components object, but few are adequately considering how the components object can be centralized, allowing for API gears to be consistently applied across many different APIs defining the digital factory floor.</p>
<p><img src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/stalin-time-train-tracks-seattle-waterfront.jpg" alt="" width="47%" align="right" /></p>
<h3>Layer Three - Multiple API Derivates</h3>
<p>Beyond there being many individual APIs defined as OpenAPI, as well as multiple APIs consistently defined using OpenAPI defined components there are going to be multiple collection derivatives of each API. While some derivatives will be in service of specific stops along the API life cycle, something I touch on below, these definitions act as a governor between many different aspects of operations, and specific audiences, acknowledging there could potentially be many different machine readable artifacts present that will be used in different ways, and require keeping in sync with the central truth.</p>
<ul>
<li><strong>Reference Collections -</strong> Used primarily for delivering API documentation.</li>
<li><strong>Workflow Collections </strong>- Defining workflows across many different APIs.</li>
<li><strong>On-Boarding Collections </strong>- Introducing individuals to APIs and concepts.</li>
<li><strong>Mocking Collections -</strong> Providing virtualized environments for developers.</li>
<li><strong>Documentation Collections</strong> - Providing what is needed for humans to use APIs.</li>
<li><strong>Testing Collections </strong>- Test suite, integration, as well as contract testing.</li>
<li><strong>Monitoring Collections -</strong> Details for monitoring the availability of APIs.</li>
<li><strong>Performance Collection -</strong> Information pertaining to the performance of an API.</li>
<li><strong>Security Collections -</strong> Details for scanning, fuzzing, and poking at APIs.</li>
<li><strong>Governance Collections</strong> - Applying rules the the design defined in OpenAPI.</li>
<li><strong>Life Cycle Collections </strong>- Scaffolding for moving an API through its life cycles.</li>
</ul>
<p>Essentially, how do you manage the OpenAPI, but also down to how each request is used across all derivatives. You can have the truth for each API defined as part of the OpenAPI schema, but also have to maintain derivative definitions for one or many stops along the API life cycle, or packaged up to speak to specific audiences. In 2020, your API definitions help you standard your APIs, as well as infrastructure, and overall life cycles behind each API, providing a derivative of the OpenAPI truth designed for a specific need.</p>
<h3>Layer Four - Multiple API Iterations</h3>
<p>Across my OpenAPI truth and my collection derivatives I have many iterations to manage, making for one of the biggest headaches API developers face when managing many different APIs over time. Meaning your APIs will change, and you will have to track on what is going on across many APIs, spread across time, and versioning is the primary way for managing change.</p>
<ul>
<li><strong>Versioning</strong> - How does versioning across my OpenAPI and Postman collections work, and how is translated to each stop along the API life cycle using a well defined collection?</li>
</ul>
<p>Developers aren&rsquo;t just needed OpenAPI versioning guidance and assistance through the aPI lifecycle, they need it to work flawlessly across multiple artifacts, managing the truth, but also it&rsquo;s derivatives and environments.</p>
<ul>
<li><strong>OpenAPIs</strong> - Versioning of the OpenAPI truth.</li>
<li><strong>Collections</strong> - Versioning of each collection derived.</li>
<li><strong>Environments</strong> - Versioning of the environments used.</li>
<li><strong>Services</strong> - Commercial services applied across the API life cycles.</li>
<li><strong>Tooling</strong> - Open source tools applied across the API life cycles.</li>
</ul>
<p>All of this has to work in concern across operations. Versioning needs to be authoritative and prescriptive, while also woking across all steps across the API life cycle via collections. You can see the beginning of this when you click &ldquo;Generate Collection&rdquo; for an API in Postman&mdash;you get a dropdown option for which stop along the API lifecycle this collection will service. We need this for every stop, so that the collection that drives documentation is seamlessly versioned with the OpenAPI, while the collection that drives serverless code generation is also in alignment as well. This won&rsquo;t be easy, and collections can be the central governor in this reality.</p>
<h3>Layer Five - Multiple API Life Cycle Stops</h3>
<p>If the OpenAPI contract cannot properly service multiple stops along the API life cycle then we are in trouble. Right now it is effective servicing documentation, testing, and handful of others, but for the most part nobody has brought it all together into a coherent approach to actually servicing the entire API life cycle. While layer three&mdash;derivatives speaks a little to this by acknowledging there are derivatives of the OpenAPI truth, this layer is about being thoughtful about how those definitions, or extensions of definitions will specification service different stops along the API life cycle.<span>&nbsp;</span></p>
<ul>
<li><strong>Documentation</strong> - Defining collections for publishing documentation.</li>
<li><strong>Mocking</strong> - Generating virtualizations of an API and it's data for developers.</li>
<li><strong>Testing</strong> - Defining collections that define a full suite of test scenarios.</li>
<li><strong>Monitoring</strong> - Defining collections that run on schedule to automate.</li>
<li><strong>Server Code</strong> - Defining collections that generate server side implementations.</li>
<li><strong>Client Code</strong> - Defining collection that generate client side code and integrations.</li>
<li><strong>CI / CD</strong> - Further automation and executions of collections within the pipeline.</li>
<li><strong>Discovery</strong> - Ensuring APIs are discoverable at design, develop, and run time.</li>
<li><strong>Security</strong> - Making sure that all APIs are properly locked down and audited. -<span>&nbsp;</span></li>
<li><strong>Governance</strong> - Providing guidelines, metrics, and reporting on the deliver of APIs.</li>
<li><strong>Observability</strong> - Opening up the logging, testing, monitoring, and other signals.</li>
</ul>
<p>Postman collections, and other definitions or extensions can act as the connector between an APIs central truth, and the realization of each version across the API lifecycle. This relationship has to be easily defined, realized, observes, and reported upon to fully realized as part of maintaining and elevating an OpenaPI as the central truth of an API. Postman collections and OpenAPI extensions augment the truth, providing a completely separate API definition that is derived from the truth but contains additional data that speaks to the individual needs at each stop of the API life cycle.</p>
<p><img src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/stalin-time-subway-brooklyn-station.jpg" alt="" width="47%" align="right" /></p>
<p><strong>Layer Six - Multiple People (aka Collaboration)</strong></p>
<p>Lastly, after multiple APIs, derivatives, versions, and stops along the API life cycle(s), we have many different people with different incentive structures. This layer is all about the people, and providing a meaningful way to bring all of this together as a hub, core, heart, nerve center, platform, or whatever is defined as the centralized or distributed platform within an organization. Each of these areas will deeply impact the success or failure of OpenAPIs as the central truth of API operations.</p>
<ul>
<li><strong>Users</strong> - Empowerment of individuals, while also expanding the different roles Postman includes as a stakeholder.</li>
<li><strong>Teams</strong> - Helping define, redefine, and better understand how teams are working, or not working across operations.</li>
<li><strong>Workspaces</strong> - Strategically as well as organically define workspaces for effective delivery and management of APIs.</li>
<li><strong>Organizations</strong> - Dovetail with existing organization directories and structures, while also allowing them to evolve.</li>
<li><strong>Conversations</strong> - The discussions occurring around all the moving parts of each API across the API life cycle.</li>
<li><strong>Sharing</strong> - Understanding sharing of OpenAPI, collections, and life cycle deliverables at every turn by all users.</li>
<li><strong>Forking</strong> - Effectively forking of OpenAPI and collections as part of the overall flow of APIs being defined and delivered.</li>
<li><strong>Merging</strong> - Confidently merging of OpenaPI and collections as part of the overall flow of APIs being defined and delivered.<span>&nbsp;</span></li>
<li><strong>Publishing</strong> - Thoughtful publishing of OpenAPI, collections, and other deliverables whenever possible through the flow.</li>
<li><strong>Discovery</strong> - Ensuring that the discovery of APIs is always baked into the workflow, while adhering to privacy and security.</li>
<li><strong>Governance</strong> - Providing an authoritative and leadership layer to operations that allows a small group to drive the overall flow.</li>
</ul>
<p>These are the primary human initiated actives that need to be incentivized, organized, and realized on a daily basis for all of this to work. These activities are all centered around the OpenAPI truth, and the collection derivatives which drive each stop along the API life cycle. The trick is how do you get people to do them in a thoughtful, educated, and deliberate way, adhering to enterprise orchestration and choreography? One important aspect of this orchestration and choreography involves two key areas, and remembering to focus on what is expected by:</p>
<ul>
<li><strong>People</strong> - A human being taking a collection derived from an API truth and accomplishing a specific business objective.</li>
<li><strong>Systems</strong> - A computer taking a collection derived from an API truth and accomplishing a specific business objective.</li>
</ul>
<p>Some of the stops along the API life cycle are meant for humans (ie documentation), while others are purely for other systems (ie. Server code and CI/CD). Some are meant for both. OpenAPI and collection derivatives are what bridge this divide, and should be usable by both human beings and computers. This is a fundamental element of OpenAPI and collaboration in the API space, and something we often forget. This is why companies like Stripe and Twilio have done so well when it comes their operations, because they get, and work hard to strike a balance between people and systems.</p>
<h3>The API Life Cycle Collaboration Onion</h3>
<p>All of this is not meant to be a playbook, it is simply meant to help elevate my view of the landscape, while still considering the technical, organizational, and human elements of how all of this works or doesn't work. i am not happy with the differences between layer three and layer five, there is still too much overlap there. However i think the separation between artifact and what it is serving is important, even if I can't 100% nail it all down. Ultimately I'm just trying to get a handle on all the moving parts, and begin to think deeply about the different directions in which the factory floor is moving. I am trying to understand both the human and machine elements of an OpenAPI-driven API life cycle, and be more honest, fair, and balanced about how collaboration works and doesn't work across large enterprise.</p>
<p>I will keep poking at this narrative to see where I can take it. This is really the first time I've elevated beyond what OpenAPI can do across the API lifecycle and begin to think more deeply about the organizations and people who are actually getting the work done. I have spent a lot of time thinking about OpenAPI, the API life cycle, as well as how the two work. However, I have not spent much time outlining or diagramming how organizations and humans actually fit into the equation and how they actually collaborate to get things work. As with the rest of my work it will take many iterations before it all comes together for me, and is something that rolls smoothly off the tongue, which is why I do all of this writing here on the blog--it is something that puts me in the optimal state for talking about APIs across the enterprise groups I'm speaking with on a regular basis.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/03/03/peeling-the-openapidriven-api-life-cycle-collaboration-onion/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/03/02/the-technology-business-and-politics-of-the-openapi-conversation/">The Technology Business And Politics Of The Openapi Conversation</a></h3>
        <span class="post-date">02 Mar 2020</span>
        ---
published: true
layout: post
title: 'The Technology, Business, and Politics of the OpenAPI Conversation'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2020_03_02_at_3.15.06_pm.png
---
<p><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/screen_shot_2020_03_02_at_3.15.06_pm.png" alt="" width="40%" align="right" /></p>
<p class="p1">I was pondering a tweet from Aidan Cunniffe (<a href="https://twitter.com/aidandcunniffe">@aidandcunniffe</a>) over at&nbsp;<a href="https://www.useoptic.com/">Optic</a>&nbsp;they other day.&nbsp; He was expressing what he says is a&nbsp;<a href="https://twitter.com/aidandcunniffe/status/1229097618686513157">&ldquo;controversial opinion that keeps getting backed up by conversations. Each version of OpenAPI and JSON Schema map to ~15 versions. All the implementations by vendors, cloud providers, and open source libs implement a useful (but not always the same subset.&rdquo;</a>&nbsp;I don&rsquo;t think it is a controversial opinion at all, I think he points to a pretty critical deficiency in our belief around APIs and specifications like OpenAPI. Something that begins with the specification itself and how it evolves, but as Aidan points out, echoes out through API service and tooling providers, but then also across API providers themselves who put the OpenAPI specification as part of their own operations.&nbsp;</p>
<p class="p1">On Twitter, Aidan continues with, &ldquo;what is the point of a data-spec if it's not enforceable the same way, everywhere? We have to acknowledge that there's no one spec (a versioned markdown file doesn't count), there's 15, 20, 30, 50 of them in the wild today -- and that's blocking teams from using tooling end-end.&rdquo; Then continues by suggesting &ldquo;a wasm reference implementation that every vendor and lib could drop-in and link to across programming languages might actually solve this problem and truly enable end-end use of OpenAPI I'd make this objective #1 for 2020 if I had the keys. I just have the tweets :)&rdquo;. Makes sense to me, and I&rsquo;d say something that the OpenAPI community should adopt. Honestly, and I&rsquo;ve made the argument before, I think the OAI should be investing to stabilize core OpenAPI tooling, going beyond just the spec.&nbsp;</p>
<h3>Technical Solutions Require Business and Industry Political Understanding</h3>
<p class="p1">I support the technical solution Aidan puts forward, and would love to see investment across multiple providers to make happen. However, I think we will need to better understand the business and politics of it all to see the change we want&mdash;consistent support of the OpenAPI spec across services and tooling. What features are adopted as part of each service and tooling provider is more business and politics than it is technical, and the investment, or lack of investment into each commercial service or open source tooling is a reflection of the overall OpeAPI spec and it&rsquo;s road map. The technical details of the OpenAPI spec isn&rsquo;t easy to map out by itself, and how those details are adopted across a variety of commercial services, and open source tooling is exponentially more difficult&mdash;mapping out the business and politics of all of this is pretty near impossible, but let&rsquo;s give it a try.</p>
<h3>The Business and Politics of the OpenAPI Specification</h3>
<p class="p1">To understand the foundation of it all we have to consider the motivations of everyone involved in moving the OpenAPI specification forward. There are many different reasons why people are involved in the evolution of the API specification, and while it is pretty difficult to fully understand the motivations beyond everyone involved, it helps to acknowledge at a high level that there different business and political motivations at play, amongst stakeholders.</p>
<table width="100%">
<tbody>
<tr>
<td valign="top">
<ul>
<li><strong><a href="http://www.3scale.net/">3Scale</a></strong></li>
<li><strong><a href="https://42crunch.com/">42Crunch</a></strong></li>
<li><strong><a href="https://aapi.io/">AAPI</a></strong></li>
<li><strong><a href="https://www.ably.io/">Ably</a></strong></li>
<li><strong><a href="https://www.acumatica.com/">Acumatica</a></strong></li>
<li><strong><a href="http://apifortress.com/">APIFortress</a></strong></li>
<li><strong><a href="https://assertible.com/">Assertible</a></strong></li>
<li><strong><a href="https://www.atlassian.com/">Atlassian</a></strong></li>
<li><strong><a href="https://bitmovin.com/">BitMovin</a></strong></li>
<li><strong><a href="https://www.techatbloomberg.com/">Blomberg</a></strong></li>
<li><strong><a href="https://www.ca.com/">CA Technologies</a></strong></li>
<li><strong><a href="https://www.ebayinc.com/">eBay</a></strong></li>
<li><strong><a href="http://finxact.com/">Finxact</a></strong></li>
<li><strong><a href="http://www.google.com/">Google</a></strong></li>
<li><strong><a href="https://www.gov.uk/government/organisations/cabinet-office">HM Government</a></strong></li>
<li><strong><a href="http://www.ibm.com/">IBM</a></strong></li>
<li><strong><a href="http://www.ifs.com/">IFS</a></strong></li>
<li><strong><a href="https://www.imperva.com/">Imperva</a></strong></li>
<li><strong><a href="https://www.imperva.com/">Imperva</a></strong></li>
</ul>
</td>
<td valign="top">
<ul>
<li><strong><a href="https://inten.to/">Intento</a></strong></li>
<li><strong><a href="https://www.interzoid.com/">Interzoid</a></strong></li>
<li><strong><a href="http://www.isa.us.es/">ISA</a></strong></li>
<li><strong><a href="https://konghq.com/">Kong</a></strong></li>
<li><strong><a href="https://www.liferay.com/solutions/headless-apis">Liferay</a></strong></li>
<li><strong><a href="https://www.linksrez.com/">LinksRez</a></strong></li>
<li><strong><a href="http://www.microsoft.com/">Microsoft</a></strong></li>
<li><strong><a href="https://www.mulesoft.com/">Mulesoft</a></strong></li>
<li><strong><a href="http://www.nhsx.nhs.uk/">NHS</a></strong></li>
<li><strong><a href="https://apiary.io/">Oracle + Apiary</a></strong></li>
<li><strong><a href="https://www.reprezen.com/openapi">Repreen</a></strong></li>
<li><strong><a href="http://sap.com">SAP</a></strong></li>
<li><strong><a href="http://smartbear.com/">Smartbear</a></strong></li>
<li><strong><a href="http://www.softwareag.com/">Software AG</a></strong></li>
<li><strong><a href="http://stoplight.io/">Stoplight</a></strong></li>
<li><strong><a href="https://www.talend.com/">Talend</a></strong></li>
<li><strong><a href="https://teejlab.com/">TeejLab</a></strong></li>
<li><strong><a href="https://tyk.io/">Tyk</a></strong></li>
<li><strong><a href="https://wso2.com/">WSO2</a></strong></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p class="p1">I am not making any assumption regarding the motivations of any of these OAI members, merely acknowledging they have different business and political motivations. Adding another dimension, I think it is worth also knowing the weight each company wields as part of the OpenAPI conversation and road map, by sending a delegate for the OAI technical steering committee.&nbsp;</p>
<ul>
<li>Darrel Miller @darrelmiller - Microsoft</li>
<li>Jeremy Whitlock @whitlockjc - Google</li>
<li>Marsh Gardiner @earth2marsh - Google</li>
<li>Mike Ralphson @MikeRalphson - Mermade Software</li>
<li>Ron Ratovsky @webron - SmartBear</li>
<li>Uri Sarid @usarid - Mulesoft</li>
</ul>
<p class="p1">I know everyone on this list, and know they all have the best interest of the community in mind. I also know that like me, they work for a company, and have the best interest of that company in mind. Beyond the technical steering committee you also have the technical oversight board who can help resolve conflicts:</p>
<ul>
<li>Isabelle Mauny @isamauny</li>
<li>Uri Sarid @usarid</li>
<li>Marsh Gardiner @earth2marsh</li>
<li>Ron Ratovsky @webron</li>
</ul>
<p class="p1">Why each of the companies above are members of the OAI varies, and why each company has support their employees being on each of the technical committees isn&rsquo;t without reason. Again, I&rsquo;m not passing judgement about what their motivations are, just that they do bring business and political motivations that are either in alignment with the wider API community, or may have more alignment with commercial aspirations, both good and bad. All of these companies influence what the OpenAPI specification should be, and they also influence what services and tooling exist, or do not exist within the community, and how much of the OpeAPI specification each service and tool supports. These aren&rsquo;t purely technical decisions to support or not support all or part of the OpenAPI specifications. Consistent support of these features across tools begins with business considerations, like the amount of investment each service or tool gets, but then also have to do with the political climate that exists within the OpenAPI and wider API community.</p>
<h3>A Technical Base To Stabilize The OpenAPI Service and Tooling Space</h3>
<p class="p1">I support Aidan&rsquo;s request for a &ldquo;wasm [WebAssembly] reference implementation that every vendor and lib could drop-in and link to across programming languages&rdquo;. This would begin laying the necessary technical base for helping stabilize tooling, however I&rsquo;d say that we&rsquo;d also need the OAI to consider investing in some of the core tooling needed by all services and tooling. Socializing some of the essential tooling like parsers, generators, and validators, along with the specification will help further stabilize things&mdash;if developers know there is one first-class validator, parser, and generator, the confidence in the community goes way up. This will provide a nice base for services and tooling providers to work from, helping ensure 100% (or near) of the OpenAPI specification is supported by default across at least the essential areas of tooling, but it won&rsquo;t solve all of our problems. We are going to need more business investment in not just the core tooling areas, but also the long tail of solutions that are being offered across the sector.</p>
<p class="p1">This technical base for services and tooling, collectively investing in what is needed to standardize the adoption of the OpenAPI specification across commercial services and open source tooling. However, much more will be needed to actually incentivize, support, and certify the actual adoption of the OpenAPI specification across available services and tools. I know it sounds easy, but if you build the WebAssembly, and provide essential tooling, there is no guarantees that the companies and individuals behind services and tooling will actually implement them, and support 100% of the capabilities that OpenAPI provides. This is where the conversation moves beyond just the technical, and moves into the business and political realm. This is the part of the game that many technologists don&rsquo;t see, and because many business people who do get these things aren&rsquo;t aware of the technical details, there is a significant opportunity for a few savvy stakeholders to lead the way, and steer the ship.</p>
<h3>Defining Support For The OpenAPI Specification Across Services and Tools</h3>
<p class="p1">Shifting from the OpenAPI specification itself, and moving more towards the open source tooling that exists, or doesn&rsquo;t exist. I want to highlight the mix of business and politics that occurs within the open source tooling realm of the OpenAPI community. There are many different reasons why companies, organizations, and individuals invest in open source tooling that supports OpenAPI, and there are many varying levels of support for all or part of the OpenAPI specification. Take a look at a handful of the open source tooling that exists in the space, and think a little bit about why these tools exists, and who the individuals and companies behind each of them existing.</p>
<h3>Converters</h3>
<ul>
<li><strong><a href="https://github.com/googleapis/gnostic">Gnostic</a></strong> - A compiler for APIs described by the OpenAPI Specification with plugins for code generation and other API support tasks.</li>
<li><strong><a href="ttps://github.com/Mermade/oas-kit">OAS Kit</a></strong> - Convert Swagger 2.0 definitions to OpenAPI 3.0 and resolve/validate/lint.</li>
</ul>
<h3>Documentation</h3>
<ul>
<li><strong><a href="https://github.com/swagger-api/swagger-ui">Swagger UI</a></strong> - Swagger UI is a collection of HTML, Javascript, and CSS assets that dynamically generate beautiful documentation from a Swagger-compliant API.</li>
<li><strong><a href="https://github.com/Redocly/redoc/">Redoc</a></strong> - OpenAPI/Swagger-generated API Reference Documentation.</li>
<li><strong><a href="https://github.com/LucyBot-Inc/documentation-starter">LucyBot</a></strong> - Interactive REST API Documentation.</li>
</ul>
<h3>Editor</h3>
<ul>
<li><strong><a href="https://github.com/swagger-api/swagger-editor">Swagger Editor</a></strong> - A simple OpenAPI / Swagger editor.</li>
<li><strong><a href="https://github.com/mermade/openapi-gui">OpenAPI GUI</a></strong> - GUI / visual editor for creating and editing OpenAPI / Swagger definitions.</li>
<li><strong><a href="https://github.com/Apicurio/apicurio-studio">Apicurio</a></strong> - An open source API design editor.</li>
</ul>
<h3>Mocks</h3>
<ul>
<li><strong><a href="https://github.com/microcks/microcks">Microcks</a></strong> - Manage your micro-services and API mocks.</li>
<li><strong><a href="https://github.com/zalando/connexion">Connexion</a></strong> - Swagger/OpenAPI First framework for Python on top of Flask with automatic endpoint validation &amp; OAuth2 support.</li>
<li><strong><a href="https://github.com/danielgtaylor/apisprout">APISprout</a></strong> - Lightweight, blazing fast, cross-platform OpenAPI 3 mock server with validation.</li>
</ul>
<h3>SDKs</h3>
<ul>
<li><strong><a href="https://github.com/OpenAPITools/openapi-generator">OpenAPI Generator</a></strong> - OpenAPI Generator allows generation of API client libraries (SDK generation), server stubs, documentation and configuration automatically given an OpenAPI Spec (v2, v3).</li>
<li><strong><a href="https://github.com/swagger-api/swagger-codegen">Swagger CodeGe</a></strong> - swagger-codegen contains a template-driven engine to generate documentation, API clients and server stubs in different languages by parsing your OpenAPI / Swagger definition.</li>
</ul>
<p class="p1">Open source tooling is fraught with challenges, but the open source tooling build around Swagger and OpenAPI have a uniquely challenging past due to the robust number of tools that existed around version 2.0, and the acquisition of the name, spec, and tooling by SmartBear, then the resulting establishment of the OAI, OpenAPI, and the lukewarm investment in tooling that supports version 3.0. The current state of open source tooling around the OpenAPI, and the varying scopes of the OpenAPI specification that each tool supports is a direct reflection of the OpenAPI governance, participating companies, and a vacuum when it comes to overall leadership. I invested hundreds of hours into advocating in this space during the 2.0 evolution of the specification, but ended up burnt out by the time we got things into the foundation, and 3.0 emerged. Phil Sturgeon has done an amazing job evangelizing around 3.0, and publishing of his API.Tools, but ultimately this is too big of a thing for any individual to take on, and there needs to be some tooling investment by the OAI, and from its members.</p>
<h3>Mapping the OpenAPI Business and Political Landscape</h3>
<p class="p1">To help drive this conversation I have a few things I am working on to help map out what is going on. I think that Phil&rsquo;s OpenAPI.Tools helps us map the service and tooling landscape, but I want to better map out the corporate landscape of the OpenAPI community. I want to be able to see what companies are investing in the space, who is behind some of the tooling and better understand the business makeup of what is going on, while also trying to tune into where more of the politics are, and where I might be able to poke at to make some change. Here are some of the areas I&rsquo;m investing in when it comes to mapping out the landscape of the OpenAPI community.</p>
<ul>
<li><strong><a href="https://github.com/api-evangelist/openapi-support/blob/master/companies.md">Company Listing</a></strong>&nbsp;- List of all companies who are doing things with OpenAPI.</li>
<li><strong><a href="https://github.com/api-evangelist/openapi-support/blob/master/services.md">Service Listing</a>&nbsp;</strong>- List of all commercial services that use OpenAPI.</li>
<li><strong><a href="https://github.com/api-evangelist/openapi-support/blob/master/tools.md">Tool Listing</a>&nbsp;</strong>- List of all open source tooling that uses OpenAPI.</li>
<li><strong><a href="https://github.com/api-evangelist/openapi-support/blob/master/features.md">Feature Listing</a>&nbsp;-</strong>&nbsp;List of all features delivered by services and tools.</li>
<li><strong><a href="https://github.com/api-evangelist/openapi-support/blob/master/openapi-features.md">OpenAPI Feature Listing</a>&nbsp;</strong>- List of all the OpenAPI features available.</li>
</ul>
<p class="p1">I have a lot of this data laying around, but I am looking at moving it forward in isolation, to try and move forward the conversation when it comes to OpenAPI and the services and tooling that exists. While I feel like the OAI and the governance leadership is doing well when it comes to the specification, I feel like there is a huge void when it comes to leadership on the services and tooling front. Now that I have a full time job I am going to invest more time into this conversation, as part of my work with Postman, but also as part of more formal work with the OAI. I feel like I am one of the few people who see the business and political currents swirling around, and I feel like most people involved right now only are seeing the technical details, as well as the business considerations of the companies they represent. If we are going to drive the OpenAPI specification forward in a meaningful way that serves the entire community, we are going to need a lot more investment in herding all the cats forward in a more constructive direction when it comes to not just the specification, but also how it is used within a variety of industries, and how it is applied across the services and tooling that exists across the API landscape.&nbsp;</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/03/02/the-technology-business-and-politics-of-the-openapi-conversation/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/02/25/design-and-build-api-with-postman/">Design And Build Api With Postman</a></h3>
        <span class="post-date">25 Feb 2020</span>
        ---
published: true
layout: post
title: 'Design and Build API with Postman'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/braceros-domingo-ulloa-construction-crane-city.jpg
---
<img src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/braceros-domingo-ulloa-construction-crane-city.jpg" width="40%" align="right" style="padding: 15px;" /><p class="p1">I am doing more talks and workshops within enterprise organizations educating teams about designing and building APIs, helping Postman customers be more successful in not just using Postman, but in defining, designing, delivering, supporting, and evolving high quality APIs using Postman. 90% of the teams I work with are still build-first when it comes to delivering API capabilities across the enterprise, so we are invested in helping bring that number down. Empowering teams to go API-first when it comes to designing and building their APIs, moving beyond the more costly approach of writing code first, and develop more healthy practices that involve business and technical stakeholders in the process.</p>
<p class="p1">It is natural for developers to want to roll up their sleeves and begin coding to deliver an API. It is what they are trained to do. However, it makes a lot more sense to involve business stakeholders earlier on in the process, and avoid the costly, isolating, and more time intensive approach of purely approach APIs a writing code. API has been working internally, and with our most engaged customers to better define what an API-first workflow involving the following stops along the API life cycle:</p>
<ul>
<li><strong>APIs Builder </strong>- On the Postman platform, all APIs begin with the new APIs tab—the beta implementation of being able to manage the API life cycle within Postman.</li>
<li><strong>Create</strong> - You can create a new API by starting fresh, or importing an existing API definition in the OpenAPI, RAML, or GraphQL formats, and use it as the definition for each new API></li>
<li><strong>Definition</strong> - To change the design of an API, you can directly edit the OpenAPI, RAML, or GraphQL definition, manipulating the design of the API and the underlying schema.</li>
<li><strong>Mock</strong> - With an API definition you can then mock each API, providing a virtualized representation of each path, with examples returned as mocked responses.</li>
<li><strong>Environment</strong> - Defining key / value pairs and globals that can be used to authenticate and establish context for each API, providing one or many different ways to use an API.</li>
<li><strong>Document</strong> - Publishing modern API documentation for the API, providing human readable documentation including paths, parameters, schema, examples, and code snippets.</li>
<li><strong>Test</strong> - Investing in test suites that allow each API to be automated, orchestrated, and validated that it is delivering as expected, based upon a set of known outcomes.</li>
<li><strong>Monitor</strong> - Scheduling the regular monitoring and execution of APIs, and API-driven workflows, ensuring that they are run on a regular basis and in response to particular events.</li>
<li><strong>Share</strong> - Make an API available within organized workspaces that are targeting specific teams, making it available as collections, complete with environments that make them usable.</li>
<li><strong>Collaborate</strong> - Invite teams to collaborate around the designing and building of APIs, allowing business and developer stakeholders to be part of the overall API life cycle.</li>
</ul>
<p class="p1">This is intentionally an API life cycle that is inclusive to business stakeholders as well as developers. It is intentionally void of the bitter gritty technical details to make more accessible for business users, but also help developers consider the bigger picture. This is an API-first approach to designing and building APIs that can be then be developed and put to work in a production environment. This approach to delivering APIs centers on providing everything that is needed for business and technical stakeholders to work together to establish a complete definition of what each API should do, before it is actually realized by writing code or publishing to an API gateway. Providing an iterative workflow that can be repeated until all of the technical and business details of an API are well-defined, and approved by everyone involved.<span> </span></p>
<p class="p1">Designing and building APIs isn’t something that developers and IT groups do in isolation anymore. This process represents the evolution of and maturity of modern API infrastructure, and not just providing APIs, but delivering consistent and reliable APIs that meet business objectives. Postman is widely known amongst developers for being a dead simple tool for putting APIs to work, but it is also becoming where you design and build APIs. Providing not just API client tooling, but as you can see from the list above, a whole suite of stops along a modern API life cycle that helps organizations take control over how APIs are delivered across their teams. Establishing a common set of practices for how API infrastructure can be defined, delivered, and evolved at enterprise scale.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/02/25/design-and-build-api-with-postman/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/02/24/managing-api-secrets-using-postman-environments/">Managing Api Secrets Using Postman Environments</a></h3>
        <span class="post-date">24 Feb 2020</span>
        ---
published: true
layout: post
title: 'Managing API Secrets Using Postman Environments'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/birth-of-a-nation-P9180054.jpg
---
<img src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/birth-of-a-nation-P9180054.jpg" width="40%" align="right" style="padding: 15px;" /><p class="p1">Postman environments are machine readable definitions of design, development, staging, and production environments that can be used across API operations. When used properly they contain the keys, tokens, and other secrets needed for authorizing each individual, or collection of API requests. Making them an excellent place to begin getting more organized about how API secrets are applied, managed, and audited across teams. Secrets can also be littered throughout Postman collections, but when collections and environments are used properly, developers should be isolating secrets to environments, helping make sure Postman collections contain the technical details of the surface area of an API, but the unique values applied to each API is actually present as part of well defined Postman environments. Providing the opportunity for managing and governing how API secrets are being applied and stored by developers, and opening up the opportunity to use Postman as part of wider API governance efforts.</p>
<p class="p1">Environments are an essential building block to be considered as part of wider API governance strategy. Like Postman collection, environments will need the greatest amount of governance to inject the most observability, reliability, and security across API operations. When used right, Postman environments help isolate and standardize how secrets, PII, and other sensitive information is used across the delivery and integration of APIs. Allowing for centralized control over environments by leveraging Postman for the managementof environments through the interface and the API.</p>
<p class="p1"><strong>GUI</strong> - Managing all of the environments in use with the Postman web interface.</p>
<ul class="ul1">
<li class="li1"><strong><a href="https://api-evangelist.postman.co/me/environments">All Environments</a></strong> - Manually manage all of the environments in use using the central Postman web interface, allowing any member of governance to audit how environments are being used.</li>
</ul>
<p class="p1"><strong>API</strong> - Automating the management of environments using the Postman API, opening up the opportunity for auditing, managing, and enforcing governance at scale across the environments being applied by all enterprise teams engaging with API operations.</p>
<ul class="ul1">
<li class="li1"><strong><a href="https://docs.api.postman.com/?version=latest#d26bd079-e3e1-aa08-7e21-66f55df99351">All Environments</a></strong> - Programmatically pulling all environments via Postman API, so that they can evaluated separated.</li>
<li class="li1"><strong><a href="https://docs.api.postman.com/?version=latest#96c34392-1e36-d1cb-af89-1c95365184ab">Single Environment</a></strong> - Programmatically pulling a single environment, so that the details of the environment can be used.</li>
<li class="li1"><strong><a href="https://docs.api.postman.com/?version=latest#6517e0d6-3bc3-3da5-ab57-7a578a8504ce">Update Environment</a></strong> - Updating a single environment using the Postman API, providing centralized control over what environments contain.</li>
<li class="li1"><strong><a href="https://docs.api.postman.com/?version=latest#c943a79b-0c36-c003-5f22-1c8b1998188e">Delete Environment </a></strong>- Remove old and unused environments using the API, helping keep environments active and effective.</li>
</ul>
<p class="p1">The value of governing environments manually or automatically via the API is only as valuable as how consistently environments are used. If developers put secrets directly inside of collections then environment governance is diminished, but if governance dictates that all secrets should be managed using Postman environments than automated governance and management of Postman environments becomes much more effective. Governance of API secrets using Postman environment is heavily dependent on how Postman collections and environments are used, and is something that will increase in effectiveness as more governance is realized across operations.</p>
<p class="p1"><strong>Actions</strong> - Identifying some of the common actions that exist for governing environment usage across operations.</p>
<ul class="ul1">
<li class="li1"><strong>List Environments</strong> - Providing a list of all environments in use across operations.</li>
<li class="li1"><strong>Aggregate Variables</strong> - Aggregating variables that are in use across all environments.</li>
<li class="li1"><strong>Govern Variables</strong> - Evaluate and govern how variables are defined and used.</li>
<li class="li1"><strong>Scrub Secrets </strong>- Automatically scrub secrets that are published as part of environments.</li>
<li class="li1"><strong>Scrub PII </strong>- Automatically scrub PII that are published as part of environments.</li>
<li class="li1"><strong>Merge Environments </strong>- Merge one or more environments together into a single one.</li>
<li class="li1"><strong>Refresh Tokens </strong>- Automatically refresh tokens and turn over keys to maintain security.</li>
<li class="li1"><strong>Backup Environments </strong>- Backup environments to external locations and workspaces.</li>
<li class="li1"><strong>Sync Environments </strong>- Sync environments to external locations and workspaces.</li>
</ul>
<p class="p1">The proper usage of environments along with a healthy amount of manual and automated governance represents one of the greatest opportunities for helping secure and stabilize API operations. Isolating how secrets, PII, and other essential data is stored and applied across API operations. Which when combined with effective governance of collections, workspaces, and teams, makes for a pretty effective approach to not just defining how Postman gets used, but how APIs are used across an organization.</p>
<p class="p1">How API secrets are managed across API development teams is one of the biggest challenges that enterprise organizations will face in the next decade. The number of APIs and micro services is only growing, and developers are already creating, applying, storing and sharing these secrets in many different ways across their regular activities. Postman environments provide the opportunity for healthier governance of API secrets through two distinct dimensions, 1) consistently using Postman environments for storing and applying API secrets manually by developers as well as automatically via CI/CD pipeline tests, and 2) through centralized spidering, auditing, review, refresh, and cleanup of Postman environments through the Postman API. Making Postman environments the number on place enterprise security and compliance groups should be started when it comes to locking down how developers are managing and applying API secrets across enterprise operations.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/02/24/managing-api-secrets-using-postman-environments/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/02/24/content-negotiation-for-apis-and-the-web/">Content Negotiation For Apis And The Web</a></h3>
        <span class="post-date">24 Feb 2020</span>
        ---
published: true
layout: post
title: 'Content Negotiation for APIs and the Web'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/nazi_invasion_gears_pipes_plumbing.jpg
---
<img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/nazi_invasion_gears_pipes_plumbing.jpg" width="40%" align="right" style="padding: 15px;" /><p class="p1">APIs often seem like another one of those very technical acronyms that only the most technical people will care about. If you don’t aspire to be a software developer, why should you ever care about what application programming interfaces (APIs)? To push back on this notion I regularly push myself to make APIs more accessible to business users. I feel it is important that anyone who use the web daily as part of their professional career should possess a working understanding of the tool(s) they depend, and have a grip on how APIs aren’t some add-on to the World Wide Web we depend on each day--understanding that APIs and the web are one and the same. Over the last twenty years the web has became a fundamental aspect of how we do business online, and APIs are just the latest evolution of how the web is being put to use to use as part of the digital transformation businesses are going through across every business sector today.</p>
<p class="p1">The World Wide Web, commonly known as the Web, is an information system where documents and other web resources are identified by Uniform Resource Locators, which may be interlinked by hypertext, and are accessible over the Internet—with “documents and other web resources” being the bridge between APIs and the web. If you are using the web you can use APIs, as long as you understand one of the fundamental building blocks of the web--that you can negotiate “documents and other web resources” in the following information formats.</p>
<ul>
<li><strong><a href="https://en.wikipedia.org/wiki/HTML">Hyper Text Markup Language (HTML)</a></strong> - Each time you use the web you are getting and posting HTML documents using the Internet. HTML is a machine readable format that renders each web page you view, helping make easier for humans to read in a variety of languages. While you may not write HTML or directly “read” HTML, you are using HTML each day as you make your away around to different web sites and applications across your personal and professional lives.<span> </span></li>
<li><strong><a href="https://en.wikipedia.org/wiki/Comma-separated_values">Comma-Separated Values (CSV)</a></strong><span class="s2"> </span>- If you have used Microsoft Excel or Google Sheets it is likely you’ve imported or exported a CSV file, providing a portable machine readable document that contains data which is separated using commas. Storing data within a document that any spreadsheet or other application can open up the data and render it in a tabular field / row format. Striking a balance between data being structured and consumable by machines as well as human beings in a lightweight format.</li>
<li><strong><a href="https://en.wikipedia.org/wiki/PDF">Portable Document Format (PDF)</a></strong> - The PDF is a file format developed by Adobe in the 1990s to present documents, including text formatting and images, in a manner independent of application software, hardware, and operating systems. A format that survived the transition to the web, providing a common way of sharing text, images, and other graphics in a format that will render the same no matter who is viewing it—adding to the toolbox of data formats which can be shared online via simple web URLs.</li>
<li><strong><a href="https://en.wikipedia.org/wiki/XML">Extensible Markup Language (XML)</a></strong><span class="s2"> </span>- XML is a markup language that defines a set of rules for encoding documents in a format that is both human-readable and machine-readable. The design goals of XML emphasize simplicity, generality, and usability across the Internet, but has widely been used only within IT and developer circles when it comes to sharing data in a consistent way between systems using web technologies.</li>
<li><strong><a href="https://en.wikipedia.org/wiki/JSON">JavaScript Object Notation (JSON)</a></strong> - Provides an open-standard file format that uses human-readable text to transmit data objects consisting of attribute–value pairs and array data types. It is a very common data format, with a diverse range of applications, such as serving as replacement for XML in desktop, web, mobile, and device applications. Offering a more lightweight, but still machine and human readable format that can be used to define data, content, media, and other resources being transmitted via the web.</li>
</ul>
<p class="p1">These <a href="https://www.iana.org/assignments/media-types/media-types.xhtml">media types</a><span class="s2"> </span>are the fundamental building blocks of the web, and represent how we make data available using the web, allowing for consumers to access data via a simple URL. <a href="https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol">HyperText Transfer Protocol (<strong>HTTP)</strong></a>, the underlying protocol used by the World Wide Web and this protocol defines how messages are formatted and transmitted, and allows any web user to negotiate the format of the data they are accessing via a simple Uniform Resource Locator (URL), also known as a web address. You can negotiate to receive HTML, CSV, PDF, XML, or JSON data. While not all web sites offer all of these formats for each page, these are the most common formats in which data is made available via the web. Making data accessible via the web in a public or private way that anyone with the web address and proper credentials can view or download.</p>
<p class="p1">APIs are not just some new and exclusive thing for developers to access. APIs are just the next step in the evolution of the web, and those who are in the know, will have the edge over those who do not. There is no difference between APIs and the web. If you are using the web you are using APIs. You just either no how to negotiate the access you need to what you need, or you do not. HTML is designed to be human and machine readable. So are APIs. There is nothing standing between you and getting access to the data, content, media, and algorithms you will need in the course of your daily operations. APIs are not outside your reach, if you take the time to understand and stay in tune with what is happening behind the scenes of everything happening online today.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/02/24/content-negotiation-for-apis-and-the-web/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/02/19/the-caltech-university-api-landscape/">The Caltech University Api Landscape</a></h3>
        <span class="post-date">19 Feb 2020</span>
        ---
published: true
layout: post
title: 'The Caltech University API Landscape'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/caltech_campus_entrance_sign.jpg
---
<p><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/caltech_campus_entrance_sign.jpg" alt="" width="40%" align="right" /></p>
<p>I regularly take a look at what different universities are up to when it comes to their APIs. I spent two days talking with different universities at the University API summit in Utah a couple weeks back, and I wanted to continue working my way through the list of schools I am speaking with, profiling their approach to doing APIs, while also providing some constructive feedback on what schools might consider doing next when it comes to optimizing API delivery and consumption across campus.</p>
<p>Next up on m list is Caltech, who we have been having conversations with at Postman, and I wanted to conduct an assessment of what the current state of APIs are across the school. The university reflects what I see at most universities, meaning there are plenty of APIs in operation, but not any visible organized effort when it comes to bringing together all the existing APIs into a single developer portal, or centralizing API knowledge and best practices when it comes to the interesting API things going on across a campus, and with other partners and stakeholders.</p>
<h3>APIs in the Caltech Library</h3>
<p>When it comes to APIs at the University level the first place to start is always at the library, and things are no different at Caltech. While there is no official landing page specifically for APIs the Caltech library has GitHub page dedicated to a variety of programmatic solutions https://caltechlibrary.github.io/, but you can find many signals of API activity behind the scene, like this API announcement that the write API is available https://www.library.caltech.edu/news/write-api-now-operational. <a href="https://clarivate.com/webofsciencegroup/wp-content/uploads/sites/2/2019/10/WS357135774_Case-Study_Xpp_CaltechAPICashStudy_v7-1.pdf">You can also find an interesting case study on how the library is using APIs</a> provided by <a href="https://clarivate.com/webofsciencegroup/solutions/xml-and-apis/">an interesting API provider called Clarivate</a>, which I will be looking to understand further. As with every other university, there is a huge opportunity for Caltech to be more organized and public about the API resources offered as part of the library--even if it isn't widely available to the public, making everything API easy to find by faculty and students online helps a lot.</p>
<h3>Rich Datasets as APIs</h3>
<p>Another common pattern you see with API availability across higher eduction is that there are often rich datasets made available from across research that is occurring, and Caltech is no different. <a href="https://data.caltech.edu">You can find several hundred rich datasets out of Caltech, provided in a simple, browsable catalog</a> provided <a href="https://tind.io/">by Tind</a>, which like Clarivate, provides another service provider I'd like to dive into and learn about more. Most of the datasets Caltech publishes are available in a spreadsheet or CSV format, but also provide a rich place when it comes to simple API development. It doesn't take much for Tind, the platform behind Caltech datasets to make APIs available for all the datasets, or even make it a class project for students to work with Caltech data stewards to make each dataset available as a simple easy to use web API. Something that would reduce friction hen it came to putting the data to work, make the data more usable, while also potentially providing a learning opportunity for Caltech students when it comes to publishing APIs.</p>
<h3>Cataloging Existing Caltech APIs</h3>
<p>Beyond the library, and the low hanging fruit involving Caltech datasets, there are a number of really interesting APIs available at Caltech--the problem is they just aren't available as part of any organized API effort. When you spend time looking around Caltech's online presence for APIs there are two APIs that stand out.</p>
<ul>
<li><strong>NASA Exolanet Archive -</strong> The NASA Exoplanet Archive is an online astronomical exoplanet and stellar catalog and data service that collates and cross-correlates astronomical data and information on exoplanets and their host stars, and provides tools to work with these data. The archive is dedicated to collecting and serving important public data sets involved in the search for and characterization of extrasolar planets and their host stars. These data include stellar parameters (such as positions, magnitudes, and temperatures), exoplanet parameters (such as masses and orbital parameters) and discovery/characterization data (such as published radial velocity curves, photometric light curves, images, and spectra). 
<ul>
<li><strong><a href="https://exoplanetarchive.ipac.caltech.edu/docs/program_interfaces.html">Website</a></strong> - The website for the Exoplanet archive.</li>
<li><strong><a href="https://documenter.postman.com/view/35240/SzKSSeRR">Docs</a></strong> - Documentation I published using Postman.</li>
<li><strong><a href="https://www.postman.com/collections/db2b1b862a348d033505">Collection</a></strong> - A Postman collection for the API.</li>
</ul>
</li>
<li><strong>MIST</strong> - MiST 3.0 provides signal transduction profiles of more than 125,000 bacterial and archaeal genomes. This release of the database is a result of a substantial scaling to accommodate constantly growing microbial genomic data. 
<ul>
<li><strong><a href="https://mistdb.com/">Website</a></strong>&nbsp;- The website for the MiST database.</li>
<li><strong><a href="https://api.mistdb.caltech.edu/">Developer</a></strong> - The developer area for the MiST database.</li>
<li><strong><a href="https://documenter.postman.com/view/35240/SzKSSeRQ">Docs</a></strong> - Documentation I published using Postman.</li>
<li><strong><a href="https://www.postman.com/collections/1b631a5b275b243946d8">Collection</a></strong> - A Postman collection for the API.</li>
</ul>
</li>
</ul>
<p>It is very clear that there is some super valuable research coming out of Caltech, and the work it does with it's partners like NASA. With a little help these APIs could be made more discoverable and usable by the community. I spent some time crafting Postman collections for both of these APIs, and published documentation from them to show a little of what is possible. I'll be making more time to better organize them, and polish the documentation available for each, but ideally it is something that can be tackled on campus by administrators, faculty, or by students.</p>
<p>The NASA Exoplanet Archive and MIST are two shining examples of valuable APIs out of Caltech, but with just a little more searching you can find many others that should also be available as Postman collections with consistent documentation. While by no means an exhaustive search, here are few others that I came across as I was making my way through what is available from Caltech.</p>
<ul>
<li><strong>Caltech Electron Tomography Database </strong>- A public repository featuring 11293 electron tomography datasets of intact bacterial and archaeal cells, representing 85 species. 
<ul>
<li><a href="https://etdb.caltech.edu/"><strong>Website</strong></a></li>
</ul>
</li>
<li><strong>NASA/IPAC Infrared Science Archive</strong> - IRSA offers program-friendly interfaces to all of its holdings. Through an Application Program Interface (API), users can access IRSA data directly (within a script or on the command line) without the need to go through interactive web-based user interfaces. These APIs allow users to write software that can talk to IRSA's software to carry out queries and download data, with no user intervention.</li>
<li><strong>Finder Chart </strong>- Finder Chart is a visualization tool that allows cross-comparison of images from various surveys of different wavelengths and different epochs. 
<ul>
<li><a href="https://irsa.ipac.caltech.edu/applications/FinderChart/"><strong>Website</strong></a></li>
<li><a href="https://irsa.ipac.caltech.edu/onlinehelp/finderchart/api.html"><strong>Developer</strong></a></li>
</ul>
</li>
<li><strong>AstroPix</strong> - Images from telescopes around the world and in space are now at your fingertips. AstroPix is a new way to explore and share the universe. 
<ul>
<li><a href="https://astropix.ipac.caltech.edu/"><strong>Website</strong></a></li>
<li><a href="https://astropix.ipac.caltech.edu/page/developers"><strong>Developer</strong></a></li>
</ul>
</li>
</ul>
<p>After looking through the NASA/PIAC Infrared Science Archive I begin finding a bunch more single use APIs, and I'm sure there are many more buried across the rich research coming out of the institution. All of this should be available via a single Caltech owned landing page--something they could accomplish using GitHub, similar to what the Caltech library has already done for its other technical resources. Caltech has a rich set of APIs, you just wouldn't know it at first glance, but with a little investment the work going on across campus could be made more discoverable and usable across different web, mobile, device, and network applications.</p>
<h3>Further Investment in APIs at CalTech</h3>
<p>Caltech is doing APIs. That is clear. The only thing that is missing is a more deliberate and organized effort to publish and provide APIs across campus. This is something that every higher educational institution I am talking to struggles with, and it is something that can be corrected with just a little bit of investment by staff and students. I recommend beginning with just documenting what is already in motion, and investing in a handful of the common building blocks you need to be successful when it comes to making APIs available.</p>
<ul>
<li><strong>Portal</strong> - Publishing a single landing page and portal for accessing all APIs across campus. It is common to place this at developer.[university-domain].edu, providing a common known location where anyone can go to discover and learn about APIs at Caltech. Helping centralize APIs from across departments and external stakeholders, as well as knowledge, information, and communication around how to provide and consume APIs.</li>
<li><strong>Administrative APIs</strong> - Publish a section or page dedicated to campus IT and other administrative APIs that faculty can put to use. These APIs already are in existence and used by staff, they just aren't easy to find. They should all be defined using common machine readable formats like OpenAPI and Postman collections, and then published as documentation using Postman, or other open source API documentation format. Making APIs more accessible, even if you need approval and credentials to actually put to work as part of any integration or application.</li>
<li><strong>Research APIs </strong>- Next, gather up all of the research related APIs like what I have listed above, and beyond, and do the same as I just suggested for administrative APIs. Define them using OpenAPI and Postman collections, and then publish API documentation for all of them, making easily available via the centralized API portal. Making the distributed research that is occurring across campus more easily accessible by researchers and the general public.</li>
<li><strong>Student APIs </strong>- Once administrative and research APIs are well documented I recommend begin defining the APIs that might benefit students. Common APIs from other universities include access to course catalog, building locations, events calendar, and other resources that are relevant to students. Check out some of the other API programs available as part of my wider university API research for examples. Ideally, all web and mobile applications that students engage with should also be available via simple web APIs, allowing students to hack the systems they depend on as part of class work, or just out of a desire to improve upon the overall student experience on their own time.</li>
<li><strong>3rd Party APIs -</strong> Lastly, I recommend dedicating a section or page to the 3rd part APIs that are already in use, or would be available across campus. Some of the APIs I've seen showcased are Twitter, Dropbox, Google Drive, JSTOR, World Bank data, WordPress, and other common services in use today. Highlighting these 3rd party APIs alongside existing campus APIs helps faculty and students understand what is possible when it comes to developing applications and streamlining integrations.</li>
<li><strong>Resources</strong> - Provide a list of other resources that faculty and students can take advantage of when it comes to putting APIs to work. Ideally all APIs are well documented, and have Postman collections available for them, but it can also be helpful to provide code snippets, sandboxes, videos, tutorials, and other resources that will help people understand what is possible, and how they can put APIs to work.</li>
<li><strong>Showcase</strong> - Make sure and showcase how APIs are being put to use on campus and off. Try to highlight existing uses of APIs and the benefits they deliver via web, mobile, and device applications. Having the APIs is not enough. It helps stimulate the imagination to show what developers and non-developers are doing with API resources.</li>
<li><strong>Events</strong> - Provide a calendar of events regarding API and other relevant meetings, conferences, or external events that API providers and consumers will find interesting. If there are no events, start organizing them, and make sure there is always active discussion around how APIs are put to use on campus.</li>
<li><strong>Support</strong> - Publish the names and contact information for API advocates, champions, owners, and practitioners. Make forums, chats, and other communication channels easily accessible so that API providers and consumers can ask questions and get the help they need. The spread of information, and supporting existing API efforts is critical to growing and expanding the reach of APIs across campus.</li>
</ul>
<p>Start there. There will be more work down the road. But, publishing a single portal with documentation and definitions of administrative, research, student, and 3rd party APIs, as well as a handful of resources, showcase, events, and support for the API conversation will provide the base necessary for the API conversation to take root at Caltech. Now I am sure some folks are asking why? Why should there be more investment in APIs at Caltech? Let's take a crack at answer that in context of the four types of APIs that commonly exist across campus.</p>
<ul>
<li><strong>Administrative</strong> - Caltech already operates on digital infrastructure that possess APIs, and by further making these existing APIs more known, and leveraging them as part of campus operations, you have an opportunity to reduce friction and workload for staff, making their lives easier.</li>
<li><strong>Research</strong> - As demonstrated by the existing APIS coming out of Caltech, there is valuable data and research coming out of the institution. In a digital age you want this information easily available for use in new web, mobile, and device applications--APIs are how you do that.</li>
<li><strong>Students</strong> - APIs are how Internet connected web, mobile, and device applications work. Students are already using APIs when they browse the course catalog, sign up for classes, and pay tuition. By exposing them to what is going on behind the scenes of the applications they already use, and let them tinker and optimize their own experience, you are better preparing them for the digital world they'll be working in within just a couple years.</li>
<li><strong>3rd Party -</strong> Software as a service (SaaS) solutions are ubiquitous across our personal and professional lives. Services like Dropbox, Google Apps, WordPress, and others have APIs that allow us to more seamlessly integration these solutions into our lives, and enable us to take advantage of low code or no code solutions to orchestrate with these services. Introducing an opportunity to further reduce friction, and allow for the optimization of how faculty does their job, and also helping students be more successful in their studies.</li>
</ul>
<p>APIs are everywhere once you begin looking for them. At Caltech, and across the web we depend on each day. It isn't a question of whether or not Caltech should do APIs--they already are. It is a matter of whether the campus wants to be more organized in how they are doing APIs. Hopefully this research provides a look at some of the next steps Caltech could consider when it comes to doing APIs in a more organized fashion. This look at Caltech APIs isn't just about using Postman, it is about how Caltech can step up it's API game using Postman. I'm guessing Postman is already in use across campus IT and development staff. I'm also guessing there are students who are using Postman. The problem is that it is most likely just being used as an API client, allowing users to make calls to existing APIs, and debug the response. Once users realize they can also use it to mock, document, test, and make APIs more accessible and collaborative by publishing a documentation for common APIs, I predict the conversation will shift, and pick up momentum--it always does.</p>
<p>I am looking forward to further documenting the APIs coming out of Caltech, and talking with folks from different groups across campus. Like the other schools I am talking to they are up to some really interesting things--they just need to get better at documenting, showcasing, and telling stories about what is happening. Something Postman can help facilitate. <a href="https://github.com/api-evangelist/caltech">Next I am going to publish the two collections I have made to GitHub, and begin documenting some of the other APIs using Postman</a>. Once I have a better view of the Caltech API landscape I will spend more time thinking about how we can further jumpstart the API conversation with some administrative, student, and 3rd party API work. Ideally the school would setup a GitHub repository and landing page for API efforts, and then folks like me, or others on campus can submit pull requests to add APIs and other resources tot he central Caltech API portal. With some centralization of existing API activity, and stimulation of the API conversation using GitHub, you never know what you can se into motion when it comes the API journey at Caltech University.</p>
<ul>
</ul>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/02/19/the-caltech-university-api-landscape/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/02/14/api-interrogation/">Api Interrogation</a></h3>
        <span class="post-date">14 Feb 2020</span>
        ---
published: true
layout: post
title: 'API Interrogation'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/bf-skinner-hiding-monster-statue.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/bf-skinner-hiding-monster-statue.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">I was doing some investigation into how journalists are using APIs, or could / should be using APIs. After some quick Googling, Binging, and DuckDuckGoing, <a href="https://ire.org/events-and-training/event/2702/3064/">I came across a workshop by &nbsp;David Eads of ProPublica Illinois, called a A hitchhiker's guide To APIs</a>. As I began reading, I was struck by how well it captured not only usage of Postman in journalism, but also how well it captures what Postman does in general in a single precise sentence, &ldquo;In this hands-on session, you will use Postman to interrogate a web API.&rdquo; That is how I use Postman. That is why 10 million developers use Postman.<span>&nbsp;</span></p>
<p class="p1">APIs are how we can interrogate the digital world unfolding around us. It is increasingly how we can interrogate the digital world emerging across our physical worlds. I like the concept in general, but definitely think it is something I should explore further when it comes to journalism and investigative storytelling. Postman provides a pretty powerful way to get at the data being published by city, county, state, and federal government. It also provides a robust way to get at the social currents flowing around us on Twitter, Facebook, LinkedIn, and other leading platforms. Postman and APIs provides technical and non-technical users with what they need to target a source of data or content, authenticate, and begin interrogating the source for all relevant information.</p>
<p class="p1">I find that interrogating a startup is best done via their own API, as well as their digital presence via Twitter, LinkedIn, GitHub, Stack Overflow, Facebook, Youtube, and Instagram using APIs, over speaking with them directly. I find that interrogating a federal agency is often only possible through the datasets it publishes, providing me with a self service way to understand a specific slice of the how our society works (or doesn&rsquo;t). While I can interrogate a company, organization, institution, and government agencies using their websites, I find that also being able to interrogate their platform, operations, communities, industries and overall online presence using APIs provides a much more honest view of what is happening. Allowing me to read between the lines of what is occuring in real time, rather than relying on official marketing and communication channels for the official narrative.</p>
<p class="p1">Postman provides me with what I need to interrogate any API Uniform Resource Locator (URL) or Uniform Resource Identifier (URI) I come across. It allows me apply standard authentication methods, or replicate the existing cookie authenticate applied within the browser, and securely access online resources. Allowing me to fine tune the API requests I make, adjusting the parameters and headers, and dial in each request. It also lets me properly inspect each response, which allows me to assert control over much of the interrogation process. Postman reveals many of the silent elements of how the web works, which many of us are completely unaware of or just take for granted, which might also have significant influence over me getting access to the answers I am looking for. Postman allows me interrogate companies, organizations, institutions, and government agencies using the web, helping me find the information I need to do my job.</p>
<p class="p1">I will spend more time telling stories about how Postman can be used by journalists to interrogate data, content, and algorithmic resources. I will also use the word <span style="text-decoration: underline;">interrogation</span>&nbsp;more to describe what Postman does. Developers tend to dominate the discussion around how APIs are put to use in web, mobile, and device applications. However, I feel like the potential for less technical folks to put APIs to work is where the larger opportunities exsit. We just have to get better at telling stories that reach journalists, and other non-developer users and help them understand what APIs are, and how Postman can help them put APIs to work without writing code. I&rsquo;ll work on some more examples of how Postman can be used as part of a journalists toolbox, and find more examples of useful APIs that apply to what the type of investigative journalism happening today. Who knows, maybe I&rsquo;ll riff off of David Eads workshop, and provide some more hands on sessions showing how Postman can be used to interrogate a wide variety of APIs in support of journalism.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/02/14/api-interrogation/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/02/12/all-of-the-discussions-from-the-byu-api-university-workshop-in-utah/">All Of The Discussions From The Byu Api University Workshop In Utah</a></h3>
        <span class="post-date">12 Feb 2020</span>
        ---
published: true
layout: post
title: 'All of the Discussions from the BYU API University Workshop in Utah'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/university_api_workshop_1.jpg
---
<p><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/university_api_workshop_1.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">I went to Provo Utah a couple weeks ago and participated in <a href="https://ocio.byu.edu/university-api-winter-workshop">the sixth annual Brigham Young University (BYU) University API Workshop</a>. I was the keynote opener for the first edition of the conference, and I was the same for the sixth edition of the event bringing together many different universities together to talk about API usage across their campuses. When the event began it was primarily BYU staff, but it has expanded to include administrators and faculty from what I counted to be over twenty other universities from across the United States--making for a pretty interesting mix of conversation from higher education API practitioners looking to solve problems, and share their stories of how APIs have help make an impact at how universities serve students and the public.</p>
<p class="p1">The University API Workshop is an <em>&ldquo;unConference Focused on University &amp; Personal APIs &amp; Their Use in Improving Learning&rdquo;</em>. It brought together around one hundred folks to discuss a wide variety of API topics. Since it was an unconference, everyone pitched their own ideas, with some of them being about sharing API knowledge, while others was about soliciting knowledge from the other attendees. Resulting in a pretty compelling list of session spread across two days. You can browse through the sessions using the Google Docs that every session organizer published.<span>&nbsp;</span>Providing a pretty compelling look at how APIs are making an impact at the higher education level, shining a light on the concerns of API stakeholders across the campus.</p>
<p class="p1"><strong>Session One</strong></p>
<ul>
<li><a href="https://docs.google.com/document/d/1A6mkBWeimKB1bAmTjF_DjweVd-bbp4EHMxaIHr4DrOc/edit">Let&rsquo;s stop using usernames &amp; passwords</a></li>
<li><a href="https://docs.google.com/document/d/18T0XocZ-SaQk_InQHAH2pPw9y58B1BTvjcFmaBY6Ghs/edit">User Experience in the API World</a></li>
<li><a href="https://docs.google.com/document/d/1pTWt36zxtrhBCYoVSKTtEdEuwaliLgMmLhymCV5AtsI/edit">Postman Fundamentals</a></li>
<li><a href="https://docs.google.com/document/d/1ivL13v56JJ8hIxaSA9I7HDPcsszqEsToZxZiZRnQ5yw/edit">Securing APIs/data with proper authorization</a></li>
</ul>
<p class="p1"><strong>Session Two</strong></p>
<ul>
<li><a href="https://docs.google.com/document/d/17Y19-mGhcpLAJiYlEDBkrMrWNToPKai5QcyUJAX304E/edit">Walk, Talk, and API Stalk</a></li>
<li><a href="https://docs.google.com/document/d/1P8cMIv-urHPq2NAQEP5l4gknLk3BHUczK6jSbxMIA_E/edit">API Governance at Scale taking ideas to consistent execution</a></li>
<li><a href="https://docs.google.com/document/d/1Vb4oegcCn3SKbB9-B3s66umKsrp7c3jr18ZJT_JNciY/edit">Mendix (HPAPaaS/Low Code) After a Year at BYU</a></li>
<li><a href="https://docs.google.com/document/d/1Os89kKX8X8Na2eVnpa9MkgnnCaRtMsiniREyPp9mSik/edit">Our New NGDLE | Open Courses Made With Web Components, Microservices, Docker, CI/CD and more!</a></li>
<li><a href="https://docs.google.com/document/d/16FMnssWZ7ER8N4jpGll-TME4ZtpXD8-6m2Ol544sKlI/edit">DDD vs. BI - Balancing Centralizing and Decentralizing Forces in Data Architecture</a></li>
</ul>
<p class="p1"><strong>Session Three</strong></p>
<ul>
<li><a href="https://docs.google.com/document/d/1-hKYZzg2x_u-TPP72vbSAc3vHXpEBVJReD3AeF-3SHw/edit">How do I test APIs in Integration - Or How do I break your code</a></li>
<li><a href="https://docs.google.com/document/d/11zCTxc2xEOSBqTYHA8GQGMhsjoiAyC2rUh9nVY0AY5w/edit">Mobile Applications</a></li>
<li><a href="https://docs.google.com/document/d/1KU398y8dNGHzJv9taUlLyFZ17XyIeRYUHuuE2mqkAwQ/edit">Living with WSO2</a></li>
<li><a href="https://docs.google.com/document/d/1uciwex-JJ4KphtfShDZKsu-4KL_uwVGtw24otG32IbE/edit">SSI / Blockchain in Education</a></li>
<li><a href="https://docs.google.com/document/d/1rKhvpYVSEVLObrFk44IqYC4TPM_CeN94JI7sXofYFcY/edit">SSO Problems, Implementation, and Testing</a></li>
</ul>
<p class="p1"><strong>Session Four</strong></p>
<ul>
<li><a href="https://docs.google.com/document/d/17PIFfVXg5I54z4nZDyO-RAa_POasw87is9kyEAeYykk/edit">HAX + HAX cims</a></li>
<li><a href="https://docs.google.com/document/d/1lymdeI2S9HxYi3aX2Tf4_JDY7-VqSuULcPUoF1cJ6mg/edit">HATEOAS: What is this? Am I doing it right? How do I say this without sounding like an idiot?</a></li>
<li><a href="https://docs.google.com/document/d/1U-S6gQdCXnncwxQvbTSz9S56OFDbgcl4x_flDYw_p_U/edit">Giving my Things a Home Page</a></li>
<li><a href="https://docs.google.com/document/d/13-uxaX2wGvXVoeAFdF6BK-oR5vrsnOQGbUZCj7eN8Q8/edit">PII (Personally Identifiable Information) Visibility</a></li>
<li><a href="https://docs.google.com/document/d/16OctWLlQGpOLhmVUk9mnAsYmT4qNZwrCGCcXJ8OKzC8/edit">Do nothing for API versioning: Change my mind</a></li>
</ul>
<p class="p1"><strong>Session Five</strong></p>
<ul>
<li><a href="https://docs.google.com/document/d/1bgmVl5ATlwxzRcDL4QD5nhdk2zQUqG3POyqMVuz-YDI/edit">OpenAPI Enforcer (Truth enforced) (NodeJs)</a></li>
<li><a href="https://docs.google.com/document/d/17lXqREOcYX4FmZuaNpGI-R1bCd156Pf1d-fWis-OgRU/edit">Surf Sessions</a></li>
<li><a href="https://docs.google.com/document/d/1yiywJ8AX2aFsBSgcKVn_EmsUwsa6VhLpJ95q1bXfpgM/edit">Automating Support - Chatsbots et al</a></li>
<li><a href="https://docs.google.com/document/d/1RhKPQsMmVBR_WM3UJ1h_TJm14NfG6xYcjootU7yRbw8/edit">Docker Discussion (multi-stage builds)</a></li>
<li><a href="https://docs.google.com/document/d/1iFz2SGDnXK8jhJs-JDRXG30vdfE0A65Bu-FbF8xn-eQ/edit">Reclaim The API</a></li>
</ul>
<p class="p1"><strong>Session Six</strong></p>
<ul>
<li><a href="https://docs.google.com/document/d/19iMIYC5lNDAp7k29xHHI7HMeXbt_ux6OAFeSF-gLPdE/edit">Web Components and Microservices featuring Open-WC and LitElement</a></li>
<li><a href="https://docs.google.com/document/d/12TGi9EB-nMVkucu4X3y7AuAD9A-ui7t_l26j9v80BzI/edit">Modeling to Avoid Chaos</a></li>
<li><a href="https://docs.google.com/document/d/1KZEdAqqZuzO0X9RQDIUeivZWq_kvhe-aQORAZRAqTJA/edit">Document the PROs &amp; CONs of ad-hoc vs pre-defined fieldset authorization in APIs</a></li>
<li><a href="https://docs.google.com/document/d/1YB6aQHrc6YuKRT4OTNooHE-4ZomrwNQpnlLqC8H5mw4/edit">API&rsquo;s and Pi&rsquo;s: Using distributed architectures and API&rsquo;s to solve edge problems with commodity hardware. What are you doing?</a></li>
</ul>
<p class="p1"><strong>Session Seven</strong></p>
<ul>
<li><a href="https://docs.google.com/document/d/1j0iOL4ejQ62Na21jeXTSTF22xqN3WbXHrC0ftpBS29w/edit">Distributed API/Distributed Token</a></li>
<li><a href="https://docs.google.com/document/d/1sT3FsnYWMTcGr6mtdAkK93dCaDEShl6FfL0mC9ln0Qk/edit">Meditating on: The How and Why of API</a></li>
<li><a href="https://docs.google.com/document/d/15LDTjUy5IQ3dW49neq-xOIAC7TMWago4dECTLqZxFSM/edit">Virtual team roles using student employees for agile and devops delivery</a></li>
<li><a href="https://docs.google.com/document/d/1XwebVWSEaw1RovMlu1jbyIXoyfPBkhRUjVPpT8oJxgw/edit">Securing APIs/Data With Proper Authorization (i.e. How BYU uses The_ABACUS for authorization</a></li>
<li><a href="https://docs.google.com/document/d/1ruU_jRfTD_79w8NAXrWemrjHlEA_5r1Jb-_6jpl4BTg/edit"> the web / install - debug - find issues</a></li>
</ul>
<p class="p1"><strong>Session Eight</strong></p>
<ul>
<li><a href="https://docs.google.com/document/d/1j8t3rj3Ku9cU2qmGIhDA8kNhz5a_AozDa7HgsKpV6UU/edit">A new Definition of DDD:<span>&nbsp; </span>Data, Discovery, and Delivery</a></li>
<li><a href="https://docs.google.com/document/d/1dAMz2btZd6JxfVVHble-vuauHKAuH_cM98MvWqG8b8w/edit">Learning how to build APIs</a></li>
<li><a href="https://docs.google.com/document/d/1VGXMGgDunJAa2jXzjemwwjjFJlc5_Z7bDz3O8L2e9gA/edit">What&rsquo;s Behind The API?</a></li>
<li><a href="https://docs.google.com/document/d/1bN99FvfUJ9X8gYexq8FQFQhJ0pdi3gQkMxMCL5QYKz0/edit">Alexa and APIs</a></li>
</ul>
<p class="p1"><strong>Session Nine</strong></p>
<ul>
<li><a href="https://docs.google.com/document/d/1eX_D3Wn0WY4Kl50A8U-uzziDOlA2ZMlnVOQvw7Yuvc0/edit">Fast to Develop, Cheap to Maintain (Mendix Demo)</a></li>
<li><a href="https://drive.google.com/drive/folders/1up9BAh9Fj1z6R5Ng1b5KJHYw_LTkaYaC">Reclaim the API (Part II) Electric Boogaloo</a></li>
<li><a href="https://docs.google.com/document/d/1CFuP89ELQ5aMY16AM6mAK8gDYs2ukXkeIspk5B_LIUY/edit">2nd chance: Give your Things a Home Page</a></li>
<li><a href="https://docs.google.com/document/d/1SXv20DUwYo6tCCx7Mr5mhJfCnDG1MYDpq1pWsyIZVEc/edit">Account Creation - Preventing Duplicates</a></li>
<li><a href="https://docs.google.com/document/d/1aKvPWas_RJS2pT2mtrC_Pf48mc0NKXspceJQxjzS2TM/edit">REST. Get over it</a></li>
</ul>
<p class="p1">The titles don&rsquo;t do all of the discussions justice, so make sure and peek inside each of the Google Docs. I participated in as many of the talks as I could and will be doing additional posts on my Postman talk, Reclaim the API, API governance, and the Raspberry Pi session. I think overall the gathering provides a pretty compelling look into the university API landscape and showcases the challenges they face, and the problems they are looking to solve. In my experience universities aren&rsquo;t always the best at telling the stories of the interesting things they are working on across campus, so this type of event is critical for helping us better understand the university API landscape.</p>
<p><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/university_api_workshop_2.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">A small API event like this in Utah is easy for many API folks in the mainstream to dismiss, but I hold this event, and what the BYU team up at the same level as just about any other event I attend as part of my global work on APIs. BYU&rsquo;s CIO Kelly Flanagan (and team) has carved out the space for API exploration across campus in a way I have not seen anywhere else. I&rsquo;m not <span id="docs-internal-guid-bf9eff9d-7fff-c7c3-40eb-24520685fe6e"><span>exaggerating</span></span>. Sure, startups like Twilio and Stripe are rocking APIs, but there is no other institution, government agency, or enterprise organization I&rsquo;ve seen that has issued an API mandate like Kelly Flanagan has. If you want to truly understand the successes and challenges of doing APIs at scale across a large organization I recommend talking with the BYU team, and participating in one of the University of API gatherings&mdash;I am still learning from them after a decade of API Evangelist, and six years of being exposed to what their teams are up to.</p>
<p class="p1">BYU is already planning the edition of the event so feel free to reach out to them and get involved. I&rsquo;m determined to get more universities involved and learn from what is happening in Utah. If you are just beginning your API journey at your school, or are curious about what it takes to jumpstart the API conversation I recommend being present next year. The event is picking up momentum, and has something for everyone. You don&rsquo;t have to be a technical person to get involved. While some of the discussions are more technical, there is plenty of discussion around how APIs impact the average administrator, faculty, or student. I am going to be reaching out to more schools to get more universities represented, so if you have any ideas of who I should be reaching out to please let me know. The University of API conversation is one of the most important API discussions we need to be having in the coming decade, and it is a conversation that will continue to make an exponential impact on how our world works by equipping future generations with the tools they need to be successful in this digital world we've unleashed.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/02/12/all-of-the-discussions-from-the-byu-api-university-workshop-in-utah/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/02/11/postman-governance-as-the-foundation-for-wider-api-governance/">Postman Governance As The Foundation For Wider Api Governance</a></h3>
        <span class="post-date">11 Feb 2020</span>
        ---
published: true
layout: post
title: 'Postman Governance as the Foundation for Wider API Governance'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/stalin-time-supreme-court_36341562380_o.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/stalin-time-supreme-court_36341562380_o.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">This an overview of possible strategies for governing how Postman is used across a large organization. It is common for Postman to be already in use across an organization by individuals operating in isolation using a free tier of access. Governance of not just Postman, but also the end to end API life cycle begins with getting all developers using Postman under a single organizational team, working across master planned workspaces. If there are concerns about how Postman is being used across an enterprise organization, governance of this usage begins by focusing on bringing all enterprise Postman users together under a single license, and team, so that activity can be managed collectively.</p>
<h3>Postman Users</h3>
<p class="p1">Over the last five years Postman has become an indispensable tool in the toolbox of developers. 10 million developers have downloaded the application and are using it to authorize and make requests to APIs then debug the responses. The benefit to API operations for the enterprise is clear, but the challenge now for enterprise organizations is to identify their individual Postman users and encourage them to operate under a single pro, team, or enterprise license.<span>&nbsp;</span></p>
<p class="p1">Currently users are operating in isolation, defining, storing, and applying secrets and PII locally on their own workstations within Postman, and syncing to the cloud as part of their regular usage of Postman&mdash;isolating details about APIs, secrets, potentially PII, and other sensitive data within these three areas.</p>
<ul class="ul1">
<li class="li1"><strong><a href="https://api-evangelist.postman.co/workspaces">Personal Workspaces</a></strong>&nbsp;- Storing collections, and environments within their localized personal workspaces and individual Postman account.</li>
<li class="li1"><strong><a href="https://api-evangelist.postman.co/me/collections">Personal Collections</a></strong>&nbsp;- Developing API collections in isolation, leaving them inaccessible to other teams, and reusable across operations.</li>
<li class="li1"><strong><a href="https://api-evangelist.postman.co/me/environments">Personal Environments</a></strong>&nbsp;- Using environments to store secrets, PII, and other data within their localized personal workspaces and individual Postman account.&nbsp;</li>
</ul>
<p class="p1">When it comes to enterprise API governance, observability, and security, the problem isn&rsquo;t with Postman being used by developers, the problems is developers are not using Postman together under a single license, across managed shared workspaces. Putting individual developers into Postman teams, and incentivizing them to collaborate and share Postman collections and environments, while also making everything observable through centralized auditing and governance.</p>
<p class="p1"><strong>Actions</strong> - Identifying some actions that can be taken to begin evolving users towards centralized governance.</p>
<ul class="ul1">
<li class="li1"><strong>Identify Users</strong> - Understand who is already using Postman, and begin considering how to bring them under a single license.</li>
<li class="li1"><strong>Educate Users</strong> - Once users are identified, then they can be made aware of efforts to use Postman in more organized way.</li>
</ul>
<p class="p1">Individual users of Postman within the enterprise are ground zero for governance efforts. API governance and Postman governance will overlap. But it will all depend on bringing together individual users underneath a single team, and getting them to work in concert across many managed Postman workspaces. Getting more organized when it comes to how Postman is being put to work across the enterprise.</p>
<h3>Postman Teams</h3>
<p class="p1">To realize governance of Postman usage, and how APIs are delivered and consumed across the enterprise all Postman users should be added to a centralized Postman team, allowing for more visibility into API operations, and control over how individual users are working.<span>&nbsp; </span>Postman provides a variety of UIT tooling for managing teams underneath pro, team, or enterprise access tiers.</p>
<ul class="ul1">
<li class="li1"><strong><a href="https://api-evangelist.postman.co/settings/team/manage-invite-links">Invites (UI)</a></strong>&nbsp;- Inviting all individual users to operate under a single team.</li>
<li class="li1"><strong><a href="https://api-evangelist.postman.co/team">Members (UI)</a></strong>&nbsp;- Managing the members of teams, bringing all users under a single license.</li>
<li class="li1"><strong><a href="https://api-evangelist.postman.co/settings/team/roles">Roles (UI)</a>&nbsp;</strong>- Properly define the rules of each user when they are added to a team.</li>
<li class="li1"><strong><a href="https://api-evangelist.postman.co/team/activity">Activity (UI)</a>&nbsp;</strong>- Tuning into the activity for all users who have been added to a team.</li>
</ul>
<p class="p1">Currently there is no API for managing teams, but the Postman web account provides what is needed to invite users, manage team members, and maintain administrative control through role and activity management. Setting up other actions that can be taken to govern Postman usage and how enterprise users are putting Postman to work as part of their daily work.<span>&nbsp;</span></p>
<p class="p1"><strong>Actions</strong> - Identifying some actions that can be taken begin governing individual Postman users under one team.</p>
<ul class="ul1">
<li class="li1"><strong>Invite Users </strong>- Invite individual new and existing Postman users to a designated team.</li>
<li class="li1"><strong>Manage Roles </strong>- Effectively define and assign roles to team members for an organization.</li>
<li class="li1"><strong>Audit Users </strong>- Regularly review and audit team members to understand an individuals usage.</li>
<li class="li1"><strong>Remove Users </strong>- Remove any inactive users, and manage team membership regularly.</li>
</ul>
<p class="p1">Defining a centralized team helps establish visibility into what users are doing, and what they have access to. Providing the foundation for how Postman, and wider API governance can be realized across operations. Connecting the dots between all the individual Postman users, applying roles and access control, and allowing for additional Postman runtime features to be used in concert, instead of in isolation.<span>&nbsp;</span></p>
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/stalin-time-supreme-court-columns.jpg" alt="" width="40%" align="right" /></p>
<h3>Postman Workspaces</h3>
<p class="p1">Like teams, Postman workspaces allow for not just better organizing team members, but also the artifacts they will be working on to define the APIs they are delivering or consuming. Providing another dimension to how APIs and Postman can be governed, made more observable, providing more awareness and control over how APIs are moved along throughout the API life cycle, and how existing APIs are consumed as part of the integration process.</p>
<p class="p1"><strong>GUI</strong> - You can manage team workspaces through he Postman web interface, defining how team members work together.<span>&nbsp;</span></p>
<ul class="ul1">
<li class="li1"><strong><a href="https://api-evangelist.postman.co/workspaces?type=team">All Workspaces</a></strong><span>&nbsp;&nbsp;</span>- Manage all the workspaces through the Postman web interface.</li>
<li class="li1"><strong><a href="https://api-evangelist.postman.co/settings/team/general">Workspace Settings</a></strong> &nbsp;- Understanding and configuring all the workspace settings properly.</li>
<li class="li1"><strong><a href="https://api-evangelist.postman.co/settings/team/roles">Workspace Roles</a></strong>&nbsp;- Tuning into what all of the workspace roles are for use across teams.</li>
</ul>
<p class="p1"><strong>API</strong> - You can also automate the management and governance of operations using the Postman teams API.</p>
<ul class="ul1">
<li class="li3"><span class="s3"><strong><a href="https://docs.api.postman.com/?version=latest#5b53aa96-042d-4bc2-8c85-c10bc7ea0553">All Workspaces</a></strong>&nbsp;- Programmatically pull all workspaces.</span></li>
<li class="li3"><span class="s3"><strong><a href="https://docs.api.postman.com/?version=latest#feefc577-d86b-4a71-8c06-9816e0df970d">Single Workspace</a></strong>&nbsp;- Programmatically pull a single workspace.</span></li>
<li class="li3"><span class="s3"><strong><a href="https://docs.api.postman.com/?version=latest#34edebd3-8a53-4927-8ed6-4874a298c2e3">Update Workspace</a></strong>&nbsp;- Programmatically manage and update a single workspace.</span></li>
<li class="li3"><span class="s3"><strong><a href="https://docs.api.postman.com/?version=latest#ebba8fd1-da24-4987-aa3a-00d803baee93">Delete Workspace</a></strong>&nbsp;- Remove old and unused workspaces.</span></li>
</ul>
<p class="p1"><strong>Actions</strong> - Identifying some of the actions that can be taken to govern how collections and environments are accessed and stored.</p>
<ul class="ul1">
<li class="li1"><strong>Audit Workspaces </strong>- Audit the purpose and usage of an individual workspace.</li>
<li class="li1"><strong>Define Workspaces </strong>- Define workspaces as part of overall governance activities.</li>
<li class="li1"><strong>List Workspace Collections </strong>- List the collections that exist within a single workspace.</li>
<li class="li1"><strong>List Workspace Environments</strong> - List the environments that exist within a single workspace.</li>
<li class="li1"><strong>Backup Collections in Workspaces </strong>- Backup collections that exist within a workspace.</li>
<li class="li1"><strong>Backup Environments in Workspaces</strong> - Backup environments that exist within a workspace.</li>
<li class="li1"><strong>Sync Collections in Workspaces</strong> - Sync collections between workspaces.</li>
<li class="li1"><strong>Sync Environments in Workspaces</strong> - Sync environments between workspaces.</li>
<li class="li1"><strong>Manage Workspace Members &amp; Roles </strong>- Regularly manage workspace members and their roles.</li>
<li class="li1"><strong>Clean Up Unused Workspaces</strong> - Actively clean up workspaces that are no longer being used.</li>
</ul>
<p class="p1">Postman workspaces are designed to keep teams working on collections, and applying environments logically organized and protected with teams and workspace roles and access management. Thoughtfully defining spaces that reflect how teams are structured, lines of business operate, and how products or services are delivered. Providing manual and automated management of workspaces is critical for realizing governance across teams.</p>
<h3>Collections</h3>
<p class="p1">Collections are how individual requests are organized and then access by developers, and executed as part of CI/CD pipelines as well as using monitors. Ideally collections are defined, developed, and evolved in concert, and reused across teams using workspaces, instead of completely within the isolation of each individual users personal account. With team and workspaces setup, collections can then be organized in more useful ways that are in alignment overall governance. With a handful of ways to manage via the web interface, and further automate using the Postman API.</p>
<p class="p1"><strong>GUI</strong> - Managing all collections and access control for team members via the Postman web interface.</p>
<ul class="ul1">
<li class="li1"><strong><a href="https://api-evangelist.postman.co/me/collections">All Collections</a></strong> - Quickly getting at a list of all collections in the web UI.</li>
<li class="li1"><strong><a href="https://api-evangelist.postman.co/settings/team/roles">Collection Roles</a></strong> - Being able to manage the roles associated with collections.</li>
</ul>
<p class="p1"><strong>API</strong> - Automating the management of our collections using the Postman API.</p>
<ul class="ul1">
<li class="li3"><span class="s3"><strong><a href="https://docs.api.postman.com/?version=latest#3190c896-4216-a0a3-aa38-a041d0c2eb72">All Collections</a></strong>&nbsp;- Pulling all collections via the Postman API.</span></li>
<li class="li1"><strong><a href="https://docs.api.postman.com/?version=latest#647806d5-492a-eded-1df6-6529b5dc685c">Single Collections</a></strong> &nbsp;- Pulling details of single collection using the Postman API.</li>
<li class="li3"><span class="s3"><strong><a href="https://docs.api.postman.com/?version=latest#aa3701e8-7f99-b421-7d74-0d571b051f3c">Update Collection</a></strong>&nbsp;- Update the details of a collection using the aPI.</span></li>
<li class="li3"><span class="s3"><strong><a href="https://docs.api.postman.com/?version=latest#af648b8e-236c-b9e8-dd6c-3d7058d5c04b">Delete Collection</a></strong>&nbsp;- Delete a collection using the API.</span></li>
</ul>
<p class="p1"><strong>Actions</strong> - Identifying some of the actions that can be taken when governing collections being defined, developed, and ran across operations.</p>
<ul class="ul1">
<li class="li1"><strong>List Collections </strong>- Pulling all collections that exist across workspaces.</li>
<li class="li1"><strong>Discover APIs</strong> - Searching and discovering APIs defined within collections.</li>
<li class="li1"><strong>Backup Collection </strong>- Backing up collections to other locations and workspaces.</li>
<li class="li1"><strong>Sync Collection </strong>- Automatically syncing collections to other locations and workspaces.</li>
<li class="li1"><strong>Scan Collection </strong>- Look inside of collection for specific patterns and data points.</li>
<li class="li1"><strong>Scrub Collection</strong> - Scrub secrets, PII, and other sensitive data from within collections.</li>
<li class="li1"><strong>Extract Tests </strong>- Pull tests from collections and publish them to centralized location.</li>
<li class="li1"><strong>Validate Collection</strong> - Ensure that collections are compliant with any governance rules.</li>
<li class="li1"><strong>Identify Unused Collections </strong>- Find and flag collections that are no longer being used.</li>
<li class="li1"><strong>Enforce Encryption</strong> - Make sure the https is being used by default across all collections.</li>
<li class="li1"><strong>Cleanup Collection</strong> - Remove collections that are not longer being used by teams.</li>
</ul>
<p class="p1">As the number of collections grow across a team and an organization, the need to automate the governance of collections will only increase. Going beyond what is possible via the Postman web and desktop interfaces to govern how APIs are delivered and consumed, with collections as the defining artifact. Establishing visibility and control over how all teams are working with APIs, and injecting governance into how teams work.</p>
<h3>Postman Environments</h3>
<p class="p1">Environments are the final building block to be considered as part of wider API and Postman governance. Like collection, environments will need the greatest amount of governance to provide the most observability, reliability, and security across API operations. When used right, Postman environments help isolate and standardize how secrets, PII, and other sensitive information is used across the delivery and integration of APIs. Postman allows for the management of environments through the interface and the API.</p>
<p class="p1"><strong>GUI</strong> - Managing all of the environments in use with the Postman web interface.</p>
<ul class="ul1">
<li class="li1"><strong><a href="https://api-evangelist.postman.co/me/environments">All Environments</a></strong>&nbsp;- Manually manage all of the environments in use.</li>
</ul>
<p class="p1"><strong>API</strong> - Automating the management of environments using the Postman API.</p>
<ul class="ul1">
<li class="li3"><span class="s3"><strong><a href="https://docs.api.postman.com/?version=latest#d26bd079-e3e1-aa08-7e21-66f55df99351">All Environments</a></strong>&nbsp;- Programmatically pulling all environments via Postman API.</span></li>
<li class="li3"><span class="s3"><strong><a href="https://docs.api.postman.com/?version=latest#96c34392-1e36-d1cb-af89-1c95365184ab">Single Environment</a></strong>&nbsp;- Programmatically pulling a single environment.</span></li>
<li class="li3"><span class="s3"><strong><a href="https://docs.api.postman.com/?version=latest#6517e0d6-3bc3-3da5-ab57-7a578a8504ce">Update Environment</a></strong>&nbsp;- Updating a single environment using the Postman API.</span></li>
<li class="li3"><span class="s3"><strong><a href="https://docs.api.postman.com/?version=latest#c943a79b-0c36-c003-5f22-1c8b1998188e">Delete Environment</a></strong>&nbsp;- Remove old and unused environments using the API.</span></li>
</ul>
<p class="p1">The value of governing environments manually or automatically via the API is only as valuable as how consistently environments are used. If developers put secrets directly inside of collections then environment governance is diminished. But if governance dictates that all secrets should be managed using Postman environments than automated governance and management of Postman environments becomes much more effective.</p>
<p class="p1"><strong>Actions</strong> - Identifying some of the common actions that exist for governing environment usage across operations.</p>
<ul class="ul1">
<li class="li1"><strong>List Environments</strong> - Providing a list of all environments in use across operations.</li>
<li class="li1"><strong>Aggregate Variables</strong> - Aggregating variables that are in use across all environments.</li>
<li class="li1"><strong>Govern Variables</strong> - Evaluate and govern how variables are defined and used.</li>
<li class="li1"><strong>Scrub Secrets </strong>- Automatically scrub secrets that are published as part of environments.</li>
<li class="li1"><strong>Scrub PII </strong>- Automatically scrub PII that are published as part of environments.</li>
<li class="li1"><strong>Merge Environments </strong>- Merge one or more environments together into a single one.</li>
<li class="li1"><strong>Refresh Tokens </strong>- Automatically refresh tokens and turn over keys to maintain security.</li>
<li class="li1"><strong>Backup Environments</strong> - Backup environments to external locations and workspaces.</li>
<li class="li1"><strong>Sync Environments </strong>- Sync environments to external locations and workspaces.</li>
</ul>
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/stalin-time-statue-supreme-court.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">The proper usage of environments along with a healthy amount of manual and automated governance represents one of the greatest opportunities for helping secure and stabilize API operations. Isolating how secrets, PII, and other essential data is stored and applied across API operations. Which when combined with effective governance of collections, workspaces, and teams, makes for a pretty effective approach to not just defining how Postman gets used, but how APIs are used across an organization.</p>
<h3>Postman Runtime Governance</h3>
<p class="p1">The governance of Postman usage, as well as the overall API life cycle begins with the establishment of a Postman team, and the aggregation of all individual Postman users underneath that team. Then you can begin to define workspaces that reflect organizational objectives around how teams are structured, lines of businesses operate, and projects, products, and services are delivered. With all of this in motion, the wider governance of the API life cycle, and how developers, testers, QA, DevOps, and other roles are using Postman becomes possible. Enabling teams to collaborate and work together within designated teams and workspaces, allowing them to be as organized and efficient as possible when it comes to how APIs are delivered and consumed across the enterprise.<span>&nbsp;</span></p>
<p class="p1">Governance does not just happen. Effective governance takes laying the groundwork for how APIs are delivered and consumed. Postman is a ubiquitous tool across the enterprise API landscape, making it the best place to start when it comes to governance. Making Postman governance, and the thoughtful, well-planned defining and management of Postman users, teams, workspaces, collections, and environments where every organization should be starting when it comes to API governance. If you are effectively governing Postman, then you have the groundwork laid for effectively governing the entire API life cycle. Providing the observability needed to understand how teams are working (or not), while incentivizing collaboration, reuse, and governance of all the key artifacts that are in use across the API factory floor across the enterprise.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/02/11/postman-governance-as-the-foundation-for-wider-api-governance/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/02/11/conducting-api-weaponization-audits/">Conducting Api Weaponization Audits</a></h3>
        <span class="post-date">11 Feb 2020</span>
        ---
published: true
layout: post
title: 'Conducting API Weaponization Audits'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/nazi-invasion-surveillance-cameras_36569244062_o.jpg
---
<img src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/nazi-invasion-surveillance-cameras_36569244062_o.jpg" width="40%" align="right" style="padding: 15px;" /><p class="p1">I’ve been thinking about <a href="https://principlesofchaos.org/?lang=ENcontent">chaos engineering</a> lately, the discipline of experimenting on a software system in production in order to build confidence in the system's capability to withstand turbulent and unexpected conditions. I listened to a talk by Kolton Andrus the CEO of Gremlin the other day, and my partner in crime at Postman Joyce (<a href="https://twitter.com/petuniagray">@petuniagray</a>) is an avid evangelist on the subject. So I have been thinking about the concept, how it applies to your average enterprise organization, and the impact it could make on the way we operate our platforms. I don’t think chaos engineering is for every company, but I think there are lessons involved in chaos engineering that are relevant for every company. Similarly I think we need an equal approach in the area of weaponization, and how APIs can easily be used to harm a platform, its community, and the wider public—a sort of weaponization audit.</p>
<p class="p1">Let’s take what we’ve learned from Twitter, Facebook, Youtube, and others. Let’s look at the general security landscape, but let’s get more creative when it comes to coloring within the lines of an API platform, but in unexpected ways. Let’s get women and people of color involved. Let’s focus on ways in which a platform can be abused. Using the web, mobile, device, or APIs underneath. I’d like to consider security, privacy, reliability, observability, as well as out of the box ways to game the system. Let's assume that nobody can be trusted, but recognizing we still need to offer a certain quality of service and community for our intended users. I am guessing it won’t be too hard to hire a savvy group of individuals who could poke and prod at a platform until the experience gets compromised in some harmful way.<span> </span></p>
<p class="p1">Like chaos engineering, I’m guessing most organizations wouldn’t be up for an API weaponization audit. It would reveal some potentially uncomfortable truths that leadership probably isn’t too concerned with addressing, and lower levels probably would not have the operational bandwidth to address. I am guessing you’d learn a lot with each platform targeted. Both target organization, but also collectively across organizations, and across different industries. How you weaponize a social platform versus a video platform will probably shine a light on different tactics. You really would have to look at not just the technical weaponization opportunities, but also the alignment with or against the business model. Like how hate and harassment can be a positive signal when it comes to advertising. Thinking not just how the technology is abused, but how the business model actually incentivizes bad behavior, or at least looking the other way while it is going on.</p>
<p class="p1">Unfortunately security, privacy, and observability are already some of the most malnourished aspects of API operations, so I am not holding out much hope API weaponization audits. However Is till like putting these ideas out there and letting them simmer and even fester. If nothing else it should remind us to at least put a minimal amount of thought into how our platforms might be potentially used in negative ways. Plant that seed in the back of our minds that there is one more layer of threats lurking out there in the shadows of the platforms we are assembling. That despite our best technical and business intentions there are forces out there who will use our own tools against us and our communities. Revealing the darker side of not just how we view and wield technology, but also the human side of our operations, and that like the physical world around us, there are massive dark spots that exist across our digital platforms where we should be shining a light on, otherwise something or someone might take root in these spaces in ways we never imagined.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/02/11/conducting-api-weaponization-audits/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/02/10/the-basics-of-working-with-the-postman-api/">The Basics Of Working With The Postman Api</a></h3>
        <span class="post-date">10 Feb 2020</span>
        ---
published: true
layout: post
title: 'The Basics of Working with the Postman API'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/postman_api_docs_get_all_collections.png
---
<img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/postman_api_docs_get_all_collections.png" width="40%" align="right" style="padding: 15px;" /><p class="p1">It is pretty easy to think of Postman as the platform where you engage with your internal APIs, as well as other 3rd party APIs. It doesn’t always occur to developers that <a href="https://docs.api.postman.com/?version=latest">Postman has an API as well</a>. Most everything you can do through the Postman interface you can do via the Postman API. Not surprisingly, the Postman API also has a Postman collection, providing you with quick and easy access to your Postman collections, workspaces, teams, mocks, and other essential elements of the Postman platform and client tooling. Providing you with the same automation opportunities you have come to expect from other APIs.</p>
<p class="p1">API access, integration, and automation should be the default with everything you do online—desktop, web, mobile, and device applications all use APIs. Your API infrastructure is no different. Postman takes this seriously, and works to make sure that anything you can do through the desktop or web interfaces, that you can also do via <a href="https://docs.api.postman.com/?version=latest">the Postman API</a>--allowing API providers and consumers to seamlessly integrate and automate the Postman platform into their operations by leveraging the following APIs.</p>
<ul>
<li><strong>Collections</strong> - Being able to programmatically create and manage Postman API collections in use.</li>
<li><strong>Environments</strong> - Adding and managing the details of the environments applied across Postman collections.</li>
<li><strong>Mocks</strong> - Creating, retrieving, and deleting mocks APIs that are generated from Postman collections.</li>
<li><strong>Monitors</strong> - Create, update, retrieve, delete, and run monitors that execute Postman collections.</li>
<li><strong>Workspaces</strong> - Creating, retrieving, updating, and deleting the workspaces that collections are organized in.</li>
<li><strong>Users</strong> - Provides a /me endpoint that allows for pulling of information about the API key being used.</li>
<li><strong>Import</strong> - Allowing for the import of Swagger, OpenAPI, and RAML API definitions into Postman.</li>
<li><strong>API</strong> - Programmatically creating and managing APIs, including version, schema, and its link relations.</li>
</ul>
<p class="p1">These eight API paths give you full control over managing the full API life cycle of APIs you are developing, and the integration and automation of the APIs you are consuming. Allowing for tighter integration with other services and tools you are using to define, design, develop, support, and evolve your API infrastructure, acknowledging the critical role that Postman plays in the enterprise life cycle, while also being just one of many tools developers are putting to work to deliver critical API infrastructure. Ensuring that Postman places nicely with the variety of tools in our API development toolbox, and acting as a Swiss army knife that will work with any existing and diverse API life cycle workflow.</p>
<p class="p1">Postman has evolved from hits humble roots as simply a browser plugin and desktop API client to become a full featured API platform, and platforms depend on APIS to operate at scale. The Postman APIs are how API development and governance groups can scale and automate the API development life cycle, while also being able to audit and engage with the life cycle across teams and the workspace they are using to organize operations. If you are looking to take your API life cycle to the next level, take a look at the Postman API collection and documentation, and begin brainstorming ways in which you can automate and streamline how APIs are delivered, seamlessly integrating your existing workflows with how your developers are already using Postman on the ground across your organization.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/02/10/the-basics-of-working-with-the-postman-api/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/02/10/standardizing-my-api-life-cycle-governance/">Standardizing My Api Life Cycle Governance</a></h3>
        <span class="post-date">10 Feb 2020</span>
        ---
published: true
layout: post
title: 'Standardizing My API Life Cycle Governance'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/amusement-park-amusement-park-2-copper-circuit.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/amusement-park-amusement-park-2-copper-circuit.jpg" alt="" width="40%" align="right" /></p>
<p>I am working on redesigning all of my base APIs, as well as produce a mess of new ones. As part of the process I am determined to be more thoughtful and consistent in how I design and deliver the APIs. API governance always begins with using API definitions, as you can't govern something you can't measure and track, so having machine readable artifacts is essential. After that, the design of the API is the first place to look when it comes to standardizing each of the APIs coming off the assembly line. Then I am looking to do my best to begin defining, measuring, and standardizing how I do many other areas of API operations, hleping me keep track of the many moving parts of doing microsservices.&nbsp;</p>
<p>To help me govern the life cycle for each API, I am going to be quantifying and measuring as many of the follow areas as I can. These are what I consider to be the essential building blocks of each API that I deliver, and since I'm using Postman to not just interact with these APIs once they are in production, I will be using Postman to also deliver and govern each stop along the API life cycle. Using Postman collections to define, deliver, and govern each of these areas, using scripts, runners, and monitors to automate the enforcement of standards and consistency across the APIs I am delivering on a regular basis.&nbsp;</p>
<p><strong>Definitions</strong></p>
<ul>
<li><strong>OpenAPI</strong> - There is an OpenAPI for each individual API.</li>
<li><strong>Collection</strong> - This is a Postman collection for each individual API.</li>
<li><strong>JSON Schema</strong> - There is a JSON schema for each individual schema.</li>
</ul>
<ul>
</ul>
<ul>
</ul>
<p><strong>Design</strong></p>
<ul>
<li><span><strong>Requests</strong></span> 
<ul>
<li><strong>Base</strong> - Ensure the base path is planned.</li>
<li><strong>Versioning</strong>&nbsp;- Define how APIs are versioned.</li>
<li><strong>Resource</strong>&nbsp;- Evaluate each resource published.</li>
<li><strong>Sub-Resources&nbsp;</strong>- Evaluate each sub-resource published.</li>
</ul>
<ul>
<li><strong>Methods</strong>&nbsp;- Ensure common use of HTTP methods.</li>
<li><strong>Actions</strong>&nbsp;- Determine how actions are taken beyond methods.</li>
<li><strong>Path Parameters </strong>-&nbsp;Establish common approach for path parameters.</li>
<li><strong>Query Parameters</strong>&nbsp;- Establish common approach for query parameters.</li>
<li><strong>HTTP Headers</strong>&nbsp;- Evaluate what headers are in use.</li>
<li><strong>Body</strong>&nbsp;- Define how request bodies are being put to use.</li>
<li><strong>Filtering</strong>&nbsp;- Enure there are common approaches to querying and filtering.</li>
<li><strong>Field Selection</strong>&nbsp;- Determine how and if fields can be selected.</li>
<li><strong>Date Selection</strong>&nbsp;- Establish common approach to using dates.</li>
<li><strong>Time Selection</strong>&nbsp;- Establish common approach to using times.</li>
<li><strong>Sorting</strong>&nbsp;- Establish common approach to how sorting is done.</li>
<li><strong>Pagination</strong>&nbsp;- Establish common approach to pagination of results.</li>
<li><strong>Granularity</strong>&nbsp;- Evaluate the size, scope, and potential granularity of requests.</li>
<li><strong>Content Negotiation</strong>&nbsp;- Provide the ability to negotiate different content types.</li>
</ul>
</li>
<li><span><strong>HTTP Methods</strong></span> 
<ul>
<li><strong>GET</strong>&nbsp;- Use of GET properly across all APIs.</li>
<li><strong>POST</strong>&nbsp;-&nbsp;Use of POST properly across all APIs.&nbsp;</li>
<li><strong>PUT</strong>&nbsp;-&nbsp;Use of PUT properly across all APIs.</li>
<li><strong>PATCH</strong>&nbsp;-&nbsp;Use of PATCH properly across all APIs.</li>
<li><strong>DELETE</strong>&nbsp;-&nbsp;Use of DELETE properly across all APIs.</li>
<li><strong>OPTIONS</strong>&nbsp;-&nbsp;Use of OPTIONS properly across all APIs.</li>
</ul>
</li>
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/amusement-park-amusement-park-2-blue-circuit.jpg" alt="" width="40%" align="right" /></p>
<li><span><strong>Response</strong></span> 
<ul>
<li><strong>HTTP Headers&nbsp;</strong>- Ensure the common usage of standard or custom HTTP headers</li>
<li><strong>Status Codes&nbsp;</strong>- Learn about, and use HTTP status codes in a consistent way across all API operations.</li>
<li><strong>Error Handling&nbsp;</strong>- Establish a single error handling strategy, and apply consistently across all API operations.</li>
<li><strong>Rate Limits&nbsp;</strong>- Establish a single approach to rate limiting of API resources, and apply consistently across all API operations.</li>
<li><strong>Caching</strong>&nbsp;- Learn about common approaches to caching, and make sure it is applied through API operations.</li>
<li><strong>Request-Ids&nbsp;</strong>- Employ Request-Ids if possible providing added details for logging, auditing, and reporting on API usage.</li>
<li><strong>UTF-8</strong>&nbsp;- UTF-8 is a character encoding capable of encoding all possible characters, or code points.</li>
<li><strong>CORS</strong>&nbsp;- Enable CORS for your API endpoints, providing the most flexibility possible in making API calls.</li>
<li><strong>JSONP</strong>&nbsp;- Provide JSONP if you are unable to enable CORS, allowing for easier integrations.</li>
<li><strong>Compression</strong>&nbsp;- Gzip or other compression format for API responses.</li>
</ul>
</li>
<li><span><strong>Success</strong></span> 
<ul>
<li><strong>200 OK&nbsp;-</strong> Standard response for successful HTTP requests. The actual response will depend on the request method used.</li>
<li><strong>201 Created&nbsp;-</strong> The request has been fulfilled, resulting in the creation of a new resource.</li>
<li><strong>202 Accepted&nbsp;-</strong> The request has been accepted for processing, but the processing has not been completed. The request might or might not be eventually acted upon, and may be disallowed when processing occurs.</li>
<li><strong>204 No Content&nbsp;- </strong>The server successfully processed the request and is not returning any content.</li>
</ul>
</li>
</ul>
<ul>
<li><strong>Redirection</strong></li>
<li> 
<ul>
<li><strong>301 Moved Permanently&nbsp;</strong>- This and all future requests should be directed to the given URI.</li>
<li><strong>302 Found</strong>&nbsp;- Common way of performing URL redirection. An HTTP response with this status code will additionally provide a URL in the location header field. The user agent (e.g. a web browser) is invited by a response with this code to make a second, otherwise identical, request to the new URL specified in the location field.</li>
<li><strong>303 See Other&nbsp;</strong>- The response to the request can be found under another URI using a GET method. When received in response to a POST (or PUT/DELETE), the client should presume that the server has received the data and should issue a redirect with a separate GET message.</li>
<li><strong>304 Not Modified</strong>&nbsp;- Indicates that the resource has not been modified since the version specified by the request headers If-Modified-Since or If-None-Match. In such case, there is no need to retransmit the resource since the client still has a previously-downloaded copy.</li>
</ul>
</li>
<li><span><strong>User Error</strong></span> 
<ul>
<li><strong>400 Bad Request&nbsp;-</strong> The server cannot or will not process the request due to an apparent client error (e.g., malformed request syntax, too large size, invalid request message framing, or deceptive request routing).</li>
<li><strong>401 Unauthorized</strong>&nbsp;- Similar to 403 Forbidden, but specifically for use when authentication is required and has failed or has not yet been provided. The response must include a WWW-Authenticate header field containing a challenge applicable to the requested resource.</li>
<li><strong>403 Forbidden&nbsp;</strong>- The request was a valid request, but the server is refusing to respond to it. The user might be logged in but does not have the necessary permissions for the resource.</li>
<li><strong>404 Not Found&nbsp;</strong>- The requested resource could not be found but may be available in the future. Subsequent requests by the client are permissible.</li>
<li><strong>405 Method Not Allowed&nbsp;</strong>- A request method is not supported for the requested resource; for example, a GET request on a form which requires data to be presented via POST, or a PUT request on a read-only resource.</li>
<li><strong>406 Not Acceptable&nbsp;</strong>- The requested resource is capable of generating only content not acceptable according to the Accept headers sent in the request.</li>
<li><strong>408 Request Timeout&nbsp;</strong>- The server timed out waiting for the request. According to HTTP specifications: The client did not produce a request within the time that the server was prepared to wait. The client MAY repeat the request without modifications at any later time.</li>
<li><strong>409 Conflict&nbsp;-</strong> Indicates that the request could not be processed because of conflict in the request, such as an edit conflict between multiple simultaneous updates.</li>
<li><strong>410 Gone&nbsp;-</strong> Indicates that the resource requested is no longer available and will not be available again. This should be used when a resource has been intentionally removed and the resource should be purged. Upon receiving a 410 status code, the client should not request the resource in the future. Clients such as search engines should remove the resource from their indices. Most use cases do not require clients and search engines to purge the resource, and a 404 Not Found may be used instead.</li>
<li><strong>411 Length Required&nbsp;-</strong> The request did not specify the length of its content, which is required by the requested resource.</li>
<li><strong>412 Precondition Failed&nbsp;- </strong>The server does not meet one of the preconditions that the requester put on the request.</li>
<li><strong>415 Unsupported Media Type&nbsp;-</strong> The request entity has a media type which the server or resource does not support. For example, the client uploads an image as image/svg+xml, but the server requires that images use a different format.</li>
<li><strong>422 Unprocessable Entity&nbsp;-</strong> The request was well-formed but was unable to be followed due to semantic errors.</li>
<li><strong>423 Locked&nbsp;-</strong> The resource that is being accessed is locked.</li>
<li><strong>428 Precondition Required&nbsp;-</strong> The user has sent too many requests in a given amount of time. Intended for use with rate-limiting schemes.</li>
<li><strong>429 Too Many Requests&nbsp;- </strong>The user has sent too many requests in a given amount of time. Intended for use with rate-limiting schemes.</li>
</ul>
</li>
<li><span><strong>Server Error</strong></span> 
<ul>
<li><strong>500 Internal Server Error&nbsp;-</strong> A generic error message, given when an unexpected condition was encountered and no more specific message is suitable.</li>
<li><strong>501 Not Implemented&nbsp;- </strong>The server either does not recognize the request method, or it lacks the ability to fulfill the request. Usually this implies future availability (e.g., a new feature of a web-service API).</li>
<li><strong>503 Service Unavailable&nbsp;- </strong>The server is currently unavailable (because it is overloaded or down for maintenance). Generally, this is a temporary state.</li>
</ul>
</li>
<li><strong>Error Handling</strong> 
<ul>
<li><strong>Error Format</strong>&nbsp;- Having a common approach to delivering errors to API consumers.</li>
<li><strong>Problem Details for HTTP APIs</strong>&nbsp;- Leveraging RFC 7807 for machine readable details of errors in a HTTP response.</li>
</ul>
</li>
<li><strong>Media Types</strong> 
<ul>
<li><strong>application/json&nbsp;</strong>- Provide JSON media types for API responses.</li>
<li><strong>application/xml&nbsp;-</strong> Provide XML media types for API responses.</li>
<li><strong>application/csv&nbsp;-</strong> Provide CSV media types for API responses.</li>
<li><strong>text/html&nbsp;-</strong> Provide HTML media types for API responses.</li>
<li><strong>application/atom+xml&nbsp;-</strong> Provide ATOM media types for API responses.</li>
</ul>
</li>
<li><strong>Schema</strong> 
<ul>
<li><strong>Name</strong>&nbsp;- Establishing a common approach to naming schema in use across APIs.</li>
<li><strong>Description</strong>&nbsp;- Have a clear description for each schema.</li>
<li><strong>Property Names&nbsp;</strong>- Establish common practices for how schema properties are named.</li>
<li><strong>Property Description&nbsp;</strong>- Ensure that all schema properties have descriptions.</li>
<li><strong>Property Types&nbsp;</strong>- Establish common practices for which property types are used.</li>
<li><strong>Property Requirements&nbsp;</strong>- Ensure that all properties are defined as required or not required.</li>
<li><strong>JSON Schema&nbsp;- </strong>Provide JSON schema represenations for all schema in use.</li>
<li><strong>Schema.org&nbsp;</strong>- Consider using Schema.org representations for common data elements.</li>
</ul>
</li>
</ul>
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/amusement-park-amusement-park-2-purp-paper.jpg" alt="" width="40%" align="right" /></p>
<p><strong>Mock</strong></p>
<ul>
<li><strong>API</strong> - Provide a virtualized endpoint for each individual API.</li>
<li><strong>Data</strong>&nbsp;- Provide virtualized data for each individual API.</li>
<li><strong>Versions</strong> - There are mocks available for each version of an API.</li>
<li><strong>Coverage</strong> - Ensure that I have 100% coverage of all APIs.</li>
</ul>
<p><strong>Portal</strong></p>
<ul>
<li><strong>GitHub Repo -</strong>&nbsp;There is a GitHub repository for each indiviudal API.</li>
</ul>
<p><strong>Documentation</strong></p>
<ul>
<li><strong>Documentation</strong>&nbsp;- There is documentation published with URL available.</li>
<li><strong>Versions</strong> - There is documentation available for each version of an API.</li>
</ul>
<p><strong>Testing</strong></p>
<ul>
<li><strong>Assertions</strong> - Ensure there are assertions available for each API.</li>
<li><strong>Monitor</strong>&nbsp;- There is an testing monitor in place from multiple regions.</li>
<li><strong>Results</strong>&nbsp;- I have the monitoring results published somewhere for evaluation.</li>
</ul>
<p><strong>Database</strong></p>
<ul>
<li><strong>Script</strong> - A script is available to create the database for each API.</li>
<li><strong>Platform</strong> - There is a common database platform for each API.</li>
<li><strong>Billing</strong> - What does it cost me to run each database for each API.</li>
<li><strong>Backup</strong> - Each database is backed up as part of regular process.</li>
<li><strong>Restore</strong> - There is a process for easily restoring the database.</li>
</ul>
<p><strong>Compute</strong></p>
<ul>
<li><strong>Platform</strong>&nbsp;- There is a common compute platform for each API.</li>
<li><strong>Billing</strong>&nbsp;- What does it cost me to run each database for each API.</li>
<li><strong>Setup</strong> - There is automation in place to setup and configure the compute.</li>
<li><strong>Backup</strong>&nbsp;- All code and configuration is backed up as part of regular process.</li>
<li><strong>Restore</strong>&nbsp;- There is a process for easily restoring the compute layer.</li>
</ul>
<p><strong>Storage</strong></p>
<ul>
<li><strong>Platform</strong>&nbsp;- There is a common storage platform for each API.</li>
<li><strong>Billing</strong>&nbsp;- What does it cost me to run each database for each API.</li>
<li><strong>Backup</strong>&nbsp;- All storage is backed up as part of regular process.</li>
<li><strong>Restore</strong>&nbsp;- There is a process for easily restoring the storage.</li>
</ul>
<p><strong>Pipeline</strong></p>
<ul>
<li><strong>Platform</strong> - All pipeliens are delivered using common CI/CD platform.</li>
<li><strong>Tests</strong> - Run the required tests at the pipeline level to ensure quality.</li>
</ul>
<p><strong>Management</strong></p>
<ul>
<li><strong>Platform</strong>&nbsp;- There is a common database platform for each API.</li>
<li><strong>Billing</strong> - What does it cost me to manage each individual API.</li>
<li><strong>Plan</strong> - There is a plan in place for each individual API.</li>
<li><strong>Activity</strong> - Track all activity of API consumption at the management layer.</li>
</ul>
<p><strong>Logging</strong></p>
<ul>
<li><strong>Shipped</strong> - All logs are shipped to central location for evaluation and auditing.</li>
<li><strong>Reporting</strong> - There is reporting in place for each of the APIs log files.</li>
</ul>
<p><strong>Encryption</strong></p>
<ul>
<li><strong>Certificate</strong>&nbsp;- Establish and manage certificate for APIs.</li>
<li><strong>Default</strong>&nbsp;- Enforce encryption for all APIs beind delivered.</li>
</ul>
<p><strong>DNS</strong></p>
<ul>
<li><strong>Mock Host&nbsp;</strong>- Ensure there is a mock host for each API.</li>
<li><strong>Development Host</strong>&nbsp;- Ensure there is a mock host for each API.</li>
<li><strong>Production Host&nbsp;</strong>- Ensure there is a mock host for each API.</li>
</ul>
<p><strong>Authentication</strong></p>
<ul>
<li><strong>API Key</strong> - Mock, development, and production instances all require an API key to use.</li>
</ul>
<p><strong>Road Map</strong></p>
<ul>
<li><strong>Add</strong> - I can easily add items to the road map for each API.</li>
<li><strong>Listing</strong> - There is a listing of road map entries for each API.</li>
<li><strong>Version</strong> - The road map is organized by version.</li>
<li><strong>Activity</strong> - Track the planning activity around the road map.</li>
</ul>
<p><strong>Issues</strong></p>
<ul>
<li><strong>Add</strong>&nbsp;- I can easily add items to the road map for each API.</li>
<li><strong>Listing</strong>&nbsp;- There is a listing of road map entries for each API.</li>
<li><strong>Version</strong>&nbsp;- The road map is organized by version.</li>
<li><strong>Activity</strong> - Track any acitivity when it comes to issues.</li>
</ul>
<p><strong>Change Log</strong></p>
<ul>
<li><strong>Add</strong>&nbsp;- I can easily add items to the road map for each API.</li>
<li><strong>Listing</strong>&nbsp;- There is a listing of road map entries for each API.</li>
<li><strong>Version</strong>&nbsp;- The road map is organized by version.</li>
<li><strong>Activity</strong> - Track the change log activity.</li>
</ul>
<p><strong>Monitoring</strong></p>
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/amusement-park-amusement-park-2-atari-asteroids.jpg" alt="" width="40%" align="right" /></p>
<p><strong>Mock</strong></p>
<ul>
<li><strong>Monitor</strong> - There is an uptime and availablility monitor in place for multiple regions.</li>
<li><strong>Results</strong> - The monitoring results published somewhere for evaluation.</li>
</ul>
<p><strong>Performance</strong></p>
<ul>
<li><strong>Monitor</strong>&nbsp;- There is an performance monitor in place for multiple regions.</li>
<li><strong>Results</strong>&nbsp;- The performance results published somewhere for evaluation.</li>
</ul>
<p><strong>Security</strong></p>
<ul>
<li><strong>Monitor</strong>&nbsp;- There is an security monitor in place</li>
<li><strong>Results</strong>&nbsp;- The security results published somewhere for evaluation.</li>
</ul>
<p><strong>Support</strong></p>
<ul>
<li><strong>Contact</strong> - There is an owner for each API responsible for supporting it.</li>
<li><strong>Ticket</strong> - There is an ability to submit and manage tickets for support.</li>
<li><strong>Email</strong> - An email exists for supporting each individual API.</li>
<li><strong>Activity</strong> - Track the support activity for each API.</li>
</ul>
<p><strong>Communication</strong></p>
<ul>
<li><strong>Update</strong> - A message, Tweet, or other update is pushed for any activity.</li>
<li><strong>Blog</strong> - A blog post is written with each release of an API or other activity.</li>
<li><strong>Activity</strong>&nbsp;- Track the communication activity for each API.</li>
</ul>
<p><strong>Discovery</strong></p>
<ul>
<li><strong>APIs.json </strong>- An APIs.json index is created for each API, and included in other indexes.</li>
</ul>
<p>I am working to establish a single Postman request for each entry in this outline, operating as a single, or suite of collections that I can run as a monitor, or manually against each individual API I am developing--helping keep me honest. <a href="https://github.com/stoplightio/spectral">I'd like to standardize the rules around Spectral, building upon what already exists out in the API space, contributing to a common approach to defining API design governance</a>. My only concern is how to I use Spectral for governing non API design elements, but I'm optimistic that I will be able to use it on OpenAPI, AsyncAPI, JSON Schema, Postman Collections, as well as APIs.json--allowing me to cover all my bases when it comes to API governance.</p>
<p><a href="https://github.com/postman-api-governance/default">To help me manage this effort I have created a GitHub repository to manage all the details, issues, and help me move things forward</a>. I need to spend some time playing with Spectral before I invest more time into the Postman collection, and writing scripts for the governance. I already have some scripting down, but it was just proof of concept stuff, and I'd rather standardize my approach using an open source format, and set of JavaScript libraries. Then I will go ahead and publish some of my APIs and begin moving them through the process I've laid out here, helping me establish some of the artifacts and metrics I will need to actually realize this list. While most of the API design elements I can rely on the OpenAPI truth for each API, but for some of the other API life cycle elements I am going to have to get creative using APIs.json, and totally inventing other artifacts to get the job done--eventually getting me where I need to be when it comes to governance.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/02/10/standardizing-my-api-life-cycle-governance/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/02/10/backend-aws-api-gateway-integration-openapi-extensions/">Backend Aws Api Gateway Integration Openapi Extensions</a></h3>
        <span class="post-date">10 Feb 2020</span>
        ---
published: true
layout: post
title: 'Backend AWS API Gateway Integration OpenAPI Extensions'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/aws-s3-stories-gears-smoking-cigarette.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/aws-s3-stories-gears-smoking-cigarette.jpg" alt="" width="25%" align="right" /></p>
<p class="p1">I have spent a lot of time automating my AWS API infrastructure, working to make it so I can automatically deploy API infrastructure to AWS.<span>&nbsp; </span>I am using AWS API Gateway as part of this suite of API deployments so I have been working hard to understand how AWS speaks OpenAPI as part of their implementation. As part of my work there are three distinct types of APIs I am deploying using AWS API Gateway, which have three distinct ways of extending OpenAPI to describe.</p>
<h3>The Pass Through</h3>
<p>Just passing what comes in to an HTTP host and path I give it and then passing the response back through without any transformations or other voodoo along the way. This is a basic OpenAPI extension for defining a pass through API using the AWS API Gateway.</p>
<script src="https://gist.github.com/postkin/2d8ca638710e96c960825f6b8c8d422d.js"></script>
<h3>A DynamoDB Backend</h3>
<p class="p1">For my basic CRUD databases I am just using a DynamoDB backend because it allows me to quickly launch data APIs that allow me to Create, Read, Update, and Delete (CRUD) data I am storing in the NoSQL database&mdash;providing me with a pretty basic approach to delivering data API infrastructure. Here is the OpenAPI vendor extension for wiring things up using a DynamoDB backend.</p>
<script src="https://gist.github.com/postkin/48df44b4edd1cbaf2a2eca4a0bcecf75.js"></script>
<p class="p1">I like DynamoDB because you can just make API calls to get most of what you need without any sort of business logic or code in between. If I am just looking to manage data using simple web API endpoints, this is what I am doing when it comes to deploying API infrastructure.</p>
<h3>Logic with Lambda</h3>
<p class="p1">I would say the the previous two types of APIs represent the most common implementations I have, but I am working to evolve my infrastructure to take advantage of newer approaches to delivering APIS like Lambda. Here is the OpenAPI extension for defining a Lambda backend, which I can then wire up to a database and storage or purely implement some business logic to do what I need to accomplish.</p>
<script src="https://gist.github.com/postkin/0a965510d41246ff2f051c50d5f64b13.js"></script>
<p class="p1">I am still not 100% sold on serverless, similar to containers. While there are definitely advantages I am not convinced all of the tradeoffs are worth it. At least for my infrastructure, which probably isn&rsquo;t as demanding as what some of my readers are facing when it comes to APIs. Regardless, if I actually end up putting these new solutions to work, I like staying up to speed on what is going on.</p>
<h3>Extending OpenAPI for API Deployment and Management</h3>
<p class="p1">I am dynamically generating these types of OpenAPI extension, populating the OpenAPI for my APIs, and then deploying using the AWS Gateway. Each type of API deployment requires a different backend setup and configuration to support, but these extensions allow me to automatically provision the facade for each API using AWS API Gateway. Once deployed I can then add each API to an existing API plan, or create a new one, and then issue API keys as needed to secure each of my APIs and limit the usage. These extensions are the key to me automating the deployment layer of my API, allowing me to move from a code-first API deployment to an API-first approach, something that is mostly myth in the AP space, but getting closer to reality in my stack.</p>
<p class="p1">It is OpenAPI extensions and sister specifications that are going to allow us to eventually automate and govern the API life cycle. Doing for every stop along the API life cycle as OpenAPI has done for API design and documentation. I have been documenting Swagger and OpenAPI extensions for some time now, using them to understand what vendors are up to. Now I am going further when possible and actually applying them to automating and governing my API life cycle to see where I can get traction with them. Along the way I&rsquo;d like to make further proposals for more formal extensions or sister specifications that help us better define and execute on the API life cycle. In the end there should be a machine readable artifact quantifying every stop along the API life cycle&mdash;it will just take us a while to get there, and in agreement on what is needed across different platforms.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/02/10/backend-aws-api-gateway-integration-openapi-extensions/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/02/10/api-links-for-every-ui-element/">Api Links For Every Ui Element</a></h3>
        <span class="post-date">10 Feb 2020</span>
        ---
published: true
layout: post
title: 'API Links For Every UI Element'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/cloudflare_ssl_tls_encryption_levels_1.png
---
<p class="p1">I&rsquo;ve showcased ClokudFlare's approach making their API available as part of their user interface several times now. It is a practice I want to see replicated in more desktop, web, and mobile applications, so I want to keep finding new ways of talking about, and introducing to new readers. If you sign up or use CloudFlare, and navigate your way to their SSL/TLS section, you will see a UI element for changing the levels of your SSL/TLS encryption, and below it you see some statics on the traffic that has been served over TLS over the last 24 hours. Providing you full control over SSL/TLS within the CloudFlare UI.</p>
<p class="p2"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/cloudflare_ssl_tls_encryption_levels_1.png" alt="" width="100%" align="center" /></p>
<p class="p1">At the bottom of the UI element for managing your SSL/TLS you will see an API link, which if you click you get three API calls for getting, changing, and verifying the SSL/TLS status of your domain. Providing you with one click access to the API calls behind the UI elements, giving you two separate options for managing your DNS.</p>
<p class="p2"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/cloudflare_ssl_tls_encryption_levels_2.png" alt="" width="100%" align="center" /></p>
<p class="p1">This is how all user interfaces within applications should be. The API shouldn&rsquo;t just be located via some far off developer portal, they should be woven into the UI experience, revealing the API pipes behind the UI at every opportunity. This allows for the automation of any activity a user is taking through the interface using the platform's API. You could also consider embedding a simple <a href="https://www.postman.com/collection">Postman Collection</a> for each API capability, allowing a user to run in Postman&mdash;to further support, you could also make a <a href="https://learning.postman.com/docs/postman/environments-and-globals/manage-environments/">Postman environment</a> available, pre-populated with a users API Key, making execution of each platform capability outside of the platform possible in just one or two clicks.</p>
<p class="p1">Once each UI capability is defined as a Postman collection it can immediately be executed by a user in a single click. It can also be executed using a <a href="https://learning.postman.com/docs/postman/collection-runs/starting-a-collection-run/">Postman runner</a> as part of an existing CI/CD process, or on a schedule using a <a href="https://learning.postman.com/docs/postman/monitors/intro-monitors/">Postman monitor</a>. This extends the reach of any UI feature, making it portable, sharable, and executable outside of the UI by any consumer. Can you imagine if all UI elements had this approach baked in by default? If every UI element was API-driven and had a link to the API call behind, with an environment that provides the user context which the API call should be ran. This would change the API game, making APIs more about single use execution and automation, even before they are used within other applications&mdash;drastically changing who APIs serve.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/02/10/api-links-for-every-ui-element/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/01/27/secrets-and-personally-identifiable-information-pii-across-our-api-definitions/">Secrets And Personally Identifiable Information Pii Across Our Api Definitions</a></h3>
        <span class="post-date">27 Jan 2020</span>
        ---
published: true
layout: post
title: 'Secrets and Personally Identifiable Information (PII) Across Our API Definitions'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/bf-skinner-crypto-wheels-old-compute-bletchley.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/bf-skinner-crypto-wheels-old-compute-bletchley.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">As API providers and consumers we tend to have access to a significant amount of credentials, keys, tokens, as well as personally identifiable data (PII). We use this sensitive information throughout the API integration and delivery life cycles. We depend on credentials, keys, and tokens to authorize each of our API requests, and we potentially capture PII as part of the request and response for each the individual API requests we execute regularly. Most developers, teams, and organizations I&rsquo;ve spoken with do not have a strategy for addressing how secrets and PII are applied across the internal and external API landscape. API management over the last decade has helped us as API providers better manage how we define and manage authentication for the APIs we are providing, but there hasn&rsquo;t been a solution emerge that helps us manage the tokens we use across many internal and external APIs.</p>
<p class="p1">With this reality, there are a lot of developers who are self-managing how they authenticate with APIs, and work with PII that gets returned from APIs. I am working on several talks with enterprise organizations about this challenge, and to prepare I want to work through my thoughts on the problem, as well as some possible solutions. I wanted to map out how we integrate with the APIs we are developing and consuming, and think about what the common building blocks of how we can better define, educate, execute, audit, and govern the secrets and PII that is applied throughout the API life cycle across all of the APIs we depend on. Allowing me to have a more informed conversation about how we can get better at managing the more sensitive parts of our operations.</p>
<p class="p1"><strong>What Are The Types of Sensitive Information?</strong></p>
<p class="p1">First I wanted to understand the types of common information being applied by API developers, helping me establish and evolve a list of the types of data we are looking for when securing the API development life cycle. This list will grow as I flesh out this work more, but here are the types of sensitive information I&rsquo;m looking to identify and manage across API operations.</p>
<ul class="ul1">
<li class="li1"><strong>API Keys</strong> - Static keys and secrets generated by API providers.</li>
<li class="li1"><strong>API Tokens</strong> - Dynamic OAuth, JWT, and other tokens being issued.</li>
<li class="li1"><strong>Username / Passwords</strong> - Account usernames and passwords.</li>
<li class="li1"><strong>Personally Identifiable Information (PII)</strong> - Names, age, addresses, phones, SSN, and other PII.</li>
</ul>
<p class="p1">I am sure there are other pieces of data we should be looking for, but this provides a nice list to get us going. I just want to begin making a meaningful impact on the most critical aspects of this conversation, and we can expand into other areas in the future. It is a problem we need to begin investing in now, otherwise as the number of APIs we depend on increases, the bigger this problem will become.</p>
<p class="p1"><strong>Where Is Sensitive Information Is Used?</strong></p>
<p class="p1">There are going to be many ways in which these sensitive items get used across API operations. I don&rsquo;t think I&rdquo;ll be able to identify all of them because each organization is going to operate differently, but it helps to have a list to consider when solving this problem. Here are some of the common places where sensitive information gets stored, specifically as part of the API development process.</p>
<ul class="ul1">
<li class="li1"><strong>Definitions</strong> - Swagger, OpenAPI, Postman collections and environments all have the potential to be storing secrets and PII.</li>
<li class="li1"><strong>Code</strong> - Developers are baking secrets and PII into the code they are producing and pushing out on a regular basis.<span>&nbsp;</span></li>
<li class="li1"><strong>Applications</strong> - The desktop and server applications we are using throughout the API life cycle will possess secrets and PII.</li>
<li class="li1"><strong>Services</strong> - The cloud services that we are putting to work throughout the API life cycle will possess secrets and PII.<span>&nbsp;</span></li>
</ul>
<p class="p1">We are applying secrets, and in some cases applying PII across all of these areas. Rarely with any way of defining, guiding, auditing, and governing how they are applied across teams. Peppering a variety of secrets and PII across many different locations, with no way of understanding the scope and properly securing, scrubbing, and getting things in order&mdash;something folks should be concerned with across all levels of the enterprise.</p>
<p class="p1"><strong>Where Is Sensitive Information Stored?</strong></p>
<p class="p1">Building upon where sensitive information stored, I wanted to think about where it actually resides for use across operations. It will be used in different ways by different individuals, teams, and organizations. However, I think there are some common places we can be looking for how sensitive information gets stored as it is being applied throughout the API life cycle. These are just a handful of the locations I am thinking about currently, providing me with targets to think about as I look to get a handle on sensitive information across API operations.</p>
<ul class="ul1">
<li class="li1"><strong>Local</strong> - Each individual user is storing definitions, code, and has applications installed that all contribute to the storing and applying of secrets and PII.</li>
<li class="li1"><strong>Cloud</strong> - Each individual user is potentially storing, syncing, and ackupingv up data to the cloud, extending the reach of the secrets and PII in use.</li>
<li class="li1"><strong>Postman</strong> - It is common for developers to be using Postman, leaning on the application to store secrets in collections and environments.</li>
<li class="li1"><strong>Repository</strong> - Definitions and code will be often managed using Git, making repositories a good place to look for secrets and PII in use across an organization.</li>
<li class="li1"><strong>Workspaces</strong> - Taking advantage of the workspaces offered by different applications used to engage with the API life cycle, establishing common spaces where API definitions and environments are used.</li>
</ul>
<p class="p1">I am sure there are more locations I can target, but this gives me a place to start. This represents about 75% of the API definition, code, and other artifacts where we are going to find secrets and PII. I want to examine each of these locations and see what our options are when it comes to improving upon our behavior when it comes to managing secrets and PII across the API life cycle.</p>
<p class="p1"><strong>How Do We Improve Our Situation?</strong></p>
<p class="p1">One of the first things we can do to help improve our situation is to have a conversation about it. Discuss the type of information we are concerned about, how it is being applied, and where we can find it stored. I want to help stimulate the conversation by thinking about some tangible things we can be focusing on to help improve how secrets and PII are used across teams. I will be fleshing out the details of each of these areas in future posts, but these are the areas I would like to focus on when it comes to how we manage sensitive information in use across our APIs.</p>
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/bf-skinner-dragon-desert-looking.jpg" alt="" width="40%" align="right" /></p>
<ul class="ul1">
<li class="li1"><strong>Definitions</strong> - Using OpenAPI and Postman collections consistently across all API operations helps isolate how secrets and PII is applied and stored.</li>
<li class="li1"><strong>Environments</strong> - Using machine readable environments help isolate and standardize how secrets and PII is applied and stored across API operations.</li>
<li class="li1"><strong>Pipelines</strong> - Having a standardized approach to how secrets are used as part of the pipeline operation, consistently using definitions and environments.<span>&nbsp;</span></li>
<li class="li1"><strong>Documentation</strong> - Establish constant practices for how documentation is published using tools where definitions and environments can be applied.</li>
<li class="li1"><strong>Automation</strong> - Using APIs and the CLI to automate the API life cycle, using definitions and environments to drive all of the automation, and orchestration.</li>
<li class="li1"><strong>Guidance</strong> - Investing in automated and self-service guidance for individuals and teams when it comes to how secrets and PII should be produced, applied, stored, and refreshed as part of<span>&nbsp;</span></li>
<li class="li1"><strong>Education</strong> - Make sure there is investment in education of individuals and teams when it comes to get everyone up to speed on how the management of secrets and PII works across teams.</li>
<li class="li1"><strong>Storytelling</strong> - Tell stories regularly about the types of secrets and PII that are of concern, and how they are applied and stored across API operations, helping keep the conversation going across teams.</li>
</ul>
<p class="p1">This is how we are going to improve things. By standardizing the usage of OpenAPI and Postman collections across the API life cycle, and then leveraging machine readable environments for manual and automated execution of API integrations. Allowing developers to more consistently define, store, apply, and refresh secrets and PII manually when working with APIs, while also automating via monitors, pipelines, as well as publishing documentation and other ways of making our APIs more usable by other developers, systems, and applications. Then we should be able to automate the auditing, governance, and monitor the health of how secrets and PII are used across the API delivery life cycle. Helping shine a light on the problems associated with having secrets and PII laying all over the place, and get people doing things in a more organized fashion.</p>
<p class="p1">I feel like how we manage our secrets is one of the biggest challenges we face in the coming years. The number of APIs are only growing, but there hasn&rsquo;t been enough discussion and solutions for helping us manage how we use secrets across the API life cycle. I am also pretty convinced that the executable dimension of using Postman collections and environments provides us with a blueprint, and tooling for how we can improve how we manage secrets and PII across the API life cycle. We just need to get more strategic about how we use Postman as not just an API client, but also for making documentation available, and applying API collections as part of CI/CD pipelines that are driving the deployment of our API infrastructure. I am going to flesh out some secrets governance strategies using Postman for some of the conversation I&rsquo;m having here in January and February, and then revisit this topic to see what other refinements I can make to how I approach this subject on my blog, and in my work.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/01/27/secrets-and-personally-identifiable-information-pii-across-our-api-definitions/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/01/27/an-introduction-to-api-authentication/">An Introduction To Api Authentication</a></h3>
        <span class="post-date">27 Jan 2020</span>
        ---
published: true
layout: post
title: 'An Introduction to API Authentication'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/stories-new-old-door-lock-smoking-cigarette.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/stories-new-old-door-lock-smoking-cigarette.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">APIs operate using the web, but like web applications, many API require some sort of authentication or authorization before you can access the valuable resources available within each API path. When you open up your APIs on the web you aren&rsquo;t just giving away access to your resources to anyone who comes along. API providers employ a number of different authentication mechanisms to ensure only the applications and systems who should have access are actually able to make a successful API call. To help refresh the types of authentication available across the API landscape, while also demonstrating the reach of Postman as an API client, I wanted to take a fresh look at authentication to help my readers understand what is possible.</p>
<p class="p1">Depending on the API provider, platform, and the types of resources being made available you will encounter a number of different authentication methods&mdash;here are the 11 that Postman supports, reflecting 90% of the APIs you will come across publicly, as well as within the enterprise organization. Refelecting what the API sector employs for authentication of their APIs, as well as what Postman supports as an API client.</p>
<ul>
<li><strong>No Authentication</strong> - Like the web, these APIs are publicly available and accessible without any authentication. You can just make a request to a specific URL, and you get the response back without needing any credentials or key. This reflects a very small portion of the API economy, but still is an important aspect of the overall authentication discussion, and what is possible.</li>
<li><strong><a href="https://en.wikipedia.org/wiki/Application_programming_interface_key">API Key</a></strong> - An application programming interface key (API key) is a unique identifier used to authenticate a user, developer, or calling program to an API. However, they are typically used to authenticate a project with the API rather than a human user. Different platforms may implement and use API keys in different ways.</li>
<li><strong><a href="https://oauth.net/2/bearer-tokens/">Bearer token</a></strong> - A Bearer Token is an opaque string, not intended to have any meaning to clients using it. Some servers will issue tokens that are a short string of hexadecimal characters, while others may use structured tokens such as JSON Web Tokens.</li>
<li><strong><a href="https://en.wikipedia.org/wiki/Basic_access_authentication">Basic Auth</a></strong> - In the context of an HTTP transaction, basic access authentication is a method for an HTTP user agent to provide a user name and password when making a request. In basic HTTP authentication, a request contains a header field in the form of Authorization: Basic , where credentials is the base64 encoding of id and password joined by a single colon. It is specified in RFC 7617 from 2015, which obsoletes RFC 2617 from 1999.</li>
<li><strong><a href="https://en.wikipedia.org/wiki/Digest_access_authentication">Digest Auth</a></strong> - Digest access authentication is one of the agreed-upon methods a web server can use to negotiate credentials, such as username or password, with a user's web browser. This can be used to confirm the identity of a user before sending sensitive information, such as online banking transaction history. It applies a hash function to the username and password before sending them over the network. In contrast, basic access authentication uses the easily reversible Base64 encoding instead of hashing, making it non-secure unless used in conjunction with TLS.</li>
<li><strong><a href="https://oauth.net/core/1.0/">OAuth 1.0</a></strong> - The OAuth protocol enables websites or applications to access Protected Resources from a web service (Service Provider) via an API, without requiring Users to disclose their Service Provider credentials to the Consumers. More generally, OAuth creates a freely-implementable and generic methodology for API authentication.</li>
<li><strong><a href="https://oauth.net/2/">OAuth 2.0</a></strong> - OAuth 2.0 is the industry-standard protocol for authorization. OAuth 2.0 focuses on client developer simplicity while providing specific authorization flows for web applications, desktop applications, mobile phones, and living room devices. This specification and its extensions are being developed within the IETF OAuth Working Group.</li>
<li><strong><a href="https://github.com/hapijs/hawk">Hawk Authentication</a></strong> - hawk is part of the hapi ecosystem and was designed to work seamlessly with the hapi web framework and its other components (but works great on its own or with other frameworks). If you are using a different web framework and find this module useful, check out hapi &ndash; they work even better together.</li>
<li><strong><a href="https://docs.aws.amazon.com/general/latest/gr/signature-version-4.html">AWS Signature</a></strong> - Signature Version 4 is the process to add authentication information to AWS requests sent by HTTP. For security, most requests to AWS must be signed with an access key, which consists of an access key ID and secret access key. These two keys are commonly referred to as your security credentials. For details on how to obtain credentials for your account, see Understanding and Getting Your Security Credentials.</li>
<li><strong><a href="https://en.wikipedia.org/wiki/NT_LAN_Manager">NLTM authentication</a></strong> - In a Windows network, LAN Manager (NTLM) is a suite of Microsoft security protocols intended to provide authentication, integrity, and confidentiality to users. NTLM is the successor to the authentication protocol in Microsoft LAN Manager (LANMAN), an older Microsoft product. The NTLM protocol suite is implemented in a Security Support Provider, which combines the LAN Manager authentication protocol, NTLMv1, NTLMv2 and NTLM2 Session protocols in a single package. Whether these protocols are used or can be used on a system is governed by Group Policy settings, for which different versions of Windows have different default settings. NTLM passwords are considered weak because they can be brute-forced very easily with modern hardware.</li>
<li><strong><a href="https://developer.akamai.com/legacy/introduction/Open_Source.html">Akamai EdgeGrid</a></strong> - An OPEN EdgeGrid API Client is the conduit between your application and the Akamai Intelligent Platform, specifically delivered by Akamai to support their platform.</li>
</ul>
<p>No authentication, API key, and OAuth are the most common authentication mechanisms you will find in place for publicly available APIs, but Postman has worked hard to support as wide of a spectrum of authentication mechanisms by listening to the community and supporting what they need. I always recommend that API providers, especially public API providers standardize the authentication for their APIs, ensuring that the wider API ecosystem reflects this list, but Postman will continue to follow the latest trends and make sure we are always supporting what is most needed by developers&mdash;helping reduce friction for them whenever we can.</p>
<p class="p1">Hopefully this authentication overview introduces you API authentication in use by API providers and also supported by Postman. It should demonstrate that publishing APIs using the isn&rsquo;t about freely and publicly making data, content, media, and other resources available on the open web, and that there are a strong set standards in place for securing our digital assets. We see authentication much like consumer and business banking, in that everyone should have a light understanding of how things work. In banking, you don&rsquo;t have to understand the inner workings of the banking industry, but you should definitely understand who has access to your accounts. API authentication is the same&mdash;you don&rsquo;t have to understand all the technical details, but you need to have a understanding of how your digital resources are access, and who has access to what.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/01/27/an-introduction-to-api-authentication/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/01/23/profiling-adobe-apis/">Profiling Adobe Apis</a></h3>
        <span class="post-date">23 Jan 2020</span>
        ---
published: true
layout: post
title: 'Profiling Adobe APIs'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/adob_io_home_page_1.png
---
<p><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/adob_io_home_page_1.png" alt="" width="40%" align="right" /></p>
<p dir="ltr">As I was <a href="https://github.com/api-evangelist/index">profiling APIs on my list of APIs</a>&nbsp;I found myself profiling Adobe. I am moving through the list of companies alphabetically, so you can see how far along I am. Anyways, like any other large company I need to make a decision about how I am going to manage the profiling of different API products and lines of business. Companies like Amazon, Google, Azure, and Adobe have large numbers of APIs and I always know I will need to have some sort of plan for documenting everything that is going on. With Adobe, I am going to track everything in <a href="https://github.com/api-evangelist/adobe">a single GitHub repository</a>, but will be working to create separate API definitions (OpenAPI and Postman collections) for each of the individual APIs being offered.</p>
<p dir="ltr">To provide some context, it helps to understand why I profile APIs in the first place. As the API Evangelist I review public API operations studying how API providers are doing what they do. I then aggregate the "building blocks" of their public operations into a master set of reserarch that I use to drive my storytelling and API strategy workshops. So, with the Adobe APIs I'm not looking to review their API operations as much as I am looking to understand how they operate, and develop an understanding of how far along they are in their enterprise API journey. As with any profiling of a company, I begin by Googling their name pus API, but then dive as deep as I can into the details of what I find with each click.</p>
<p dir="ltr"><span>When you Google Adobe APIs you get this main landing page with the tagline, &ldquo;<em>APIs and SDKs for all Adobe products &ndash; create mobile, web and desktop apps&rdquo;</em>. You can tell Adobe is working hard to bring together their APIs under one big tent, with the following main areas to support developers:</span></p>
<ul>
<li><strong><a href="https://www.adobe.io/apis.html">Landing Page</a> </strong>- Adobe API landing page.</li>
<li><strong><a href="https://www.adobe.io/authentication.html">Authentication</a></strong> - Overview of authentication.</li>
<li><strong><a href="https://www.adobe.io/open.html">Open Source</a> -</strong> An open source page.</li>
<li><strong><a href="https://medium.com/adobetech">Blog</a></strong> - Their tech blog for their APIs.</li>
<li><strong><a href="https://github.com/adobe">GitHub</a></strong> - A dedicated GitHub account.</li>
<li><strong><a href="https://twitter.com/adobedevs">Twitter</a></strong> - A dedicated Twitter account.</li>
<li><strong><a href="https://www.youtube.com/channel/UCDtYqOjS9Eq9gacLcbMwhhQ">YouTube</a></strong> - A dedicated YouTube account.</li>
<li><strong><a href="https://www.adobe.io/support">Support</a></strong> - The support for API developers.</li>
<li><strong><a href="https://www.adobe.io/releasenotes.html">Release Notes</a> </strong>- Release notes for APIs.</li>
<li><strong><a href="https://www.adobe.com/privacy.html">Privacy Policy</a> </strong>- The privacy policy.</li>
<li><strong><a href="https://www.adobe.com/legal/terms.html">Terms of Use</a> -</strong> The terms of use.</li>
<li><strong><a href="https://www.adobe.com/privacy/cookies.html">Cookies</a></strong> - The cookies policy.</li>
</ul>
<p><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/adob_io_home_page_2.png" alt="" width="40%" align="right" /></p>
<p dir="ltr"><span>These building blocks provides the basis for their API operations, providing a single landing page for brining everything together, and help folks find what they are looking for when it comes to APIs for all of the Adobe products. When listing out their products Adobe breaks them into three distinct categories:</span></p>
<ul>
<li> <strong>Creative Cloud</strong></li>
<li><strong>Document Cloud</strong></li>
<li><strong>Experience Cloud</strong></li>
<li><strong>Adobe Experience Platform</strong></li>
</ul>
<p dir="ltr"><span>I worked my way through each of the Adobe products, there is a mix of available resources for each of their lines of business, but I am purely looking specific HTP API signals that I can profile and add to my index of APIs. While looking through each of these area I&rsquo;m looking for the elements that help me quantify the value being offered by each of the Adobe APIs. While looking through the Adobe I/O program I can ame across 15 APIs, that had enough meat on the bones for me to profile and add to my index.</span></p>
<h2 dir="ltr"><span>Adobe Launch&nbsp;</span></h2>
<p dir="ltr"><span>First I came across Adobe Launch, a <em>&ldquo;platform to develop and deploy tag management extensions into the Adobe ecosystem.&rdquo; </em>While profiling I documented the following building blocks supporting operations.</span></p>
<ul>
<li><strong><a href="https://developer.adobelaunch.com">Landing Page</a> </strong>- Domain dedicated for Adobe Launch.</li>
<li><strong><a href="http://join.launchdevelopers.chat/">Join Slack Group</a> -</strong> You can request to join their Slack group.</li>
<li><strong><a href="https://docs.adobe.com/content/help/en/launch/using/overview.html">User Documentation</a> -</strong> Overall documentation for Adobe Launch.</li>
<li><strong><a href="https://developer.adobelaunch.com/api/">API Documentation</a> - </strong>The API documentation for Adobe Launch.</li>
<li><strong><a href="https://medium.com/adobetech/search?q=launch">Blog</a> -&nbsp;</strong> They have a tag dedicated to the API as part of the tech blog.</li>
<li><strong><a href="https://developer.adobelaunch.com/resources/example_projects/">Example Projects</a> -</strong> They provide some example projects.</li>
<li><strong><a href="https://developer.adobelaunch.com/resources/tooling/">Tooling</a></strong> - They have some tooling available.</li>
</ul>
<p dir="ltr">It was notable that Adobe&nbsp;<a href="https://github.com/adobe/reactor-developer-docs">publishes documentation using GitHub</a> , allowing anyone to edit the documentation. Another thing I found worth highlighting was that they use the JSON API specification as part of their API first approach to delivering the platform.</p>
<p dir="ltr"><span>I have to be honest I don&rsquo;t fully understand what the ADobe Launch API does. I am not intimate with how the Adobe experience platform works, but I wanted to try and understand the value it delivers within a couple minutes of reading through the API documentation, and other supporting building blocks. Overall, it could use a little more work to help on-board new users, but maybe it is a pretty Adobe ecosystem focused thing, and I am not in the know.</span></p>
<p><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/adob_io_home_page_3.png" alt="" width="40%" align="right" /></p>
<p dir="ltr"><span>One of the things I like about doing these types of profiles is the little nuggets I find about how teams are doing what they do. Here are two of the interesting nuggets I found while profiling the Adobe Launch API:</span></p>
<ul>
<li><strong><a href="https://github.com/stewartschillingsdi/serverless-newman">Serverless Newman</a></strong> - A serverless project that executes postman tests via newman in AWS lambda and writes test results to cloudwatch logs using winston. The Lamdba will return with an error if the test fails / does not complete.</li>
<li><strong><a href="https://github.com/adobe/reactor-postman">Reactor Postman</a> </strong>- A Postman collection of Reactor API examples for Adobe Experience Platform Launch. This collection shows a simplified use case of provisioning a new property, creating extensions rules and data elements, and initiating a library build.</li>
</ul>
<p dir="ltr"><span>These open source projects gives me material for additional stories about how Adobe delivers their API infrastructure, but also how they use Postman as part of their API life cycle. I&rsquo;d like to spend more time playing with the Adobe Reactor Postman collection, and learn more about how it all works in concert with their platform.</span></p>
<h2 dir="ltr"><span>Adobe Sign</span></h2>
<p dir="ltr"><span>Next, I profiled the Adobe Sign API, providing <em>&ldquo;a powerful and easy way to integrate Adobe Sign functionality into your own applications.&rdquo; </em>Here are the building blocks I found while profiling the Adobe Sign API, and helping support developers.&nbsp;</span></p>
<ul>
<li><strong><a href="https://www.adobe.io/apis/documentcloud/sign.html">User Documentation</a></strong></li>
<li><strong><a href="https://secure.na1.echosign.com/public/docs/restapi/v6">Interactive Documentation</a></strong></li>
<li><strong><a href="https://documenter.postman.com/view/14752/RWEnmFPv?version=latest#79df9293-6869-49b5-8039-736a65f52b79">Postman Documentation</a></strong></li>
<li><strong><a href="https://acrobat.adobe.com/us/en/sign/developer-form.html">Sign Up</a></strong></li>
<li><strong><a href="https://acrobat.adobe.com/us/en/business/integrations.html">Integrations</a></strong></li>
<li><strong><a href="https://adobe.na1.documents.adobe.com/public/esignWidget?wid=CBFCIBAA3AAABLblqZhBcIyctfWChQ2OfwTTESQKbOcM39xrj4rd7rlFin-XujK-XC2nj_m3mD1F8R_E035s*">Verification</a></strong></li>
<li><strong><a href="https://www.adobe.io/apis/documentcloud/sign/docs.html#!adobedocs/adobe-sign/master/webhooks/webhook_apis.md">Webhooks</a></strong></li>
<li><strong><a href="https://www.adobe.io/apis/documentcloud/sign/docs.html#!adobedocs/adobe-sign/master/api_usage/api_change_log.md">Change Log</a></strong></li>
<li><strong><a href="https://www.adobe.io/apis/documentcloud/sign/docs.html#!adobedocs/adobe-sign/master/migrating_from_soap.md">SOAP Migration</a></strong></li>
<li><strong><a href="https://github.com/adobe-sign">GitHub Organization</a></strong></li>
<li><strong><a href="https://cloud-elements.com/elements/adobe-esign-services-api/">Cloud Elements</a></strong></li>
</ul>
<p dir="ltr"><span>You can see them exploring with different types of API documentation here by providing interactive documentation using a </span><a href="https://github.com/adobe-sign/AdobeSign-OpenAPI/tree/master/json"><span>Swagger 1.2 definition</span></a><span>, as well as </span><a href="https://documenter.postman.com/view/14752/RWEnmFPv?version=latest#79df9293-6869-49b5-8039-736a65f52b79"><span>Postman documentation with a Run in Postman button</span></a><span>. With additional evidence of Adobe working to evolve the API with the SOAP migration, and the different approaches to documenting, and making their APIs available to a public audience.</span></p>
<p><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/adob_io_home_page_4.png" alt="" width="40%" align="right" /></p>
<h2 dir="ltr"><span>Privacy Service</span></h2>
<p dir="ltr"><span>Next, I looked into the Adobe Privacy Service API, which &ldquo;provides a common, centralized facilitation of access/delete requests and opt-out-of-sale requests for private data.&rdquo; A pretty interesting concept for an API, where I found the following building blocks supporting its operations.</span></p>
<ul>
<li><strong><a href="https://www.adobe.com/experience-platform/privacy-service.html">Website</a></strong></li>
<li><strong><a href="https://www.adobe.io/apis/experiencecloud/gdpr/docs.html">User Documentation</a></strong></li>
<li><strong><a href="https://www.adobe.io/apis/experiencecloud/gdpr/api-reference.html#/">API Documentation</a></strong></li>
<li><strong><a href="https://s4r5s3t9.stackpathcdn.com/AdobeAtAdobe/kirby_docs/master/acpdr/swagger-specs/privacy-service.yaml">Swagger 2.0</a></strong></li>
<li><strong><a href="https://www.adobe.io/apis/experienceplatform/home/tutorials/alltutorials.html#!api-specification/markdown/narrative/tutorials/privacy_service_tutorial/privacy_service_api_tutorial.md">Tutorial</a></strong></li>
</ul>
<p dir="ltr"><span>The GDPR implications of this API are very interesting. I am going to set this API aside and spend some more time playing with as I work to generate a Postman collection from the Swagger 2.0. At first glance it looks like one of those APIs that can be used as a blueprint for other implementations, or maybe become an open source API that anyone can use.&nbsp;</span></p>
<h2 dir="ltr"><span>Cloud Manager</span></h2>
<p dir="ltr"><span>Next, I looked at Cloud Manager, which is part of the Adobe Managed Cloud Services, and enables &ldquo;organizations to self-manage Experience Manager environments in the cloud&rdquo;. The Cloud Manager API enables Cloud Manager customers to interact with the same underlying capabilities exposed through the web UI in a fully programmatic fashion, allowing for integration of the Cloud Manager Continuous Integration / Continuous Delivery pipeline into other systems. There were just a handful of building blocks available for cloud manager.</span></p>
<ul>
<li><strong><a href="https://www.adobe.io/apis/experiencecloud/cloud-manager/docs.html">User Documentation</a></strong></li>
<li><strong><a href="https://www.adobe.io/apis/experiencecloud/cloud-manager/api-reference.html#/">API Documentation</a></strong></li>
<li><strong><a href="https://github.com/AdobeDocs/cloudmanager-api-docs">Docs GitHub Repo</a></strong></li>
<li><strong><a href="https://s4r5s3t9.stackpathcdn.com/AdobeDocs/cloudmanager-api-docs/master/swagger-specs/api.yaml">Swagger 2.0</a></strong></li>
</ul>
<p dir="ltr"><span>With Cloud Manager I am seeing a common thread in how Swagger is used to deliver documentation, providing a Swagger 2.0 spec behind the scenes--something I will use to generate a Postman collection to help me further index the API as part of my research. I also notice that the Cloud Manager API documentation is hosted via GitHub along with other projects within </span><a href="https://github.com/AdobeDocs"><span>a single AdobeDocs GitHub organization</span></a><span>.</span></p>
<h2 dir="ltr">Target Manager</h2>
<p dir="ltr"><span>Now for the Target Manager API which &ldquo;implements Target on client-side applications, server-side applications, mobile apps, IoT and export your Target data to third-party solutions.&rdquo; Here are the building blocks for the Target Manager API.</span></p>
<ul>
<li><strong><a href="http://developers.adobetarget.com">Landing Page</a></strong></li>
<li><strong><a href="https://docs.adobe.com/content/help/en/target/using/target-home.html">User Documentation</a></strong></li>
<li><strong><a href="http://developers.adobetarget.com/api/#reports">API Documentation</a></strong></li>
<li><strong><a href="https://github.com/adobe-target">GitHub</a></strong></li>
<li><strong><a href="http://developers.adobetarget.com/api/#admin-postman-collection">Admin API Postman Collection</a></strong></li>
<li><strong><a href="https://github.com/adobe-target/adobe-target.github.io/blob/master/api/recommendations/Recommendations.postman_collection.json">Recommendations API Postman Collection</a></strong></li>
</ul>
<p dir="ltr"><span>There isn&rsquo;t a lot of meat on the Target Manager API bones, but they do prominently link to Postman collections for each of the APIs. Allowing you to, &ldquo; tailor and personalize your customers' experience so you can maximize revenue on your web and mobile sites, apps, social media, and other digital channels.&rdquo;</span></p>
<h2 dir="ltr"><span>Primetime</span></h2>
<p dir="ltr"><span>Now for Adobe Primetime which, &ldquo;brings TV to every IP-connected screen. It gives programmers and operators modular capabilities to stream, protect, analyze, and monetize video across desktops and devices, powering these experiences are a number of streaming technologies used to deliver content and advertising to Primetime video players.&rdquo; These are the building blocks I identified for Adobe Primetime while looking around.</span></p>
<ul>
<li><strong><a href="https://www.adobe.io/apis/experiencecloud/primetime.html">User Documentation</a></strong></li>
<li><strong><a href="https://www.adobe.com/devnet/primetime.html">Developer Documentation</a></strong></li>
</ul>
<p dir="ltr"><span>You can tell that Primetime isn&rsquo;t quite fully baked as a web API, and posses many of the characteristics of a legacy API, relying on PDF only documentation, and other building blocks that will cause friction with developers, and slow down on-boarding.</span></p>
<h2 dir="ltr">Campaign Standard</h2>
<p dir="ltr"><span>Moving on to the Campaign Standard APIs which lets &ldquo;you create integrations for Adobe Campaign Standard and build your own ecosystem by interfacing Adobe Campaign Standard with the panel of technologies that you use. There is just documentation for the API present in the help section.</span></p>
<ul>
<li dir="ltr">
<p dir="ltr"><strong><a href="https://docs.adobe.com/content/help/en/campaign-standard/using/working-with-apis/about-campaign-standard-apis/about-campaign-standard-apis.html">API Documentation</a></strong></p>
</li>
</ul>
<p dir="ltr"><span>The Campaign Standard API is a pretty classic example of an API that doesn&rsquo;t get much attention, or supporting building blocks. Revealing the Adobe still has some significant investment ahead when it comes to standardizing how resources are distributed across different teams, and take more advantage of shared resources across APIs.</span></p>
<h2 dir="ltr"><span>Analytics</span></h2>
<p dir="ltr"><span>With the Analytics API you see a little more investment in providing &ldquo;a collection of APIs that power Adobe Analytics products like Analysis Workspace, allowing for the creation of data rich user interfaces that you can use to manipulate and integrate data, create reports to explore, get insights, or answer important questions about your data.&rdquo; Here are the building blocks I documented as I was learning about the Adobe Analytics API.</span></p>
<ul>
<li><strong><a href="https://www.adobe.io/apis/experiencecloud/analytics/docs.html">User Documentation</a></strong></li>
<li><strong><a href="https://www.adobe.io/apis/experiencecloud/analytics/api-reference.html">API Documentation</a></strong></li>
<li><strong><a href="https://s4r5s3t9.stackpathcdn.com/AdobeDocs/analytics-2.0-apis/master/docs/swagger.json">Swagger 2.0</a></strong></li>
<li><strong><a href="https://github.com/AdobeDocs/analytics-2.0-apis/blob/master/discovery.md">Discovery API</a></strong></li>
<li><strong><a href="https://github.com/AdobeDocs/analytics-2.0-apis/blob/master/reporting-guide.md">Reporting API</a></strong></li>
<li><strong><a href="https://www.adobe.io/apis/experiencecloud/analytics/docs.html#!AdobeDocs/analytics-2.0-apis/master/oauth-postman.md">OAuth in Postman</a></strong></li>
<li><strong><a href="https://www.adobe.io/apis/experiencecloud/analytics/docs.html#!AdobeDocs/analytics-2.0-apis/master/support.md">Support</a></strong></li>
<li><strong><a href="https://github.com/AdobeDocs/analytics-2.0-apis">Github Docs</a></strong></li>
</ul>
<p dir="ltr"><span>There is a lot more meat on the Adobe Analytics API bones. There is a Swagger 2.0 behind things, and they leverage Postman to help with OAuth. Definitely more work to be done here, but the Analytics API clearly gets more resources and attention by the team and the community.</span></p>
<p><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/adob_io_home_page_5.png" alt="" width="40%" align="right" /></p>
<h2 dir="ltr"><span>User Management</span></h2>
<p dir="ltr"><span>Next up is the User Management API which &ldquo;provides programmatic access to the user accounts that are associated with your Adobe organization, integrating the API into your organization&rsquo;s administrative applications and processes. You can use the API in scripts or programs to allow authorized administrators to create, update, and delete user accounts for your enterprise, and retrieve information about your Adobe users and their access to Adobe products."&nbsp;</span>I only found documentation for the User Management API:</p>
<ul>
<li dir="ltr">
<p dir="ltr"><strong><a href="https://adobe-apiplatform.github.io/umapi-documentation/en/RefOverview.html">API Documentation</a></strong></p>
</li>
</ul>
<p dir="ltr"><span>There was no OpenAPI, Swagger, or Postman collection for the API, but I will add o the list of API definitions I can create, or help encourage Adobe and the community to step up and contribute to. I&rsquo;m guessing the Adobe User Management API can reduce friction for a lot of teams when it comes to orchestrating the use of Adobe products across the enterprise.&nbsp;</span>The Adobe User Management API is definitely one of the more anemic Adobe APIs, and could use some more investment when it comes to its supporting elements, and would significantly benefit from shared resources made available across all of the Adobe APIs.</p>
<h2 dir="ltr"><span>I/O Events</span></h2>
<p dir="ltr"><span>Next, Adobe I/O Events &ldquo;offer you a powerful way to integrate your application with Adobe services and solutions. Starting with Creative Cloud Assets, Adobe Experience Manager, and Adobe Analytics Triggers, we are adding events across our entire range of technologies.&rdquo; They don&rsquo;t provide much beyond some robust user documentation.</span></p>
<ul>
<li dir="ltr">
<p dir="ltr"><strong><a href="https://www.adobe.io/apis/experienceplatform/events/docs.html">User Documentation</a></strong></p>
</li>
</ul>
<p dir="ltr"><span>Adobe I/O Events clearly provides a lot of value, but lacks many of the characteristics of a modern API, and like others would benefit from more resources, and an investment in shared resources across Adobe API teams.</span></p>
<h2 dir="ltr"><span>Audience Manager</span></h2>
<p dir="ltr"><span>Next up is an Audience Manager API, that provides a &ldquo;data management platform that helps you build unique audience profiles so you can identify your most valuable segments and use them across any digital channel". LIke other Adobe APIs, it only has some user documentation to support its integration into other applications and systems.</span></p>
<ul>
<li dir="ltr">
<p dir="ltr"><strong><a href="https://docs.adobe.com/content/help/en/audience-manager/user-guide/api-and-sdk-code/rest-apis/rest-api-main.html">User Documentation</a></strong></p>
</li>
</ul>
<p dir="ltr"><span>The documentation says they are migrating to use Swagger, revealing more of the work that is occurring behind the scenes. I recommend skipping over the Swagger migration and upgrade to OpenAPI 3.0, so that you can take advantage of the evolution of the specification and the tooling it supports.</span></p>
<h2 dir="ltr"><span>Adobe Places</span></h2>
<p dir="ltr"><span>Now for the Places API which, <em>&ldquo;lets you work programmatically with your organization's point of interest (POI). The POIs are organized into libraries so that you can easily create grouped actions on these POIs. The APIs allow you to create, update, and delete your libraries and the POIs in those libraries.&rdquo;</em> The API isn&rsquo;t fully public, and you have to sign up to get access.</span></p>
<ul>
<li dir="ltr">
<p dir="ltr"><strong><a href="https://forms.office.com/Pages/ResponsePage.aspx?i%20d=Wht7-jR7h0OUrtLBeN7O4fkr821yYptFo-ghlnlXCyhUM0dQVkJCSzVDMFNGWEFXWUUwNEJWSjhSRS4u">Signup Form to Get Access</a></strong></p>
</li>
</ul>
<p dir="ltr"><span>I don&rsquo;t fully see how the places API fits into the bigger Adobe picture. Which is kind of a theme I&rsquo;m finding across the APIs I have been profiling. They all seem to have an individual purpose, but I don&rsquo;t see a strong argument for how the API supports the overall Adobe platform objective.</span></p>
<h2 dir="ltr"><span>CC Storage</span></h2>
<p dir="ltr"><span>While I was Googling to see what else I missed, I came across the CC Storage API, which &ldquo;lets you access and modify assets stored in the Creative Cloud, the world's most popular creative platform.&rdquo;&nbsp; All I found was this API documentation:</span></p>
<ul>
<li dir="ltr">
<p dir="ltr"><strong><a href="https://www.adobe.io/apis/creativecloud/ccstorageapi.html">API Documentation</a></strong></p>
</li>
</ul>
<p dir="ltr"><span>CC Storage seems like an API that should be getting a significant amount of investment. I am guessing that seamless integration of storage when it comes to Adobe customers would be a pretty huge priority, and one they would be willing to pay a premium for.&nbsp;</span></p>
<h2 dir="ltr"><span>Stock</span></h2>
<p dir="ltr"><span>Last up is the Adobe Stock API, which <em>&ldquo;provides programmatic access to Adobe Stock content. You can integrate this API into your organization's applications and processes. You can use the API in scripts or programs to search for and retrieve Adobe Stock assets such as photos, videos, and vector files, and to license assets for your users.&rdquo;</em> All I have found to support is the following documentation.</span></p>
<ul>
<li><strong><a href="https://www.adobe.io/apis/creativecloud/stock/docs.html">User Documentation</a></strong></li>
<li><strong><a href="https://github.com/adobe/stock-api-docs">API Documentation</a></strong></li>
</ul>
<p dir="ltr"><span>The documentation for all of Adobes APIs feel like old school documentation for desktop software. Like storage API, I can only imagine the Stock API is a pretty high value API, and would significantly benefit from more investment, and availability as a modern set of APIs. Allowing people to seamlessly integrate and automate with Adobe Stock images across their applications and websites.</span></p>
<h2 dir="ltr"><span>Adobe I/O Summary</span></h2>
<p dir="ltr"><span>It is clear that Adobe is working on bringing together the API vision across all lines of business under a single tent. It is also clear how hard that is to do this across a large established enterprise organization. There isn&rsquo;t a lot of consistency across the APIs minus the nice looking landing page they have for Adobe I/O. I am going to go through each of the APIs that have a Swagger, and upgrade them to use OpenAPI 3.0, and generate Postman collections for each of the APIs, but alongside I have the following recommendations for the Adobe team(s).</span></p>
<ul>
<li><strong>Definitions</strong> - Make sure there is a machine readable definition (OpenAPI and Postman collection) for each API. I am working on doing this as part of my research, publishing to GitHub, so if you want to collaborate on it, I'm here to help. Then let's train everyone at Adobe on why API definitions are so important to API evolution and adoption.</li>
<li><span><strong>Documentation</strong> - Invest in a single API definition driven approach to delivering documentation, either OpenAPI + ReDoc, or go all in on Postman for documentation. Train your teams and make sure they understand the importance of documentation being driven by an API definition, and consistently published for consumers to use.</span></li>
</ul>
<p>I'd say let's start there. I will be investing in this as part of my API Evangelist reserarch. I want there to be complete API definitions for all of the Adobe APIs. Defining what is possible, and allowing consumers to use themn in other services and tooling. I will be publishing these API definitions to GitHub for additional community feedback and contributions, where I will also publish API documentation using Postman. So, I am happy to collaborate on this. I think once there is a complete (enough) API definition plus consistent documentation for each of the existing APIs things will look significantly different, and we can start thinking about other ways to tighten things up.</p>
<p>I fully get the value of Adobe products. Honestly though, I don't see the value in the Adobe APIs. I don't really even grasp what some of them do, and I don't see an overarching vision for how they work together and benefit Adobe or Adobe customers. I know the value is there, it just isn't pulled out in the design and deliver of the APIs. Something that can be significantly enhanced with just a few iterations, and by making sure there are API definitions, and consistent docs present. I am going to take all of this research and publish it to my API Monitoring system, and then publish the API defintions and documentation I have to GitHub. Then I'll step back and consider other areas I can contribute to the Adobe API journey from the outside-in, and I am also hoping some of the Adobe API teams will have reached out to me and initiatied conversations around what they'd like to see.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/01/23/profiling-adobe-apis/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/01/22/three-ways-to-use-postman-and-azure-devops/">Three Ways To Use Postman And Azure Devops</a></h3>
        <span class="post-date">22 Jan 2020</span>
        ---
published: true
layout: post
title: 'Three Ways to Use Postman and Azure DevOps'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/bf_skinner_gears_pipes_plumbing.jpg
---
<p><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/bf_skinner_gears_pipes_plumbing.jpg" alt="" width="40%" align="right" /></p>
<p>I set out to understand the role that Postman can play in an <a href="https://azure.microsoft.com/en-us/services/devops/">Azure DevOps </a>powered API life cycle. I was fully prepared to crash course Azure Dev Ops, and begin mapping out the role that Postman can play, but before I got started I began Googling Postman + Azure DevOps. I was happily surprised to find a number of rich walk throughs written by the passionate Postman community--surpassing anything I could have put together for a version 1.0 of my Azure DevOps Postman guidance. I will still work to pull together my own official Azure DevOps Postman walkthrough, but to prepare I wanted to publish a summary of what I have found while thinking about how Postman and Azure DevOps can work together.&nbsp;</p>
<h3>The Postman Basics</h3>
<p>Before we get going with what I have found, I wanted to point to a couple of key concepts readers will need to be familiar with before they set out trying to use Postman with Azure DevOps, helping set the tone for any integration. It always helps to start with the basics and not assume all of my readers will understand what Postman delivers.</p>
<ul>
<li><strong><a href="https://learning.postman.com/docs/postman/collections/intro-to-collections/">Intro to collections</a>&nbsp;-</strong> Getting familiar with what collections are, and how they work.</li>
<li><strong><a href="https://learning.postman.com/docs/postman/collection-runs/intro-to-collection-runs/">Intro to collection runs</a>&nbsp;-</strong> Understanding the nuance of how collections can be run.</li>
<li><strong><a href="https://learning.postman.com/docs/postman/scripts/intro-to-scripts/">Intro to scripts</a>&nbsp;-</strong> Learning about how to script within the collections being run.</li>
</ul>
<p class="p2">It is critical that you have a decent grasp on what are possible with Postman collections, and how it can be applied as part of any CI/CD pipeline. Most developers think of Postman as simply an HTTP client for just making calls to APIs. Once you understand how collections can be run, and the many different ways that scripts can be applied, you will be much more effective at applying as part of any pipeline, including with Azure DevOps--providing a great place to start.</p>
<h3>Testing Azure DevOps APIs Using Postman</h3>
<p class="p2">While mapping out this walk through I came across two interesting blog posts on using Postman and Azure DevOps together. It will take me weeks to produce a decent integration, so I figured I'd just share these excellent walk-throughs, helping you expedite your awarneeess of how you can use Postman and Azure DevOps together.</p>
<ul>
<li><strong><a href="https://medium.com/@ganeshsirsi/how-to-configure-postman-newman-api-tests-in-azure-devops-or-tfs-and-publish-html-results-caf60a25c8b9">How to Configure Postman / Newman API tests in Azure DevOps or TFS and Publish HTML Results? </a></strong>- The numbering of these steps are a little confusing, but it provides a nice walkthrough of the core functionality that Postman can deliver as part of Azure DevOps, in just a handful of steps:        
<ul>
<li><span style="white-space: pre;">Export postman Tests Collection</span></li>
<li><span style="white-space: pre;">Export Environment Variables (Optional)</span></li>
<li><span style="white-space: pre;">Create a build pipeline in Azure DevOps/TFS</span></li>
<li><span style="white-space: pre;">Verifying the results after execution</span></li>
<li><span style="white-space: pre;">Adding build tasks to Azure DevOps / TFS build pipeline</span></li>
</ul>
</li>
<li><strong><a href="http://blog.tdwright.co.uk/2018/10/27/mega-mash-up-api-testing-with-postman-azure-devops-and-randomuser-me/">Mega mash-up: API testing with Postman, Azure DevOps and randomuser.me</a></strong> - I'd say this one has slightly less detail in it, but I find it useful to have differing views of how to do it, helping me think through what I'd consider to be a healthy approach--I'll leave you to figure out your own way of doing things.</li>
</ul>
<p class="p1">I am going to take both of these walk throughs and distill them down into my own official Postman Azure DevOps guidance and publish to the <a href="https://learning.postman.com/">Postman Learning Center</a>. I'll let you figure out which one works for you and the way you are using Postman and Azure DevOps. Once I have an official walk through published, I'll share here on the blog as a separate story.</p>
<h3>Azure Pipeline Postman Script Management</h3>
<p class="p1">Another use of Postman as part of Azure DevOps operations that I discovered, and was intrigued by, was a project to manage and govern scripts within Postman collections as part of the Azure Pipeline. Providing a blueprint I'd like to see emerge when it comes to general Postman test script management no matter which pipeline you are using.</p>
<ul>
<li><strong><a href="https://marketplace.visualstudio.com/items?itemName=OneLuckiDev.getPostmanJSON">Azure Pipeline Get Postman Scripts </a></strong>- TFS and Azure Pipeline task that will call the Postman API to retrieve the JSON scripts from your account and workspaces. Utilizing this task you can leverage your Postman Enterprise account to manage your scripts, and then pull them down locally so you can put them in a Git repo for better version control. AND/OR You can also utilize this in conjunction with the Postman Newman task in the Marketplace to pull the JSON files locally for use with that task to run your Postman scripts as part of your build and release pipeline.</li>
<li><strong><a href="http://blog.oneluckidev.com/post/using-postman-and-newman-in-your-azure-devops-pipeline">Using Postman and Newman in your Azure DevOps Pipeline</a></strong> - The story behind the Azure Pipeline Postman scripts, providing a little more context of how it can be used as part of your API delivery workflow.</li>
</ul>
<p class="p2">This is a pretty critical pattern for any API provider to think about. I am working with several large enterprise groups on this very subject. Acknowledging that Postman is in heavy use across many teams, and that a more formal strategy is needed to quantify, manage, and govern scripts in place across all teams, workspaces, and collections. Allowing this community example to set a pretty important precedent for how the enterprise can approach their own Postman test governance.</p>
<h3>Azure DevOps Postman Collections</h3>
<p class="p1">There is one last use of Postman in conjunction with the Azure DevOps platform that I wanted to highlight. Allowing you to orchestrate your Azure DevOps life cycle using a Postman collection for the Azure DevOps API. You can get at the collection via GitHub, but also the Postman documentation they have published to support the Azure DevOps Postman collection usage.</p>
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/bf-skinner-train-tracks-seattle-waterfront.jpg" alt="" width="40%" align="right" /></p>
<ul>
<li><strong><a href="https://github.com/hkamel/azuredevops-postman-collections">Azure DevOps Collection</a></strong> - A Postman collection for the Azure DevOps API, for orchestrating your deployment.</li>
<li><strong><a href="https://explore.postman.com/templates/4400/azure-devops-rest-apis-v50">Azure DevOps API Documentation</a></strong> - Resulting Postman documentation published from collection.</li>
</ul>
<p class="p1">This is what I'd consider to be a Postman life cycle collection. Sure, it is a reference of the Azure DevOps API, but it can also be used to deploy and manage the life cycle of your API. Elevating it one level up from a standard Postman reference collection, demonstrating the versatility in how Postman collections can be applied, depending on what API you are applying it to.</p>
<h3>Putting Postman To Work With Azure DevOps</h3>
<p class="p1">This dive into the world of Azure DevOps has provided me with three meaningful ways in which Postman can be used with Azure DevOps. I'd say that the testing Azure DevOps APIs with Postman is the most straightforward and common example of the value Postman delivers, when it comes to CI/CD. Secondarily I would say say that the Postman collection for the Azure DevOps API reflects how API consumers and providers are putting Postman collections to work. After that the look at script management provides us with a forward thinking look at how Postman can be used, providing us with three distinct lessons on how to use Postman, but specifically with Azure DevOps.</p>
<ul>
<li><strong>Pipeline Testing </strong>- Baking API contract testing into your Azure DevOps pipeline.</li>
<li><strong>Life Cycle Collection </strong>- Orchestrating the deployment and testing of your APIs.</li>
<li><strong>API Test Governance -</strong> Governing the tests you have in place across all APIs.</li>
</ul>
<p>This gives me three areas to focus on as I play around with Azure DevOps more. It also provides my readers with some insight into how they can use Postman with Azure DevOps, while I am working on more stories, and some formal tutorials. It provides me with three pretty solid arguments for how Postman can be used with not just Azure DevOps, but also potentially any other CI/CD solution. I'll make sure and begin diving into Jenkins, AWS, Google, CircleCI, and others to see how they are being used, aggregating what I find across the community--similar to what I've done here with Azure DevOps. I enjoy doing this kind of work because it helps me understand what is possible when it comes to the API life cycle, while also providing insight into how Postman can be used by my readers as part of their own CI/CD workflow. #WinWin</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/01/22/three-ways-to-use-postman-and-azure-devops/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/01/22/the-state-of-california-doing-apis-the-right-way-by-starting-simple/">The State Of California Doing Apis The Right Way By Starting Simple</a></h3>
        <span class="post-date">22 Jan 2020</span>
        ---
published: true
layout: post
title: 'The State of California Doing APIs The Right Way By Starting Simple'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/state_of_california.png
---
<p><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/state_of_california.png" alt="" width="40%" align="right" /></p>
<p class="p1">I got introduced to the<a href="https://medium.com/cadotgov/introducing-the-ca-gov-alpha-team-6daff8e0b4b8"> CA.gov Alpha Team</a> by my fellow government change maker Luke Fretwell (<a href="https://twitter.com/lukefretwell">@lukefretwell)</a> the other day, and I am beginning to tune into what they are up to in similar ways to how I&rsquo;ve done with other city, state, and federal government entities over the years. We kicked off a conversation around their approach to delivering APIs, and what was possible with Postman. After we were done kicking things off they shared some links with me to help me get up to speed on what they have been doing with their new approach to delivering technology across the State of California.</p>
<p class="p1">As far as first impressions go I am super stoked with their approach. They are starting small, and working hard to be as public with how they are doing everything. The CA.gov Alpha Team gets right down to the core of doing API well, by setting up the essential communication channels you need to do APIs well across any small or large organization.</p>
<ul>
<li><strong><a href="https://github.com/cagov/">GitHub</a></strong>&nbsp;- All of the projects they develop are published to GitHub.</li>
<li><strong><a href="https://twitter.com/CAdotGov">Twitter</a></strong>&nbsp;- Providing a social stream from what is happening.</li>
<li><strong><a href="https://medium.com/cadotgov">Blog</a></strong>&nbsp;- Shaping the narrative around all of the work that is occuring.</li>
</ul>
<p class="p1">The CA.gov Alpha Team has not just gone all in on GitHub, they are all about their work truly existing in the public domain. It looks like everything they are doing is first being defined as a GitHub repository, providing a default way for other government stakeholders, as well as the public at large to stay in tune with what is going on, and even contribute to what is happening. This is how all government should be by default, and the CA.gov Alpha Team provides one possible blueprint for other city, state, and federal agencies to follow.</p>
<p class="p1"><span class="s2">I really like that the </span>CA.gov Alpha Team is seeding and managing everything out in the open on Twitter, and being so vocal about it all with a blog, making sure they tell the story about what is happening in real time&mdash;this is critical for API success. In addition to these essential building blocks, they have begun working in some areas, to help define how they will be doing what they do.<span>&nbsp;</span></p>
<ul>
<li><strong><a href="https://github.com/cagov/Alpha">Website</a></strong> - They are working on a centralized website for the groups work.</li>
<li><strong><a href="https://github.com/cagov/cwds">Web Design System</a></strong>&nbsp;- Defining a web design system based on Bootstrap.</li>
<li><strong><a href="https://github.com/cagov/Alpha.CA.gov-theme">Website Theme</a></strong>&nbsp;- A website theme for use across projects.</li>
<li><strong><a href="https://github.com/cagov/handbook-cadotgov">Handbook</a></strong>&nbsp;- Document lessons learned as they build a hybrid multi-disciplinary team.</li>
<li><strong><a href="https://github.com/cagov/UX">UX</a>&nbsp;</strong>- A repository dedicated to tracking all of their user needs and stories.</li>
<li><strong><a href="https://github.com/cagov/API">API</a></strong>- The actual API(s) they are developing as part of their work for the state.</li>
<li><strong><a href="https://github.com/cagov/actions-eleventy">GitHub Actions</a></strong>&nbsp;- Defining how GitHub actions are used for pipelines.</li>
</ul>
<p class="p1">Since all of their work is available on GitHub you can follow each individual projects to get updates, and you can submit issues or pull requests for each of the individual projects. I am going to be tuning into <a href="https://github.com/cagov/API">the API repository</a>&nbsp;because that is the one that interests me the most (surprise). Although I will also be evaluating how they are using GitHub Actions in conjunction with the rest of their API architecture. Then I will be thinking more deeply about their API life cycle workflow, and making suggestions along the way, beginning with their new API requests template which uses GitHub issues.</p>
<ul>
<li><strong><a href="https://github.com/cagov/API/issues/new/choose">New API Request (Issues)</a></strong>&nbsp;- The CA.gov Alpha Team is using GitHub issues to allow other government stakeholders, as well as the public to submit suggestions for which APIs and services they should be delivering&mdash;something that all government agencies should have. Currently they have X questions to help submit the seed for each new API request   
<ul>
<li><strong>Is your feature request related to a problem? </strong>- A clear and concise description of what the problem is.</li>
<li><strong>Describe the solution you'd like</strong> - How would you like to interact with this API</li>
<li><strong>Are there any existing related APIs or data sources</strong> - Are you aware of data sources or existing APIs related to this request</li>
<li><strong>Additional context</strong> - Add any other context or screenshots about the feature request here.</li>
</ul>
</li>
</ul>
<p class="p1">I am going to spend some time thinking about this approach to allowing suggestions for new APIs within government, and provide some feedback on how to improve, and establish a workflow to manage a steady flow of incoming API requests. You can already see this process in action with the three new APIs they are currently defining and developing, working to deliver specific services but also flesh out what their API delivery life cycle will look like.</p>
<ul>
<li><strong><a href="https://github.com/cagov/API/tree/master/DrinkingWaterQuality">Water Quality</a></strong>&nbsp;- Water quality contaminant measurements after water passes through each local California water treatment plant.</li>
<li><strong><a href="https://github.com/cagov/API/tree/master/LaneClosures">Lane Closures</a></strong>&nbsp;- Caltrans CCWWP, could consume all the separate district specific json files from Caltrans web portal.</li>
<li><strong><a href="https://github.com/cagov/API/tree/master/SafeToSwim">Safe to Swim</a></strong>&nbsp;- Swimming location water contaminant measurements, which could also include algae bloom info.<span>&nbsp;</span></li>
</ul>
<p><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/1_jgrirb9lj7tsrvkesuxwta.jpeg" alt="" width="40%" align="right" /></p>
<p class="p1">I&rsquo;m going to dive into thinking about all three of these APIs, and using them as an opportunity to help their team think through the delivery of each API, but also begin defining what their overall API life cycle might look like. Helping them establish some clear guidelines on how to deliver APIs consistently across teams, eventually maybe publishing it alongside their web site, UX, handbook, and the other resources they are making available. I just wanted to get up to speed on their approach to doing things, and process all of the links they had shared with me. Next I am going to focus on a couple of areas to hopefully contribute some value.</p>
<ul>
<li><strong>API First</strong> - I am going to work to establish an API first workflow for each of the APIs they are working on currently, attempting to demonstrate the value of API first in a way that they can also reuse to convince other stakeholders.</li>
<li><strong>Pipeline</strong> - Then I want to better understand how they are using Azure to deliver their APIs, and how they are building using GitHub Actions, working to better define how the API collections for each API can be used as part of the pipeline.</li>
</ul>
<p class="p2">After that I will thinkg more about where else I can help out. I&rsquo;m just looking to shadow what they are doing and provide additional elements that they can consider merging into their existing work. I don&rsquo;t want to create extra work or processes for them, I just want to help them see the bigger picture when it comes to delivering APIs efficiently at scale, and provide resources they can share with their other stakeholders. After this first dive into things, a couple of areas I&rsquo;d consider thinking more about before moving forward too fast are:</p>
<ul>
<li><strong>GitHub Standards</strong> - Establish naming conventions for GitHub repositories, as well as establish a template for README, to help standardize how repositories are put to use as part of work&mdash;standardizing things before they explode too much.</li>
<li><strong>Mono Repo vs Multi Repo</strong> - Considering the pros and cons of operating a single repo for all APIs being delivered or breaking them up into separate repositories, and being honest about the tradeoffs now as well as down the road with hundreds of APIs.</li>
</ul>
<p class="p1">I am sure I will have lots of other suggestions now that I have their work loaded up into my old brain, letting me simmer more on what is going on. After fleshing out an API first approach for the three APIs that are on the table, and thinking more deeply on the pipeline and how they use GitHub and Azure, I am sure I&rsquo;ll have lots of other feedback which I&rsquo;ll submit as GitHub issues. Then they can decide what they actually want listen to, and what feedback might not make sense. I just want to make sure they have another pair of eyes on things. I know how hard it can be to see the big picture when you are down on the ground within government agencies. I&rsquo;m hoping my contributions and storytelling will also drum up interest from other government employees as well as the general public. I get pretty excited to think about the potential of people pitching in when it comes to moving forward the conversation around how government does what it does, and how it leverages the web to be more engaged with the public.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/01/22/the-state-of-california-doing-apis-the-right-way-by-starting-simple/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/01/22/help-defining-13-of-the-asyncapi-protocol-bindings/">Help Defining 13 Of The Asyncapi Protocol Bindings</a></h3>
        <span class="post-date">22 Jan 2020</span>
        ---
published: true
layout: post
title: 'Help Defining 13 of the AsyncAPI Protocol Bindings'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/stalin-time-shipping-docks_36331347010_o.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/stalin-time-shipping-docks_36331347010_o.jpg" alt="" width="40%" align="right" /></p>
<p>I have been evolving my definition of what my API toolbox covers, remaining focused on HTTP APIs, but also make sure I am paying attention to HTTP/2 and HTTP/3 APIs, as well as those that depend on TCP only. My regular call with Fran M&eacute;ndez (<a href="https://twitter.com/fmvilas">@fmvilas</a>) of <a href="https://www.asyncapi.com/">AsyncAPI</a> reminded me that I should be using the specification to ground me in the expansion of my API toolbox, just as OpenAPI has defined much of it for the last five years. For this particular multi-protocol API toolbox research, <a href="https://github.com/asyncapi/bindings">the AsyncAPI protocol bindings </a>reflect how I am looking to expand upon my API toolbox.</p>
<p>Here are <a href="https://github.com/asyncapi/bindings">the 13 protocols being defined around the AsyncAPI specification</a>:</p>
<ul>
<li><a href="https://github.com/asyncapi/bindings/blob/master/amqp">AMQP binding</a>&nbsp;-&nbsp;<span>This document defines how to describe AMQP-specific information on AsyncAPI.</span></li>
<li><a href="https://github.com/asyncapi/bindings/blob/master/amqp1">AMQP 1.0 binding</a>&nbsp;-&nbsp;<span>This document defines how to describe AMQP 1.0-specific information on AsyncAPI.</span></li>
<li><a href="https://github.com/asyncapi/bindings/blob/master/http">HTTP binding</a>&nbsp;-&nbsp;<span>This document defines how to describe HTTP-specific information on AsyncAPI.</span></li>
<li><a href="https://github.com/asyncapi/bindings/blob/master/jms">JMS binding</a>&nbsp;-&nbsp;<span>This document defines how to describe JMS-specific information on AsyncAPI.</span></li>
<li><a href="https://github.com/asyncapi/bindings/blob/master/kafka">Kafka binding</a>&nbsp;-&nbsp;<span>This document defines how to describe Kafka-specific information on AsyncAPI.</span></li>
<li><a href="https://github.com/asyncapi/bindings/blob/master/mqtt">MQTT binding</a>&nbsp;-&nbsp;<span>This document defines how to describe MQTT-specific information on AsyncAPI.</span></li>
<li><a href="https://github.com/asyncapi/bindings/blob/master/mqtt5">MQTT5 binding</a>&nbsp;-&nbsp;This document defines how to describe MQTT 5-specific information on AsyncAPI.</li>
<li><a href="https://github.com/asyncapi/bindings/blob/master/nats">NATS binding</a>&nbsp;-&nbsp;<span>This document defines how to describe NATS-specific information on AsyncAPI.</span></li>
<li><a href="https://github.com/asyncapi/bindings/blob/master/redis">Redis binding</a>&nbsp;-&nbsp;This document defines how to describe Redis-specific information on AsyncAPI.</li>
<li><a href="https://github.com/asyncapi/bindings/blob/master/sns">SNS binding</a>&nbsp;-&nbsp;This document defines how to describe SNS-specific information on AsyncAPI.</li>
<li><a href="https://github.com/asyncapi/bindings/blob/master/sqs">SQS binding</a>&nbsp;-&nbsp;This document defines how to describe SQS-specific information on AsyncAPI.</li>
<li><a href="https://github.com/asyncapi/bindings/blob/master/stomp">STOMP binding</a>&nbsp;-&nbsp;This document defines how to describe STOMP-specific information on AsyncAPI.</li>
<li><a href="https://github.com/asyncapi/bindings/blob/master/websockets">WebSockets binding</a>&nbsp;-&nbsp;This document defines how to describe WebSocket-specific information on AsyncAPI.</li>
</ul>
<p>Not all of the protocol bindings are fully fleshed out, and AsyncAPI could use help from the community to quantify what is required with each of the protocols. I am going to try and contribute what I can as I make my way through each of the protocols as part of my API toolbox research.I am defining the building blocks for each of the protocols which is somethign that overlaps with many of the configurations needed to define each of the protocol bindings.</p>
<p>I am also looking to map out a kind of decision tree to go along with my API toolbox. Crafting an interactive way to help people understand the strengths and weaknesses of each of the approaches to delvering APIs. So if you have an expertise in any of these areas I'd love to hear from you about what your reasons are for choose one protocol over another, and if you have the bandwidth to contribute to helping define each of the 13 protocols as part of the AsyncAPI specification, go ahead and <a href="https://github.com/asyncapi/bindings">submit a pull request on the GitHub repository</a>, or at least leave an issue to help us think through what the technical details of what it takes to bind to each of the protocols.</p>
<ul>
</ul>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/01/22/help-defining-13-of-the-asyncapi-protocol-bindings/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/01/21/my-upcoming-talk-with-the-uk-government-digital-services-gds-the-api-life-cycle-is-for-everyone/">My Upcoming Talk With The Uk Government Digital Services Gds The Api Life Cycle Is For Everyone</a></h3>
        <span class="post-date">21 Jan 2020</span>
        ---
published: true
layout: post
title: 'My Upcoming Talk with the UK Government Digital Services (GDS): The API Life Cycle Is For Everyone'
image: https://s3.amazonaws.com/kinlane-productions2/kin-lane/153-Post+Con+2018-Speakers.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/kin-lane/153-Post+Con+2018-Speakers.jpg" alt="" width="40%" align="right" /></p>
<p><a href="https://www.eventbrite.co.uk/e/gds-tech-talks-interoperability-and-open-standards-tickets-89225117729">I am heading to London in February to talk to the UK government about APIs</a>. They invited me out to talk about my history of work with government in the US and EU, and share my views of the API life cycle. To help share my view of the API landscape I pulled together a talk titled, <em><strong>"The API Life Cycle Is For Everyone"</strong></em>. I am hoping to share my view of the fundamentals of a modern API life cycle, as well as emphasize the importance of both developers and non-developers having a place at the table. Here is what I've pulled together for my time with the GDS in London.</p>
<p class="p1" style="padding-left: 30px;"><em>APIs are widely considered to be something that is exclusively in the domain of software developers. While it is true that APIs are often a very technical and abstract concept which requires a more technically inclined individual to engage, APIs are something that impacts everyone across todays digital landscape, impacting both business users and developers, making the API development life cycle something all parties should be educated on, made aware of, and equipped to participe in. As part of my contribution to the GDS talks on interoperability and open standards I&rsquo;d like to spend an hour with you talking through the human-machine intersection across:</em></p>
<ul style="list-style: none;">
<li> 
<ul>
<li class="li1"><em><strong>API Definitions - </strong>Talking about Swagger / OpenAPI, as well as Postman collections and environments, and how they are being put to use.</em></li>
<li class="li1"><em><strong>API Documentation -</strong> Understanding common approaches to delivering and maintaining documentation for APIs that are being delivered.</em></li>
<li class="li1"><em><strong>API Mocks -</strong> Thinking about how API mocking can be used to articulate and share what an API delivers for all stakeholders involved.</em></li>
<li class="li1"><em><strong>API Testing -</strong> Understanding the role that API assertions and testing play in defining the operations and reliability of our API infrastructure.</em></li>
<li class="li1"><em><strong>API Management -</strong> Looking at how API management secures our APIs, but also helps us develop the awareness of how they are used.</em></li>
<li class="li1"><em><strong>API Contracts -</strong> Having an honest conversation about the observability and reliability of the APIs we are providing to our consumers.</em></li>
<li class="li1"><em><strong>API First - </strong>Highlight the potential of being API first when it comes to delivering desktop, web, mobile, and device applications.</em></li>
</ul>
</li>
</ul>
<p class="p1" style="padding-left: 30px;"><em>This discussion about APIs in government is meant to help show the important role that non-developers play in the API development and delivery life cycle. Focusing on the role that API definitions play in making APIs more accessible to developers and non-developers, and help facilitate a more organized and collaborative approach to delivering and consuming APIs. Helping all participants understand how APIs are driving different types of applications, as well as system integrations, helping ensure that government better serves its constituents, and is an active player in the API economy, maintaining its role when it comes to setting the tone in how markets work.</em></p>
<p class="p1">If you work within the UK government, I'll be participating in <a href="https://www.eventbrite.co.uk/e/gds-tech-talks-interoperability-and-open-standards-tickets-89225117729">the&nbsp;GDS Tech Talks: Interoperability and Open Standards</a>&nbsp;on February 3rd--you can sign up with your government email account using the EventBrite page they have setup. I'll be in town on February 3rd and 4th, but then have to get back to San Francisco for the kickoff of <a href="https://www.postman.com/galaxy-tour-2020">the Postman Galaxy Tour on February 6th</a>. I'll be back in Europe later on in the spring to talk APIs as the Postman Tour makes its way around the globe, so if you don't catch this talk I'll be back. As part of my Postman work, I will be continuing to invest in my work with the US, UK, and other federal governments, as well as my work at the state and municipal levels. If you would like to have me come talk with your government agency, I'd be happy to fit into the calendar when it make sense--just let me know.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/01/21/my-upcoming-talk-with-the-uk-government-digital-services-gds-the-api-life-cycle-is-for-everyone/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/01/21/looking-at-electronic-data-interchangeedi-reminds-me-that-the-api-economy-is-just-getting-started/">Looking At Electronic Data Interchangeedi Reminds Me That The Api Economy Is Just Getting Started</a></h3>
        <span class="post-date">21 Jan 2020</span>
        ---
published: true
layout: post
title: 'Looking at Electronic Data Interchange (EDI) Reminds Me that the API Economy is Just Getting Started'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/scream-IMG_8494.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/scream-IMG_8494.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">I am neck deep <a href="http://apievangelist.com/2020/01/21/expanding-my-api-toolbox-for-the-next-decade/">in the expansion of what I consider to be my API toolbox</a>, and I have been spending time mapping out the world of EDI. If you aren&rsquo;t familiar with&nbsp; <a href="https://en.wikipedia.org/wiki/Electronic_data_interchange">the Electronic Data Interchange&nbsp;(EDI)</a>, it &ldquo;is the electronic interchange of business information using a standardized format; a process which allows one company to send information to another company electronically rather than with paper. Business entities conducting business electronically are called trading partners.&rdquo;&nbsp; EDI is the original API by providing a, &ldquo;technical basis for automated commercial "conversations" between two entities, either internal or external. The term EDI encompasses the entire electronic data interchange process, including the transmission, message flow, document format, and software used to interpret the documents&rdquo;. EDI is everywhere, and truly the backbone of the global supply chain, but one that you only hear lightly about as part of the overall API conversation.</p>
<p class="p1">I have regularly come across the overlap between EDI and API over the last 10 years of doing API Evangelist, and while I have engaged in discussion around modernizing legacy EDI approaches in healthcare and commerce, most other fundamental building blocks of the global supply chain are entirely new to me. Revealing how little I know about the bigger picture of EDI, and how small my API world actually is. I don&rsquo;t claim to know everything about information exchange and interoperability, but EDI is something that should be a bigger part of my storytelling, and the fact that it isn&rsquo;t I think is revealing about how much more work we actually have in front of us when it comes to delivering on the promise of the API economy.<span>&nbsp;</span></p>
<p class="p1">Take a look at some of the major EDI standards to get a sampling of the scope I am talking about. These are the electronic data interchange standards that have governed commerce before the Internet was around, and continues to define how data moves around.</p>
<ol>
<li><strong><a href="https://www.edigas.org/">Edig@s (EDIGAS)</a></strong> - The Edig@s Workgroup decided to implement EDI messages to: Reduce the number of different messages currently used; Achieve a more efficient and more flexible way of handling the dispatching activities; Allow a faster reaction to a changed working environment. The EDI standard selected for those messages is the UN/EDIFACT standard and starting from Edig@s version 4 we introduced the XML standard.</li>
<li><strong><a href="https://en.wikipedia.org/wiki/GS1_EDI">GS1 EDI</a></strong> - GS1 EDI is a set of global electronic messaging standards for business documents used in Electronic Data Interchange (EDI). The standards are developed and maintained by GS1. GS1 EDI is part of the overall GS1 system, fully integrated with other GS1 standards, increasing the speed and accuracy of the supply chain. Examples of GS1 EDI standards include messages such as: Order, Despatch Advice (Shipping Notice), Invoice, Transport Instruction, etc.</li>
<li><strong><a href="https://en.wikipedia.org/wiki/Health_Insurance_Portability_and_Accountability_Act">HIPAA</a></strong> - The Health Insurance Portability and Accountability Act of 1996 was enacted by the 104th United States Congress and signed by President Bill Clinton in 1996. It was created primarily to modernize the flow of healthcare information, stipulate how Personally Identifiable Information maintained by the healthcare and healthcare insurance industries should be protected from fraud and theft, and address limitations on healthcare insurance coverage</li>
<li><strong><a href="https://www.hl7.org/">Hl7</a></strong> - Health Level Seven International (HL7) is a not-for-profit, ANSI-accredited standards developing organization dedicated to providing a comprehensive framework and related standards for the exchange, integration, sharing and retrieval of electronic health information that supports clinical practice and the management, delivery and evaluation of health services.</li>
<li><strong><a href="https://www.iata.org/en/publications/store/cargo-interchange-message-procedures--cargo-imp-/">IATA Cargo-IMP</a></strong> - Cargo data exchange automation between airlines and other parties works much more efficiently if messaging procedures and standards are applied. IATA's Cargo-IMP is the legacy standard for exchanging critical cargo operations information.</li>
<li><strong><a href="https://www.odette.org/">Odette</a></strong>- Odette is a pan-European collaboration and services platform working for the entire automotive network. We bring together supply chain professionals and technology experts to create standards, develop best practice and provide services which support logistics management, e-business communications and engineering data exchange throughout the world.<span>&nbsp;</span></li>
<li><strong><a href="https://en.wikipedia.org/wiki/SCRIPT_(medicine)">SCRIPT</a></strong> - SCRIPT is a standard promulgated by the National Council for Prescription Drug Programs (NCPDP) for the electronically transmitted medical prescriptions in the United States.</li>
<li><strong><a href="https://en.wikipedia.org/wiki/SWIFT_message_types">Swift</a></strong> - The Society of Worldwide Interbank Financial Telecommunication was formed in 1973 and is headquartered in Brussels. SWIFT operates a worldwide financial messaging network which exchanges messages between banks and financial institutions. SWIFT also markets software and services to financial institutions, much of it for use on the SWIFTNet Network.</li>
<li><strong><a href="https://en.wikipedia.org/wiki/TRADACOMS">TRADACOMS</a></strong> -<span>&nbsp; </span>Tradacoms is an early standard for EDI primarily used in the UK retail sector. It was introduced in 1982 as an implementation of the UN/GTDI syntax, one of the precursors of EDIFACT, and was maintained and extended by the UK Article Numbering Association.</li>
<li><strong><a href="https://en.wikipedia.org/wiki/EDIFACT">UN/EDIFACT</a></strong> - An international EDI standard developed under the United Nations, providing a set of syntax rules to structure data, an interactive exchange protocol (I-EDI), and standard messages which allow multi-country and multi-industry exchange.</li>
<li><strong><a href="https://en.wikipedia.org/wiki/ASC_X12">X12 Electronic data interchange (EDI)</a></strong> - The X12 Electronic data interchange (EDI) and Context Inspired Component Architecture (CICA) standards along with XML schemas which drive business processes globally. The membership of ASC X12 includes technologists and business process experts, encompassing health care, insurance, transportation, finance, government, supply chain and other industries.</li>
</ol>
<p class="p1">EDI is API. These standards employ FTP, SFTP, FTPS, Email, HTTP, AS1, AS2, and AS4 to move data around. If SOAP is the father of API, then EDI is the grandfather. Each of these standards provide the technical details of the exchange of data, and providers can use any of these protocols to move the data around between providers. Going beyond the standards themselves, you can look at some of the EDI efforts out of enterprise and federal government agencies who set the tone for how markets work each day.</p>
<ul>
<li><strong>Commerce</strong> 
<ul>
<li><a href="https://corporate.walmart.com/suppliers/merchandise-support-center">Walmart</a></li>
<li><a href="https://developer.amazonservices.com/index.html">Amazon</a></li>
</ul>
</li>
<li><strong>Automotive</strong> 
<ul>
<li><a href="https://www.gsec.ford.com/Hub">Ford</a></li>
<li><a href="https://www.vwgroupsupply.com/one-kbp-pub/en/kbp_public/information/electronic_data_interchange/electronic_data_interchange.html">Volkswagen</a></li>
</ul>
</li>
<li><strong>Healthcare</strong> 
<ul>
<li><a href="https://www.gsec.ford.com/Hub">Centers for Medicare &amp; Medicaid Services</a></li>
<li><a href="https://www.cigna.com/health-care-providers/coverage-and-claims/submit-claims/electronic-data-interchange-vendors">Cigna</a></li>
</ul>
</li>
<li><strong>Government</strong> 
<ul>
<li><a href="https://dodprocurementtoolbox.com/site-pages/ebusiness-data-standards-edi">Deparment of Defense</a></li>
<li><a href="https://www.eda.gov/edi/">Department of Commerce</a></li>
</ul>
</li>
<li><strong>Aerospace</strong> 
<ul>
<li><a href="http://www.boeingsuppliers.com/edi/PCOS_EDI_guidelines.pdf">Boeing</a></li>
<li><span class="s1"><a href="https://www.airbus.com/be-an-airbus-supplier.html">Airbus</a></span></li>
</ul>
</li>
<li><span class="s1"><a href="https://www.airbus.com/be-an-airbus-supplier.html"></a></span></li>
</ul>
<p class="p2">EDI is the supply chain API, orchestrating purchasing, fulfillment, logistics, invoices, and other elements of commerce, automative, healthcare, aerospace, and other top industries. If you want the road map for API industry over the next 30 years, take a look at the EDI space. If we want the backbone of the API economy to move into the future and use modern API practices, we are going to need to target this layer of the economy that governs how data is moved around and incentivize companies to employ HTTP, and HTTP/2 and standardize on XML, JSON, Avro, Protocol Buffers, and other common data exchange and serialization formats. If you map out the world of EDI, you could plot what is needed when it comes to API adoption in the next couple of decades.</p>
<p class="p1">The EDI space is messy and specialized, but it is very busy. There are many different agencies and governing bodies out there servicing the EDI layer of the global economy. Next, I will be diving more into each of the standards, as well as who are some of the dominant brokers when it comes to the certification and brokering of EDI discovery, integration, and ultimately evolution. If we want to modernize this legacy world of APIs we are going to have to focus on these power brokers, helping make them more aware of APIs, and why they represent the future of data interoperability. The most movement I have seen in this area to showcase is the work around HL7 and the FHIR specification for healthcare, but I&rsquo;m going to need to assess the other business sectors serviced by EDI to understand their current state. After studying the world of EDI for a few days it is painfully clear how early in this whole API journey we are, and that the way we move data around with APIs is just in its infancy when it comes to the maturity and scope of EDI. Demonstrating to me that I&rsquo;m going to be spending the rest of my career evangelizing APIs, and helping people understand the benefits of standardizing how we move bits and bytes around using HTTP.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/01/21/looking-at-electronic-data-interchangeedi-reminds-me-that-the-api-economy-is-just-getting-started/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/01/21/i-think-we-will-have-to-embrace-chaos-with-the-future-of-apis/">I Think We Will Have To Embrace Chaos With The Future Of Apis</a></h3>
        <span class="post-date">21 Jan 2020</span>
        ---
published: true
layout: post
title: 'I Think We Will Have To Embrace Chaos With the Future of APIs'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/rain-princess-IMG_7162.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/rain-princess-IMG_7162.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">I like studying APIs. I like to think about how to do APIs well. I enjoy handcrafting a fully fleshed out OpenAPI definition for my APIs. The challenge is convincing other folks of the same. I see the benefits of doing APIs well, and I understand doing the consequences of not doing them well. But, do others? I never assume they do. I assume that most people are just looking to get an immediate job done, and aren&rsquo;t too concerned with the bigger picture. I think people have the perception that technology moves too fast, and they either do not have the time to consider the consequences, or they know that they will have moved on by the time the consequences are realized. I&rsquo;m pretty convinced that most of our work on API design, governance, and other approaches to try and standardize how we do things will fall on deaf ears. Not that we shouldn&rsquo;t keep trying, but I think it helps if we are honest about how this will utlimately play out.</p>
<p class="p2">If I give a talk about good API design at a tech conference everyone who shows up for the talk is excited about good API design. If I give a talk about good API design within an enterprise organization and leadership mandates everyone attend, not everyone present is excited, let alone cares about API design. I wish people would care about API design, and be open to learning about how others are designing their APIs, but they aren&rsquo;t. Mostly it is because developers aren&rsquo;t given the space within their regular sprints to care, but it is also because people are only looking to satisfy the JIRA ticket they are given, and often times the ticket has said nothing about the API being well designed, and consistent with other teams. Even with teams that have been given sufficient API design training and governance, if it isn&rsquo;t explicitly called out as part of the acceptance criteria for a specific unit of work, it is unlikely to get done.</p>
<p class="p1">I guess this is where automation and pipeline testing comes into play right? We make sure there is a healthy amount of contract, as well as governance testing across our pipelines. We make sure the design and implementation of each individual API path meet any assertions laid down as part of the design and governance efforts. I think this will definitely make a significant impact on things, and go further than just depending on individuals to step up, but I still think there will be plenty of pushback on API governance by some teams and individuals, and there will always be projects that manage to escape governance efforts. With this in mind we are going to have to be more honest that there will always be chaos. We will never have a handle on all of our schema, and be able to consistently deliver APIs across teams at scale. Again, it doesn&rsquo;t mean we shouldn&rsquo;t try. It means that we should also be investing in tools, services, and processes that help us make sense of the chaos, and find ways to work in this environment. Knowing that it will always be like this with things getting better or worse from time to time, depending on team and leadership turnover across the enterprise.</p>
<p class="p2">After a decade of watching all of this play out I am just not convinced that everyone is really interested in getting their house in order. The number of APIs is exponentially growing, with meaningful investment in governance by enterprise organizations, and service or tooling makers progressing at a very slow pace. There is no way that we will be able to keep up. This story is triggered by me analyzing thousands of Swagger, OpenAPI, and Postman collections I have harvested across GitHub. I see a lot of public APIs, but I also see people trying to document, mock, test, and make sense of internal APIs. These are rarely Swagger, OpenAPI, and Postman collections from people working to define, design, and deliver APIs&mdash;it is mostly people trying to just make sense of the world around them, and deliver what they need to be successful in the moment. These API artifacts aren&rsquo;t complete, they are simply done enough to allow someone to publish documentation, generate a mock, generate tests, scan for security holes, or the numerous other things they need to move from A to B. These artifacts tell me that people are just trying to stay afloat, make sense of what is going on around them, and rarely have time and bandwidth to do things well. Reflecting chaos as usual I encounter across every enterprise organization I have worked with over the years.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/01/21/i-think-we-will-have-to-embrace-chaos-with-the-future-of-apis/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/01/21/expanding-my-api-toolbox-for-the-next-decade/">Expanding My Api Toolbox For The Next Decade</a></h3>
        <span class="post-date">21 Jan 2020</span>
        ---
published: true
layout: post
title: 'Expanding My API Toolbox for the Next Decade'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/bf-skinner-satellite-dishes-pointing-up.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/bf-skinner-satellite-dishes-pointing-up.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">I am <a href="https://apievangelist.com/2018/02/03/api-is-not-just-rest/">continuing to iterate on what I consider to be a modern API toolbox</a>. API Evangelist research is born out of the SOA and API worlds colliding, and while I have been heavily focused on HTTP APIs over the years, <a href="https://dzone.com/articles/my-evolving-definition-of-a-robust-and-diverse-api">I have regularly acknowledged that a diverse API toolbox is required for success</a>, and invested time in understanding just what I mean when I say this. Working to broaden my own understanding of the technologies in use across the enterprise, and realistically map out what I mean when I say API landscape. I am still workshopping my new API toolbox definition for 2020, but I wanted to work on some of the narrative around each of the items in it, helping me learn along the way, while also expanding the scope of what I am talking about.</p>
<h3>Transmission Control Protocol (TCP)</h3>
<p class="p1">The Transmission Control Protocol (TCP) is one of the main protocols of the Internet protocol suite, and provides reliable, ordered, and error-checked delivery of a stream of bytes between applications running on hosts communicating via an IP network. The Web and APIs both rely on TCP, which is part of the Transport Layer of the TCP/IP suite. SSL/TLS often runs on top of TCP. It is the backbone of our API toolbox, but there are many different ways you can put TCP to work when it comes to the programming interfaces behind the applications we depend on.</p>
<p class="p1">It can be tough to separate what is a protocol, and what is a methodology when looking at the API landscape. I&rsquo;m still working to understand each of these tools in the toolbox, and organize them in a meaningful way&mdash;which is why I am writing this post. While all APIs technically rely on TCP, these approaches to communication and information exchange are often implemented directly using TCP.</p>
<ul>
<li><strong>Electronic Data Interchange&nbsp;(EDI) - </strong>Electronic Data Interchange (EDI) is the electronic interchange of business information using a standardized format; a process which allows one company to send information to another company electronically rather than with paper. Business entities conducting business electronically are called trading partners.</li>
<li><strong>Advanced Message Queuing Protocol (AMQP) - </strong>The Advanced Message Queuing Protocol (AMQP) is an open standard application layer protocol for message-oriented middleware, focusing on message orientation, queuing, routing, reliability and security.</li>
<li><strong>MQ Telemetry Transport (MQTT) -</strong> MQTT<span>&nbsp; </span>is a publish/subscribe, extremely simple and lightweight messaging protocol, designed for constrained devices and low-bandwidth, high-latency or unreliable networks.<span>&nbsp;</span></li>
<li><strong>Java Message Service (JMS) -</strong> The Java Message Service (JMS) API is a Java message-oriented middleware API for sending messages between two or more clients. JMS is a part of the Java Platform, Enterprise Edition (Java EE).</li>
<li><strong>Simple Object Access Protocol (SOAP) </strong>- SOAP is a message protocol that allows distributed elements of an application to communicate. SOAP can be carried over a variety of lower-level protocols, including the web-related Hypertext Transfer Protocol (HTTP).</li>
<li><strong>Streaming Text Oriented Messaging Protocol (STOMP) </strong>- STOMP<span>&nbsp; </span>provides an interoperable wire format so that STOMP clients can communicate with any STOMP message broker to provide easy and widespread messaging interoperability among many languages, platforms and brokers.</li>
<li><strong>Websockets -</strong> The WebSocket Protocol enables two-way communication between a client running untrusted code in a controlled environment to a remote host that has opted-in to communications from that code.<span>&nbsp;</span></li>
<li><strong>Kafka -</strong> Apache Kafka is an open-source stream-processing software platform that provides a unified, high-throughput, low-latency platform for handling real-time data feeds, connecting external systems via Kafka Connect and provides Kafka Streams.</li>
</ul>
<p class="p1">I am still defining the individual building blocks of each of these tools, allowing me to better organize them, and articulate how they overlap and differ. Understanding the technical details of each approach, as well as the history and details of where they have been put to use helps be better understand the API landscape. I have been exposed to Websockets, Kafka, SOAP, and MQTT, but the other areas are new for me, and I have a lot to learn. For now I am just trying to quantify each technology as simply as I can, and work to define the community around them. While HTTP APIs still dominate much of the API conversation, areas like EDI still dominate much of the true commerce landscape, and I need to better understand what is going on if I am going to paint a clearer picture of what the future might hold.</p>
<h3>User Datagram Protocol (UDP)</h3>
<p class="p1">UDP uses a simple connectionless communication model with a minimum of protocol mechanisms. UDP provides checksums for data integrity, and port numbers for addressing different functions at the source and destination of the datagram. It has no handshaking dialogues, and thus exposes the user's program to any unreliability of the underlying network; there is no guarantee of delivery, ordering, or duplicate protection.</p>
<p class="p1">I am sure that some of the other approaches to delivering APIs also use UDP, but until I get to know them better, or find examples of that, SOAP is the only item I have on my UDP list.</p>
<ul>
<li><strong>Simple Object Access Protocol (SOAP) - </strong>SOAP is a message protocol that allows distributed elements of an application to communicate. SOAP can be carried over a variety of lower-level protocols, including the web-related Hypertext Transfer Protocol (HTTP).</li>
</ul>
<p class="p1">I will be looking for other examples of APIs delivered vi UDP, but I also wanted to have UDP on my list because of what is happening with HTTP/3. I have long felt like APIs were too TCP focused, and would benefit from some of the constraints of UDP when it came to how we design our API infrastructure. I am looking forward to further falling down this rabbit hole with each pass over my diverse API toolbox research.</p>
<h3>HTTP 1.1 / 2 / 3</h3>
<p class="p1">Now we get into the more known (showcased and talked about) API toolbox territory with HTTP 1.1 APIs, and what we are seeing evolve with HTTP/2 and now HTTP/3. Obviously HTTP is dependent on TCP, but the philosophies, methodologies, and other belief systems list below live primarily in the HTTP layer of this global network we&rsquo;ve evolved over the last fifty years. This is the portion of the toolbox we have been hyper focused on in the API sector for over a decade, but as the space matures I think we are being forced to realize that there is a bigger world out there, and there are many approaches we should be considering beyond just HTTP and REST.</p>
<ul>
<li><strong>Electronic Data Interchange&nbsp;(EDI) -</strong> Electronic Data Interchange (EDI) is the electronic interchange of business information using a standardized format; a process which allows one company to send information to another company electronically rather than with paper. Business entities conducting business electronically are called trading partners.</li>
<li><strong>Simple Object Access Protocol (SOAP) - </strong>SOAP is a message protocol that allows distributed elements of an application to communicate. SOAP can be carried over a variety of lower-level protocols, including the web-related Hypertext Transfer Protocol (HTTP).</li>
<li><strong>Remote Procedure Call (RPC) -</strong> RPC is a remote procedure call (RPC) protocol which uses XM or JSONL to encode its calls and HTTP as a transport mechanism to deliver APIs that might be resource based, but usually are more programmatic in nature.<span>&nbsp;</span></li>
<li><strong>Representational State Transfer (REST) -</strong> Representational state transfer (REST) is a software architectural style that defines a set of constraints to be used for creating Web services. Web services that conform to the REST architectural style, called RESTful Web services, provide interoperability between computer systems on the Internet.</li>
<li><strong>Hypermedia -</strong> Hypermedia, an extension of the term hypertext, is a nonlinear medium of information that includes graphics, audio, video, plain text and hyperlinks. This designation contrasts with the broader term multimedia, which may include non-interactive linear presentations as well as hypermedia.</li>
<li><strong>Server-Sent Events -</strong> A server-sent event is when a web page automatically gets updates from a server. This was also possible before, but the web page would have to ask if any updates were available. With server-sent events, the updates come automatically.</li>
<li><strong>GraphQL -</strong> GraphQL is an open-source data query and manipulation language for APIs, and a runtime for fulfilling queries with existing data. It allows clients to define the structure of the data required, and the same structure of the data is returned from the server, therefore preventing excessively large amounts of data from being returned, but this has implications for how effective web caching of query results can be.</li>
<li><strong>gRPC</strong> - gRPC is a modern open source high performance RPC framework that can run in any environment. It can efficiently connect services in and across data centers with pluggable support for load balancing, tracing, health checking and authentication.<span>&nbsp;</span></li>
</ul>
<p class="p1">This list, minus EDI, is the usual list of tools I include in my API toolbox. However, due to the growth of Websockets and Kafka for more real time applications, and MQTT and AMQP for Internet of Things and other device centered approaches, I have continued to expand my horizons. While I believe strongly that HTTP 1.1 APIs using REST is where most developers should begin their API journey, I believe that all of these approaches have their use and should be a ready to go part of our API toolboxes, and I will keep fleshing out, understanding, and using within my storytelling until I am able to confidently explain which tool should be applied in each possible scenario.</p>
<h3>SMTP/POP</h3>
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/bf-skinner-shipping-docks_36331347010_o.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">As part of this latest wave of research into what I consider to be the wider API economy I was reminded of how SMTP is still used by many legacy providers when it comes to EDI and SOAP. While this still might be a relic of the past I am still interested in understanding how email is used as the OG messaging system and can either still be applied or at least considered as we evolve our modern approaches to messaging.</p>
<ul>
<li><strong>Electronic Data Interchange&nbsp;(EDI) -</strong> Electronic Data Interchange (EDI) is the electronic interchange of business information using a standardized format; a process which allows one company to send information to another company electronically rather than with paper. Business entities conducting business electronically are called trading partners.</li>
<li><strong>Simple Object Access Protocol (SOAP) - </strong>SOAP is a message protocol that allows distributed elements of an application to communicate. SOAP can be carried over a variety of lower-level protocols, including the web-related Hypertext Transfer Protocol (HTTP).</li>
</ul>
<p class="p1">While I prefer a dead simple HTTP API for most implementation, the concept of sending and receiving machine readable information using email is still very intriguing<span> </span>to me. I like email in the same way I like spreadsheets, because they are ubiquitous, and is an infrastructure item that exists everywhere and is used by the common folk. While I&rsquo;m not prescribing that we start delivering APIs via email, I do think there are interesting use cases here already in existence, and we should be learning from this approach to messaging when we think about the future of machine readable messaging.</p>
<h3>Data Formats</h3>
<p class="p1">Next, I wanted to look at the data formats being used as part of each API in operation, and how data is passed, serialized, and made sense of in a machine readable way. I think that data serialization is one of the competitive edges that gRPC has over REST, and I think this can also be seen across Kafka adoption with the use of Apache Avro when it comes to moving data around the enterprise. Here are the data formats portion of my API toolbox, helping us standardize how the bits and bytes are moved around between systems, and used to power applications.</p>
<ul>
<li><strong>CSV -</strong> A CSV is a comma-separated values file, which allows data to be saved in a tabular format. CSVs look like a garden-variety spreadsheet but with a . csv extension. CSV files can be used with most any spreadsheet program, such as Microsoft Excel or Google Spreadsheets.</li>
<li><strong>JSON</strong> - JSON (JavaScript Object Notation) is a lightweight data-interchange format. It is easy for humans to read and write. It is easy for machines to parse and generate. It is based on a subset of the JavaScript Programming Language Standard ECMA-262 3rd Edition - December 1999. JSON is a text format that is completely language independent but uses conventions that are familiar to programmers of the C-family of languages, including C, C++, C#, Java, JavaScript, Perl, Python, and many others. These properties make JSON an ideal data-interchange language.</li>
<li><strong>XML</strong> - Extensible Markup Language (XML) is a markup language that defines a set of rules for encoding documents in a format that is both human-readable and machine-readable. The World Wide Web Consortium's XML 1.0 Specification of 1998 and several other related specifications&mdash;all of them free open standards&mdash;define XML.</li>
<li><strong>Apache Avro</strong> - Apache Avro is a data serialization system. Avro provides: Rich data structures. A compact, fast, binary data format. A container file, to store persistent data. Remote procedure call (RPC). Simple integration with dynamic languages. Code generation is not required to read or write data files nor to use or implement RPC protocols. Code generation as an optional optimization, only worth implementing for statically typed languages.</li>
<li><strong>Apache Thrift</strong> - The Apache Thrift software framework, for scalable cross-language services development, combines a software stack with a code generation engine to build services that work efficiently and seamlessly between C++, Java, Python, PHP, Ruby, Erlang, Perl, Haskell, C#, Cocoa, JavaScript, Node.js, Smalltalk, OCaml and Delphi and other languages.</li>
<li><strong>Protocol Buffers<span>&nbsp;</span></strong> - Protocol buffers are Google's language-neutral, platform-neutral, extensible mechanism for serializing structured data &ndash; think XML, but smaller, faster, and simpler. You define how you want your data to be structured once, then you can use special generated source code to easily write and read your structured data to and from a variety of data streams and using a variety of languages.</li>
</ul>
<p class="p1">While JSON still dominates the discussion, I predict that Protobuf, Avro, and Thrift will continue to gain mindshare because of performance. I also think that we will continue to realize what we threw out in the move from XML to JSON, and we will find that some things are still needed. I also demand that CSV always be a first class citizen when possible, because it makes the APIs we deliver more accessible by the business class of consumers, allowing them to put our APIs to work within the spreadsheets they use to get work done each day.</p>
<h3>Specifications</h3>
<p class="p1">Last, I wanted to include the specifications for defining our APIs, and the schema for our data formats. Providing us with machine readable definitions of the API landscape no matter which solution we go with. Much of the expansion of the horizon when it comes to my API toolbox has been because of the work Fran is doing on AsyncAPI, but also with the maturing of OpenAPI, and the increased adoption of Postman collections when it comes to not just defining the surface area of your API, but also how it will be used at runtime. Here are the specifications I focus on when it comes to my API toolbox.</p>
<ul>
<li><strong>OpenAPI</strong> - The OpenAPI Specification, originally known as the Swagger Specification, is a specification for machine-readable interface files for describing, producing, consuming, and visualizing RESTful web services.</li>
<li><strong>AsyncAPI</strong> - AsyncAPI is an open source initiative that seeks to improve the current state of Event-Driven Architectures (EDA). Our long-term goal is to make working with EDA&rsquo;s as easy as it is to work with REST APIs. That goes from documentation to code generation, from discovery to event management.</li>
<li><strong>Postman Collection </strong>- Postman Collections are Executable API Descriptions Collection folders make it easy to keep your API requests and elements organized. A Postman Collection lets you group individual requests together. You can organize these requests into folders. You can group together requests into folders and collections, so that you don't have to search through your history repeatedly. Then collections can be used to mock, document, and test APIs as part of the API life cycle.</li>
<li><strong>JSON Schema</strong> - JSON Schema is a vocabulary that allows you to annotate and validate JSON documents. Describes your existing data format(s). Provides clear human- and machine- readable documentation. Validates data which is useful for: Automated testing, and ensuring quality of client submitted data.</li>
</ul>
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/bf-skinner-seattle-public-market_36725946605_o.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">These specification formats help describe the surface area of API infrastructure in a machine readable way, allowing the resulting definitions to be shared and used across teams helping provide a common truth around what an API does and doesn&rsquo;t do. They can also then be used across the API life cycle to generate mock servers, publish documentation, generate tests, client and server side code, and many other aspects of operating an API. While these specifications haven&rsquo;t expanded to include every approach listed in this toolbox, that is part of my work here, to help identify where the shadows exist when it cones to adequately mapping out the API landscape.</p>
<h3>Expanding My API Toolbox For The Next Decade</h3>
<p class="p1">This list represents my API toolbox going into the next decade. I will be further fleshing it out and adding more of the life cycle tooling like mocks, docs, testing, security, and other essential areas. So the next iteration of this toolbox definition will have more detail about each of the TCP and HTTP approaches, as well as the data formats and specifications, but it will also begin to list out specific types of tooling that is being used to support each approach. I am looking to understand the maturity of standardized tooling across the HTTP and TCP universe, while also looking to understand where the new opportunities are based upon movements in single areas, which might not be known and applied across all approaches to delivering APIs.</p>
<p class="p1">One of the most important aspects of doing this API toolbox revamp goes beyond any particular technical approach and speaks to the wider API economy. I know many of us in the API space think we are the center of the world when it comes to the real world supply chain, and wield terms like the API economy to define the impact we make. However, once you start actually taking an honest look at the number of SOAP APIs still in use, as well as quantify the scope of EDI, you begin to realize that we are still just a toddler when it comes to the global economy. Sure, one can argue we are the future, and we are well on our way to redefining the supply chains of the world, but once you size up our world against what is already in place, we have a lot more work ahead of us to not just develop what&rsquo;s new, but to convert what already exists to actually operate as part of the API economy.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/01/21/expanding-my-api-toolbox-for-the-next-decade/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/01/17/devops-azure-style/">Devops Azure Style</a></h3>
        <span class="post-date">17 Jan 2020</span>
        ---
published: true
layout: post
title: 'DevOps Azure Style'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/containership-containership-copper-circuit.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/containership-containership-copper-circuit.jpg" alt="" width="40%" align="right" /></p>
<p>I am spending time thinking more deeply about how APIs can be delivered via Azure. I spent much of the holidays looking at how to deliver APIs on AWS, but only a small amount of time looking at Azure. I'm looking at how Azure can be used for the development and delivery of APIs, trying to understand the different ways you can use not just Azure for managing APIs, but also use Azure APIs for managing your APIs. Next up is Azure DevOps, and learning more about the nuts and bolts of how the orchestration solution allows you to streamline and stabilize the delivery of your API infrastructure using Azure.</p>
<p>First, I want to just break down what the core elements of <a href="https://azure.microsoft.com/en-us/services/devops/">Azure Devops</a>. Learning more about how Azure sees the DevOps workflow and how they have provided a system to put their vision to work. Here are the main elements of Azure DevOps that help us understand the big picture when it comes to mapping to your API life cycle.</p>
<ul>
<li><strong><a href="https://azure.microsoft.com/en-us/services/devops/server/">Azure DevOps Server</a></strong> - Share code, track work, and ship software using integrated software delivery tools, hosted on-premises</li>
<li><a href="https://azure.microsoft.com/en-us/services/devops/boards/"><strong>Azure Boards</strong> </a>- Deliver value to your users faster using proven agile tools to plan, track, and discuss work across your teams.</li>
<li><strong><a href="https://azure.microsoft.com/en-us/services/devops/pipelines/">Azure Pipelines</a></strong> - Build, test, and deploy with CI/CD that works with any language, platform, and cloud. Connect to GitHub or any other Git provider and deploy continuously.</li>
<li><strong><a href="https://azure.microsoft.com/en-us/services/devops/repos/">Azure Repos</a></strong> - Get unlimited, cloud-hosted private Git repos and collaborate to build better code with pull requests and advanced file management.</li>
<li><strong><a href="https://azure.microsoft.com/en-us/services/devops/test-plans/">Azure Test Plans</a></strong> - Test and ship with confidence using manual and exploratory testing tools.</li>
<li><strong><a href="https://azure.microsoft.com/en-us/services/devops/artifacts/">Azure Artifacts</a></strong> - Create, host, and share packages with your team, and add artifacts to your CI/CD pipelines with a single click.</li>
<li><strong><a href="https://azure.microsoft.com/en-us/services/devtest-lab/">Azure DevTest Labs</a></strong> - Fast, easy, and lean dev-test environments</li>
</ul>
<p>Not every API implementations will use all of these elements, but it is still nice to understand the big picture. Depending on how your team will be developing and delivering your APIs, and the applications they serve you will be applying Azure DevOps elements in different ways. Another important dimension can be found on their DevOps integration page, which demonstrates how you can choose to replace some of the elements here with existing CI/CD solutions like Jenkins, as well as infrastructure configuration, orchestration and automation solutions like Ansible and Terraform. Additionally you can put one of the <a href="https://marketplace.visualstudio.com/azuredevops">Azure DevOps extensions</a> to work, augmenting these elements with community driven solutions. I'd love to eventually see Postman added to integration page, as well as added as one or more extensions, allowing it to be used as a seamless player in Azure DevOps ecosystem.</p>
<p>Next I am diving into different ways you can use Azure DevOps with Postman. There are quite a few tutorials out there walking through how to use Postman with Azure DevOps. So why reinvent the wheel here. I am just going to find the best community approaches to using Azure DevOps and Postman, highlighting the great work of our community when it comes to Postman-driven DevOps on the Azure platform. This is one of the things I love about being part of the Postman team--there is such a compassionate community of users, you can find people who are doing interesting things across almost every platform and solution, complete with a detailed walkthrough on how to make it all work.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/01/17/devops-azure-style/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/01/17/a-view-of-the-api-delivery-life-cycle-from-the-azure-getting-started-page/">A View Of The Api Delivery Life Cycle From The Azure Getting Started Page</a></h3>
        <span class="post-date">17 Jan 2020</span>
        ---
published: true
layout: post
title: 'A View of the API Delivery Life Cycle from the Azure Getting Started Page'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/stalin-time-seatlle-shipping-mountain.jpg
---
<p>I am working my way through doing more work around the multi-cloud deployment of APIs and spending some more time on the Azure platform here in 2020, and I found<a href="https://docs.microsoft.com/en-us/azure/"> their getting started</a> page pretty reflective of what I'm seeing out there when it comes to delivering the next generation of software. When landing on AWS home page it can be overwelming to make sense of everything, and I thought that Azure organized things into a coherent vision of how software is being delivered in the cloud.</p>
<h3>Infrastructure</h3>
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/stalin-time-seatlle-shipping-mountain.jpg" alt="" width="40%" align="right" /></p>
<p>Providing the fundamental building blocks of compute for all of this.</p>
<ul>
<li> Linux virtual machines&nbsp;</li>
<li>Windows virtual machines&nbsp;</li>
</ul>
<p>I never thought I"d see Linux and Windows side by side like this.</p>
<h3>Languages</h3>
<p>Acknowledging there are multiple programming languages to get the job done.</p>
<ul>
<li> .NET&nbsp;</li>
<li>Python&nbsp;</li>
<li>Java&nbsp;</li>
<li>PHP&nbsp;</li>
<li>Node.js&nbsp;</li>
<li>Go</li>
</ul>
<p>Again, I never thought I'd see such strong support for anything beyond .NET.</p>
<h3>Application</h3>
<p>This nails the different layes in which I see folks delivering API infrastructure.</p>
<ul>
<li> Web Apps&nbsp;</li>
<li>Serverless Functions&nbsp;</li>
<li>Containers&nbsp;</li>
<li>Microservices with Kubernetes&nbsp;</li>
<li>Microservices with Service Fabric</li>
</ul>
<p>I think its silly to put microservices there, because APIs are delivered in all.</p>
<h3>Database</h3>
<p>The database layers behind the APIs we are all delivering across operations.</p>
<ul>
<li> Relational Databases&nbsp;</li>
<li>SQL Database as a service&nbsp;</li>
<li>SQL Database for the edge&nbsp;</li>
<li>SQL Server on an Azure&nbsp;</li>
<li>PostgreSQL database as a service&nbsp;</li>
<li>MySQL database as a service&nbsp;</li>
<li>Azure Cosmos DB (NoSQL)</li>
</ul>
<p>Again, I am blown away to see MySQL and PostgreSQL along with SQL Server.</p>
<h3>Storage</h3>
<p>Where you put all of your blobs and other objects used across your APIs.</p>
<ul>
<li> Blob Storage</li>
</ul>
<p>I'd say this layer is a little anemic compared with other cloud environmetns.</p>
<h3>Machine Learning</h3>
<p>Acknolwedging that machine learning is a growing area of API deployment.</p>
<ul>
<li> Machine Learning&nbsp;</li>
<li>Cognitive Services&nbsp;</li>
<li>Azure Notebooks</li>
</ul>
<p>This area will continue grow pretty rapidly in coming years in all industries.</p>
<h3>Interfaces</h3>
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/stalin-time-seattle-shipping-people-walking.jpg" alt="" width="40%" align="right" /></p>
<p>The ways in which we are interfacing with the software development life cycle.</p>
<ul>
<li> Azure CLI&nbsp;</li>
<li>Azure PowerShell&nbsp;</li>
<li>Azure portal&nbsp;</li>
<li>Azure mobile app</li>
</ul>
<p>I am suprised that they do not have APIs as one of the interfaces to be used.</p>
<h3>Orchestration</h3>
<p>How the software development life cycle is realized across teams and operations.</p>
<ul>
<li> Azure DevOps&nbsp;</li>
<li>Azure Pipelines&nbsp;</li>
<li>Chef&nbsp;</li>
<li>Jenkins&nbsp;</li>
<li>Terraform</li>
<li>Ansible&nbsp;</li>
</ul>
<p>It is also interesting to see each cloud provider stake their own native claim against Jenkins.</p>
<h3>Management</h3>
<p>Providing a suite of tools for being able to manage and ensure reliability across your operations.</p>
<ul>
<li> Azure Backup&nbsp;</li>
<li>Azure Cost Management&nbsp;</li>
<li>Azure Migrate&nbsp;</li>
<li>Azure Monitor&nbsp;</li>
<li>Azure Policy&nbsp;</li>
<li>Azure Security Center&nbsp;</li>
<li>Azure Lighthouse&nbsp;</li>
<li>Azure Site Recovery</li>
</ul>
<p>Azure provides this sensible management layer as well as a suite of resources you can use to get up to speed and become an expert in any of these areas, recognizing the importance of education. Capping off a pretty robust list of how software gets delivered which includes your teams being knowledgable in what they are doing.</p>
<p>These building blocks of the Auzre view of the software development life cycle provides for me. It helps me see how they see things. Which reflects how they see their customers. I mine these types of building blocks to use in my API strategy development and storytelling. I'll file these away as part of my API life cycle research, combine them with other research from Google, AWS, and other places. Then use them to help paint a better picture of where things are going when it comes to API operations in the cloud.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/01/17/a-view-of-the-api-delivery-life-cycle-from-the-azure-getting-started-page/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/01/16/what-is-your-api-development-workflow/">What Is Your Api Development Workflow</a></h3>
        <span class="post-date">16 Jan 2020</span>
        ---
published: true
layout: post
title: 'What Is Your API Development Workflow?'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/stalin-time-construction-zone-claw.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/stalin-time-construction-zone-claw.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">I am going to invest in a new way to tell stories here on API Evangelist&mdash;we will see if I can make this stick. I enjoy doing podcasts but I am not good at the scheduling and reliable repetition many expect of a podcast. Getting people to join me on a podcast takes a lot of work (I know from experience) to do reliably. People usually want to talk, but finding slots in both of our schedules and getting them to jump online and successfully record an episode isn&rsquo;t easy to do on a regular basis. However, I still want to be able to craft audio narratives around specific topics that are relevant to the API sector, while also allowing many different voices to chime in. So I&rsquo;ve come up with a formula I want to test and and see if I can build some momentum.</p>
<p class="p1">To help stimulate the API conversation and bring in other voices I want to pose a single question on a regular basis and solicit audio responses from folks across the API space, then compile the results into a single podcast that I will publish on the blog and via other channels. All folks need to do in their response to one of my questions is open up their phone and record their response and send me the resulting audio file via email, DM, or carrier pigeon. Then I will organize all the responses into a single coherent podcast with me opening, asking my questions, then chaining together the responses, and closing up with a little analysis. Make sense?<span>&nbsp;A kind of an asynchronous podcast conversation amongst several participants.</span></p>
<p class="p1">Ok, let&rsquo;s start with my first question.:</p>
<p class="p1" style="padding-left: 30px;"><em><strong>How do you develop APIs? </strong>Describe how you or your team actually develops an API. What is the workflow for how you go from idea to production, and what tools and services are involved. Be honest. I am not looking for fluff or pie in the sky visions of should be. I am looking for real world examples of how people do what they do on a daily basis. Try to keep the responses to five minutes or less, but I will make exceptions if your responses are really good. Don't worry about all the nitty gritty details, I am just looking for an overview of your approach.</em></p>
<p class="p1">That is it. Grab your cell phone and record your answer. Do not worry about providing a perfectly crafted response, just make it a natural one. Try to leave some empty space at the beginning and ending of your recording, and make sure and breathe in between sentences a bit. Then go ahead and send the resulting audio to me via email (<a href="mailto:info@apievangelist.com">info@apievangelist.com</a>), DM (<a href="https://twitter.com/apievangelist">@apievangelist</a>), or whatever channel works. Then I am going to compile into a single podcast and publish after I get enough responses from folks, sharing here on the blog and via my social media channels.</p>
<p class="p1">Feel free to share your thoughts on this whole approach too. It is just a proof of concept at this point, and it doesn&rsquo;t even really have a title or any other details. I&rsquo;m just kicking it off to see if I can even get anyone responding and contributing. I really like listening to podcasts as I work, and I&rsquo;d love to create a regular stream of consciousness from across the API community on a variety of subjects. We&rsquo;ll see if we can make this work. I&rsquo;ve seen a number of amazing API podcasts (I miss Traffic and Weather) come and go over the years, and this is my attempt at rebooting the concept and seeing what magic I can make happen. If I can&rsquo;t, no worries, I am always just trying to experiment and see what works.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/01/16/what-is-your-api-development-workflow/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/01/16/my-eventbrite-api-keys-were-easy-to-find/">My Eventbrite Api Keys Were Easy To Find</a></h3>
        <span class="post-date">16 Jan 2020</span>
        ---
published: true
layout: post
title: 'My Eventbrite API Keys Were Easy To Find'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/event_brite_api_key.png
---
<p class="p1">If you read my blog regularly you know I rant all the time about having to sign up for new APIs and then find my API keys and tokens. API providers excel at making it extremely difficult to get up and running with an API, even once you have read their documentation and figured out what their API is all about. So when I come across API providers doing it well, I have to showcase here in a blog posts. Today&rsquo;s shining example of how to make it easy to find your API keys comes from the Eventbrite API.</p>
<p class="p1"><a href="http://apievangelist.com/2020/01/15/eventbrite-events-with-order-count-and-capacity-using-the-api/">I was crafting a Postman API capability collection for my boss the other day</a>, and I needed to find me an API key to get the data I needed out of the Eventbrite API. Finding the API paths we needed to get the event and registration data needed had already taken us some time, so I was fully expected the usual friction when it came to finding my API key. Then I clicked on <a href="https://www.eventbrite.com/platform/api#/introduction/authentication">the Eventbrite authentication page</a><span class="s2"><span><a href="https://www.eventbrite.com/platform/api#/introduction/authentication">&nbsp;</a></span>and clicked on the link telling me to <a href="https://www.eventbrite.com/platform/api-keys">visit my API keys page</a>, and there they were! No hunting or detective required&mdash;my keys were prominently placed above the fold. Amazing!!!</span>&nbsp;</p>
<p><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/event_brite_api_key.png" alt="" width="95%" /></p>
<p class="p1">This is how it should be. I shouldn&rsquo;t have to look around for my key&mdash;it is the 2020s. Please stop hiding my keys and making it hard for me to find what I need to get up and running with your API. As you are planning out how to develop and deploy the user experience for the API management layer of your operations make sure you pick 25 existing public APIs, then sign up and find your keys. Learn from the experience and put your keys at a common URL that is prominently linked from your documentation and authentication page.</p>
<p class="p1">If you have a favorite API that you think adding an application and finding your keys is the pattern other providers should follow, I&rsquo;d love to hear about tit. Also if there are nightmare APIs that you&rsquo;ve never been able to actually find your keys, or each time you need to it takes you a lifetime to actually find what you are looking for I&rsquo;d like to learn about these as well. I&rsquo;m always on the hunt for the healthy as well as the unhealthy patterns from across the API space. Talking about this stuff in a very public helps us learn about this stuff out in the open, and helps us make fewer mistakes as we are doing our work down in the trenches, and reduces friction for the entire community</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/01/16/my-eventbrite-api-keys-were-easy-to-find/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/01/16/api-life-cycle-governance-beyond-just-api-design/">Api Life Cycle Governance Beyond Just Api Design</a></h3>
        <span class="post-date">16 Jan 2020</span>
        ---
published: true
layout: post
title: 'API Life Cycle Governance Beyond Just API Design'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/braceros-domingo-ulloa-working-waterfront-2.jpg
---
<p><a href="http://governance.apievangelist.com/"><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/braceros-domingo-ulloa-working-waterfront-2.jpg" alt="" width="40%" align="right" /></a></p>
<p class="p1">When you hear enterprise organizations talk about <a href="http://governance.apievangelist.com/">API governance</a> they usually mean the governance of API design practices across the organization. This is the place where everyone starts when it comes to standardizing how APIs are delivered. It makes sense to start here because this is where the most pain is experience at scale when you try to put APIs to work across a large enterprise organization. Even if all APIs and micro services are REST(ish), there are so many different ways you can deliver the details of an API--you might as well be using APIs from different companies when trying to put APIs developed across different teams to use in a single application. Making API design the first stumbling block teams consider when planning API governance, and something that would make a meaningful impact on how APIs are delivered.</p>
<p class="p1">After working with enterprise organizations who have been on their API journey for 5+ years I have begun to see API governance move beyond API design, and begin to look at other stops along the API life cycle, and work to standardize other critical elements. Here are some of the next steps I see enterprise organizations taking when it comes to getting a handle on API governance across teams:</p>
<ul>
<li><strong>Documentation</strong> - Making sure everyone is using the same services and tooling for documenting APIs making sure the most common elements are present, and all APIs are well defined.</li>
<li><strong>Monitoring</strong> - Requiring all teams monitor APIs and report upon the available of each API, establishing a common monitoring and reporting practice that is consistent across all development teams.</li>
<li><strong>Testing</strong> - Standardizing tooling and approaches to API testing, indexing and cataloging the tests that are in place, and beginning to measure the test coverage for any API in production.</li>
<li><strong>Performance</strong> - Looking at the speed of APIs and making sure that all APIs are benchmarked as soon as they are developed, then measured against that across multiple regions and clouds.</li>
<li><strong>SDKs</strong> - I am seeing more guidance for how API SDKs should be developed ensuring that all SDKs, code libraries, and snippets are generated and developed, providing a consistent client front.</li>
</ul>
<p class="p1">These are the main areas I see enterprise organization moving into as they begin to nail down some of the nuances of API design governance and getting teams on board with healthy practices put in place. When I say API governance most people either don't understand exactly what it actually means, or they purely think it is all about the design of the API. Very few organizations are seeing beyond API design when you talk about governance efforts across teams. I am working to gather more examples of this in action, but sadly most of the conversation I am having are with enterprise teams developing internal APIs, and without approval, or them actively publishing stories I don&rsquo;t have much to share.</p>
<p class="p1">As I do with all of my work, I publish anything I curate on governance, as well as anything I write on the subject to <a href="http://governance.apievangelist.com/">my API governance research subdomain</a>.&nbsp;If you have any API governance practices you have in place across your teams I&rsquo;d love to hear from you, even if I can&rsquo;t share the stories publicly. It helps to understand the successes and challenges teams face when it comes to standardizing how teams are delivering APIs. I predict that API governance will continue to be one of the number one conversations I am having in 2020 with enterprise organizations.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/01/16/api-life-cycle-governance-beyond-just-api-design/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/01/15/eventbrite-events-with-order-count-and-capacity-using-the-api/">Eventbrite Events With Order Count And Capacity Using The Api</a></h3>
        <span class="post-date">15 Jan 2020</span>
        ---
published: true
layout: post
title: 'Eventbrite Events with Order Count and Capacity Using the API'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/https__cdn.evbuc.com_images_85596975_293025926021_1_original.png
---
<p><a href="https://www.eventbrite.com/o/postman-18177015627"><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/https__cdn.evbuc.com_images_85596975_293025926021_1_original.png" alt="" width="40%" align="right" /></a></p>
<p class="p1">My boss asked me if I could build <a href="https://documenter.postman.com/view/35240/SWLk3QwT?version=latest">a Postman collection that would pull our future events from Evenbrite and display ticket counts for each individual event</a>. So I got to work hacking on <a href="https://www.eventbrite.com/platform">the Eventbrite API</a>, learning each of the events API paths, stitching together what I needed to pull together my Postman collection for this new API capability. I&rsquo;m a big fan of not just creating reference collections for different APIs like the Eventbrite API, but also creating individual capability collections that use one or many API requests to deliver on a specific business objective.</p>
<p class="p1">I was able to craft my Postman API capability collection using two Eventbrite APIs, getting me the data I need to satisfy what my boss needed to get the updates he needed.</p>
<ul>
<li><strong><a href="https://www.eventbrite.com/platform/api#/reference/event/list/list-events-by-organization">Events By Organization</a>&nbsp;</strong>- Pulls all of the future active events for our Eventbrite organization.</li>
<li><strong><a href="https://www.eventbrite.com/platform/docs/orders">Event Orders&nbsp;</a></strong>- Pulling the orders fore each individual event, pulling the relevant information needed to assess each event.</li>
</ul>
<p class="p1">This Eventbrite event order Postman capability collection only has one request in it, but I call the second API multiple times using a test script for the request. So in the end I&rsquo;m making multiple API calls using a single Postman request, allowing me to get at what I need for each future event across multiple APIS--abstracting away some of the complexity.<span>&nbsp;</span><a href="https://www.eventbrite.com/platform">I have published the collection as a Postman template which you can access via the Postman documentation I&rsquo;ve published</a>, but you will need to add your own Eventbrite token and organization id to actually execute. Once you added these properties entered you can click send and see a listing of events with ticket counts as well as maximum capacity for all the future events using the Postman visualizer tab.</p>
<p class="p1">I&rsquo;ve added this Postman capability collection <a href="https://github.com/api-evangelist/capabilities">my list of individual API collections I&rsquo;ve been building.</a> Providing a list of the common things I need to accomplish across the different platforms I depend for my operations. I&rsquo;m looking to keep each of these collections as simple as I possibly can doing one thing well, reflecting my view of how APIs should work. Helping reduce friction when it comes to putting APIs to work, while also making APIs more accessible to non-developers by providing simple sharable, executable, API capabilities that help them accomplish common everyday tasks they need to get done.</p>
<p class="p2">&nbsp;</p>
<p class="p2">&nbsp;</p>
<p class="p2">&nbsp;</p>
<p class="p3"><span class="s2"><a href="https://www.eventbrite.com/platform">https://www.eventbrite.com/platform</a></span></p>
<p class="p2">&nbsp;</p>
<p class="p2">&nbsp;</p>
<p class="p3"><span class="s2"><a href="https://documenter.postman.com/view/35240/SWLk3QwT?version=latest">https://documenter.postman.com/view/35240/SWLk3QwT?version=latest</a></span></p>
<p class="p2"><span class="s2">&nbsp;</span></p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/01/15/eventbrite-events-with-order-count-and-capacity-using-the-api/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/01/13/why-hasnt-there-been-another-stripe-or-twilio/">Why Hasnt There Been Another Stripe Or Twilio</a></h3>
        <span class="post-date">13 Jan 2020</span>
        ---
published: true
layout: post
title: 'Why Hasn’t There Been Another Stripe or Twilio?'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/christianity-christianity-under-construction-copper-circuit.jpg
---
<img src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/christianity-christianity-under-construction-copper-circuit.jpg" width="40%" align="right" style="padding: 15px;" /><p class="p1">Stripe and Twilio are held up as shining examples of how to do APIs in our world. This shining blueprint of how to do APIs has been around for a decade for others to follow. It isn’t a secret. So, why haven’t we seen more Stripes or Twilios emerge? Don’t get me wrong, there are other well done APIs that have emerged, but none of them have received the attention and level of business that Stripe and Twilio have enjoyed. These things always get me thinking and wondering what the reality really is, and if the narrative we are crafting is the one that fits with reality on the ground—pushing me to ask the questions that others aren’t always prepared to ask.</p>
<p class="p1">I am going to spend some time flagging some of the new APIs who do rise the to the occasion, but while I am working on that I wanted to pose some questions about why we haven’t seen the Twilio and Stripe being modeled by more API providers. Here are a few of my thoughts as I work through this view of the API landscape, and helping me understand why there aren’t more API rockstars to showcase:</p>
<ul>
<li><strong>Investment</strong> - Investment cycles have changed and the investment you need to do this right is available for startups in the last five years.</li>
<li><strong>Blueprint</strong> - Twilio and Stripe are not a blueprint that applies universally to other APIs, but worked will in those business verticals.</li>
<li><strong>APIs</strong> - This use case of APIs is not as universal as we think it is and is not something that will work being applied to all business verticals.</li>
<li><strong>Skills</strong> - It takes more skills than we anticipate when it comes to actually delivering an API as well as Twilio and Stripe have done.</li>
<li><strong>Cloud</strong> - The dominance of the cloud providers is making it harder for small API startups to get traction and attention of investors.</li>
<li><strong>Wrong</strong> - These API providers exist and I am just not seeing them for some reason, and the model is alive and well in a number of API startups.</li>
<li><strong>Stories</strong> - The tech blogosphere doesn’t care, and there isn’t enough storytelling around the API startups that already exist out there.</li>
<li><strong>REST</strong> - Delivering APIs using REST isn’t the future and the next waves of startups will be using GraphQL, Kafka, and other API patterns.</li>
</ul>
<p class="p1">These are just a handful of thoughts I had thinking about why we don’t see more Stripes and Twilios. I’m perfectly prepared to be wrong here, so let me know what API startups I am missing. I really haven’t thought about this subject enough to weigh in and provide my opinions on why there haven’t been added waves of API rockstars. I am not looking to have all the answers here, I am just looking to understand where we are, what they future holds, and what works and doesn’t work when it comes to APIs.</p>
<p class="p1">If you think there is an API that was started in the last five years, and sizes up to Twilio and Stripe—let me know. If you have additional reasons why there haven’t been any additional Stripes or Twilios in the last five years I’d love to hear what they are. <a href="http://apievangelist.com/#Blueprints">I have a Twilio blueprint that I use as a shining example of how other API providers should consider operating,</a> and if there are elements missing, or I am entirely wrong I want to know it. There have been a number of API fairy tales I’ve told over the years that have proven to be untrue, so I’m always ready to call bullshit on my own work, and the narratives we craft in the world of APIs.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/01/13/why-hasnt-there-been-another-stripe-or-twilio/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/01/09/the-state-of-simple-crud-api-creation/">The State Of Simple Crud Api Creation</a></h3>
        <span class="post-date">09 Jan 2020</span>
        ---
published: true
layout: post
title: 'The State of Simple CRUD API Creation'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/docks-docks-light-dali.jpg
---
<img src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/docks-docks-light-dali.jpg" width="40%" align="right" style="padding: 15px;" /><p class="p1">With all the talk of APIs you think it would be easier to publish a simple Create, Read, Update, and Delete (CRUD) API. Sure, there are a number of services and open source solutions for publishing a CRUD API from your database, but for me to just say I want a CRUD resource, give it a name, push a button, and have it—there isn’t much out there. I should be able to just write the word “images”, and hit go, and have a complete images API that I can add properties to the schema, and query parameters to each method. After ten years of doing this I am just amazed that the fundamentals of API deliver are still so complicated and verbose.<span> </span></p>
<p class="p1">We even have the vocabulary to describe all of the details of my API (OpenAPI), and I still can’t just push a button and get my API. I can take my complete OpenAPI definition and publish it to AWS, Azure, or Google and “generate my API”, but it doesn’t create the backend for me. There has been waves of database or spreadsheet to API solutions over the years, but there is not single API solution to plant the seeds when there is no existing data source. Over the holidays <a href="http://apievangelist.com/2020/01/02/deploying-my-postman-openapi-to-aws-api-gateway/">I managed to create a Postman collection that will take my OpenAPI from a Postman-defined API and generate a AWS DynamoDB and AWS API Gateway instance of API</a>, but it was the closest I could get to what is in my head across AWS, Azure, and Google. Why can’t I just hit GO on my OpenAPI, and have an API in a single click? Nio matter which cloud provider I am on!</p>
<p class="p1">The reasons why I can’t immediately have a CRUD API are many. Some technical. Most are business reasons. I would say it is primarily a reflection of our belief that we are all innovative special snowflakes, when in reality we are all saying pretty much the same things in similar ways—we just can’t 100% agree on the details. So we all just all continuing developing schema and APIs in isolation. I would say there is also a very narrow proprietary view of what APIs should or shouldn’t be, and the business and technical wizards don’t want it to be easy. It needs to be complex, and something that is done with specialized tooling by specialized individuals. When in reality, we’d all be better off if most of things were standardized and interoperable—then we could get down to business doing the actual unique things we are good at, not just managing technical debt.</p>
<p class="p1">As technologists we are really good at keeping things complicated so that we are needed and have something to sell. The state of API deployment after all of these years demonstrates that the API lifecyle is governed more by business and political decisions than they are ever by technical ones. Showing that us technologists aren't as in control over what is going on as we think we are, and that the "right" technical approach isn't the "right" answer to most API questions being asked.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/01/09/the-state-of-simple-crud-api-creation/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/01/09/a-postman-api-governance-collection/">A Postman Api Governance Collection</a></h3>
        <span class="post-date">09 Jan 2020</span>
        ---
published: true
layout: post
title: 'A Postman API Governance Collection'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/aws-s3-square-supreme-court-judgement.jpg
---
<p class="p1">You can use Postman to test your APIs. With each request you can include a test script which evaluates each incoming response and validates for specific elements, displaying the test results along with each response. However, you can also use the same mechanisms to evaluate the overall design of any API you are managing with Postman. One of the new beta features of Postman is being able to manage your APIs, allowing you to define each API using OpenAPI 3.0, then generate collections, mocks, docs, and tests with Postman. This got me thinking&mdash;why can&rsquo;t we use the new Postman API manager, plus the Postman API, and script testing for governing the design of an API.</p>
<p class="p1">To explore the possibilities I created <a href="https://documenter.postman.com/view/35240/SWLh46Dv?version=latest">a Postman collection for applying some basic API design governance to any API you have defined in a Postman workspace</a>. The collection uses the Postman API to pull the OpenAPI for each API and store it within an environment, then there are a range of basic requests that can be made to evaluate the design of the APIs that we have defined as an OpenAPI.<span>&nbsp; </span>The collection is a proof of concept, and is meant to be a starting point for designing many difference types of API governance rules, and thinking about how Postman collections can be used to govern the API life cycle, starting with the design of our APIs&mdash;something that is exposed as OpenAPI.</p>
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/aws-s3-square-supreme-court-judgement.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">My new Postman API governance collection has a handful of folders, and the following requests:</p>
<ul>
<li><strong>Info</strong> - Looking at the general info for the API.    
<ul>
<li>Validate the Name Of The API</li>
<li>Validate the Description for the API</li>
</ul>
</li>
<li><strong>Paths</strong> - Evaluating the design patterns of each API path.    
<ul>
<li>Ensure Words Are Used in Paths</li>
</ul>
</li>
<li><strong>Methods</strong> - Looking at the details of each API method.    
<ul>
<li>Check For GET, POST, PUT, and DELETE</li>
<li>Check All Methods Have Summaries</li>
<li>Check All Methods Have Descriptions</li>
<li>Check All Methods Have Operation Ids</li>
<li>Check All Methods Have Tags</li>
</ul>
</li>
<li><strong>Parameters</strong> - Ensuring there is consistency across parameters.    
<ul>
<li>Make Sure All Method Query Parameters Are Camel Case</li>
<li>Make Sure All Method Query Parameters Have Descriptions</li>
</ul>
</li>
<li><strong>Responses</strong> - Diving into the details of each of the responses.    
<ul>
<li>Check For HTTP Status Success (2xx)</li>
<li>Check For HTTP Status Failure (5xx)</li>
</ul>
</li>
<li><strong>Schema</strong> - Understanding what is going on with the schema.    
<ul>
<li>Check If Any Schema Have Properties</li>
<li>Make Sure All Schema Properties Have Descriptions</li>
</ul>
</li>
</ul>
<p class="p1">These governance requests are pretty superficial at the moment. I&rsquo;d say the ensure words are used in paths, and the check for GET, POST, PUT, and DELETE are the most ambitious. Everything else is just looking that a key or value is present in the OpenAPI, reflecting a pattern I want to see when it comes to the design of my APIs, but ultimately it has to be defined as an OpenAPI property for me to validate. It is interesting to move forward some of my APIs and think about what the most common illnesses and deficiencies are across the APIs I am developing&mdash;then write a little bit of JavaScript to bring each API governance check to life.</p>
<p class="p1">I am adding all my other ideas for API governance requests to the GitHub issues for the project. I have a whole lot of needs when it comes to<span>&nbsp; </span>enforcing consistency across my APIs. I know what needs to be done I just don&rsquo;t always have the discipline to make it happen&mdash;I am hoping a set of API governance checks defined as Postman requests help me police things a little better. Right now I am developing each governance check as a individual request, then organizing them into folders within a collection. I may start consolidating some of them down the road, but for now I wanted to keep them modular and individual executable. I think I will rely on running them as a monitor to aggregate all the checks and results into a single report. IDK. I am just getting going when it comes to defining how I apply API governance to my APIs using Postman.</p>
<p class="p1">You can find <a href="https://documenter.postman.com/view/35240/SWLh46Dv?version=latest">the documentation for this collection published using Postman</a>, and I have <a href="https://github.com/api-evangelist/api-governance-postman-collections">the collection and environment published to GitHub</a> for easy management. If you have an additions, comments, questions, feel free to submit a <a href="https://github.com/api-evangelist/api-governance-postman-collections/issues">GitHub issue for the repository.</a></p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/01/09/a-postman-api-governance-collection/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/01/08/spreading-api-collections-from-my-personal-workspaces-across-multiple-workspaces/">Spreading Api Collections From My Personal Workspaces Across Multiple Workspaces</a></h3>
        <span class="post-date">08 Jan 2020</span>
        ---
published: true
layout: post
title: 'Spreading API Collections From My Personal Workspaces Across Multiple Workspaces'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/la_muse_gears_pipes_plumbing.jpg
---
<p><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/la_muse_gears_pipes_plumbing.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">As a Postman user for a number of years I have several hundred random collections littering my personal workspace. I had noticed that workspaces emerged a while back, but really hadn&rsquo;t ever put much thought into how I organize my collections. As the number of collections grows I&rsquo;m noticing performance issues within Postman, and general chaos because I work primarily fro within my personal workspace. Pushing me to step back and think more holistically in how I create, store, organize, and share my API collections within the Postman platform and beyond using AWS S3 and GitHub. Forcing a little organization and structure on how I move APIs forward across thier own API life cycle trajectory.</p>
<p class="p1">First, when working in my personal workspace there were performance issues using Postman. There were just too many Postman collections in there to be efficient. This further slowed me down when it comes to finding the collections I needed. Having to look purely alphabetically for collections that could have any sort of naming conventions applied to them took way too much time. This reality has pushed me to think about the different bucket in which I operate and get work done proved to be helpful, helping me create a handful of workspaces for me to organize my API collections into, rather than just operating from a single workspace filled with hundreds of APIs I have imported over the years.</p>
<p class="p1">My frist task was to just delete things that was clearly junk. Then I looked at all my collections via the Postman API to see if there was any last modified or run date&mdash;sadly there isn&rsquo;t. I will have to think about way in which I can track the evolution and usage of my Postman collections so that I can consider automating the cleanup of collections, or at least archiving of them based upon them being modified or not. Once I cleaned up a little bit I was able to see the forest for the trees and I begin organizing my collections by domain and project relevance, putting collections into teams for accessing when I&rsquo;m working on specific projects and area of my operations (ie. <a href="http://apievangelist.com"><span class="s1">apievangelist.com</span></a> vs <a href="/admin/blog/algorotoscope.work">algorotoscope.work</a>). Helping me not stumble over work on other projects, while I&rsquo;m focused in a specific area of my work.</p>
<p class="p1">As I was organizing my collections I began to see new ways in which I could be organizing them. So I began creating workspaces based upon resource area and topics, allowing me to put image API collections into an images workspaces, and video API collections into video workspaces. Sometimes a collection would need to be in multiple workspaces depending on the type of resources it offered up, or how I was using the API in my work. An additional layer of separation between workspaces is based upon them being in my personal workspace, or my team workspace. I only have one team account for my API Evangelist efforts, but I am looking to expand on this team effort by bringing in more help when it comes to profiling APIs and producing useful Postman collections.</p>
<p class="p1">There is still a lot of work left to do when it comes to organizing my Postman collections, but I managed to alleviate the load on my personal workspace. I notice some efficiency gains in the application as well as just my general workflow. I am also learning to have multiple Postman workspaces open in multiple windows, helping me more efficiently navigate the workspaces, share collections and environments, and assemble new Postman collections from the capabilities that exist in the many reference API collections I have. Spreading my API collections that exist in my personal workspace across multiple personal and team workspaces has shifted how I work, and has helped me be more thoughtful in what collections I keep around, and how I put them to work as part of my regular work&mdash;streamlining how I work with APIs and manage my integrations and orchestration across hundreds of different APIs.<span>&nbsp;</span></p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/01/08/spreading-api-collections-from-my-personal-workspaces-across-multiple-workspaces/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/01/08/postman-tutorials-are-common-but-the-postman-collection-is-often-missing/">Postman Tutorials Are Common But The Postman Collection Is Often Missing</a></h3>
        <span class="post-date">08 Jan 2020</span>
        ---
published: true
layout: post
title: 'Postman Tutorials are Common but the Postman Collection is Often Missing'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/clearbit_api_docs_run_in_postman.png
---
<p><a href="https://clearbit.com/docs?ruby#api-reference"><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/clearbit_api_docs_run_in_postman.png" alt="" width="40%" align="right" /></a></p>
<p class="p1">I am amazed at the number of blog posts I come across for API providers explaining how their API consumers can use Postman with their API, but do not actually share a complete Postman collection for developers to use. API providers obviously see Postman as a tool for making API calls, but do not fully grasp the ability to document an API with a Postman collection, save, publish, and share this collection with documentation or the Run in Postman button. As part of this realization I am not looking to shame API providers for not understanding what is possible, I am more looking to acknowledge how much work we (Postman) have to to when it comes to helping folks understand what is possible with the Postman platform, moving folks being the notion that Postman is just an HTTP client.</p>
<p class="p1">There are some pretty involved tutorials out there for using Postman with a variety of APIs. API providers have invested a lot into these blog posts, tutorials, and other resources to help their API consumers on-board with their APIs, but do not publish Postman collections as part of their documentation or tutorial. This tells me that API providers aren&rsquo;t seeing the portability and share-ability of Postman collections. They simply see Postman as an API client, not as tooling for defining, sharing, publishing, versioning, saving, organizing, and evolving API requests. This means we have a lot of work ahead of us to educate folks about what Postman collections are, and how they will make your life easier, while reducing redundancy across operations. Helping folks move beyond simply operating Postman as an isolated HTTP client.</p>
<p class="p1">Having full control over defining a request to an API while being able to see the details of that response is the core value of Postman. Developers get it. Clearly they also see the need in sharing this ability, and equip others realize the same value. They are crafting tutorials and blog posts to help folks understand what is possible if they use Postman, but they don&rsquo;t go that extra step to use Postman documentation and Run in Postman button as a quick way to move people from learning about what an API does to experiencing what that API does. The share feature within Postman is pretty prominent, but I think the concepts why and when you&rsquo;d share with another workspace, via a button, or simply a link gets lost on most folks. I&rsquo;m thinking we need hundreds of examples of this in the wild&mdash;every time I see an API provider publish their Run in Postman button I am going to Tweet out the fact that they are using Postman in this way.</p>
<p class="p1">I am looking to help existing Postman users see a collection as more than a folder structure for saving API requests within their local Postman. I want to help them realize that a default characteristic of a Postman collections is that it can be shared into workspaces, within documentation via the Run in Postman button, and within any API narrative simply using a Postman link. I want to help folks understand that being able to have full control over an API request as well as the response is the fundamental value of using Postman, but the portability of your collections is how you exponentially extend that value to your co-workers, community, and other stakeholders in your API journey. Every API should have documentation, but every API should also have one or more Postman collections available for enabling anyone to put that API to work within one click. We have a lot of work ahead of us to highlight all the ways in which folks are using collections, and expand the awareness of users who haven&rsquo;t broke free of their isolated usage Postman, helping them make sure there is always a Postman collection available when publishing your docs, tutorials, or other API stories.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/01/08/postman-tutorials-are-common-but-the-postman-collection-is-often-missing/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/01/08/deploy-publish-or-launch-an-api/">Deploy Publish Or Launch An Api</a></h3>
        <span class="post-date">08 Jan 2020</span>
        ---
published: true
layout: post
title: 'Deploy, Publish or Launch An API?'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/bw_api_deployment.png
---
<p class="p1">I&rsquo;m always fascinated by the words we use to describe what we do in a digital world. One dimension of the API life cycle that perpetually interests me is the concept of deploying an API, or as some might call it publishing or launching. I am fascinated by how people describe the act of making an API available, but I&rsquo;m even more interested in how shadows exist within these realities. Meaning, within a 30 minute Googling session for publish, deploy, and launch an API, I come across many real world examples of delivering an API, but how few of them will deliver the actual tangible, functional, nuts and bolts of the API.</p>
<p class="p1">After searching for publish API, here is what stood out:</p>
<p><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/bw_api_deployment.png" alt="" width="38%" align="right" /></p>
<ul>
<li><a href="https://cloud.google.com/apigee/api-management/publish-apis/"><strong>Apigee</strong></a></li>
<li><a href="https://app.swaggerhub.com/help/apis/publishing-api"><strong>SwaggerHub</strong></a></li>
<li><a href="https://www.postman.com/publishers"><strong>Postman</strong></a></li>
<li><a href="https://docs.oracle.com/en/cloud/paas/api-platform-cloud/apfad/publish-apis.html"><strong>Oracle</strong></a></li>
<li><a href="https://techdocs.broadcom.com/content/broadcom/techdocs/us/en/ca-enterprise-software/layer7-api-management/api-developer-portal/4-2/publishers/manage-apis/publish-apis.html"><strong>Broadcom</strong></a></li>
<li><a href="https://docs.microsoft.com/en-us/learn/modules/publish-manage-apis-with-azure-api-management/"><strong>Azure</strong></a></li>
<li><a href="https://docs.mulesoft.com/api-community-manager/publish-apis"><strong>MuleSoft</strong></a></li>
<li><a href="https://docs.wso2.com/display/AM210/Create+and+Publish+an+API"><strong>WSO2</strong></a></li>
<li><a href="https://developers.sap.com/tutorials/cp-apim-shoppingfresh-publish-api.html"><strong>SAP</strong></a></li>
<li><a href="https://dev.socrata.com/publishers/"><strong>Socrata</strong></a></li>
</ul>
<p class="p1">After searching for deploy API, here is what stood out:</p>
<ul>
<li><a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-deploy-api-with-console.html"><strong>AWS API Gateway</strong></a></li>
<li><a href="https://firebase.google.com/docs/hosting/api-deploy"><strong>Firebase</strong></a></li>
<li><a href="https://cloud.google.com/endpoints/docs/openapi/deploy-api-backend"><strong>Google</strong></a></li>
<li><a href="https://serverless-stack.com/chapters/deploy-the-apis.html"><strong>Serverless Stack</strong></a></li>
<li><a href="https://docs.mendix.com/apidocs-mxsdk/apidocs/deploy-api"><strong>Mendix</strong></a></li>
<li><a href="https://api-platform.com/docs/deployment/"><strong>API Platform</strong></a></li>
<li><a href="http://deployment.apievangelist.com/"><strong>API Evangelist</strong></a></li>
<li><a href="https://developer.github.com/v3/repos/deployments/"><strong>GitHub</strong></a></li>
<li><a href="https://devcenter.heroku.com/articles/mean-apps-restful-api"><strong>Heroku</strong></a></li>
</ul>
<p class="p1">After searching for launch API, here is what stood out:</p>
<ul>
<li><strong><a href="https://developer.adobelaunch.com/">Adobe Launch</a></strong></li>
<li><a href="https://github.com/r-spacex/SpaceX-API"><strong>SpaceX</strong></a></li>
<li><strong><a href="https://developer.apple.com/documentation/coreservices/launch_services">Apple Launch Services</a></strong></li>
<li><a href="https://docs.rapidapi.com/v2.0/docs/ive-added-my-api-to-rapidapi-now-what"><strong>RapidAPI</strong></a></li>
</ul>
<p class="p1">80% of these will not actually deliver the API, it will just take an existing and make it available. I know most of these service providers believe that their solution does deploy because use it proxies an existing API, but really very few of these actually deliver the API, they more publish, deploy, and launch it into some state of availability&mdash;the final act of making it available and open for business. After all these years of studying API gateway and management providers I&rsquo;m still fascinated by the lack of true API deployment present, and how much it is about proxying what already exists, creating a shadow that continues to prevent us fro standardizing how we deliver APIs.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/01/08/deploy-publish-or-launch-an-api/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/01/08/dead-simple-real-world-api-management/">Dead Simple Real World Api Management</a></h3>
        <span class="post-date">08 Jan 2020</span>
        ---
published: true
layout: post
title: 'Dead Simple Real World API Management'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/bf-skinner-docks-big-cosco-ship.jpg
---
<p><a href="https://tyk.io/"><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/bf-skinner-docks-big-cosco-ship.jpg" alt="" width="40%" align="right" /></a></p>
<p class="p1">I began API Evangelist research almost a decade ago by looking into the rapidly expanding concept of API management, so I think it is relevant to go into 2020 by taking a look at where things are today.<span>&nbsp;</span>In 2010, the API management conversation was dominated by 3Scale, Mashery, and Apigee. In 2020, API management is a commodity that is baked into all of the cloud providers, and something every company needs. In 2010 there were not open source API management provider, and in 2020 there a numerous open source solutions. While there are forces in 2020 looking to continue moving the conversation forward with service mesh and other next generation API management concepts, I feel the biggest opportunity in tackling the mundane work of just effectively managing our APIs using simple real world API management practices.</p>
<p class="p1">I am neck deep in working to deploy a simple set of APIs, looking for the path of least resistance when it comes to going from 0 to 60 with a new API. After playing around with AWS, Azure, and Google for a couple days, reminded of how robust, but also complex some of their API management approaches can be, I find myself on the home page of API Evangelist, staring at the page, and I click on my sole sponsor <a href="https://tyk.io/">Tyk</a>&mdash;finding myself pleasantly reminded how <a href="https://tyk.io/">effective simple real world API management</a> can be. Within 10 minutes I have singed up for an account and began managing one of my prototype APIs, allow me to:</p>
<ul>
<li><strong>Add API</strong> - Add the url and authentication for one of my project APIs.</li>
<li><strong>Version</strong> - Choose to version, or not version the API I am deploying.</li>
<li><strong>Endpoints</strong> - Design a fresh set of endpoints transforming my API.</li>
<li><strong>Load Balance</strong> - Round-robin load-balance traffic to all my APIs.</li>
<li><strong>Regions</strong> - Manage the geographic distribution of my API infrastructure.</li>
<li><strong>Rate Limit</strong> - Limit the amount of API calls that can be made to API.</li>
<li><strong>Users</strong> - Manage all of the users who will be access my APIs.</li>
<li><strong>Keys</strong> - Manage all of the keys in which users will be using to access.</li>
<li><strong>Policies</strong> - Define the policies for access all of the APIs being published.</li>
<li><strong>Certificates</strong> - Make sure everything is properly encrypted across APIs.</li>
<li><strong>Logging</strong> - Establish view into all of the logs for API access across users.</li>
<li><strong>Errors</strong> - Have visibility into errors being generated across APIs.</li>
<li><strong>Activity</strong> - Gain visibility into how APIs are being used across applications.</li>
<li><strong>Portal</strong> - Have a portal dedicated to accessing all of the APIs I make available.</li>
<li><strong>Catalog</strong> - Publish a catalog of all APIs that I am managing using Tyk.</li>
</ul>
<p class="p1">Within 10 minutes I am effectively managing my APIs. Tyk provides me with all of the fundamental building blocks of API management in a simple cloud, on-premise, and open source way. They didn&rsquo;t get in my way with complex on-boarding process, pricing model, or overly robust solutions. It is all in there, but for me to go from 0 to 60 with managing my APIs, there was nothing in my way. After over a decade of evolution this is what API management should look like. I&rsquo;m sorry, service mesh is cool, but simple real world API management right at my fingertips is just much more useful and effective in my everyday world. Something that will make an impact on the bottom line today, not just about the cool new set of tools for tomorrow.</p>
<p class="p1">After a decade of doing this, dead simple <a href="https://tyk.io/">API management solutions like Tyk</a> are what makes me happy. They reflect what I used to highlight about 3Scale back in the day. It took Mashery and Apigee a while to come around to the freemium approach to API management. For me, Tyk represents one of the most mature aspects of the API industry. There is no other stop along the API life cycle that is as proven, simplified, and made available in the cloud and on-premise in both SaaS and open source varietals. I know I am biased, but going into the next decade, Tyk is my favorite API management solution out there, and something that provides a framework I am hoping other API service providers will emulate and integrate with as they look to service the API life cycle&mdash;every stop along the API life cycle should be this easy.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/01/08/dead-simple-real-world-api-management/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/01/07/postman-open-source/">Postman Open Source</a></h3>
        <span class="post-date">07 Jan 2020</span>
        ---
published: true
layout: post
title: 'Postman Open Source'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/postman_open_source_philosphy.jpg
---
<p><a href="https://www.postman.com/open-philosophy/"><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/postman_open_source_philosphy.jpg" alt="" width="40%" align="right" /></a></p>
<p class="p1">I get asked a lot <a href="https://www.postman.com/open-philosophy/">if Postman is open source</a>. I get told ocasionally that people wish it was open source. I have to admit I didn't fully grasp how open Postman was until I helped work on the new open source philosophy page for Postman. While the Postman application itself isn't open source (it is built on open source), the core building blocks of Postman are open source, shifting my view of how you can use the application across operations. Expanding Postman usage beyond just being a solitaire desktop applicaton, and turning it into a digitally scalable gear on the API factory floor.</p>
<p class="p1">Postman as a desktop application is not open source, but here are the core components that are open source, making Postman something you can run anywhere:</p>
<ul>
</ul>
<ul>
<li class="p1"><a href="https://github.com/postmanlabs/postman-runtime"><strong>Postman Runtime</strong></a>&nbsp;- The core runtime of Postman that allows you to run collecctions, including requests, scripts, etc anywhere, extending the work that gets done within the application to anywhere the runtime can be installed and executed.</li>
<li class="p1"><a href="https://github.com/postmanlabs/openapi-to-postman"><strong>Postman Collections Format</strong></a>&nbsp;- The collections you save and share with Postman are all open source and can be shared, exported, published, and used as a unit of currency within any application or system, further extending the reach of the platform.</li>
<li class="p1"><strong><a href="https://github.com/postmanlabs/newman">Newman</a></strong> - Command-line tool for running and testing a Postman Collection as part of any pipeline, making Postman collecitons a unit of compute that can be baked into the software development life cycle, and leveraged as API truth wherever it is needed.</li>
<li class="p1"><strong><a href="https://github.com/postmanlabs/postman-collection">Postman Collection SDK</a></strong> - SDK to quickly unlock the power of Postman Collections format using JavaScript, allowing you to create, manage, and automate how collections are defined and put to work across a platform withoiut depending on the application.</li>
<li class="p1"><a href="https://github.com/postmanlabs/postman-code-generators"><strong>Postman Code Generators</strong></a> - Convert Postman collections to usable code in more than 20 different programming languages, generating simple client scripts for consumers that are defined by the Psoitman collections used as the code generators definition.</li>
</ul>
<p>I am a big fan of open source. I get the power of it across the API landscape. I also understand the benefits of commercial implementations. I've spent a lot of time thinking about the pros and cons of open vs closed across the API landscape. I do not think open always equals good, and I don't think closed always equals bad. I think there is a balance of open and commercial offerings that can be struck to find the optimal conditions within any industry. I think Postman is striking this balance by leveraging both open and closed source offerings to build a viable business, but done in a way that allows other businesses to bake open source components and workflows into their operations.</p>
<p>Honestly, over the last decade I've developed open fatigue from being associated with some faux open source projects, misleading open API efforts, adn damaging open data missions. I haven't lost my belief in open, but I have grown tired of open being used to manipulate the landscape, and I am extremely wary of people who wield open as part of their marketing. I feel good about the balance we are striking at Postman, and I will continue to workk to incentivize and incite more open processes, content, and components at Postman, allowing us to continue baking the goodness that is possible within the application into our infrastructure, withouit concern for lock-in.&nbsp;</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/01/07/postman-open-source/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/01/07/challenges-binding-apis-deployed-via-gateway-to-backend-services/">Challenges Binding Apis Deployed Via Gateway To Backend Services</a></h3>
        <span class="post-date">07 Jan 2020</span>
        ---
published: true
layout: post
title: 'Challenges Binding APIs Deployed Via Gateway To Backend Services'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/stories-statue-face-open-mouth-blue-circuit-5.png
---
<img src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/stories-statue-face-open-mouth-blue-circuit-5.png" width="40%" align="right" style="padding: 15px;" /><p class="p1">I spent some of the holidays immersed in the backend integrations of the top three cloud providers, AWS, Azure, and Google. Specifically I was studying the GUI, APIs, schema, mapping, and other approaches to wiring up APIs to backend systems. I am looking for the quickest API-driven way to deploy an API, and hooking it up to a variety of meaningful resources on the backend, beginning with SQL and NoSQL data stores, but then branching out discovering the path of lest resistance for more complex backends. Maybe it is because of my existing experience with Amazon, but I found the AWS approach to wiring up integrations using OpenAPI to be the easiest to follow and implement, over what Azure and Google offered. Eventually I will be mapping out the landscape for each of the providers, but at first look, Azure and Google required substantially more work to understand and implement even the most basic backends for a simple API.<span> </span></p>
<p class="p1">Don’t get me wrong, if you want to just gateway an existing API using AWS, Azure, or Google, it is pretty straightforward. You just have to learn each of their mapping techniques and you can quickly define the incoming request, and out going response mappings without much effort. However, for this exercise I was looking for an end to end actual deployment of an API, not the proxying or Hollywood front for an existing API. If you want to launch a brand new API from an existing datasource, or a brand new API with a brand new data source, I found AWS to be path of least resistance. I was able to launch a full read / write API using AWS API Gateway + AWS DynamoDB with no code, something I couldn’t do on Azure or Google, without specific domain knowledge of their database solutions. I had only light exposure to DynamoDB, and while there were some quirks of the implementation I had to get over, I was able to stand up a completely new API with just a couple hours of work. I could have done similar with Google and Azure, but from what I could tell they would require some code in between the database and the API backend—something I will tackle in future work.</p>
<p class="p1">As I was wrapping up this work, and preparing to write some stories about it, I came across a blog post from Red Hat introducing the service binding operator, which as their way of <a href="https://developers.redhat.com/blog/2019/12/19/introducing-the-service-binding-operator/">streamlining how you bind backend services in the Red Hat universe</a>. It go me thinking about the need for standards, or at least common approaches to how we map the backend of an API to other APIs, but also how we map the backend of APIs to other common systems. I’m too old and jaded to think we’ll pull together a common standard for everyone to use, but man it would be nice if they weren’t so wildly different. The cognitive load with Azure, even with their pretty slick resource manager, and with Google was just too much for me to tackle in a short time frame. If I can justify the investment I will be diving in deeper on Azure and Google in January, but for now I’ll be focusing on the low hanging fruit with Amazon. While my objective is multi-cloud API deployment, I have lots of work ahead of me to streamline <a href="http://apievangelist.com/2020/01/02/a-postman-collection-for-managing-the-life-cycles-of-my-apis/">Postman collections that help you quickly deploy different types of APIs just to AWS</a>. I will need someone to tell me they have a need for Azure or Google before I dive in deeper there.</p>
<p class="p1">All of this work is about defining one of the more difficult stops along the API life cycle—deployment. API deployment means so many different things to many different people, and is a word that has been hijacked by API management and gateway providers to mean the publishing of an API facade, making it a really difficult thing to actually nail down and discuss. After years of investment in the API life cycle why is API deployment still so complicated? It shouldn’t be. We’ve had all the moving parts for easily deploying from databases, using API definitions, and other approaches for years. Why haven’t they come together into a single suite of open source, cloud, or on-premise solutions. Well, the answer is more business and political than technical, and something I’m not looking to solve. I am just looking for ways to help standardize, streamline, and talk about until API deployment gets a little easier. Right now the challenges in binding APIs deployed via gateways to backend services is largely too cumbersome and technical for the average API provider to realize--we can do better.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/01/07/challenges-binding-apis-deployed-via-gateway-to-backend-services/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/01/07/academic-or-street-api-tooling/">Academic Or Street Api Tooling</a></h3>
        <span class="post-date">07 Jan 2020</span>
        ---
published: true
layout: post
title: 'Academic or Street API Tooling'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/rain-princess-P5290036.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/rain-princess-P5290036.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">There always seems like there are two separate types of tools in my world, the academic tools that consider the big picture and promise to steer me in the right direction, and then there is the street tooling that helps me get my work done on a day to day basis. After going to work for a street tooling vendor who has some academic tooling aspirations, it has gotten me thinking more about the tools I depend on, and learning more about what people are using within the enterprise to get their work done each day.</p>
<p class="p1">I have used different academic tooling over my life as the API Evangelist. I&rsquo;d say every API management tool I&rsquo;ve adopted has been very academic until recently. From my view API management started as academic and then became a factory floor commodity. I feel say Kong and Tyk are the only version that have achieved a street level status within all of this, and NGINX is looking to turn it&rsquo;s street cred into more of something that is more academic, and visionary. There aren&rsquo;t many academic API tooling that have gone from vision to implementation&mdash;they just can&rsquo;t survive the investment and acquisition cycles that gobble them. Making it difficult to see the real adoption they need to become baked into our daily lives. API management has done it, but very few other stops along the API life cycle have realized this level of adoption.</p>
<p class="p1">Street tooling, or the hand tools developers use to get their jobs done on a daily basis are a much different beast. Postman and NGINX are both examples of tools that developers know about and depend on to operate each day. Using NGINX to deploy and Postman to consume APIs each day. These aren&rsquo;t tools that promise some grand vision of how we could or should be, these are tools about dealing with what is right in front of us. These are tools that keep things manageable, and operating each day. They are the tools that allow us to do what we do, make sense of the fast moving digital gears around us, and reliably delivering the resources that we are expected to deliver.<span>&nbsp;</span></p>
<p class="p1">I am not passing judgement on the value of academic over street tooling here. I am simply acknowledging that there is a difference between what is already in motion across the enterprise, and what you'd like to be in motion. I think you can consciously develop a street API tool, but I think it is very hard to actually realize at scale. I think we always lean towards the future, rather than designing tooling for what we need now. This is one of the dangers of always looking towards the future and thinking about what is next. Sure, thinking strategically is important, but ultimately it is the tools that make a difference in our day that will see the adoption street tools enjoy. The other very challenging aspect of street tools is the business model isn&rsquo;t always clear&mdash;it is the academic vision of what will be that strategically grabs enough attention to warrant dropping the money needed to move things forward. <span>&nbsp;</span></p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/01/07/academic-or-street-api-tooling/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/01/06/the-fundamentals-deploying-apis-from-your-databases/">The Fundamentals Deploying Apis From Your Databases</a></h3>
        <span class="post-date">06 Jan 2020</span>
        ---
published: true
layout: post
title: 'The Fundamentals: Deploying APIs From Your Databases'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/stories-36575484422-087495fca9-z.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/stories-36575484422-087495fca9-z.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">You know, I tend to complain about a lot of things across the API space while focusing on the damage caused by fast moving technology startups and the venture capital that fuels them. Amidst all of this forward motion I easily forget to showcase the good in the space. The things that are actually moving the conversation forward and doing the hard work of connecting the dots when it comes to APIs. I easily forget to notice when there are real businesses chugging along delivering useful services for for all of us when it comes to APIs. One of my favorite database to API businesses out there, and one of the companies who have been around for a significant portion of my time as the API Evangelist, working hard to help people deploy APIs from their databases, is <a href="https://www.slashdb.com/">SlashDB</a>.</p>
<p class="p1">If you want to <a href="https://www.slashdb.com/">deploy APIs from your databases</a>, SlashDB is the solution. If you are looking to make <a href="https://www.slashdb.com/">data within MySQL, PostgreSQL, SQLite, MS SQL Server, Oracle, IBM DB2, Sybase, RedShift, NoSQL, or other data source available quickly as an API</a>, SlashDB has the solutions you are looking for. SlashDB isn&rsquo;t one of those sexy new startups with a bunch of venture funding looking to be your new API best friend. SlashDB is looking to do the mundane difficult work needed to make the data available within your legacy databases available as APIs so that you can use across your applications. SlashDB is all about securely exposing your data using standardized web APIs, making your digital resources available wherever you need them.</p>
<p class="p1">SlashDB doesn&rsquo;t have the splashy website, but they have the goods when it comes doing one of the most common tasks when deploying APIs&mdash;wiring up your APIs to their data backends. They also have the straightforward pricing tiers for you to navigate as you expand the number of data sources you are wiring up, and the number of consumers you have consuming data via your APIs. In this industry it can be easy to always chase the shiny new objects and forget about the hard work we have across the enterprise. Instead of chasing the next new API trend we should be ensuring that all of our databases are securely exposed as APIs. SlashDB is all about making sure that all of our data is accessible and put to work across different applications, allowing us to reach as wide as possible audience as we can with standardized web API aceess by default for all of our data sources.</p>
<p class="p1">Developing APIs is rarely glamours work. Doing the hard work of exposing Create, Read, Update, and Delete (CRUD) APIs isn&rsquo;t fun work for anyone, and something we need assistance automating and there is no reason we should be doing manually, or trying o reinvent the wheel. Sometimes we just need a trusted service provider to come in and help us with the heavy lifting. As I work to understand the technology, business, and politics of APIs I don&rsquo;t want to only focus on the shine objects and big explosions in the API sector, and miss out on showcasing API services provider who have been quietly doing the hard work over the years. As SlashDB&rsquo;s latest newsletter came into my inbox I was reminded that they are still out there doing what they have always been doing for years&mdash;deploying APIs from databases. In 2020 if you are looking for some help when it comes to <a href="https://www.slashdb.com">API deployment from your databases make sure you reach out to the SlashDB team</a> for some help.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/01/06/the-fundamentals-deploying-apis-from-your-databases/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/01/06/postman-collections-for-pulling-my-twitter-friends-and-followers/">Postman Collections For Pulling My Twitter Friends And Followers</a></h3>
        <span class="post-date">06 Jan 2020</span>
        ---
published: true
layout: post
title: 'Postman Collections For Pulling My Twitter Friends And Followers'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/twitter_home_page_friends_followers.png
---
<p><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/twitter_home_page_friends_followers.png" alt="" width="40%" align="right" /></p>
<p class="p1">I have been cranking out <a href="https://github.com/api-evangelist/capabilities">the Twitter API capabilities</a> lately, crafting single request Postman collections that focus on a specific capability of the popular social API. I use the API for a number of different things around API Evangelist, and as I assess how I use the social media API I wanted to be engineering my integrations as Postman collections so I can better organize and execute using Postman, while also adding to <a href="https://github.com/api-evangelist/capabilities">the list of API capabilities I&rsquo;m sharing with my audience of developers and non-developers</a>.</p>
<p class="p1">Today I cranked out two individual Twitter API capabilities helping me better manage my Twitter followers and friends:</p>
<ul>
<li><strong><a href="https://documenter.postman.com/view/35240/SWLe6839?version=latest">Twitter Followers</a>&nbsp;-</strong>&nbsp;Pulls your Twitter followers 200 at a time, saves them within an environment, then allows you to increment through each page of followers, eventually pulling and storing all of your followers.</li>
<li><strong><a href="https://documenter.postman.com/view/35240/SWLe683A?version=latest">Twitter Friends</a>&nbsp;-</strong>&nbsp;Pulls your Twitter friends 200 at a time, saves them within an environment, then allows you to increment through each page of friends, eventually pulling and storing all of your friends.</li>
</ul>
<p class="p1">These capabilities are separate Postman collections so that they can be used independently, or together. I am keeping them organized into a Postman workspace so that I can use manually, but then also have a daily monitoring running, pulling any new followers or friends from my Twitter. I pull the resulting JSON from the environments I pair up with each collection using the Postman API and integrate into some of my other API Evangelist monitoring and automation. Next I am going to create a Postman collection that will reconcile the two lists and tell me which people I am following do not follow me back, creating a third list that I can use to unfollow and clean up my profile.</p>
<p class="p1">Crafting these types of collections helps me renew my understanding of some of the APIs I already use. It also helps me better define the individual capabilities I put to work on a daily basis, and develop better workflows to get business done. I like the idea of individual tasks like pulling my friends and followers operating and storing the results in an environment for use in other collections, or applications via the Postman API. It is shifting how I see APIs, and how I orchestrate with them. I am looking forward to continuing to make my way through the Twitter API, developing useful collections like this and publishing to&nbsp;<a href="https://github.com/api-evangelist/capabilities">my list of API capabilities</a>,&nbsp;and here on the blog.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/01/06/postman-collections-for-pulling-my-twitter-friends-and-followers/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/01/06/my-levels-of-postman-api-environment-understanding-to-date/">My Levels Of Postman Api Environment Understanding To Date</a></h3>
        <span class="post-date">06 Jan 2020</span>
        ---
published: true
layout: post
title: 'My Levels of Postman API Environment Understanding To Date'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/la_muse_lighthouse_36679514616_o.jpg
---
<p><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/la_muse_lighthouse_36679514616_o.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">I have been a pretty hardcore Postman user since the beginning. Over the years I felt like I understood what Postman was all about, but one of the first concepts that blew up my belief around what Postman could do was the concept of the Postman environment. Like other Postman features, environments are extremely versatile, and can be used in many different ways depending on your understanding of Postman, as well as the sophistication of the APIs and the workflow you are defining using Postman. My Postman environments awakening has occurred in several phases, consistently blowing my mind about what is possible with Postman and Postman collections.</p>
<p class="p1">Postman environments are already one of the edges I have given Postman collections over a pure OpenAPI definition&mdash;it just provides more environmental context than you can get with OpenAPI alone. However, at each shift in my understanding of how Postman environments can be used, entirely new worlds opened up for me regarding how that context can be applied and evolved over time across many different APIs. Resulting in four distinct layers of understanding about how Postman environments works and can be applied in my world&mdash;I&rsquo;m sure there will be more dimensions to this, but this is a snapshot of how I see things going into 2020.</p>
<h3>Environments Settings For Single API Calls</h3>
<p class="p1">I have to start with the ground floor and express why environments matter in the first place, and provide an edge over OpenAPI all by itself. Being able to define key / value pairs for authorization and other variables across one or many different API collections helps speed up the on-boarding, orchestration, and reuse of API requests within those collections. It quickly allows you to switch users or other context, but still use the same collection of API requests, shifting how we automate and orchestrate across our API infrastructure. However, simply putting the base url for your API as a variable, and defining tokens and other secrets is just the beginning&mdash;there is so much more that you can do with an API environment.</p>
<h3>Using Environments To Chain APIs Together</h3>
<p class="p1">The next most common way of using an environment is to think of it for chaining API calls together, and then deploying a runner to execute as part of a CI/CD pipeline, or as a Postman monitor. It can be effective for grabbing values from an API response and storing in an environment and then using those values in the next API call. This is a much more efficient way of "chaining" API calls together than actually mapping and binding an API response to an API request. Storing responses and then applying as part of a request helps keep things more flexible and reusable, allowing you to break the chains associated with API chaining&mdash;revealing it is a pretty narrow way to look at API orchestration. Where you really break free is when you stop seeing things as just a sequence, but about terraforming across an environment with multiple API calls.</p>
<h3>Evolving Environments With Multiple API Calls</h3>
<p class="p1">Once you realize that any variable within an environment can be used as part of the request and response for any number of APIs, you stop seeing just individual APIs and the order in which they can be executed, and you begin to see, well, an environment that can be manipulated. Environments provide an API runtime storage that can be used across many manual API collection runs, automated runs within CI/CD pipelines with Newman, or on a schedule using monitors. Pulling from, and contributing to the desired environmental state, while maximizing both humans and other systems in the orchestration of the development and evolution for he environment. Once you can realize this in action across many different APIs, across many different platforms and geographic regions, the possibilities for developing more meaningful API workflows reaches entirely new heights.<span>&nbsp;</span></p>
<h3>Environmental Access &amp; Management Via API</h3>
<p class="p1">Going from storing my tokens and keys, to chaining APIs together, all the way to orchestrating with many different APIs shifted my view substantially, but once I figured out I can also access my environments using the Postman API, it seismically disrupted things once again. This meant I could terraform a specific Postman API environment using many different APIs across many different API providers, over a specified time frame, and then also access that environmental definition via an API and use in other applications. This meant I can use my environment for decision making within other applications. I can be manually and automatically grooming and refining an environment using Postman collections, but then I can also develop web, mobile, or other applications that interact with the data I have aggregated and made available as an API. This is difficult to understand without actually setting in motion, which is something I will work to do in a handful of prototypes, including one on the API life cycle I am currently iterating upon.</p>
<h3>Developing Entirely New Environments</h3>
<p class="p1">I no longer see environments as something that powers a single API, and occasionally a series of API calls. I see them as environments that stand on their own legs and are fed by Postman collections, while also feeding Postman collections&mdash;it is a symbiotic relationship between environments and collections. Even with this enlightenment about what is possible with Postman environments I am sure that new horizons will emerge where I didn&rsquo;t expect them. I don&rsquo;t see environments as purely a key / value store for secrets and other request settings. I see them as something to define more strategically and use to define the environment(s) in which I execute my API infrastructure.</p>
<p class="p1">I realize that environments could be used to define the context of a single Postman collection, but I hadn&rsquo;t fully thought through how many different collections could be used to define the context of different environments. It is a thought provoking and landscape expanding notion to think about environments and collections working together like this. It has completely changed how I design Postman collections. I still have all of my reference API collections defining all of the capabilities of each of the API platforms I&rsquo;m using, but I end up using these individual lego building blocks to assemble entirely new environments as well as workflows that help evolve those environments, and move the API-defined business knobs, leavers, and gears towards a desired state of operation.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/01/06/my-levels-of-postman-api-environment-understanding-to-date/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/01/06/a-dynamic-salesforce-rest-api-postman-collection-builder-collection/">A Dynamic Salesforce Rest Api Postman Collection Builder Collection</a></h3>
        <span class="post-date">06 Jan 2020</span>
        ---
published: true
layout: post
title: 'A Dynamic Salesforce REST API Postman Collection Builder Collection'
image: https://kinlane-productions2.s3.amazonaws.com/postman-collections/salesforce/salesforce-collection-builder-3.png
---
<p class="p1"><a href="http://apievangelist.com/2019/12/18/taming-the-salesforce-api-scope/">I have been working on developing new ways to make the Salesforce API more accessible and easier to onboard with over the last couple of months</a>, helping reduce friction every time I have to pick up the platform in my work. One of the next steps in this work is to develop a prototype for generating a dynamic Postman collection for the Salesforce REST API. I had created a Postman collection for the API earlier, but the Salesforce team pointed out to me that the available APIs will vary from not only version to version, but also user account to user account. With this in mind I wanted to develop a tool for dynamically generating a Postman collection for the Salesforce API, and as I got to work building it I realized that I should probably just make the tool a Postman collection itself (mind blown).</p>
<p class="p1">To help make on-boarding with the Salesforce API easier I created <a href="https://github.com/api-evangelist/salesforce-api-collection-builder">a Postman collection that uses the Salesforce API to autogenerate the Postman collection based upon the available objects and endpoints for the Salesforce REST API</a>. The Postman collection has three requests within the collection to accomplish the creation of a dynamic collection. The first request pulls all the latest versions for the Salesforce API, using the Salesforce API.</p>
<p class="p1"><img src="https://kinlane-productions2.s3.amazonaws.com/postman-collections/salesforce/salesforce-collection-builder-1.png" alt="" width="100%" /></p>
<p class="p2">Once I have the version of the Salesforce API I am targeting for a build I add it to the Postman environment I am using to define the operations of my Postman collection, and then I pull the list of available objects for this version, and for my own Salesforce account.</p>
<p class="p1"><img src="https://kinlane-productions2.s3.amazonaws.com/postman-collections/salesforce/salesforce-collection-builder-2.png" alt="" width="100%" /></p>
<p class="p1">The objects that exist will vary for each Salesforce account, as well as version, making it pretty critical that that any Postman collection is dynamic, being generated from this personalized list of objects. The next request in our Salesforce Postman collection builder is the build, which generates individual requests for all of the available objects. After you run, the response just shows the list of available objects, but the test script for the request loops through each object and generates a set of requests from the derived values.</p>
<p class="p1"><img src="https://kinlane-productions2.s3.amazonaws.com/postman-collections/salesforce/salesforce-collection-builder-3.png" alt="" width="100%" /></p>
<p class="p1">After the build request is sent, it will take 30-60 seconds for things to build, but once it does you should see a new folder called &ldquo;Generated Requests&rdquo; that has over a 1000 individual API requests in it organized by folders for each object. Providing a complete Postman collection for the entire surface area of the Salesforce REST API.</p>
<p class="p2">To use the Salesforce Postman collection builder collection you will need to <a href="https://github.com/api-evangelist/oauth-apps/blob/master/salesforce.md">setup an OAuth application in your own Salesforce account</a>, and add the settings to the authorization for your Postman collection.</p>
<p class="p1"><img src="https://kinlane-productions2.s3.amazonaws.com/postman-collections/salesforce/7-salesforce-authorization-settings.png" alt="" width="100%" /></p>
<p class="p1">You will also need a Postman environment with your base URL for your Salesforce instance, as well as the version you wish to use, and the API key for your Postman account, which you can find under your account settings.</p>
<script src="https://gist.github.com/kinlane/90760e65eeaae7a8c6521cf79bb9db2d.js"></script>
<p class="p1"><a href="https://github.com/api-evangelist/salesforce-api-collection-builder">I have published the Salesforce REST API Postman collection builder to GitHub,</a> as well as the environment I use. If you have any questions feel free to submit an issue there, and I&rsquo;ll see what I can do. This is all just a proof of concept, and I am still determining what the road map for this Salesforce API Postman collection builder will be. So if you have any needs, I&rsquo;d love to hear them.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/01/06/a-dynamic-salesforce-rest-api-postman-collection-builder-collection/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/01/03/the-many-differences-between-each-api/">The Many Differences Between Each Api</a></h3>
        <span class="post-date">03 Jan 2020</span>
        ---
published: true
layout: post
title: 'The Many Differences Between Each API'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/aws-s3-square-christianity-under-construction-copper-circuit-square.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/aws-s3-square-christianity-under-construction-copper-circuit-square.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">I&rsquo;m burning my way through profiling, updating, and refreshing the listings for about <a href="http://apievangelist.com/network/">2K+ APIs in my directory</a>. As I refresh the profile of each of the APIs in my index I am looking to make sure I have an adequate description of what they do, that they are well tagged, and I always look for an existing OpenAPI or Postman collection. These API definitions are really the most valuable thing I can find for an API provider, telling me about what each providers API delivers, but more importantly it does the same for other consumers, service and tooling providers. API definitions are the menu for each of the APIs I&rsquo;m showcasing as part of my API research.</p>
<p class="p1">As I refresh the profile for each API I re-evaluate how they do their API, not just the technical details of their API, but also the business and on-boarding of their API. If an API providers doesn&rsquo;t always have an OpenAPI, Postman collection, or other machine readable definition for their APIs, depending on the value of the API and standardization of their API design and documentation, I will craft a simple scrape script to harvest the API definition, and generate the OpenAPI and Postman collection automatically. As I cycle through this process fore each API in my index I&rsquo;m reminded of just how different APIs can be, even if they are just RESTful or web APIs. Demonstrating that there are many interpretations of what an API should be, both technically, and from a business perspective.</p>
<p class="p1">Some APIS have many different paths, representing a wide variety of resources and capabilities. Some APIs have very few paths, and heavily rely on query parameters to work the magic when it comes to applying an API. Others invest heavily in enumerators and the values of query parameters to extract what you need from each API&mdash;often times forgetting to tell you what these values should or could be. Some of the time an API provider will share documentation with you outlining most of what an API will do, but more often than not I come across APIs with entire blindspots of functionality, leaving me fumbling around trying to piece together what is possible with an API, making it difficult to ever consider a profile of an API, and the resulting OpenAPI or Postman collection truly complete&mdash;I just do not fully ever know, unless an API provider actually owns and updates the API definition themselves.</p>
<p class="p1">Beyond just the many differences in API design there are many differences between the business of an API. How you find the API, learn about it, on-boarding with it, pay for it, get support, and the other required elements before an API provider and consumer can find common ground. I regularly end my profiling of an API during the frustrating signup and on-boarding process. If I can justify the value of an API, I have less than 10 minutes to on-board and be seeing value, otherwise I&rsquo;m just walking away. APIs that possess common building blocks as part of their API portal, and employ proven API management solutions for the sign-up, on-boarding, and overall developer engagement are easier to use, and possess less friction when it comes to getting started. All the steps are familiar for me, and just make sense&mdash;I do not have to work overtime understanding how I will get access to an API. It just works.</p>
<p class="p1">After a decade of navigating the differences between APIs I am unsure how to convince API providers to standardize on how they deliver their portal, documentation, on-boarding, and design of their APIs. It doesn&rsquo;t mean I will stop encouraging them to do so, and help define standard definitions, services, and tooling that help them along the way. While we should keeping putting information out there regarding how to best design your API, then publish and make available in a standardized way, I&rsquo;m thinking we are going to need other ways to demonstrate to folks the differences in the APIs they are delivering, and how they compare to other APIs within their own company or industry. I feel like people don&rsquo;t have a sufficient enough view of the landscape to see their own position within it, and haven&rsquo;t spent much time using other APIs and developing a shared API vocabulary with their community. I think differences in APIs can be good, because there are many different ways to tackle integration, but I fear that the many differences I&rsquo;m seeing are for all the wrong reasons.<span>&nbsp; &nbsp;</span></p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/01/03/the-many-differences-between-each-api/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/01/03/pricing-comparison-for-screen-capture-apis/">Pricing Comparison For Screen Capture Apis</a></h3>
        <span class="post-date">03 Jan 2020</span>
        ---
published: true
layout: post
title: 'Pricing Comparison for Screen Capture APIs'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/stalin-time-old-time-cash-register.jpg
---
<img src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/stalin-time-old-time-cash-register.jpg" width="40%" align="right" style="padding: 15px;" /><p class="p1">There is <a href="https://underconstructionpage.com/best-site-screenshot-api-services/">a pricing comparison between 33 separate screen capture APIs</a> halfway down the page on this interesting piece about how to choose the right screen capture service. This type of comparison should exist across every business sector being impacted by APIs, as well as new ones emerging to introduce entirely new digital resources for use in our desktop, web, mobile, device, and network applications. Sadly, right now these types of machine readable, let alone human readable lists do not exist across the sector. Assembling these types of comparisons takes a lot of time and energy, and aren’t always possible in a special API snowflake of a world where seemingly similar APIs are actually very different beasts—sometimes intentionally, but usually unintentionally.</p>
<p class="p1">I have had <a href="http://plans.apievangelist.com/2016/02/13/my-tooling-and-api-for-gathering-and-organizing-the-details-of-the-plans-and-pricing-for-apis/">a machine readable schema for defining API pricing</a> for almost five years now. I’ve profiled common resources like email, SMS, and others, but ultimately haven’t had the resources to invest in the work at the levels needed. I know how much work goes into establishing an exhaustive list of APIs in any business sector as well as finding a price, and defining the access tiers for each individual API provider. I wish I had more resources to invest in profiling of APIs, but also profiling down to this level of detail where each of the individual API resources they offer have some sort of semantic vocabulary applied, and a machine readable defining of the pricing and on-boarding required for each API provider. This is how we are going to get to the API economy we all like to fantasize about, where we can automatically discover, on-board, pay for, and switch between valuable aPI resources as we need in real-time.</p>
<p class="p1">We need to get to work on doing this for the most tangible, consistent, and valuable API across the sector. We won’t be able to do for all types of APIs, and sometimes I twill be an apples to oranges comparison, but we need to get started. I’m betting that in the industries we begin to define early on we will see more consistency in how APIs are designed, and the price for API resources, as API sectors become more crowded, competitive, and cutthroat.<span>  </span>I have the strategy for mapping out the landscape and profiling API providers and their APIs, I just don’t have the resources to actually get the work done. It is a monumental challenge, and is something that is perpetually evolving and shifting, making it a full time job for a team of API professionals to quantify what is happening right now when it comes to the expansion and evolution of the API economy.<span> </span></p>
<p class="p1">Sadly, I am guessing people will keep doing the hard work of delivering API pricing comparisons like this, but won’t do a in a machine readable, shareable, and reusable way. We’ll cointinue doing it for the sake of advertising and page views. Eventually more investors will learn about the growing opportunity which will most likely spawn waves of revenue seeking data startups trying to make sense of it all in a closed proprietary way. What we really need is an open source approach to mapping out the API landscape, where the community comes together and collaborates around the creation and maintenance of OpenAPI and Postman collections for all the public APIs. While also injecting other machine readable artifacts that help us map out beyond just the surface area of the APIs, but also the on-boarding, pricing, terms of service, service level agreements, and other essential building blocks that influence the health of API platforms, their integrations, and the communities that rise up around them. <span> </span></p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/01/03/pricing-comparison-for-screen-capture-apis/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/01/03/not-just-an-api-provider-but-also-an-api-matchmaker/">Not Just An Api Provider But Also An Api Matchmaker</a></h3>
        <span class="post-date">03 Jan 2020</span>
        ---
published: true
layout: post
title: 'Not Just An API Provider But Also An API Matchmaker'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/la_muse_electric_tower_sun_behind_cropped.jpg
---
<p><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/la_muse_electric_tower_sun_behind_cropped.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">Your API is always the best. Of course it is. However, not everyone will see the value your API delivers without a little enlightenment. Sometimes the value of an API is missed in isolation when you are just looking at what a single API can do. To help developers, as well as business users understand what is possible it can help to connect the dots between your API and other valuable 3rd party APIs. This is something you see from API providers who have integration pages showcasing the different integrations that are already available, and those who have invested in making sure their API is available on integration platform as a service (iPaaS) providers like IFTTT and Zapier. If a new user isn&rsquo;t up to speed on what your API does, it can help to put it side by side with other APIs they are already familiar with.</p>
<p class="p1">Being aware of not just the industry you are operating an API within, but also complimentary industries is what we should all be striving for as an API provider. The most competitive API providers all have integration pages demonstrating the value that an API provides, but more importantly the value it can deliver when bundled with other popular services their customers are already using. This means that API providers have to be solving a real world problem, but also have done their homework when it comes to understanding a real world version of this problem that other people face. Or simply have enough consumers of an API who are demanding that are also demanding integrations with other commonly used platforms. Regardless of how an API provider gets there, having an awareness of other platforms that companies are depending on as part of their operation, and ensuring that your API solutions are compatible and interoperable by default just makes sense.</p>
<p class="p1">I find that playing with a complimentary API in Postman helps you think about the moving parts of an API in a way that helps you see more of the capabilities and potential of the API, rather than just the API resources. Twitter and GitHub are two good examples of this. When I just think about each of the APIs, I don&rsquo;t get much inspiration about what is possible. However, after I open up the Postman collection, begin browsing around the available API paths, hitting send on some of the requests, I begin to see more opportunity, and find new inspiration for what is possible. I enjoy dissecting an API, and laying out all the gears on the workbench with Postman. It helps if an API providers has already done the hard work for me of crafting a reference collection for their API, but either way getting my hands on each individual API request is a great way to light the fire underneath my imagination about what is possible with an API.</p>
<p class="p1">After breaking down a couple of complimentary APIs you find yourself able to see a uch bigger picture of business interoperability and integration. You start to better understand what is possible with an API, and how those possibilities apply in your real world of business operations. By evaluating Twitter and GitHub side by side I have come up with entirely new ways of engineering how I pull and index data from Twitter by defining API collections that pull data from Twitter and publish to private repositories on GitHub for further indexing and evaluation as part of my API discovery pipeline. I&rsquo;m not interested in storing the tweets for too long, I am more interested in indexing the API references and any URLs that are present. After shifting how I use Twitter and GitHub I began to think differently about how I publish my blog content using my own blogging API, further matching up API capabilities across my business platform, and optimizing how I collection, store, manage, and migrate my content and data using internal and 3rd party APIs.</p>
<p class="p1">To be a good API provider I strongly believe you have to be an experienced API consumer. Having robust reference collections for the APIs you depend on is essential to exercising your API consumer muscles. By having these complete API collections, combined with working keys, tokens, and authentication as part of supporting environments, I am able to play API matchmaker more frequently. If I have to on-board with an API every time I go to use it, it is unlikely I will ever understand what that API does. However, if I have a working Postman collection and environment for an API in one of my Postman workspaces ready for use, I am more likely to be exploring, learning, and re-enforcing my understanding of what value that API brings to my API workbench, while also actively using individual capabilities of an API in my API-driven business workflows. Something that just feeds and strengthens my ability to not just be an API provider, and consumer, but also as an API matchmaker&mdash;connecting the dots between the most important APIs across my business operations.<span>&nbsp;</span></p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/01/03/not-just-an-api-provider-but-also-an-api-matchmaker/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/01/02/what-is-the-api-life-cycle/">What Is The Api Life Cycle</a></h3>
        <span class="post-date">02 Jan 2020</span>
        ---
published: true
layout: post
title: 'What Is The API Life Cycle?'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/bf-skinner-hallway-mirrors-hotel.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/bf-skinner-hallway-mirrors-hotel.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">I regularly struggle with the words and phrases I use in my storytelling. I&rsquo;m never happy with my level of word-smithing, as well as the final output. Ultimately I don&rsquo;t let it stop me, I just push myself to constantly re-evaluate how I speak, being forever critical and often pedantic about why I do things, and why I don&rsquo;t. One word I struggle with is lifecycle. First I struggle with it being a word, or two words. Historically I have been team word, but more recently I&rsquo;ve switched to two words. However, this round of anxiety over the phrase is more operational, and existential, over it being about how I use the word in my storytelling. I am more interested in if we should even be using the phrase, and if we are, how do we get more formal about quantifying exactly what we mean by the API life cycle.</p>
<p class="p1">As I work to flesh out <a href="http://apievangelist.com/2020/01/02/a-postman-collection-for-managing-the-life-cycles-of-my-apis/">my API life cycle Postman collection</a>, defining an API-driven guard rails for how I deliver my APIs, and distilling each step down to a single request and set of pre and post request scripts, I am forced to think about what the API life cycle really is. Pushing me to go beyond just talking about some abstract concept, to actually having a set of interfaces and scripts that quantify each stop along the API life cycle. While I will be adding more stops to my Postman API life cycle collection, I currently have 27 stops defined, providing me with some concrete actions I can take at each point in the evolution of my APIs.</p>
<ul>
<li><strong>Define</strong> - Defining the central truth of the API using OpenAPI, JSON Schema, and Postman collections and environments.</li>
<li><strong>Environments</strong> - Providing environments that drive different stages of the API life cycle in conjunction with various collections.</li>
<li><strong>Design</strong> - Quantifying, standardizing, and evolving the HTTP and other design patterns I use across the APIs I deliver.</li>
<li><strong>Documentation</strong> - Providing a link to the Postman documentation I am generating for each API using it&rsquo;s reference collection.</li>
<li><strong>Mock</strong> - Ensuring there is one or more mock representations for an APIs, and potentially different versions of each API.</li>
<li><strong>Database</strong> - Deploying, configuring, and managing the persistent data storage behind each API I am deploying.</li>
<li><strong>Compute</strong> - Potentially providing a compute layer, using a server, container, or serverless solution, driving the API backend.</li>
<li><strong>Deploy</strong> - Taking an API contract and actually deploying an API using a gateway, framework, or other standardized approach.</li>
<li><strong>Manage</strong> - Ensuring there are usage plans, and each API require keys to access, managing how each individual API can be applied.</li>
<li><strong>Integration</strong> - Making sure there are scripts, SDKs, and other integration solutions available for consumers of each API to use.</li>
<li><strong>Authentication</strong> - Ensuring that all APIs require authentication and is selected from a standardized set of authentication and authorization methods.</li>
<li><strong>Logging</strong> - Centralizing logging for all APIs, providing a single location to tune into the activity around how each API is being applied.</li>
<li><strong>Encryption</strong> - Ensuring all API traffic is encrypted by default, managing the certificates, and usage of certificates across infrastructure.</li>
<li><strong>DNS</strong> - Being able to apply custom sub-domains to each individual API, leveraging DNS as a namespace for the API catalog.</li>
<li><strong>Portal</strong> - Providing a single doorway in which everything about an API can be accessed, making it easy to engage with each API resource.</li>
<li><strong>Road Map</strong> - Publishing a road map with everything that is planned for an API, actively adding and completing road map entries.</li>
<li><strong>Change Log</strong> - Once something has been accomplished as part of the road map it can be moved into a state where it feeds into the change log.</li>
<li><strong>Issues</strong> - Providing a way of communicating around the known issues with each API, limiting the resources needed to support<span>&nbsp; </span>the community.</li>
<li><strong>Support</strong> - Additionally providing email, social media, and ticketing support as part of an APIs operation, ensuring there is a feedback loop.</li>
<li><strong>Communication</strong> - Going beyond support and making sure there is a regular broadcast of information and knowledge from an APIs operations.</li>
<li><strong>Testing</strong> - Having a strategy for defining, executing, and reporting upon tests for 100% of the surface area for an API being delivered.</li>
<li><strong>Monitoring</strong> - Having a strategy for how an API is monitored, and how recurring tasks are schedule and reporting up as part of orchestration.</li>
<li><strong>Performance</strong> - Having your finger on the pulse of the performance for each API, tracking on how well it is delivering against expected SLAs.</li>
<li><strong>Security</strong> - Using the APIs contract to define, scan, and secure the surface area of each API, going beyond just authentication and access control.</li>
<li><strong>Discovery</strong> - Making sure all of my APIs are discoverable by default, leveraging machine readable definitions to make them discoverable.</li>
<li><strong>Governance</strong> - Adequately defining the guidance, guardrails, reporting, and feedback loop that exists across the API life cycle.</li>
<li><strong>Deprecation</strong> - Being honest that eventually an API will have to be deprecated and retired as part of it&rsquo;s evolution and support<strong>.</strong></li>
</ul>
<p class="p1">These are what I consider to be the essential stops along my API life cycle. While the life cycle for an API does begin with definition, and end with deprecation, it is definitely not a linear process. This is one reason I stopped using lifecycle as one word, because I wanted to decouple the life from the cycle, allowing the cycles to repeat in any formation and repetition throughout the life of an API. I&rsquo;m really troubled by the visions I have in my head about the API life cycle being and end to end linear type of thing. I want to evolve how I talk about the API life cycle, and how I define and execute it across many different APIs. I&rsquo;m pretty confident that in order for me to evolve in how I deliver APIs I am going to have to get more structured in how I define, talk about, and execute across the API life cycle. I am hoping with my new API collection that eventually I will be able to just harvest the exhaust of my API life cycle collection using Postman, and immediately be able to map out the actual end to end life cycle for an API.</p>
<p class="p1">Right now I see the API life cycle as and end to end affair, but with a bunch of little cycles that exist between different stops, at different frequencies, involving different API stakeholders. My goal with <a href="http://apievangelist.com/2020/01/02/a-postman-collection-for-managing-the-life-cycles-of-my-apis/">my API life cycle collection</a> is to help me better quantify each stop along the API life cycle, and ensure there is a timestamp for each individual action made at that stop. I want to know how many times I iterated upon the design of an API before I publish the documentation again. I want to understand how many actual deployments went to the gateway before the evolution of an API actually slowed and stabilized. I have a lot of questions about what API life cycle means, how we quantify and engage with it, and most importantly how we observe, measure, understand, and report upon what is going on so that over time we get better and better, while also offering more stable API solutions that people can use.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/01/02/what-is-the-api-life-cycle/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/01/02/deploying-my-postman-openapi-to-aws-api-gateway/">Deploying My Postman Openapi To Aws Api Gateway</a></h3>
        <span class="post-date">02 Jan 2020</span>
        ---
published: true
layout: post
title: 'Deploying My Postman OpenAPI To AWS API Gateway'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/braceros-domingo-ulloa-nyc-subway-train-125th.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/braceros-domingo-ulloa-nyc-subway-train-125th.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">I created <a href="https://github.com/api-evangelist/aws">a bunch of different Postman collections for AWS services</a> leading up to re:Invent this year, and now I&rsquo;m using individual requests to deliver on <a href="http://apievangelist.com/2020/01/02/a-postman-collection-for-managing-the-life-cycles-of-my-apis/">some different Postman AWS API life cycle workflows</a>. To flesh out the scaffolding for how I define and deliver APIs throughout their API life cycle I got to work on <a href="http://apievangelist.com/2020/01/02/a-postman-collection-for-managing-the-life-cycles-of-my-apis/">a Postman collection for defining and executing every single stop in my API life cycle</a> in a way that I could consistently apply across many different APIs. I am using Postman to define the central truth of each of my APIs with OpenAPI, and I want to use Postman to deliver and execute on that truth across every single stop along the API life cycles. One of the more critical stops I wanted to provide a solution for was API deployment, providing me with a simple way to immediately deploy an API from an OpenAPI definition.</p>
<p class="p1">Deploying APIs are hard. It is one of the most complicated and least standardized stops along the API life cycle. Regardless, I wanted a simple straightforward Postman collection that would allow me to take an API definition within Postman, and publish an API to one of the major cloud platforms&mdash;AWS won out for simplicity.<span>&nbsp;</span>Ultimately, using Postman I was able to pull an OpenAPI for one of my APIs, then deploy an API in five steps. Providing a basic, introductory Postman collection for deploying a Postman API to AWS API Gateway.</p>
<ol class="ol1">
<li class="li1"><strong>Pull API</strong> - Loads up the specific version of a Postman API into the environment for processing within each of the next steps.</li>
<li class="li1"><strong>Create Table</strong> - Actually creates an AWS DynamoDB table derived from the name of the API being pulled from Postman.</li>
<li class="li1"><strong>Prepare OpenAPI</strong> - Takes the OpenAPI and generates AWS API Gateway integration extensions that define the backend.</li>
<li class="li1"><strong>Publish OpenAPI</strong> - Takes the new OpenAPI with integration extensions and publishes to AWS API Gateway.</li>
<li class="li1"><strong>Deploy API</strong> - Actually deploys the API to a specific development or production stage in the gateway.</li>
</ol>
<p class="p1">All of this could easily be distilled down into a single Postman request, but I want to pause and make sure that is what I need. It has already been distilled down from multiple API calls to Postman, AWS DynamoDB, and AWS API Gateway. So, I am just pausing to make sure of the workflow I want for deploying an API to a development or production environment.<span>&nbsp; </span>Ultimately the database might be switched out depending on my implementation, and the prepartion of the OpenAPI will vary depending on backend being used, so keeping things separate and modular for now makes a lot of sense, giving me ultimately flexibility around how I evolve this API life cycle workflow collection.</p>
<p class="p1">This collection depends on an environment to authenticate with the Postman API, AWS DynamodDB API, and AWS API Gateway API, as well as to store data used across the deployment process. You can import this environment into your Postman, enter your keys and tokens, and it should work as long as your AWS IAM is configured properly&mdash;you will need to have AWS DynamoDB, and API Gateway full access for it all to work. I use the same AWS access key and secret across the API requests for both services, and depend on IAM to be properly defined for the keys, as well as AWS role which is used as part of each API backend integration definition. I&rsquo;ll document this all better in the near future.</p>
<p class="p1"><a href="https://documenter.postman.com/view/35240/SWLce9Vf?version=latest">If you want to kick the tires on ithe collection you can grab the Postman collection and the Postman environment here</a>. Of course, this is all a work in progress, and meant to flesh out a process for deploying APIs using Postman. Next I will flesh out a couple of the different types of APIs I deploy, then work to create a process to accommodate each one, preparing the OpenAPI as it leaves Postman to deliver the proper backend for each type of API I&rsquo;m publishing. Eventually I will have a suite of API deployment patterns for AWS, and I will be assessing the delivery of comparable APIs using Azure and Google&mdash;after initial work, I deemed AWS as being the easiest, as well as being the lowest hanging fruit when it comes to developing Postman collections that deploy an API you have defined using Postman.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/01/02/deploying-my-postman-openapi-to-aws-api-gateway/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2020/01/02/a-postman-collection-for-managing-the-life-cycles-of-my-apis/">A Postman Collection For Managing The Life Cycles Of My Apis</a></h3>
        <span class="post-date">02 Jan 2020</span>
        ---
published: true
layout: post
title: 'A Postman Collection for Managing the Life Cycles Of My APIs'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/udnie-IMG_2410.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/udnie-IMG_2410.jpg" alt="" width="40%" align="right" /></p>
<p>I had grown weary of just researching, talking, and teaching about the API lifecycle over the last ten years as the API Evangelist. This was one of the major motivators for me to join the Postman team. I want to take my knowledge of the API life cycle and work to make sure the rubber meet the road a little more when it comes to actually realizing much of what I talk about. I began investing in this vision over the holidays <a href="https://documenter.postman.com/view/35240/SWLb99h1?version=latest">by crafting a Postman collection that isn't for defining a single API, it is meant to define the life cycle of a single API</a>. I can manage multiple stops along the API life cycle already with Postman--I just wanted to bring it all together into a single machine readable collection that uses the Postman API, but also other APIs I use to orchestrate my world each day.</p>
<p>My <a href="https://documenter.postman.com/view/35240/SWLb99h1?version=latest">API life cycle collection</a> is still a work in progress, but it is coming together nicely, and is the most tangle format of what I have been in my head when I think of <a href="https://www.postman.com/">Postman as an API delivery platform</a>. This collection centers around managing an OpenAPI truth within Postman, then moving this API definition down the life cycle, and even deploy development or production versions of each API using AWS API Gateway. Of course everythig is API-driven, and designed to work across many different APIs to define, deliver, and manage any single API, maintaning a definition of the life cycle within a single Postman environment that can be used to bridge multiple API platform via a single collection.</p>
<p>So far I have over a hundred individual capabilities defined as Postman requests, and organized into folders that are broken down by different stops along the API life cycle. I'm still moving them around and abstracting away the friction, while I work hard to define the most sensible workflows with each of my API life cycle capabilities.</p>
<ul>
<li><strong>Define</strong> 
<ul>
<li><strong>Workspaces</strong> (Postman)  
<ul>
<li>GET Single Workspace</li>
<li>GET All Workspaces</li>
<li>POST Create Workspace</li>
</ul>
</li>
<li><strong>Organizations</strong> (GItHub)  
<ul>
<li>GET Organizations</li>
<li>GET Organization</li>
</ul>
</li>
<li><strong>Repository</strong> (GitHub)  
<ul>
<li>POST Add User Repository</li>
<li>POST Add Org Repository</li>
<li>GET Repository</li>
<li>GET Repositories</li>
</ul>
</li>
<li><strong>APIs</strong> 
<ul>
<li>GET Single API</li>
<li>GET Get all APIs</li>
<li>GET Get All API Versions</li>
<li>GET Get An API Version</li>
<li>GET Get API Schema</li>
</ul>
</li>
<li><strong>Collections</strong> 
<ul>
<li>GET All Collections</li>
<li>GET Single Collection</li>
<li>POST Create Collection</li>
<li>PUT Update Collection</li>
<li>DELETE Delete Collection</li>
</ul>
</li>
<li>POST Create Manually</li>
<li>GET OpenAPI Using Name and Version</li>
<li>GET Sync OpenAPI To GitHub Repository</li>
<li>GET Sync OpenAPI From GitHub Repository</li>
</ul>
</li>
<li><strong>Environments</strong> (Postman)  
<ul>
<li>GET Environments</li>
<li>GET Environment</li>
<li>POST Environment</li>
<li>PUT Environment</li>
<li>DELETE Environment</li>
</ul>
</li>
<li><strong>Design</strong> (Postman)  
<ul>
<li>POST Add Resource</li>
<li>POST Add Schema Property</li>
<li>POST Add Query Parameter</li>
<li>POST Add Header</li>
<li>POST Add Response</li>
</ul>
</li>
<li><strong>Documentation</strong> (Postman)  
<ul>
<li>POST Sets Documentation URL</li>
</ul>
</li>
<li><strong>Mock</strong> (Postman)  
<ul>
<li>GET Mocks</li>
<li>GET Mock</li>
<li>POST Mock</li>
<li>DELETE Mock</li>
</ul>
</li>
<li><strong>Database</strong> (AWS DynamoDB)  
<ul>
<li>POST List Tables</li>
<li>POST Add Table</li>
</ul>
</li>
<li><strong>Compute</strong> (AWS Lambda)  
<ul>
<li>GET Funtions</li>
<li>GET Function</li>
</ul>
</li>
<li><strong>Deploy</strong>&nbsp;(AWS API Gateway)  
<ul>
<li>GET List</li>
<li>GET Details</li>
<li>GET Build</li>
<li>POST Publish</li>
<li>POST Deploy</li>
<li>GET Deployment</li>
<li>GET Export OpenAPI 3.0</li>
<li>DELETE Delete</li>
</ul>
</li>
<li><strong>Manage</strong> - AWS API Gateway  
<ul>
<li><strong>Usage Plans</strong> 
<ul>
<li>GET All</li>
<li>GET Single</li>
<li>POST Add</li>
<li>GET Get Usage</li>
</ul>
</li>
<li><strong>Keys</strong> 
<ul>
<li>GET All</li>
<li>GET Single</li>
<li>POST Add</li>
<li>POST Usage Plan Keys</li>
</ul>
</li>
</ul>
</li>
<li><strong>Logging</strong> (AWS API CloudTrail)  
<ul>
<li>GET Trails</li>
<li>GET Trails Cop</li>
</ul>
</li>
<li><strong>Encryption</strong> 
<ul>
<li>GET List CloudFlare Certificates</li>
<li>GET AWS API Gateway Client Certificates</li>
<li>POST Generate Client Certificate</li>
<li>GET AWS API Gateway Client Certificate</li>
<li>DELETE AWS API Gateway Client Certificate</li>
</ul>
</li>
<li><strong>DNS</strong> 
<ul>
<li>GET Zones (CloudFlare)</li>
<li>GET DNS Records (CloudFlare)</li>
<li>GET Domain Names (AWS API Gateway)</li>
<li>GET Domain Name (AWS API Gateway)</li>
</ul>
</li>
<li><strong>Portal</strong> (GitHub)  
<ul>
<li>POST Add Org Repository</li>
<li>POST Add User Repository</li>
<li>POST Update README</li>
</ul>
</li>
<li><strong>Road Map</strong> (GitHub)  
<ul>
<li>GET All Road Map Items</li>
<li>POST New Road Map Item</li>
<li>GET Single Road Map Item</li>
<li>PATCH Mark Complete</li>
</ul>
</li>
<li><strong>Change Log </strong>(GitHub)  
<ul>
<li>GET All Change Log Entries</li>
<li>POST New Change Log Entry</li>
<li>GET Single Change Log Entry</li>
<li>PATCH Close Change Log Entry</li>
</ul>
</li>
<li><strong>Issues</strong> (GitHub)  
<ul>
<li>GET All Issues</li>
<li>POST New Issue</li>
<li>GET Single Issue</li>
<li>PATCH Close Issue</li>
</ul>
</li>
<li><strong>Support</strong> (GitHub)  
<ul>
<li>GET All Tickets</li>
<li>POST New Ticket</li>
<li>GET Single Ticket</li>
<li>PATCH Close Ticket</li>
</ul>
</li>
<li><strong>Communication</strong> (GitHub)  
<ul>
<li><strong>Blog</strong> 
<ul>
<li>POST Blog Post</li>
<li>GET Blog Posts</li>
<li>GET Blog Post</li>
</ul>
</li>
<li><strong>Twitter</strong> 
<ul>
<li>POST Tweet</li>
<li>GET Twitter Tweet Search</li>
<li>GET Twitter User Search</li>
</ul>
</li>
</ul>
</li>
<li><strong>Testing</strong> (Postman)</li>
<li><strong>Monitoring</strong> (Postman)</li>
<li><strong>Performance</strong> (Postman)</li>
<li><strong>Security</strong></li>
<li><strong>Discovery</strong> (GitHub)  
<ul>
<li>POST Update APIs.json</li>
</ul>
</li>
<li><strong>Governance</strong> 
<ul>
<li><strong>Design</strong> 
<ul>
<li>Info</li>
<li>Paths</li>
<li>Methods</li>
<li>Parameters</li>
<li>Responses</li>
<li>Schema</li>
</ul>
</li>
<li><strong>Mock</strong> 
<ul>
<li>GET Check To See If Their Is A Mock Server</li>
</ul>
</li>
<li><strong>Develpment</strong> 
<ul>
<li>GET Check To See If Their Is A Development Server</li>
</ul>
</li>
<li><strong>LIcense</strong> 
<ul>
<li>GET Validate the License for the API</li>
</ul>
</li>
<li><strong>Production</strong> 
<ul>
<li>GET Check To See If Their Is A Production Server</li>
</ul>
</li>
<li><strong>Reporting</strong> 
<ul>
<li>GET Life Cycle Outline</li>
</ul>
</li>
</ul>
</li>
<li><strong>Deprecation</strong> 
<ul>
<li>GET Set Sunset HTTP Header</li>
<li>POST Add Deprecation Date To Road Map</li>
</ul>
</li>
</ul>
<p>To help me refine <a href="https://documenter.postman.com/view/35240/SWLb99h1?version=latest">this API life cycle collection</a>&nbsp;a little more I am going to apply to around ten individual APIs I want to move forward. Three of them are for demonstration purposes, but the rest are menat for a research project I am working on. My initial goal here was to flesh out an API design first process for delivering the resources I need, but then quickly moved to being able to actulaly deliver, then rapidly evolve these resources in both development and produciton environments. They aren't resources that will ultimately see a lot of activity, or true production scale, but they will be used enough to flesh out my API life cycle in a meaningful way.&nbsp;</p>
<p>In addition to helping me realize a more API-driven approach to the API life cycle, there are two major takeaways for me from this project so far. First, I am able to go from an OpenAPI truth within Postman, to deploying a usable API using AWS API Gateway and AWS DynamoDB within just a couple clicks. Second, I was able to start delivering a meaningful set of API governance requests that I organize as part of the governance section of this collection--helping me look for some of the most common things that go wrong with my API design. There are many other little nuggets in here for me, which I will be writing about separately. There is a lot to unpack here, and I will be digging in via stories on the blog over the next couple of weeks.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2020/01/02/a-postman-collection-for-managing-the-life-cycles-of-my-apis/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/12/30/pulling-your-twitter-bookmarks-via-the-twitter-api/">Pulling Your Twitter Bookmarks Via The Twitter Api</a></h3>
        <span class="post-date">30 Dec 2019</span>
        ---
published: true
layout: post
title: 'Pulling Your Twitter Bookmarks Via The Twitter API'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/nazi-invasion-border-crossing-through-fence.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/nazi-invasion-border-crossing-through-fence.jpg" alt="" width="40%" align="right" /></p>
<p><a href="http://apievangelist.com/2019/12/29/pulling-links-from-those-tweets-you-have-favorited/">I created two Twitter API capabilities the other day to help someone pull a list of their Twitter favorites using the Twitter API</a>. They said they wanted bookmarks and I assumed they used favorites in the same way I do (as bookmarks), and created one Postman collection for pulling API favorites, and another to parse the URLs present in the body. I use Twitter public likes as a way of bookmarking, then I harvest those via the Twitter API--something I've done for over a decade. I had heard of Twitter bookmarks, and seen them in the desktop and mobile apps, but hadn't really made the shift in my brain. So I assumed they were talking about likes. DOH! Anyways, they tweeted back at me and helped me realize misconception. Ok, so how do we still get them their bookmarks? After some quick investigation there is no Twitter API for your private bookmarks, making the pulling of your data a little more challenging, but not impossible.</p>
<p>This is where I began helping people not just understand the technology of APIs, but also the politics of API operations. Meaning Twitter has an API for your bookmarks, they just don't want you to get at it via the public API (I am not sure why). Anyways, in this scenario I can't make a ready to go Postman collection for you to use, I am going to have to teach you a little bit more Postman Kung Fu, and teach you how to sniff out the APIs that exist behind everything you do each day. It is still something you can do without programming, and with Postman you can still get at your data in the same way we did for the public Twitter favorites API. You just have to be curious enough to not turn away as I pull back the curtain of the world of APIs a little bit more, with a simple walk through. Something that will ultimately give you more control over your data, and how you take control over your digital presence.</p>
<p>First, a couple of assumptions I am making here -- let's get these out of the way upfront this time, rather than after the fact.</p>
<ul>
<li><strong><a href="https://www.postman.com/downloads/">Postman Installed</a></strong> - You have downloaded and installed Postman on your Windows or Mac machine.</li>
<li><strong>Twitter Account </strong>- You already have a Twitter account and you have bookmarks stored within it.</li>
<li><strong>Chrome Browser</strong> - For this API exercise you will need to be accessing your Twitter in Chrome. </li>
</ul>
<p>Next, you will need <a href="https://chrome.google.com/webstore/detail/postman-interceptor/aicmkgpgakddgnaphhhpliifpcfhicfo?hl=en">to install the Postman Interceptor as an extension for Chrome</a>, which we will be using to intercept web traffic as we browse Twitter, and route through our Postman, capturing the API call being made to pull your bookmarks--connecting our Postman client with our Chrome browser.</p>
<p><a href="https://chrome.google.com/webstore/detail/postman-interceptor/aicmkgpgakddgnaphhhpliifpcfhicfo?hl=en"><img src="https://kinlane-productions2.s3.amazonaws.com/postman-tutorials/twitter-bookmarks/0-postman-interceptor.png" alt="" width="100%" /></a></p>
<p>Once you have Interceptor installed in Chrome, you need to go back to your Postman client, and configure the proxy before turning on the firehose in the browser. There are a couple of things we need to do in Postman before we are ready to be capturing traffic. To begin I always make sure I'm working in a relevant Postman workspace, so that my collections do not get lost in my personal workspace.</p>
<p><img src="https://kinlane-productions2.s3.amazonaws.com/postman-tutorials/twitter-bookmarks/1-postman-workspace.png" alt="" width="100%" /></p>
<p>Choose an existing workspace, or select to create a new workspace to get this work done. Then go ahead and create a new Postman collection called <em><strong>"Web Traffic"</strong></em>, which we can use to route all of our web traffic into, creating a single bucket for everything coming in.</p>
<p><img src="https://kinlane-productions2.s3.amazonaws.com/postman-tutorials/twitter-bookmarks/2-new-postman-collection.png" alt="" width="100%" /></p>
<p>Now that we have a collection to route our traffic, let's configure our Postman client to accept traffic from our Chrome Browser, turning all of the web traffic Ito individual requests that can be save, shared, and executed. To configure the Postman proxy, click on the little satellite dish in the top right corner of the application.</p>
<p><img src="https://kinlane-productions2.s3.amazonaws.com/postman-tutorials/twitter-bookmarks/3-postman-proxy-corner.png" alt="" width="100%" /></p>
<p>Once the settings window pops up we are going to click on interceptor as the source, making sure it is grabbing traffic from the Google Chrome browser extension, connecting Postman and the browser in real time.</p>
<p><img src="https://kinlane-productions2.s3.amazonaws.com/postman-tutorials/twitter-bookmarks/4-postman-proxy-source.png" alt="" width="100%" /></p>
<p>Next, we will want to turn on capturing requests by selecting the ON button, which will turn the light next to INTERCEPTOR CONNECTED green. Preparing postman for receiving web traffic coming from the Chrome browser.</p>
<p><img src="https://kinlane-productions2.s3.amazonaws.com/postman-tutorials/twitter-bookmarks/5-postman-proxy-capture.png" alt="" width="100%" /></p>
<p>Now we want to choose the collection we created as the place to save requests to, choosing <span style="text-decoration: underline;"><strong>"Collections: Web Traffic"</strong></span> from the dropdown, which hopefully isn't too long depending on how you manage your API workspaces.</p>
<p><img src="https://kinlane-productions2.s3.amazonaws.com/postman-tutorials/twitter-bookmarks/6-postman-proxy-save-requests-to.png" alt="" width="100%" /></p>
<p>Next we will need to turn on the firehose in our Chrome browser, but before we do <span style="text-decoration: underline;"><strong><a href="https://twitter.com/i/bookmarks">I recommend you visit Twitter and load up your bookmarks page</a></strong></span>, so that we are prepared to refresh the page and make the underlying API call once we turn on Interceptor. Once the page has loaded, go ahed and click on the round orange Postman Interceptor icon in the toolbar of your Chrome browser.</p>
<p><img src="https://kinlane-productions2.s3.amazonaws.com/postman-tutorials/twitter-bookmarks/7-chrome-postman-interceptor.png" alt="" width="100%" /></p>
<p>Turn on Interceptor, refresh your page, then go ahead and click to turn Interceptor back off. If you leave on you will tracking every single API call being made by every browser tab you have open. Something that might be interesting for exploration in the future, but right now we are only interested in a single API call, and we don't want to be drowned by web traffic. In the brief second I have turned on and was refreshing the bookmarks page almost 50 single API calls were made in my Chrome browser, and I'm just interested in one. To find the AP request we are looking for go back to your Postman client, and type "bookmark" in your search filter toolbar in the top / left corner.</p>
<p><img src="https://kinlane-productions2.s3.amazonaws.com/postman-tutorials/twitter-bookmarks/8-postman-collection-bookmark-filter.png" alt="" width="100%" /></p>
<p>You will notice that our Postman Interceptor captured the call to the Twitter Bookmark API for us, complete with all the parameters, and most importantly, it also captures all the headers for the API call, complete with the authentication we will need to actually make the API call.</p>
<p><img src="https://kinlane-productions2.s3.amazonaws.com/postman-tutorials/twitter-bookmarks/9-postman-collection-bookmark-headers.png" alt="" width="100%" /></p>
<p>Before I continue I always save my requests, giving each request a a meaningful name and description that describes what they do, and I store them in small portable, sharable, and executable Postman collections.</p>
<p><img src="https://kinlane-productions2.s3.amazonaws.com/postman-tutorials/twitter-bookmarks/10-postman-collection-save-bookmark.png" alt="" width="100%" /></p>
<p>Once I save my request, I go ahead and turn off my proxy in Postman and Chrome, and I delete the "Web Traffic" collection--I do not need the other requests, I now have the request that I need.</p>
<p><img src="https://kinlane-productions2.s3.amazonaws.com/postman-tutorials/twitter-bookmarks/11-postman-collection-delete-collection.png" alt="" width="100%" /></p>
<p>Now that I have a single API call that Twitter uses to display my bookmarks in the web application. Sadly, this API isn't available publicly as part of the API, but I"m guessing Twitter has its reasons. Anyways, thanks to Postman, we can still get at our data behind web applications, even when providers don't want us to. Go ahead and hit send on the API request, returning the JSON listing of all your bookmarks.</p>
<p><img src="https://kinlane-productions2.s3.amazonaws.com/postman-tutorials/twitter-bookmarks/12-postman-collections-json-response.png" alt="" width="100%" /></p>
<p>As we did with the other two collections, we want to craft a script that will sift through the JSON and pull out the links we are wanting for each of the bookmarked Tweets. Since I can't create a collection as part of this project, here is the script you will need to paste in Postman.</p>
<script src="https://gist.github.com/kinlane/4445917dcdd28a1be958545f41e2caa3.js"></script>
<p>Go ahead and copy / paste the content of this script then go back to Postman and click on the tests tab for your Twitter bookmark request. The script will take the results from the Twitter API, and render it to the visualizer for us.</p>
<p><img src="https://kinlane-productions2.s3.amazonaws.com/postman-tutorials/twitter-bookmarks/13-postman-collections-test-tab.png" alt="" width="100%" /></p>
<p>Once we have added the script to our Postman request, we can click send again, making the call to the Twitter bookmark API, parsing the JSON with our script, and publishing to the Postman Visualizer tab, rendering only our Tweets and the URLs we bookmarked.</p>
<p><img src="https://kinlane-productions2.s3.amazonaws.com/postman-tutorials/twitter-bookmarks/14-postman-collection-visualizer.png" alt="" width="100%" /></p>
<p>That is it. Phew. Hopefully it wsn't too many steps for. It is a little more involved than <a href="https://github.com/api-evangelist/capabilities">our other API capabilities</a>, but once you master this one you should be a little more equipped for reverse engineering the web applications you depend on each day. Depending on how many bookmarks you will be pulling, you may need to tweak your request, and eventually your authorization tokens will expire and you will need to recreate your request using the Postman Interceptor. Sorry, there is no way around it until Twitter adds the bookmark API to their public API--right now your Twitter developer tokens will not work for Twitter bookmarks. ;-(</p>
<p>I didn't expect to go from 101 level to 201 level API stuff as a next step, but there isn't any alternative in this situation. I feel like simple capability-driven Postman API collections are within reach of developers and non-developers alike. I also feel like proxying your web traffic, and sifting through the resulting exhaust for API gems is something within reach too. Postman isn't just for developers and APIs aren't either. If you use the web, you should have have some sort of awareness of what is happening behind the curtain of the web applicatons you use daily. Postman + Interceptor allow you to do this without writing code, or really understanding how it all works. Hopefully it provides a quick glimpse at what is going on behind the scenes, and wets your appetite enough to convince you play around a little more.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/12/30/pulling-your-twitter-bookmarks-via-the-twitter-api/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/12/29/pulling-links-from-those-tweets-you-have-favorited/">Pulling Links From Those Tweets You Have Favorited</a></h3>
        <span class="post-date">29 Dec 2019</span>
        ---
published: true
layout: post
title: 'Pulling Links From Those Tweets You Have Favorited'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/bf-skinner-fat-old-pigeon-on-fence.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/bf-skinner-fat-old-pigeon-on-fence.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">I am busy crafting new <a href="https://github.com/api-evangelist/capabilities">API capabilities</a> from my laundry list of requests I have from folks. When I get an email or come across a Tweet with someone asking how they do something on Twitter I will add to my list, and at some point pull together a simple Postman collection for accomplishing what is being desired. Providing a single Twitter capability that I can add to my list, and anyone (hopefully) can put to use with their own Twitter account and application, within their own local Postman environment. My goal here is to help provide simple API-driven capabilities that anyone can use, while also pushing my skills when it comes to crafting useful Postman collections that aren&rsquo;t just for developers.</p>
<p class="p1">Today&rsquo;s API capability is from Elana Zeide (<a href="/admin/blog/elanazeide">@elanazeide</a>) who asked on Twitter, &ldquo;<a href="https://twitter.com/elanazeide/status/1210993086295236610">So now I have a lot of twitter bookmarks of amazing things you people have shared ... is there any way to export/download them to another app? (I know you can do it w/ likes) Anyone come up with some clever workaround/automation?</a>&rdquo;. To possibly help her out I started by creating a single Postman collection that just pulls the favorites for any Twitter user via the Twitter API.</p>
<ul>
<li><strong><a href="https://documenter.postman.com/view/35240/SWLb9V6Y?version=latest">Pull Twitter Favorites Capability&nbsp;</a></strong>- It authenticates with the Twitter API and pulls the likes for any Twitter user using their handle, and publishing the list of favorites to the visualizer screen.</li>
</ul>
<p class="p1">This all by itself is a perfectly usable API capability all by itself, but once I was done I used it as my base for pulling any URL that is present in the Tweet. Making for entirely separate Twitter API capability that I hope folks will find useful.</p>
<ul>
<li><strong><a href="https://documenter.postman.com/view/35240/SWLb9V6d?version=latest">Pull Links From Twitter Favorites Capability</a></strong><span class="s2">&nbsp;</span>- It authenticates with the Twitter API and pulls the likes for any Twitter user using their handle, extracts all of the links from those tweets and publishes the list of links to the visualizer screen.</li>
</ul>
<p class="p1">Both of these Twitter API capabilities employ the Twitter API to pull JSON data, but they also take advantage of Postman&rsquo;s new visualizer to abstract away the complexity of each of the API responses, giving the consumer exactly the data they need. If you are brave enough to peak behind the curtain on how this happens you can just click on the Test tab within Postman for each of these collections. I purposefully tried to make the JavaScript as reverse engineer-able as possible so that anyone can tweak to get the results they desire in the visualizer.<span>&nbsp;</span></p>
<p class="p1">I am working to make the Twitter API more accessible to non-developers with these capabilities, so if there are any rough edges, or things that do not make sense, please let me know&mdash;you can Tweet or email at me, or leave an issue on <a href="https://github.com/api-evangelist/capabilities">my API capabilities repository on GitHub</a>.<span>&nbsp;</span>There are some complexities that are out of my control (like Twitter authentication), but I&rsquo;m always working to polish and smooth things out where I can. If you have any other capabilities you&rsquo;d like to see for Twitter, or for any other API-driven platform, please let me know. I will work to add them to my list and queue them up when I have free time, crafting more Postman collection and publishing here on my blog.<span>&nbsp;</span></p>
<p class="p1"><em><strong>P.S.</strong> Some assumptions being made here:</em></p>
<ul>
<li>You have a Twitter account.</li>
<li>You have <a href="https://www.postman.com/">downloaded Postman</a>.</li>
<li>You are brave and willing to try new things.</li>
<li>You won&rsquo;t break anything so don&rsquo;t worry.</li>
</ul>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/12/29/pulling-links-from-those-tweets-you-have-favorited/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/12/28/how-my-api-evangelist-research-and-writing-works/">How My Api Evangelist Research And Writing Works</a></h3>
        <span class="post-date">28 Dec 2019</span>
        ---
published: true
layout: post
title: 'How My API Evangelist Research and Writing Works'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/bf-skinner-surveillance-over-the-city.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/bf-skinner-surveillance-over-the-city.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">Many folks don&rsquo;t quite get my work and writing style. They are confused by the erratic flow of stories being published to API Evangelist, the incomplete nature of some of my research sites, and other annoying factors that don&rsquo;t quite make sense when you view API Evangelist a particular way. If you think it as a technology blog like Techcrunch, ReadWrite, The New Stack, or others, you will be passing certain judgement on the content of my work, the tone of what I say, and the chaotic way in which I publish my research and stories across hundreds of separate sub-domains. People expect me to write up their API, review their approach, or know everything about the thousands of APIs that exist across the public landscape. API Evangelist isn&rsquo;t this type of blog&mdash;it is simply my workbench for things that interest me, are relevant to the industry and my career, or is valuable to someone who pays me to generate value in the API universe.<span>&nbsp;</span></p>
<h3>Two Distinct Layers Of Research</h3>
<p class="p1">There are two main layers to my research, which I use<span>&nbsp;</span>to mine API information and knowledge. These two dimensions feed off of each other, but ultimately drive my research, storytelling, and at times the wider conversation in the API space. Helping me organize everything into these two buckets:</p>
<ul class="ul1">
<li class="li1"><strong>Landscape</strong> - Reviewing the public and private API offerings across many different business sectors, providing me with a unique view of how API providers are doing what they do.</li>
<li class="li1"><strong>Life Cycle</strong> - Taking what I&rsquo;ve learned across the landscape and organizing information and knowledge by stops along the API life cycle, for use in my regular work and storytelling.</li>
</ul>
<p class="p1">These two layers are constantly feeding each other. For example, after making a pass through all the payment APIs, updating the landscape for that area, I will add new building blocks I&rsquo;ve stumbled across to my API life cycle research. Then when I embark on research into the transportation API landscape I leverage my evolved API life cycle perspective to help me look at things differently--powering both sides of the coin with the momentum I have built up over the last decade of my work.</p>
<h3>Three Ways I Produce Value</h3>
<p class="p1">My research is ongoing. It will never stop. However, along the way there are three main ways I produce output from my research, delivering a never-ending stream of exhaust from my work each day. There are three ways in which I produce value from what what I read, study, and ponder each day as I obsessively think about APIs. Here are the top three ways to consume what I do as the API Evangelist, providing observability into what I do.</p>
<ol>
<li><strong>Short Form Content</strong> - Producing Tweets and blog posts to share and ideate on what I am seeing across my API work, producing a real-time stream of consciousness from my work.</li>
<li><strong>Long Form Content -</strong> Producing long form guides, white papers, and other publications that distill down my work into portable snapshots into the API landscape, life cycle, and other API dimensions.</li>
<li><strong>Projects</strong> -<span>&nbsp; </span>Contributing to free or paid projects, helping inform the API conversation, and assist other stakeholders to make more informed decisions around what should happen with a project.</li>
</ol>
<p class="p1">Really, the short form content is just exhaust from the machine operating each day. The blog posts are just me scribbling on my workbench, trying to refine my understanding of what is going on. Ultimately I am just working up towards some long form or project level output. This is why some of my short form posts are so rough, and sometimes not fully fleshed out, or well-written. I&rsquo;m not publishing a post because I want everyone to read it and understand, I am simply getting the idea out into the open, existing on the workbench, so it can be reviewed, refined, and potentially used later on in some other work. I am not writing it for page views, or attention, I am simply publishing it to my workbench, and my API workbench happens to be more open and transparent than most&mdash;something that has transformed how I do what I do&hellip;but, that is another story.</p>
<p><img src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/bf-skinner-steam-engine-iceland.jpg" alt="" width="45%" align="right" /></p>
<h3>An Open Source Page For Your API Platform</h3>
<p class="p1">After wrapping up one project, and beginning to embark on a new one, I wanted to take the time to document I how work, and share with some of my newer audience who might not be aware of my working style. To get a glimpse of how I work you can take a look and the open source page work I&rsquo;ve recently done, which ultimately ended up contributing to the development and publishing of the Postman open source philosophy page. Producing a range of outputs from me thinking deeply about how to craft and publish an open source page for your service, tool, or platform.</p>
<ul>
<li><strong><a href="http://apievangelist.com/2019/10/29/20-open-source-landing-pages-from-leading-api-providers/">20 Open Source Landing Pages From Leading API Providers</a></strong>&nbsp;- After looking at and documenting a whole bunch of open source pages for API providers I thought I&rsquo;d take some of the more noteworthy ones and publish as a blog posts for others to think about.<span>&nbsp;</span></li>
<li><strong><a href="http://apievangelist.com/2019/10/30/a-dedicated-open-source-page-for-your-api-platform/">A Dedicated Open Source Page For Your API Platform</a></strong>&nbsp;- All of the common building blocks I found while looking at many different open source pages, distilled down into an easy to understand list I can share with my team while producing an open source page for the Postman platform.</li>
<li><a href="https://www.postman.com/open-philosophy/"><strong>Postman Open Philosophy Page</strong>&nbsp;</a>- The resulting page for sharing the open source story at Postman&mdash;produced as a team effort within Postman, wit my research input helping steer the conversation and resulting work.<span>&nbsp;</span></li>
</ul>
<p class="p1">Ultimately there might be a guide and / or white paper on the subject down the line, as well as some more storytelling on the subject here, and on the Postman blog. However, this provides a simple look at how I work. Depending on the subject I may produce many more blog posts as part of my research, ideating and breaking things down as I go along, but ultimately my work is all about informing some project, or at the very least esnuring this knowlege on the tip of my tongue when I talk to companies, organizations, institutions, and government agencies about their API strategies. Repeat over and over, cycling through every dimension of the API space, and you have API Evangelist, a wealth of knowledge about how things work (or don&rsquo;t) in the API sector.<span>&nbsp;</span></p>
<p class="p1">What I like most about this work is it keeps me learning. Also, that it keeps me writing. These are my two most favorite things in the world. Thirdly, it keeps me generating value for companies like Postman to keep paying my bills. Fourth, I am hoping it helps other people. I&rsquo;m thankful I have an employer like Postman who invests in my work, allows me to keep doing this research, and share it openly with the community, while also helping (hopefully) influence the Postman road map. While there are aspects about the technology sector that drive me nuts, ultimately I have a pretty sweet gig. I get to spend my days researching something I find interesting, sharing what I know with the public, while also helping to contribute to what I feel is one of <a href="https://www.postman.com/">the most important platforms when it comes to defining the API economy&mdash;<strong>Postman</strong></a>. ;-)</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/12/28/how-my-api-evangelist-research-and-writing-works/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/12/27/atlassian-provides-run-in-postman-and-openapi-by-default-for-jira-confluence-and-bitbucket-apis/">Atlassian Provides Run In Postman And Openapi By Default For Jira Confluence And Bitbucket Apis</a></h3>
        <span class="post-date">27 Dec 2019</span>
        ---
published: true
layout: post
title: 'Atlassian Provides Run in Postman and OpenAPI by Default for Jira, Confluence, and BitBucket APIs'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/atlassian_logo.jpg
---
<p><a href="https://github.com/api-evangelist/atlassian/tree/master"><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/atlassian_logo.jpg" alt="" width="40%" align="right" /></a></p>
<p class="p1"><a href="https://github.com/api-evangelist/atlassian/tree/master">I was profiling the Atlassian APIs, considering what is possible with JIRA, Confluence, and Bitbucket</a>. Three services that are baked into many enterprise organizations I&rsquo;ve worked with over the years. My intention was to create a Postman collection for JIRA, but once I Landed on the home page for the API I noticed they had a button in the top corner for Running in Postman, and a dropdown for getting an OpenAPI 3.0 spec. Which is something that I strongly believe should be default for all APIs, ensuring there is a prominently placed link to the machine readable truth behind each API.</p>
<p class="p1">I like seeing Postman as the default executable in the top corner of the documentation for APIs. I also enjoy seeing the orange Run in Postman button across documentation, blog posts, and other resources&mdash;helping folks quickly on-board with some API resource or capabilities. I want to see more of this. I&rsquo;d like it all to become the default mode of operating for API providers. I want all API providers to manage an OpenAPI truth for their API, while also developing and evolving many different Postman derivatives of that truth. Providing reference collections that describe the full surface area of our APIs, but also make sure there are more on-boarding, workflow, and capability style APIs that empower end-users to put APIs to work distributed across API documentation, and the stories we tell about what is possible with our APIs.</p>
<p class="p2">Interestingly the Postman collection isn&rsquo;t just a unit of representation for the JIRA, Confluence, and BitBucket APIs. The Postman collection is also a representing of the unit of work that is executed across these platforms. If you have worked in software development across the enterprise you know what I am talking about. Postman is the Swiss Army Knife for how enterprise developers not only develop and deliver their work, which is defined and tracked using JIRA, Confluence, and BitBucket, but Postman collections are also how they articulate, quantify, and demo their work as part of the JIRA-driven software development lifecycle. 75% of the companies I&rsquo;ve worked for, and consulted with over the last five years are using JIra to orchestrated the development of APIs and the applications they drive. At these companies Postman is ubiquitous, and how developers quantify each unit of work they are response for, making it critical to not just how Atlassian does business, but also how all of Atlassian&rsquo;s customers do business.&nbsp;</p>
<p class="p1">A Postman collection is a representation of a unit of work within the enterprise, which once complete will represent a unit of organizational capability. Each individual API defined using Postman represents a part of the digital transformation that is occurring across every enterprise organization. Postman is how developers are defining and delivering their work, and how they are sharing, collaborating, demonstrating, and ultimately executing the result of their work. When you think of the scale of this based upon JIRA usage world wide across the enterprise, it can be pretty staggering. Trillions of units of work. Millions of Postman collections. Millions of Postman users. Trillions of individual digital capabilities being defined, delivered, monitored, executed, tested, and reported on each week. Making the digital factory floor work across companies, organizations, institutions, and government agency work each day.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/12/27/atlassian-provides-run-in-postman-and-openapi-by-default-for-jira-confluence-and-bitbucket-apis/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/12/23/applying-an-apifirst-approach-to-understanding-the-pacific-northwest-mushroom-industry/">Applying An Apifirst Approach To Understanding The Pacific Northwest Mushroom Industry</a></h3>
        <span class="post-date">23 Dec 2019</span>
        ---
published: true
layout: post
title: 'Applying An API-First Approach To Understanding The Pacific Northwest Mushroom Industry'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/mushrooms_white_pike_place.png
---
<p><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/mushrooms_white_pike_place.png" alt="" width="40%" align="right" /></p>
<p class="p1"><a href="https://documenter.postman.com/view/35240/SWLYBW9q?version=latest">This is an API first project for mapping out the mushroom industry</a>. I have always had a passion for mushrooms, but as I get older I am looking at investing in more side projects that aren&rsquo;t always 100% about APIs. I wanted to spend some time this holidays refreshing my memory about what types of mushrooms are available on the market, and what types of products are being made from them. As I do with any data or content driven research I begin by creating an API to store all of the data and content I am gathering, helping me flesh out the dimensions of each business sector I am interested in.</p>
<p class="p1">As with all of my work I really don&rsquo;t know where this research is headed&mdash;I am just interested in learning about mushrooms. Eventually I&rsquo;d like to use this data and content in a variety of web and mobile applications, but since I&rsquo;m just getting started I don&rsquo;t really understand all of the data I am needing to gather. A situation that is perfect suited for beginning as an API first project, helping me not just gather the data I need, but also do it in a way that will help me prepare for the future, while also not investing too much into wiring up a database, coding a web or mobile application, and any other costly infrastructure that may (or may not) be needed down the road. By starting as API first, I am able to flesh out the schema and structure of my APIs which will drive my research, and the resulting applications I will be needing down the road. To get started I spent about 10 minutes thinking about what the main areas of resources I will be needing to track across my work, and created ten separate individual resources.</p>
<ul>
<li><strong>Mushrooms</strong> - A list of the mushrooms, their scientific names, description, and the beginning of what I will need to map out the mushroom landscape.</li>
<li><strong>Substrates</strong> - What the most common substrates for growing mushrooms are, with as much details as I can about how they are used in the industry.</li>
<li><strong>Benefits</strong> - Documenting what the most common benefits are of eating mushrooms, helping me better understand the market opportunity for each one.</li>
<li><strong>Organizations</strong> - I needed a way to organize the different companies, organizations, institutions, and government agencies I was coming across in the research.</li>
<li><strong>People</strong> - There is a need for building out a rolodex of different individual I am talking to, keeping track of their details and the conversations around mushrooms.</li>
<li><strong>Recipes</strong> - I have been coming across some interesting mushroom recipes and want to be organized in how I document them and make them available in the future.</li>
<li><strong>Product Types</strong> - I am really curious of the types of products that I am coming across and organizing them into specific buckets helping define the market.</li>
<li><strong>Products</strong> - I want to make sure I am tracking on specific instances of products from companies, while labeling them by the type of product they are.</li>
<li><strong>News</strong> - I will be curating interesting news articles that I come across, helping me bookmark relevant news that impacts my research and sends me in new directions, or supports my existing ideas.</li>
<li><strong>Industry Sales </strong>- There is a wealth of data about the mushroom industry from state and federal government agencies which I am organizing into relevant data sets for inclusion in my research.</li>
</ul>
<p class="p1">Think of each of these resources as a worksheet in a single Microsoft Excel or Google Sheet<span>&nbsp;</span>spreadsheet. Providing me with a place where I can store data in a variety of buckets. Which begs the question, why don&rsquo;t I just use a spreadsheet? Well, the data is a little more structured than what I can easily accomplish with a spreadsheet. That is a path I may explore for other simpler projects, but I know that my mushroom, substrate, recipes, and product data will most likely end up being more multi-dimensional than a simple spreadsheet will allow. This approach allows me to define all of my core resources as APIs, which I can mock and play with in the context of different applications, eventually settling in on a design that I can use to actually deploy an API.</p>
<p class="p1"><a href="https://documenter.postman.com/view/35240/SWLYBW9q?version=latest">For my API first mushroom industry research I am using Postman to define the collections</a>, and I am saving the initial data set for each resource as an example, which then can be used to actually mock and document the API&mdash;all without having to write any code. Meaning, you can run my mushroom Postman collection in your Postman account, generate a mock, and publish documentation, and be able to actually make calls to each API path and see the data returned as part of each response. This allows me to share my mocked mushroom API with any other stakeholders who might have input on which resources I&rsquo;m defining, and the underlying schema for each one. They can even go ahead and add any resources they desire, change the underlying schema, and evolve the data as part of the collection either locally, or within the team environment where I have shared the mushroom API collection. Allowing us to collaboratively iterate on the design of the data and content I am collection as part of my mushroom industry API research.</p>
<p class="p1">I am going to keep iterating on my mushroom industry API first project, fleshing out my approach to understanding the mushroom industry here in the Pacific Northwest, and eventually beyond. It is something that may never actually become a real API, or if I find enough interesting data out there I may actually publish and begin developing a web and mobile application to make my research more widely available. Right now my list of resources, and the underlying schema is rapidly changing based upon what I am learning. API first projects trhive in this kind of environment, and doing API first within Postman is a very efficient and cost effective way for me to flesh out what this project needs. I don&rsquo;t have write code, and I can easily publish the mocks and documentation and share with other folks I am talking to about this research. They can actually see what is possible, kick the tires, and provide me with feedback. Once things stabilize somewhat I may even consider developing a simple mock web or mobile application so that I can widen the stakeholders I&rsquo;m talking to beyond the API community. This is what being API first is all about&mdash;helping me rapidly iterate on the projects I am developing, while also still building for many possible futures that I can easily service with one API.</p>
<p class="p1">If you are interested in where I am going with this you can engage with <a href="https://github.com/api-evangelist/mushrooms/">my mushroom API work over at GitHub where I am publishing the API definitions, schema, JSON data</a>, and powering the road map with <a href="https://github.com/api-evangelist/mushrooms/issues">GitHub issues</a>.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/12/23/applying-an-apifirst-approach-to-understanding-the-pacific-northwest-mushroom-industry/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/12/23/api-providers-should-maintain-their-own-api-definitions/">Api Providers Should Maintain Their Own Api Definitions</a></h3>
        <span class="post-date">23 Dec 2019</span>
        ---
published: true
layout: post
title: 'API Providers Should Maintain Their Own API Definitions'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/stalin-time-construction-crane-city.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/stalin-time-construction-crane-city.jpg" alt="" width="40%" align="right" /></p>
<p class="p1"><a href="https://github.com/api-evangelist/index">I am working my way through 2K+ API providers</a>, refreshing my view of the API landscape, and the data I use to tune into the API economy. As I refresh the profile of each API provider, one of the main things I&rsquo;m doing is looking for an OpenAPI or Postman collection. While the profiling of their API operations using APIs.json is critical, having a machine readable definition for each API is kind of the most important part of this process. Having an OpenAPI or Postman collection gives me a machine readable list of the value that each API delivers, and allows me (and others) to more easily integrate an API into other applications and systems. Sadly, not every API provider understands the need, or is able to invest the resources to produce an API definition.</p>
<p class="p1">While profiling an API provider the most ideal situation I can come across is when an OpenAPI already exists in service of API documentation, or the API provider just gets the struggle of their API consumers and they have a Postman collection already published. Ideally, the OpenAPI is publicly available and I don&rsquo;t have dig it out from behind the documentation, or they have the Run in Postman button clearly published on their website. In the best situations, API providers have their OpenAPI and / or their Postman collections published to GitHub, and are actively maintaining their API definitions using Git, which allows other API consumers and API service providers to depend on an authoritative source of truth when it comes to API definitions for each API they use. I wish every API provider would maintain their own API definitions in this way, sadly very few do.</p>
<p class="p1">The majority APIs I come across do not have documentation driven by OpenAPI and do not have Postman collections. When I encounter one of these API providers I spend usually about 60 seconds googling for Swagger, OpenAPI, and Postman + their name in hopes I will find some community generated specs. If I come up empty I will email the API provider asking them if they have an OpenAPI or Postman collection. The responses I get range from silence to not knowing what either of these API definitions formats are. From there, I try to gauge the value and complexity of the API and whether or not it would be worth it for me to create a Postman collection, and autogenerate an OpenAPI from that. If the documentation is standardized I can also scrape and generate a Postman from the HTML, but it all comes down to the value of the API and if it is worth my time. The quickest way for me to create a valuable API definition is within Postman where I get to actually make an API call to each API path, and see the response from each resource.</p>
<p class="p1">I&rsquo;d prefer for API providers to invest the resources into creating their own API definitions. It is their resources and they should own the work. However, not all of them understand the importance of their being a machine readable API definition. My goal is to convince them of the value of having an API definition beyond just documentation, and help them see that they&rsquo;ll see more integrations with iPaaS and other service providers if there is a ready to go, certified, Postman collection for their API available in the Postman API network. If there is a complete Postman collection I can add an API to my API Evangelist network within minutes, and other service providers I know can do the same. The challenge is that most API providers to not see this layer of the API economy and often need to be convinced that API definitions aren&rsquo;t just about documentation. It is a lot of work to reach out to each provider and engage with them, but I think it is worth it. At some point we are going to reach a tipping point in the number of API provider who understand having an OpenAPI and Postman collection is the default mode of operating, and then the word will be out and I won&rsquo;t have to do as much work.</p>
<p class="p1">All API providers should maintain their own API definitions. They should publish both an OpenAPI and Postman collection to a common location, preferably in a GitHub repository for easy integration into CI/CD workflows. However, this doesn&rsquo;t mean that there is not value in the community creating API definitions, and publishing what I consider to be API fan fiction. I find that sometimes the workflow Postman collections created by the community are actually of more valuable than the OpenAPI or Postman collections that comes out of the API providers efforts. While the API providers API definitions may be more authoritative and complete, I find that API consumers usage of an API can possess more creativity than the provider behind the API. Are you an API provider? Do you have an OpenAPI or Postman collection for our API? Are you on my list? If so, you&rsquo;ll be hearing from me over the holidays, because I am <a href="https://github.com/api-evangelist/index">checking my list twice</a>, and making a determination of who is naughty and who is nice when it comes to providing API definitions for their API consumers.<span>&nbsp;</span></p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/12/23/api-providers-should-maintain-their-own-api-definitions/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/12/20/where-does-the-exhaust-for-your-api-operations-end-up-being-stored/">Where Does The Exhaust For Your Api Operations End Up Being Stored</a></h3>
        <span class="post-date">20 Dec 2019</span>
        ---
published: true
layout: post
title: 'Where Does The Exhaust For Your API Operations End Up Being Stored?'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/35201856153_61bc075e4b-nazi-invasion.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/35201856153_61bc075e4b-nazi-invasion.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">As part of my ongoing API <a href="http://discovery.apievangelist.com/">discovery</a> and <a href="http://observability.apievangelist.com/">observability</a> research, I am interested in better defining where the common places are within the enterprise that we find API signals. Those log files and other exhaust by-products from API operations that will contain hosts, paths, parameters, and other parts and pieces of the APIs that are already in operation. <a href="http://apievangelist.com/2019/07/01/the-complexity-of-api-discovery/"><span class="s1">API discovery is complex</span></a> and it isn&rsquo;t something I think we are going to be able to solve by mandating teams to make their APIs more discoverable, I think it is something we are going to have to do for them. Augmenting their existing work with services and tooling that then defines what APIs they are producing and consuming as part of the existing tools, applications, and systems. Further expanding <a href="http://apievangelist.com/2019/12/16/api-observability-is-more-than-just-testing-and-monitoring/"><span class="s1">the definition of API observability</span></a> by tapping the exhaust from the outputs of existing infrastructure to help us map out the API landscape that exists within the enterprise.<span>&nbsp;</span></p>
<p class="p1">I am currently helping <a href="https://www.useoptic.com/">the Optic folks</a> think beyond the personal value their proxy delivers for individual developers by proxying your desktop, web, mobile, and Postman traffic and automatically generating OpenAPI definitions for you, and consider what the more industrial grade use cases will be. As part of these conversations I am more deeply thinking about how APIs are operated within the enterprise, and being more formal in how I discuss where you can tap into the existing exhaust that is captured around API operations, building on the following list I already have.</p>
<ul>
<li><strong>Apache Log File -</strong> The most ubiquitous open source web server out there is the default for many API providers.</li>
<li><strong>NGINX Log File - </strong>The next most ubiquitous open source web server is definitely something I should be looking for.</li>
<li><strong>IIS Log File -</strong> Then of course, many Microsoft web server folks are still using IIS to serve up their API infrastructure.</li>
<li><strong>Amazon CloudWatch -</strong> Looking at how the enterprise is centralizing their logs with CloudWatch on AWS.</li>
<li><strong>Google StackDriver - </strong>Google&rsquo;s multi-platform approach interesting and worth evaluating as part of this work.</li>
<li><strong>Azure Logging -</strong>&nbsp;Looking at how Azure customers are logging their API infrastructure across their operations.</li>
<li><strong>Proxy -</strong> Looking at what proxies are in place and considering the logging that they generate as part of their operations.</li>
<li><strong>API Management -</strong> Queueing up the logging that exists for all of the major API management providers for evaluation.</li>
</ul>
<p class="p1">I know there are more locations out there where you can find the paths and other details for APIs being consumed across the enterprise. I am not just looking for internal APIs consumed, but also external APIs consumed. Basically anything using HTTP 1.1 as a transport, and possesses an XML or JSON payload. If you have specific locations you&rsquo;d like to see mined for API signals I would like to hear about it no matter how mundane or unique it might be. I am looking for all of the existing outputs that exist across the enterprise for understanding existing API traffic across desktop, web, mobile, device, network, and system integrations. Feel free to email, DM, send over a carrier pigeon with the most common sources of API exhaust at your organization.</p>
<p class="p1">I am pretty convinced that we aren&rsquo;t going to get our schema act together anytime soon. I am also convinced we are ever going to slow down the number of APIs we are deploying to possibly get a better handle on defining, discovery, and observability. We are going to have to get better at API observability and tapping into the existing outputs that exist across our current and future infrastructure. Things just move too fast, and teams are already working too hard. We can&rsquo;t always expect that they&rsquo;ll be interested or have the time to define the APIs they are delivering or depending on. We are going to need more tooling and services that will help us make sense of the chaos that is already in place, and continues to expand across the enterprise, otherwise we will just keep stumbling.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/12/20/where-does-the-exhaust-for-your-api-operations-end-up-being-stored/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/12/20/openapi-is-the-static-truth-and-postman-collections-are-real-world-derivatives-of-that-truth/">Openapi Is The Static Truth And Postman Collections Are Real World Derivatives Of That Truth</a></h3>
        <span class="post-date">20 Dec 2019</span>
        ---
published: true
layout: post
title: 'OpenAPI is the Static Truth and Postman Collections are Real World Derivatives of that Truth'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/bf-skinner-thinking-man-statue.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/bf-skinner-thinking-man-statue.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">I was talking with <a href="https://www.useoptic.com/">the Optic folks</a> this morning about API definitions when they asked me for my opinions on what the difference between OpenAPI and Postman were. A question that isn&rsquo;t easy to answer, and will produce many different answers depending on who you are talking with. It is a question I&rsquo;ve been struggling with since before I started at Postman, and will continue to struggle with over the coming years as their Chief Evangelist. The best I can do right now is keep writing about it, and continue talking with smart people like Optic, and iterate upon the answer until I can better see what is happening.</p>
<p class="p1">Here is how I see things currently: OpenAPI is the static truth, and Postman collections are the real world, real time derivative&rsquo;s of this truth. Each individual Postman collection reflects the derived value of an API, representing how a developer, application, or system integration is applying this value in the real world. Now if you squint your eyes, all of those Postman collection derivatives roll up into a single OpenAPI truth. OpenAPI is essential for nailing down what the overarching truth of what an API contract delivers, while Postman is essential in quantifying, realizing, and executing this truth on the ground for a specific business use case. There are definitely ways in which OpenAPI and Postman collections overlap, but then there are the ways in which they bring different value to the table.<span>&nbsp;</span></p>
<p class="p1">When it comes to capital G Governance OpenAPI is more meaningful to business leadership&mdash;it represents a more constant truth that can then be translated within services, tooling, and defining policy at the macro level. When it comes to lowercase g governance Postman collection is more meaningful to developers, because it represents the transactions they need to accomplish each day, which are derived from the greater truth, but have more context regarding each specific business transaction that a developer is expected to deliver. This is why OpenAPI and an API first approach within the enterprise can still be seen as academic, and is something handed down from upon high from architects and management, where Postman collections represent the truth on the streets within an enterprise--illuminating the rift we can see within the enterprise when it comes to API definition adoption.</p>
<p class="p1">This answer is something I will keep working on. I&rsquo;m not happy with my overall understanding of the differences between how OpenAPI and Postman collections are used within the enterprise. Coming from a very academic OpenAPI reality as the API Evangelist into a very street Postman collection reality as Chief Evangelist has left me unbalanced. I&rsquo;m interested in deepening my understanding of not just what is possible with each API definition format, but how they are actually being used to grease the wheels of API operations within the enterprise. I&rsquo;m guessing that the differences between these realties will very much color what the real differences between OpenAPI and Postman are, how they get used on a daily basis within companies, organizations, institutions, and government agencies. I see both API definition formats as critical to the overall API life cycle, but exactly how I am still a little fuzzy. I&rsquo;ll keep working on my answer to this question, and see where I land in the future, when it comes to making them both work in a syncrhonized way.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/12/20/openapi-is-the-static-truth-and-postman-collections-are-real-world-derivatives-of-that-truth/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/12/20/how-i-profile-the-typeform-api/">How I Profile The Typeform Api</a></h3>
        <span class="post-date">20 Dec 2019</span>
        ---
published: true
layout: post
title: 'How I Profile The TypeForm API'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/profile_type_form_import.png
---
<p class="p1">I was being asked for more information about how I profile APIs, and deal with the many differences I come across. It isn&rsquo;t easy navigating the differences between different APIs, and come out with a standard API definition (OpenAPI or Postman collection) that you can use across different stops along the API life cycle. I&rsquo;m pretty agile and flexible in how I approach profiling different APIs, with a variety of tools and tricks I use to vacuum up as much details as I possibly can with as little manual labor as I possibly can. The example for profiling that was thrown at me was the TypeForm API, which is a pretty sophisticated API, but will still need some massaging to create an acceptable set of API definitions.</p>
<p class="p1">First thing I do is search for an OpenAPI definition, hopefully published to GitHub or prominently linked off their documentation, but I will settle having to sniff out from behind an APIs documentation. TypeForm doesn&rsquo;t have an OpenAPI or Swagger available (from what we can tell). Next, I go looking for a Postman collection. Boom!! <a href="https://developer.typeform.com/get-started/postman-collection/">Typeform has a Postman collection</a>.&nbsp;The question now is why hasn&rsquo;t Typeform published their Postman collection to <a href="https://explore.postman.com/">the Postman Network</a>? I will Tweet at them. Ok, now I have a machine readable definition for the Typeform API that I can import into my API monitoring system&mdash;which is just an API that I use in Postman to import a Postman collection (head explodes).</p>
<p class="p1"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/profile_type_form_import.png" alt="" width="100%" /></p>
<p class="p1">My Postman collection import API grabs as many elements from the Postman collection definition as it can, normalizing the paths, parameters, and other details for an API. I am always adding to what my API is capable of, but it does a pretty good job of giving me what I need to begin to profile the surface area of an API.</p>
<p class="p1"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/profile_type_form_paths.png" alt="" width="100%" /></p>
<p class="p1">Now I have all of the paths imported into my monitoring system. However, I am still at the mercy of how much work an API provider has invested into their Postman collection. Depending on the provider and the API definition format being important the differences can vary widely, so I have been developing different APIs that help me clean up and deal with the common types of data that is missing or needs work.</p>
<p class="p1"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/profile_type_form_clean.png" alt="" width="100%" /></p>
<p class="p1">I am always working to flesh out as many of the common details of an API as I can, but always stop short of doing too much manual labor when it comes to crafting a complete enough API definition. My goal is to just get as much cleaned up and normalized as I can, and leave what I can do left undone. When it comes to the Typeform API, they didn&rsquo;t provide descriptions for their API paths. Descriptions exist on the documentation, but would need to be scraped, or manually added to either the Postman collection or OpenAPI. <a href="https://github.com/api-evangelist/typeform/issues/1">I just add a GitHub issue for the todo item</a>,&nbsp;and move on. Ideally Typeform does this work, or someone from the API community submits as a pull request on the API definitions I have published to GitHub. Beyond descriptions, I am able to clean up paths, generate an operation id which is useful in SDK and code generation, and apply tags to each path based upon the words in the path.</p>
<p class="p1"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/profile_type_form_paths_2.png" alt="" width="100%" /></p>
<p class="p1">Then I go ahead and <a href="https://github.com/api-evangelist/typeform">publish both an OpenAPI and Postman collection to the GitHub repository I have for Typeform</a>. This allows me to independently track each API provider, separately manage issues, and engage with the community, and hopefully Typeform in a central place.The API definitions are far from complete, but they provide me with a good start. I can queue up some other tasks that I need accomplished, pushing the API definitions further along when i have time. For my needs, having the Typeform API paths and parameters using OpenAPI and Postman collections, then the Typeform API operations defined as an APIs.json is a damn good start. I&rsquo;ll make time in the future to continue fleshing out additional details, or hopefully the community and Typeform steps in and does it for me.</p>
<p class="p1">The next major step in profiling the Typeform API is producing JSON schema for the request bodies and responses. Because there wasn&rsquo;t an OpenAPI available, there is no JSON schema defined. It isn&rsquo;t always a guarantee you&rsquo;ll have these defined when importing OpenAPI, but they aren&rsquo;t part of the Postman collection. For my needs when it comes to API discovery, the schema is a nice to have, but not required, so I am happy to <a href="https://github.com/api-evangelist/typeform/issues/2">leave on my todo list</a>. When it comes to producing JSON schema for APIs I am profiling I will usually approach in two different ways:</p>
<ul>
<li><strong>Scrape From Documentation </strong>- If there are examples present as part of API documentation I can usually scrape, satisfying two needs: 1) adding examples to OpenAPI and Postman collections, and 2) generate standalone JSON Schema, and add to the OpenAPI definitions .</li>
<li><strong>Run In Postman </strong>- Sign up for a Typeform key, and actually make API calls within Postman, then I can use a solution like Optic (<a href="https://www.useoptic.com/"><span class="s1">https://www.useoptic.com/</span></a><span class="s2">)</span> to autogenerate the OpenAPI (and JSON Schema) for each API call I make, then run the diff against my existing OpenAPI.</li>
</ul>
<p class="p1">For now, <a href="https://github.com/api-evangelist/typeform/issues/2">I have added an issue to the GitHub repository</a> for my Typeform work. <a href="https://github.com/api-evangelist/typeform/issues/2"><span class="s1">https://github.com/api-evangelist/typeform/issues/2</span></a> I am happy to have the Typeform API in my index, and published as part my research. I can continue fleshing out my profile for Typform, and <a href="http://apievangelist.com/network/providers/typeform/"><span class="s3">publish as part of my API Evangelist Network</span></a>, at a later date in the future. Or maybe someone comes along and adds the JSON schema to the GitHub repository&mdash;doing the work for me. ;-) This is why I am publishing all of my API definitions to GitHub. So that we can all stop creating our own API definitions, and we can start sharing our work. I am going to better work at attribution and keeping in sync with existing efforts like <a href="https://apis.guru/openapi-directory/">APIs.guru</a>, helping build on the existing hard work other folks have already done. Hopefully folks can already build on top of the work I have done as I continue to publish what I have in my database to GitHub as part of my API Evangelist Network research.</p>
<p class="p1">My goal here is to keep layering on the API definitions I&rsquo;ve come across and producing a &ldquo;complete enough&rdquo; API definition for the APIs I&rsquo;m profiling and including in my research. It is also to continue convincing API providers to take ownership over their own API definitions. I&rsquo;m happy to accept pull requests from API providers, give them administrator access to my repositories, or simply keep in sync from an authoritative set of OpenAPI and Postman collections. However, I feel it is pretty important to do this out in the open, encourage other API service providers and community members to also contribute and help define the APIs available across the public API commons. Helping community-source the discovery, profiling, and deprecation of APIs that are available on the web, and going beyond what each API provider is capable of, ensuring there is human and machine readable resources available for each industry that is being impacted by APIs today.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/12/20/how-i-profile-the-typeform-api/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/12/19/what-else-has-influenced-apis-over-the-last-50-years/">What Else Has Influenced Apis Over The Last 50 Years</a></h3>
        <span class="post-date">19 Dec 2019</span>
        ---
published: true
layout: post
title: 'What Else Has Influenced APIs Over the Last 50+ Years?'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/stalin-time-old-gas-station_35891228584_o.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/stalin-time-old-gas-station_35891228584_o.jpg" alt="" width="40%" align="right" /></p>
<p>Because I have so many smart folks in my Twitter timeline I want to put out some of the seeds for stories I am working on for 2020. I want your help determining what has set the stage for the world of APIs we all believe in so much. Here are just a handful of the nuggets I have pulled out of my research and reading.</p>
<h3>Early On</h3>
<ul>
<li> 1933 - Telex Messaging </li>
<li> 1949 - Memex (Linked Documents) </li>
<li> 1949 - Computer Talk Over Phone </li>
<li> 1958 - Digital Phone Lines </li>
<li> 1959 - Semi-Automatic Ground Environment (SAGE) Wide Area Network </li>
<li> 1961 - Computer Time Sharing </li>
<li> 1963 - Hypertext </li>
<li> 1963 - Hypermedia </li>
<li> 1964 - Sync Satellite Television Network </li>
<li> 1964 - IBM Sabre Reservation System </li>
<li> 1966 - Michigan Educational Research Information Triad (MERIT)&nbsp; </li>
<li> 1968 - Multiplexing </li>
<li> 1969 - Mass produced software components By McIlroy, Malcolm Douglas </li>
<li> 1969 - Host Software The First RFC </li>
<li> 1969 - ARPANET Four Initial Nodes Established </li>
<li> 1969 - Compuserve </li>
</ul>
<h3>1970s</h3>
<ul>
<li> 1970 - ARPANET Reaches East Coast (MIT) </li>
<li> 1971 - Email </li>
<li> 1971 - File Transfer Protocol (FTP) </li>
<li> 1971 - TELNET </li>
<li> 1971 - ARPANET Has 23 nodes </li>
<li> 1972 - ARPANET Has 29 nodes </li>
<li> 1973 - ARPANET Has 40 nodes </li>
<li> 1974 - ARPANET Has 46 nodes </li>
<li> 1974 - Transmission Control Program (TCP) </li>
<li> 1974 - Systems Network Architecture (SNA) </li>
<li> 1975 - ARPANET Has 57 Modes </li>
<li> 1976 - CYCLADES Computer Network </li>
<li> 1976 - X.25 Packet Switching Protocol </li>
<li> 1979 - First Commercial Cellular Network </li>
</ul>
<h3>1980s</h3>
<ul>
<li> 1980 - USENET </li>
<li> 1981 - ARPANET Has 213 Nodes </li>
<li> 1981 - TCP/IP </li>
<li> 1982 - Simple Mail Transfer Protocol (SMTP) </li>
<li> 1983 - ARPANET Switches to TCP/IP </li>
<li> 1983 - IPV4 </li>
<li> 1983 - Berkely Sockets </li>
<li> 1984 - CD-ROM </li>
<li> 1984 - Domain Name System&nbsp; (DNS) </li>
<li> 1984 - Dynamic Host Configuration Protocol (DHCP) </li>
<li> 1984 - Open Systems Interconnect (OSI) </li>
<li> 1985 - Whole Earth 'Lectronic Link (WELL) </li>
<li> 1985 - National Science Foundation Network (NSFNET) </li>
<li> 1987 - Transport Layer Interface (TLI) </li>
</ul>
<h3>1990s</h3>
<ul>
<li> 1991 - Gopher </li>
<li> 1991 - Windows Sockets API </li>
<li> 1991 - Common Object Request Broker Architecture (CORBA) </li>
<li> 1991 - <span>HyperText Markup Language (HTML) <span>1.0 </span></span></li>
<li> 1993 - Mosaic </li>
<li> 1994 - Netscape Navigator </li>
<li> 1994 - <span>Uniform Resource Locator (URL), </span></li>
<li> 1995 - Internet Explorer </li>
<li> 1995 - <span>HyperText Markup Language (HTML)<span>&nbsp; 2.0 </span></span></li>
<li> 1995 - <span>Secure Socket Shell (SSH) </span></li>
<li> 1995 - <span>Open Network Computing (ONC) Remote Procedure Call (RPC)&nbsp; </span></li>
<li> 1996 - <span>HyperText Transfer Protocol (HTTP<span>/1.0) </span></span></li>
<li> 1996 - XML </li>
<li> 1996 - HTTP/1.1 </li>
<li> 1996 - Web Users Reach 36 Million </li>
<li> 1997 - 802.11 </li>
<li> 1997 - RSS </li>
<li> 1998 - XML-RPC </li>
<li> 1998 - IPV6 </li>
<li> 1999 - MQTT </li>
</ul>
<h3>2000s</h3>
<ul>
<li> 2000 - REST </li>
<li> 2000 - Salesforce </li>
<li> 2000 - SOAP </li>
<li> 2000 - eBay </li>
<li> 2001 - Protocol Buffers </li>
<li> 2002 - Amazon </li>
<li> 2003 - Delicious </li>
<li> 2004 - Flickr </li>
<li> 2004 - Web Services </li>
<li> 2005 - JSON-RPC </li>
<li> 2005 - ProgrammableWeb </li>
<li> 2005 - YouTube </li>
<li> 2006 - Amazon S3 </li>
<li> 2006 - Google Maps </li>
<li> 2006 - JSON</li>
<li> 2006 - Facebook </li>
<li> 2006 - Amazon EC2 </li>
<li> 2006 - Twitter </li>
<li> 2006 - Mashery </li>
<li> 2006 - OAuth </li>
<li> 2007 - iPhone </li>
<li> 2007 - Twilio </li>
<li> 2008 - GitHub </li>
<li> 2008 - Android </li>
<li> 2008 - Reddit </li>
<li> 2009 - Foursquare </li>
<li> 2009 - Amazon RDS </li>
</ul>
<h3>2010s</h3>
<ul>
<li> 2010 - Nest </li>
<li> 2010 - Instagram </li>
<li> 2010 - Oracle V Google API Copyright </li>
<li> 2010 - Swagger </li>
<li> 2010 - Docker </li>
<li> 2011 - Fitbit </li>
<li> 2011 - Apiary + API Blueprint </li>
<li> 2011 - Stripe </li>
<li> 2011 - MIcroservices </li>
<li> 2011 - Websockets&nbsp; </li>
<li> 2011 - Kafka </li>
<li> 2011 - Steve Yegge AWS Rant </li>
<li> 2012 - President Obama Federal Government API Mandate </li>
<li> 2013 - Slack </li>
<li> 2014 - Kubernetes </li>
<li> 2014 - Uber </li>
<li> 2014 - Postman </li>
<li> 2014 - Spotify </li>
<li> 2015 - gRPC </li>
<li> 2015 - JSON Web Token (JWT) </li>
<li> 2015 - Apigee IPOs </li>
<li> 2015 - HTTP/2 </li>
<li> 2015 - Amazon Launches AWS API Gateway </li>
<li> 2015 - GraphQL </li>
<li> 2016 - AsyncAPI </li>
<li> 2016 - Amazon Alexa Voice Service </li>
<li> 2018 - HTTP/3 </li>
</ul>
<p>I am working on a variety of stories, guides, and marketing materials for Postman around everything that has led up to this moment. I'm going to keep adding to this list, and flesing out the details of how each of these points in time have helped get us here.&nbsp;</p>
<p>If you have any additions feel free to lobby me via Twitter or email, and I'll consider adding. Share the moments in time, the technology, and how it helped set the tone for what we are all doing in 2019, and I might add it to the list, baking into the Postman storytelling throughout 2020.</p>
<ul>
</ul>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/12/19/what-else-has-influenced-apis-over-the-last-50-years/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/12/19/the-3dcart-developer-home-page-is-nice-and-clean/">The 3dcart Developer Home Page Is Nice And Clean</a></h3>
        <span class="post-date">19 Dec 2019</span>
        ---
published: true
layout: post
title: 'The 3dcart Developer Home Page Is Nice and Clean'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/3dcart_developer_home_page.png
---
<p>I look through a lot of API developer portals and when I come across interesting layouts I like to pause and highlight them showing to other API providers what is possible, while turning API Evangelist into a sort of style guid when it comes to crafting your API operations. I was asking the folks over at 3dcart if they have an OpenAPI or Postman collection for their API to help me round of my machine readable index of the commerce API provider, and after I stumbled across <a href="http://developer.3dcart.com/">their developer portal</a>, I thought I'd share here.</p>
<p><a href="http://developer.3dcart.com/"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/3dcart_developer_home_page.png" alt="" width="100%" /></a></p>
<p>I like it because in addition to the global navigation for their portal, it really gets at the primary next steps anyone will be taking off the landing page of their developer portal. You can tell it really forced them to pause and think about the narrative around what people will be looking for. Helping people understand what is possible, while also routing them down the most common paths taken when it comes to <a href="http://developer.3dcart.com/">building an application on 3dcart</a>.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/12/19/the-3dcart-developer-home-page-is-nice-and-clean/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/12/18/taming-the-salesforce-api-scope/">Taming The Salesforce Api Scope</a></h3>
        <span class="post-date">18 Dec 2019</span>
        ---
published: true
layout: post
title: 'Taming The Salesforce API Scope'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/salesforce_integrations_cloud_elements.png
---
<p><a href="https://cloud-elements.com/salesforce-integration/"><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/salesforce_integrations_cloud_elements.png" alt="" width="40%" align="right" /></a></p>
<p>I was recently looking to building a prototype integration between Salesforce and Workday, where I find myself needing to on-board with the Salesforce REST API for probably the 50+ time in my career. I am always looking for projects that use the API so that I can keep my skills sharp when it comes to one of the leading API platforms out there. Even with this experience, each time I on-board with the API I find myself having to work pretty hard to make sense of the Salesforce REST API, first wading through a sea of information to get to find <a href="https://developer.salesforce.com/docs/">the API reference documentation</a>, setting up an OAuth application, and getting to where I am actually making my first API call. Once I am successfully making calls to the Salesforce API, I then have to further explore <a href="https://developer.salesforce.com/docs/atlas.en-us.api_rest.meta/api_rest/resources_list.ht">the surface area of the Salesforce REST API</a> before I can fully understand all the resources are available, and what is truly possible with my integration.</p>
<p>After spending about an hour in the Salesforce documentation it all came back to me. I remembered how powerful and versatile the API is, but my moment of d&eacute;j&agrave; vu left me feeling like it would be pretty easy to reduce the time needed to go from landing on the home page of developer.salesforce.com to making your first API call. The challenge with the Salesforce API is it is extremely large, and possess a number of resources that will vary based upon two important dimensions, version and your user account. The API you see with a base developer account isn&rsquo;t the same you&rsquo;ll see with a well established corporate Salesforce implementation. Each individual Salesforce customer might be using a specific version, and have a completely different set of resources available to them, making it pretty challenging to properly document the API. Even with these challenges I think there are a number of ways in which the Salesforce API could be made more accessible for new users, while also improving how existing Salesforce developer engage with the platform&mdash;so I wanted to take a crack at building a proof of concept that would help demonstrate the potential.</p>
<h3>Salesforce Postman Collection</h3>
<p>When using the Salesforce REST APIs there are universal API paths that developers with meta level information about the API, but then there are object specific API resources which provide you with a long list of available resources which you can obtain via the /vXX.X/sobjects/ API path for each version. Then there are a whole suite of object specific API sub-resources you can put to work by simply putting the sObject into the API path vXX.X/sobjects/{SObjectName}/{id}&mdash;leveraging path variables to define which individual resource you will be working with. This design pattern is common amongst older enterprise APIs, but it is an approach that can introduce quite a cognitive load when having to learn about what objects are available, and then begin to use them in any intuitive way. To help alleviate the cognitive load for myself when working with the Salesforce API and making it easier for other stakeholders to work with, I generated a Postman collection, and p<a href="https://documenter.postman.com/view/35240/SVzua1S6?version=latest">ublished some simple and more modern API documentation from the machine readable definition</a>.</p>
<p><a href="https://documenter.postman.com/view/35240/SVzua1S6?version=latest"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/salesforce_rest_api_postman_documentation.png" alt="" width="100%" /></a></p>
<p>My goal with this collection was to bring out the potential that is present within the Salesforce API, making it available in a more intuitive and usable way. Using the /vXX.X/sobjects/ API path I generated the Postman Collection, organizing sObjects by folder. The Postman Collection is just a proof of concept and doesn&rsquo;t reflect all of the available API paths, and is generated from version 20.0 from an entry level develop account. The goal here is simply to autogenerate a Postman Collection for all sObjects for a specific version, organizing all the available API resources into a more coherent collection. Next, I will work on dynamically generating a Postman Collection for each available version, with corresponding objects. Each collection will still reflect an entry level developer account, dynamically generating Postman Collections from the Salesforce API, providing a machine readable collection that can be used by Salesforce and their API consumers throughout the API lifecycle. Providing a machine readable unit of compute for each possible manifestation of the Salesforce API, allowing the API definition shape-shift as necessary to accommodate however Salesforce is being used in the wild.</p>
<h3>A Dynamic Salesforce Collection Builder</h3>
<p>Providing Postman Collections for dynamic APIs like Salesforce can be a challenge, but this proof of concept demonstrates how more intuitive and usable Postman Collections can be generated from the Salesforce discovery APIs. Providing a dynamic Postman Collection builder can help tame the complexity of the Salesforce API, providing different API paths organized by folder, and published with informative title and descriptions. Helping bring out the diverse number of objects that are available right under the hood, while making the API-enabled actions that are available in a portable, sharable, and executable format that anyone can use locally within their Postman client, or automated via a CI / CD pipelines via the command line. This challenge with API scope and complexity isn&rsquo;t exclusive to Salesforce, as there are a number of larger data API implementations that have similar design patterns, from financial APIs like Quandl, to healthcare data APIs like OpenFDA. Salesforce is somewhat unique in that it has multiple dynamic dimensions to consider spanning the version, sObjects, and the Salesforce customer installation, configuration, and roles.</p>
<h3>Providing Salesforce Workflow Collections</h3>
<p>This dynamic approach to generating collections can also be designed to deliver different types of workflow collections, going beyond the reference nature of the Salesforce REST API proof of concept above, daisy-chaining API calls into more coherent business workflows that can be implemented by any developer or non-developer. Providing Postman Collections that deliver upon specific types of business workflows, but are dynamically defined based upon the version of the Salesforce API in use, as well as based upon the specific object available to each individual Salesforce customer. Harnessing the power of the Salesforce API, while taming the complexity of the API, making common everyday business tasks executable as a portable, sharable, and executable format that anyone can use locally within Postman. Further bringing out the value of the Salesforce API out into view, making each individual Salesforce business capability more visible, sharable, and executable as a stand alone Postman Collection.</p>
<h3>Instance, Version, and Roles Via Environments</h3>
<p>One benefit of using Postman Collection is that you can also abstract away the version, instance, roles, and other variables using Postman Environments, which can then be run against individual reference or workflow Postman Collections. The base URL you use to make API calls to the Salesforce API should always be the first key value pair within any Postman Environment, abstracting away the host of the API as this is what defines the dynamic dimension of your Salesforce customer account. The second key value pair that should be in the Postman Environment is the version of the Salesforce API you wish to be using, providing the second most important dynamic dimension of using the Salesforce API. The third key value pair that should be present is the OAuth Bearer Token for each individual user that will be putting the API to work, allowing for further defining API consumption based upon role. Separating version, user, and role dimensions from each collection, which will ultimately be dynamically generated based upon the sObjects available, and then executed based upon each individual Postman Environment&mdash;leveraging collections and environments as the union that absorbs the dynamic and ever changing nature of the Salesforce API.</p>
<h3>Providing Salesforce API Mocks</h3>
<p>As part of my work on my Salesforce REST API Postman Collection I&rsquo;m verifying each endpoint by making an actual request and saving the response as an example. Once I do this for each of the 800+ individual API path I can then use them to generate mock representations of the API. Allowing any potential application developer to build against the mocked version of the Salesforce API in a local environment without actually having to develop against the production instance. Once the application is ready, the base URL for the Postman environment can be changed back to the production instance, and the application should work as expected, but instead of mocked examples, it will be working from live responses fro the Salesforce REST API. Providing a personalized and localized experience when it comes to working with the API, further reducing the overhead required for any developer to actually get up and running with the Salesforce API, streamlining the on-boarding with he API as well as the time it takes to actually develop an application.</p>
<h3>Publishing Modern API Documentation</h3>
<p>Once I have examples saved for each of the Salesforce API paths I can also republish the API documentation I showed above as part of this proof of concept. Publishing the details of each response to compliment the details of each API request I&rsquo;ve defined. Better organizing Salesforce sObjects as folder, giving them plain language names and description, while also providing details on query parameters, headers, and the example response for each individual API path. In addition to the more cleaner, modern, and complete API documentation, developers also get code snippets in a variety of programming languages including cURL commands for use at the command line interface. Further helping to reduce friction when it comes to on-boarding new users, providing what is needed to get existing developers engaged, and understanding what is happening with a specific version and implementation of the Salesforce API.</p>
<p><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/salesforce_create_postman.png" alt="" width="40%" align="right" /></p>
<h3>API Orchestration With Runners</h3>
<p>With my Salesforce REST API reference Postman Collection, and my variety of potential workflow collections I can begin to orchestrate any of the common capabilities I possess to work by executing collections, bundled with different environments using Postman runners. This allows developers to not just manually run API calls, but to daisy chain multiple API calls together in a specific sequence, then execute manually or via a CI/CD pipeline. Allowing Salesforce user to augment what they do through the Salesforce interface via the Salesforce API with well organized Postman Collection defined workflows that help scale and automate beyond what any individual is capable of doing on their own. Demonstrating how Postman Collections aren&rsquo;t just a machine readable definition of the Salesforce API, but a digital representation of a specific Salesforce capability in the context of a specific Salesforce customer, user role, and version of the API.</p>
<h3>API Automation With Monitors</h3>
<p>Like runners, monitors can also be setup to execute a specific Salesforce API Postman Collection, allowing different capabilities to be executed in different contexts on any desired schedule, from multiple geographic regions. Monitors can be used to check for specific activity via the Salesforce platform or validating data that has been added, updated, or removed. Monitors can also automate the migration of data between different objects within the Salesforce platform, as well as with any other 3rd party APIs. Defining Postman collections that automate the syncing and migration of data across all of the services that any Salesforce customer depend on&mdash;whether it is operated by Salesforce or not. Helping Salesforce developers as well as business users better automate the tasks hey perform on a regular basis in a no-code way.</p>
<h3>Keeping The Existing API Life Cycle</h3>
<p>What I like most about this idea is it can be implemented without any change to the existing Salesforce API life cycle. It just represents a different way at looking at, and communicating with consumers about the Salesforce API. I can keep iterating upon this proof of concept from the outside-in, and keep evolving my approach to dynamically generating reference and workflow Salesforce Postman API collections and supporting Postman environments without requiring Salesforce to actually make any changes. Ideally, it would be something Salesforce would also invest in and take the reins on, but it is something that can be realized using existing process and Salesforce API paths. Making it a pretty compelling blueprint for reducing friction for Salesforce API consumers, but also potentially other APIs providers that have similar dynamic characteristics in how the API can be put to use, making documenting and on-boarding more harder.</p>
<h3>Salesforce Accounts Integration</h3>
<p>One area of friction that still exists in this implementation is when it comes to the generation of an OAuth bearer token for each user of a Salesforce Postman API Collections. Each user will need to have their own bearer token to authenticate Salesforce API requests, which currently requires each user to setup a Salesforce OAuth application, something not all consumers will be capable of doing. The concept of what is an application on the Salesforce platform needs to evolved some to accommodate integration platform as a service (iPaaS) and no-code integration opportunities, making it easier for users to generate personal OAuth tokens via their account, like platforms such as GitHub already do. This is something that can be accomplished as part of a 3rd party application or service, but would be something that would have a much wider impact on API adoption and usage of the average developer and business user if Salesforce was to deliver natively via Salesforce accounts.</p>
<h3>Organizational API Workspaces</h3>
<p>The Postman collection developed as part of this proof of concept contains over 800 individual requests organized by folders&mdash;this is a pretty large collection. Ideally it would be organized into much more meaningful groups of collections that reflect different bounded contexts of Salesforce sObjects. Additionally, very granular Salesforce workflow Postman Collections could be developed, providing much smaller, bite sized business capabilities for each Salesforce customer. All of these Postman collections can be organized into separate API workspaces, providing further segmentation of Salesforce API resources which can be powered via a variety of Postman environments published across each of the appropriate workspaces. Logically grouping the organizational capabilities of any Salesforce customer into API workspaces that reflect how business is accomplished by users within a variety of roles.</p>
<h3>A Salesforce Collection Template Marketplace</h3>
<p>Eventually I&rsquo;d also like to see the development and publishing of more workflow Salesforce Postman API Collection templates to the Postman template marketplace. Eventually maybe there can be a dedicate Salesforce wing of <a href="https://explore.postman.com/templates">the Postman template marketplace</a>. Salesforce Postman API Collection templates could be further organized by version and which sObjects they support, allowing for dynamic filtering based upon authenticating with your Salesforce user ID, only surfacing Postman workflow collections that would work for your Salesforce implementation, then potentially also help developers generate an OAuth bearer token and Postman Environment complete with baseURL, ersion, and bearer token. Making many different API workflows discoverable and executable by anyone, allowing any developer or business Salesforce API consumer to put templates from a marketplace to work.</p>
<h3>Taming The Salesforce API Scope</h3>
<p>The purpose of this story is to help me work through my thoughts around how to make the Salesforce REST API more accessible. I am using it as a scaffolding for my strategy to for iterating upon my dynamic Salesforce API Postman Collection. I am also hoping my approach might catch the attention of the Salesforce team and help them see how Postman can help them reduce friction when it comes to on-boarding with Salesforce REST API, and eventually all of the other APIs they offer via the Salesforce developer portal. I&rsquo;m hoping it can help convey how Postman can help streamline and modernize the Salesforce APIs, as well as provide a blueprint that can be applied to any other API out there. I just want to provide a straightforward vision of how to evolve how we on-board and communicate around the Salesforce REST API in a way that could be done from the outside-in, or at least without forcing Salesforce to make any changes to their current API life cycle&mdash;I know how hard this can be to do. Ultimately I wanted to be able to effectively tame the scope and complexity of the Salesforce API, making it more accessible to new API consumers, but also reduce friction for existing consumers when it comes to putting the very important API to work for them.</p>
<p><strong>Image Credit:</strong> <a href="https://cloud-elements.com/salesforce-integration/">Cloud Elements</a></p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/12/18/taming-the-salesforce-api-scope/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/12/17/apis-for-victoria-australia/">Apis For Victoria Australia</a></h3>
        <span class="post-date">17 Dec 2019</span>
        ---
published: true
layout: post
title: 'APIs For Victoria Australia'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/victoria_australia_logo.png
---
<p><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/victoria_australia_logo.png" alt="" width="40%" align="right" /></p>
<p><a href="https://github.com/api-evangelist/index">I was helping out someone trying to download air quality data in Australia today</a>, and while I was playing around the <a href="https://developer.vic.gov.au/index.php?option=com_apiportal&amp;view=apitester&amp;usage=api&amp;tab=tests&amp;apiName=EPA%20AirWatch%20API&amp;apiId=a201aa7e-ab49-40a2-9436-4bf7210b4cfb&amp;menuId=187">Victoria Australia government AirWatch data API </a>I thought I'd go ahead and add them to my API Evangelist network by importing their Swagger 2.,0 files and converting them to OpenAPI 3.0, while also publishing Postman collections for teach of their APIs. Expanding out the APIs I have in my directory, while also encouraging the state to publish the Postman collections I've created to the Postman API Network.</p>
<p><a href="https://developer.vic.gov.au/api-catalogue">The State of Victoria has some pretty interesting APIs</a> that they have made available using <a href="https://www.axway.com/en">Axway</a>. I have <a href="https://github.com/api-evangelist/victoria-australia">published an APIs.json index for the states developer portal, providing an index of their API operations</a>, as well as the individual APIs. You can get at the Postman collections I've generated using these links.</p>
<ul>
<li><a href="https://github.com/api-evangelist/victoria-australia/blob/master/abs-labour-force-api-postman-collection.json">ABS Labour Force API Postman Collection</a></li>
<li><a href="https://github.com/api-evangelist/victoria-australia/blob/master/agriculture-victoria-soils-api-postman-collection.json">Agriculture Victoria Soils API Postman Collection</a></li>
<li><a href="https://github.com/api-evangelist/victoria-australia/blob/master/datavic-ckan-api-postman-collection.json">DataVic CKAN API Postman Collection</a></li>
<li><a href="https://github.com/api-evangelist/victoria-australia/blob/master/datavic-open-data-api-postman-collection.json">DataVic Open Data API Postman Collection</a></li>
<li><a href="https://github.com/api-evangelist/victoria-australia/blob/master/epa-airwatch-api-postman-collection.json">EPA AirWatch API Postman Collection</a></li>
<li><a href="https://github.com/api-evangelist/victoria-australia/blob/master/important-government-dates-api-postman-collection.json">Important Government Dates API Postman Collection</a></li>
<li><a href="https://github.com/api-evangelist/victoria-australia/blob/master/museums-victoria-collections-api-postman-collection.json">Museums Victoria Collections API Postman Collection</a></li>
<li><a href="https://github.com/api-evangelist/victoria-australia/blob/master/popular-baby-names-victoria-api-postman-collection.json">Popular Baby Names Victoria API Postman Collection</a></li>
<li><a href="https://github.com/api-evangelist/victoria-australia/blob/master/victorian-heritage-api-postman-collection.json">Victorian Heritage API Postman Collection</a></li>
</ul>
<p>I would go ahead and publish the Postman collections to the Postman Network, but I have asked them to go ahead and publish them. I would rather the listings be more authoritative and something that is owned by the API operators. I'm just looking to maintain a GitHub repository with fresh copies of their OpenAPI, Postman collections, and APIs.json so I can use as the source of truth for the APIs across API Evangelist, APIs.io, and other iPaaS, and integration providers.&nbsp;</p>
<p>I am working through several different business sectors and government APIs, updating my directory of APIs, while also sharing with soem other API service providers I have been talking to. If there is a particular API provider you'd like to see added to my list, <a href="https://github.com/api-evangelist/index">go ahead and submit a pull request or submit an issue on my index repository</a>. I am looking to crank through profiling of 2K APIs over the holidays, and reach out to the owners as I make my way through creating OpenAPI, Postman collections, and APIs.json indexes for each of the APIs I track on. Making sure there are machine readable definitions for the APIs available on GitHub, but also building relationships with the providers as I go along.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/12/17/apis-for-victoria-australia/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/12/17/a-portable-23andme-api-sandbox/">A Portable 23andme Api Sandbox</a></h3>
        <span class="post-date">17 Dec 2019</span>
        ---
published: true
layout: post
title: 'A Portable 23andMe API Sandbox'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/23andme_request_1.png
---
<p class="p1">I was creating <a href="https://github.com/api-evangelist/23andme/blob/master/23andme-postman-collection.json">a Postman collection for the 23andMe API</a>. The <a href="https://api.23andme.com/docs/reference/#profile">23andMe API is still available</a>, despite <a href="https://blog.23andme.com/news/an-update-to-our-api-program/">the company pulling back somewhat when it comes to accessing the DNA and genetics API.</a> You can still get access to the API for research purposes, but you have to email their business development group and convince them of the merits of your research before you&rsquo;ll get access to the data. It is pretty common for companies to have valuable data like 23andMe does, and there being a significant amount of concern regarding who has access to it. This is why API management exists as a fundamental building block of API operations, so you can have total control over who has access to your data, and possess detailed logs regarding what has been accessed by consumers.</p>
<p class="p2">Requiring approval of a developer account before you get your API keys is common, pushing API developers to justify their access and establish a trusted relationship with API providers. This is something you can setup with your API management tooling or services, providing a public sign-up form, yet making each new API consumer wait to be approved before they get their API keys. Even with this security layer in place you may still want to allow API consumers to kick the tires more and see what is possible while awaiting approval for API access. One way you can accomplish this is by creating Postman collections for all the API endpoints, making sure there are one or more examples for each individual API path so that they can be mocked by any consumer using Postman.</p>
<p class="p1">I went ahead and did this for the 23andMe API. Their documentation is still available, and there are examples for each individual path. I wanted to create a Postman collection for the API to round of my collection of API definitions, and since their documentation had examples, I thought I&rsquo;d demonstrate how to create portable API sandboxes using Postman, showing how you can easily allow anyone to mock your API and work with it without actually an API key. To begin, all I needed was a complete reference collection for the 23andMe API, documenting all the available paths.</p>
<p class="p1"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/23andme_request_1.png" alt="" width="100%" /></p>
<p class="p1">Once I have each API path defined as a single request within the complete reference collection I just have to make sure each individual path has one or more API examples, showing an example of what each response will look like in production. Providing all of the details the mock server will need to return a response when a request is made to each individual path.</p>
<p class="p1"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/23andme_example_1.png" alt="" width="100%" /></p>
<p class="p1">For a couple of the API paths 23andMe provided multiple examples, demonstrating what you would get back if you changed up query parameters for the path. I made sure and included all of the examples provided, giving the mock server more robustness, and reflecting what you can get back with each response in a live environment.<span>&nbsp; </span>I have <a href="https://github.com/api-evangelist/23andme/blob/master/23andme-postman-collection.json">the Postman collection for 23andMe published to GitHub</a>, which you can import into your Postman, and generate a mock server by managing the collection.</p>
<p class="p1"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/23andme_generate_mock.png" alt="" width="100%" /></p>
<p class="p1">Once you created the mock API using the 23andMe Postman collection you can create an environment for 23andMe, add a variable with the key of 23andme_base_url, and replace the current value with the URL of your mock API server. Then each of the API paths for the 23andMe API will work, returning examples for each of the responses.<span>&nbsp;</span></p>
<p class="p1"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/23andme_environment.png" alt="" width="100%" /></p>
<p class="p1">When working with the collection, if you look at that <a href="https://documenter.postman.com/view/35240/SWECWaZy?version=latest#57e1abc7-c774-4ab5-a25c-a7cf4c3fd609">Get Report</a> and <a href="https://documenter.postman.com/view/35240/SWECWaZy?version=latest#09d49d9f-df5e-4c3d-bf6b-98d57b361f31">Get Profile Report</a> requests, you&rsquo;ll notice there are two examples available. One for wellness, and another for genetic weight. All you have to do is change the parameter value and the mock server will return the example with corresponding parameter value. Demonstrating how you can publish as many examples as you need, demonstrating all of the possible API responses. While it is a static mock, you can get pretty creative when it comes how you define what is possible, publishing as many dimensions as you&rsquo;d like when it comes to firing up the imagination of your potential consumers&mdash;without giving away any access to data you do not wish to share.</p>
<p class="p2">Hopefully that demonstrates another way in which you can provide access to your API without giving away the farm. You definitely want API management with accompanying policies in place, but crafting well defined Postman collections intended for specific audiences is another way you can on-board consumers safely. I think the 23andMe API provides a nice example of this, partly because they have a simple yet robust API, complete with examples, but also because of the challenges they&rsquo;ve faced in making their API public. It provides a powerful lesson for other API providers to consider as they are working to make their APIs available, while reducing friction for potential consumers&mdash;striking the balance needed to make sure your APIs are discoverable, but also still adequately secured.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/12/17/a-portable-23andme-api-sandbox/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/12/16/being-flexible-with-authorization-when-it-comes-to-multiple-apis-within-a-single-api-collection/">Being Flexible With Authorization When It Comes To Multiple Apis Within A Single Api Collection</a></h3>
        <span class="post-date">16 Dec 2019</span>
        ---
published: true
layout: post
title: 'Being Flexible With Authorization When It Comes To Multiple APIs Within A Single API Collection'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/postman_aws_deploy_aws_api_gateway_auth.png
---
<p class="p1">I am working on a Postman collection that deploys an API to AWS. I&rsquo;m pulling the OpenAPI from Postman using the Postman API API (mind blown), and then publishing the API to AWS as an API using the AWS API Gateway API (mind blown again). As part of this process I also need a DynamoDB instance to use as a persistent data store behind the API, which I will create using the DynamoDB API. I need all of these capabilities organized within a single Postman collection, but because of the need to authenticate with multiple API services I will be organizing each capability by AWS service so I can set the authorization for each folder, and let each individual API request inherit from the folder, otherwise I will have to set each individual API request while working&mdash;I abstract away the variables I use across the authorization as part of a Postman environment, but I still want to logically think through how I can apply authorization across services.</p>
<p class="p1">When defining Postman collections you can apply the authorization at the collection, folder, or request levels. This allows you to be more thoughtful of how authenticate across multiple APIs within a single Postman collection. This Postman collection is going to end up being what I&rsquo;d consider to be a workflow collection, meaning it will walk through each step for the deployment of an API to AWS using Postman, so eventually it most likely will just be a series of individual API requests which can be run manually by a user, or automated with a Postman runner or monitor. However, as I am architecting my collection I don&rsquo;t want to have to define the authorization for each individual request&mdash;I just want them to inherit authorizations, so I am just going to add a folder for each service. This gives me the ability to set authorization for Postman at the header level for an individual request, which I will move up to the folder level if I need to make another request to the Postman API.</p>
<p class="p1"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/postman_aws_deploy_postman_auth_header.png" alt="" width="100%" /></p>
<p class="p1">Then I can set authorization for AWS API Gateway, and inherit for each individual call that I am making to the AWS API Gateway API to configure the surface area of the API I am deploying to AWS.</p>
<p class="p1"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/postman_aws_deploy_aws_api_gateway_auth.png" alt="" width="100%" /></p>
<p class="p1">Then I can set authorization for AWS DynamoDB, and inherit for each individual call that I am making to the configure the persistent data store that I am deploying to AWS behind the API.</p>
<p class="p1"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/postman_aws_deploy_aws_dynamodb_auth.png" alt="" width="100%" /></p>
<p class="p1">I am using three separate APIs to deploy my API&mdash;Postman, AWS API Gateway, and AWS DynamoDB. I have an API key for Postman, and one set of a key and secret I am using to work with AWS&mdash;configuring AWS IAM to allow my key and secret to work with both service. While I am using the same set of key and secrets across both AWS services and relying on AWS IAM to manage access, I am still keeping the variables I use for each service separate so that I can keep all of my AWS variables consistent across the different Postman collections I am developing. I have built a whole list of AWS reference collections, and will be using these parts and pieces across many different workflow collections, with this just being the first one designed to deploy an API.</p>
<p class="p1">Once I assemble all of the different AWS capabilities across AWS API Gateway and DynamoDB I may flatten my collection into a single set of ordered API request with authorization existing for each individual request&mdash;providing a more logical sequential set of API deployment steps. Right now I am still working out what at the steps will be and just want my API requests to inherit their authorization by service. We&rsquo;ll see, my steps may still be able to be organized by folder because there will most likely be several steps for each service accomplished in some sort of logical order&mdash;I don&rsquo;t really know until I flesh it all out. I am guessing I will be adding more AWS services as part of this process. I am just thankful that Postman allows me to be so flexible with the way in which I define authorization and then abstract away variables as part of environments, which allows me to use different approaches to defining the authorization layer of my Postman collections, which allows me to orchestrate with many different APIs in a single Postman collection that accomplishes a specific business objective.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/12/16/being-flexible-with-authorization-when-it-comes-to-multiple-apis-within-a-single-api-collection/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/12/16/api-observability-is-more-than-just-testing-and-monitoring/">Api Observability Is More Than Just Testing And Monitoring</a></h3>
        <span class="post-date">16 Dec 2019</span>
        ---
published: true
layout: post
title: 'API Observability Is More Than Just Testing And Monitoring'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/stalin-time-seatlle-shipping-mountain.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/stalin-time-seatlle-shipping-mountain.jpg" alt="" width="40%" align="right" /></p>
<p><a href="http://observability.apievangelist.com/">API observability</a> is something I have written about for a while now after learning about it from Stripe. It is a phrase that has grown popular in API testing, monitoring, and performance circles. Borrowed from the physical world of control systems, observability&nbsp;is a measure of how well internal states of a&nbsp;system&nbsp;can be inferred from knowledge of its external outputs. I am all about getting on API observability train when it comes to monitoring of our systems, but if you&rsquo;ve read my work you know I am all about expanding the definition to not just include the technical, but also the business and politics of API operations.</p>
<p>One of the key aspects of observability is using the outputs or exhaust from the existing services and tooling used to operate your system. To help increase API observability within the enterprise I am always on the hunt for what the existing services and tooling that are in place so that I can better understand what the existing outputs are. If a service or tool is already in place within the enterprise, and we can tap into existing outputs, the chances for successfully changing behavior significantly increases. One tool that is ubiquitous across enterprise organizations is Postman, which provides a whole wealth of opportunity when it comes to tapping into the existing outputs to provide more observability into what is going on across the API life cycle.</p>
<p>90% of the Postman usage within the enterprise I come across occurs in isolation. One developer working with internal and external APIs within Postman. This occurs hundreds, or thousands over within medium and large enterprise organizations. Developers are profiling APIs, building requests, and saving them into collections with very little communication, coordination, and sharing of API awareness across teams. While it represents a pretty concerning trend across enterprise organizations where leadership has such little visibility into what teams are working on, it also represents a pretty significant opportunity for leadership to take advantage of the fact that developers are already using Postman. All they have to do is began actively managing users under a single organizational license (which you think would be the default), organizing collections into teams, and being more proactive about how Postman is used.</p>
<p>API observability isn&rsquo;t just about measuring the outputs of testing and monitoring. That is a good start, but there are other services and tooling already in place across enterprise API operations that can be measured and made sense of in real-time. First, enterprise organizations should be getting a handle on what internal, partner, and 3rd partner APIs are being used by developers&mdash;Postman is the best place to develop an understanding of API consumption looks like. Once an organization begins to be more structured in how it manages Postman users, and begin defining teams, organizing collections and environments, the API observability opportunities increase significantly. Allowing business and technical leadership to obtain a better view of the enterprise landscape, and begin making more strategic decisions around how APIs are deployed and consumed, helping guide and direct what developers are up to on a daily basis.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/12/16/api-observability-is-more-than-just-testing-and-monitoring/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/12/14/believing-the-technology-startup-hype-and-refusing-see-anything-else/">Believing The Technology Startup Hype And Refusing See Anything Else</a></h3>
        <span class="post-date">14 Dec 2019</span>
        ---
published: true
layout: post
title: 'Believing The Technology Startup Hype And Refusing See Anything Else'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/bf-skinner-dragon-shadow-sun-2.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/bf-skinner-dragon-shadow-sun-2.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">I&rsquo;ve been in numerous discussions with defenders of the Instructure Canvas platform after <a href="http://apievangelist.com/2019/12/09/the-instructure-lms-data-points/">posting the Instructure LMS data points</a>. These folks are&nbsp;blindly and passionately defending Instructure as a force for good, founded by good people, and being offended that I would see beyond the static representation of the startup they are demanding that everyone see and believe. I find it endlessly fascinating how we as a society continue to believe the storytelling around startups, and receive the marketing they put out as some sort of truth that will play out forever into the future. Even more dangerously these people don&rsquo;t just believe, they actively police the front-line of critics who are shining a light on what is really going on, doing the bidding of not just startups, and their investors, but the capitalist machine.</p>
<p class="p1">First, let me quickly disarm some of the standard tactics folks will use to come back at me on this piece. No, I am not anti-startup. I work for one, and have worked for many others. No, I am not anti-investor, I know lots of investors, advise them regularly, and derive most of my income from venture capital. This does not mean I am always walking the line and curbing my criticism of the bad that perpetuated by startups and investors across the landscape. People who feel the need to blindly defend technology is one of the reasons why there are so many bad actors on the stage, and why people are able to get away with the shenanigans they are pulling. Critics and whistleblowers are one of the forces that helps keep exploitative companies in the shadows, and minimize the damage they cause. I&rsquo;m not saying all critique is constructive or helpful, but I&rsquo;m saying that if you are actively pushing back on the critics and not listening to what they are saying, you are most likely part of the problem.</p>
<p class="p1">To recap for those who are just jumping in--Instructure, a popular API-driven LMS systems was acquired by a private equity group after going public, producing a wave of concern about the student data Instructure possesses. The wave of concern also produced a responding wave of people defending Instructure as being a force for good, and expressing shock that anyone would think otherwise. The point of my story was to highlight the data-driven view investors and private equity firms have of the landscape, and jumpstart discussion around the lack of policy addressing data privacy and ownership in general, but more specifically, the lack of protections for students who are just beginning their journey in this data exploitative world we&rsquo;ve created for ourselves. The point of my storytelling on this subject was not to talk badly of the Instructure founders who I have met personally, but to shine a light on lack of policy and the ignorance that exists around what technology startups are all about, and how they are viewed and wielded by (some) investors.</p>
<p class="p1">Technology startups can be a force for good, and can be run ethically by people who wish to make a positive change. I work for one now, and have worked for them in the past. This does not mean all startups are good. This does not mean the marketing and storytelling coming out of startups is always true. This doesn&rsquo;t mean we shouldn&rsquo;t be regularly critical of startup practices, and the investors behind them. We should be critical of all investors and startups, especially the ones we operate, work within, and do business with. This also means that even good startups can change leadership at any point in the future, and that a startups ethics and beliefs will not transfer to whoever acquires them down the road. There is no technology or business practice that will bake in the &ldquo;good&rdquo; of the original co-founders into the fabric of a startup's operations and guarantee it will always play out in the future. No matter how much we believe in the technology we are building or applying, we should always be skeptical and critical of how it can be used for exploitation at any point in the future.</p>
<p class="p1">I do not doubt that the Instructure founders are good people. I do not doubt that Instructure employees are good people. I do not doubt that people who made the decision to use Instructure in schools, implement and manage the LMS are good people. If you are one of these people and feel attacked by what I&rsquo;m saying then I am guessing you are insecure because deep down you know there is a bigger picture out there, and you are willfully naive or ignorant of what is happening. I strongly believe the co-founders of the startup I work for right now. I strongly believe in the employees of the startup I work for right now. I actually strongly believe in the investors behind the startup. This does not mean I won&rsquo;t be regularly critical of our practices, and concerned for what the future holds when investment grows, and business exits that wiull happen. I also believe that my leadership supports my ability to influence minds and policy when it comes to data access, privacy, governance, and the other forces which are the only things that will protect us from having our data exploited for profit.</p>
<p class="p1">I am not saying Instructure has done anything wrong. But you can&rsquo;t tell me the value of students data isn&rsquo;t a big part of the reason the private equity firm is buying the company. And you can&rsquo;t tell me that this data will not be used for doing bad down the road&mdash;do you really want to die on this hill? If you are passionately defending the credibility of a publicly traded technology company that was acquired by a private equity firm against people who are concerned for the privacy of students, and people arguing for strongly policy defending students rights&mdash;you are part of the problem. You are either believing that data is valuable and it is the right of companies to profit off student data, or you are isolated and missing the bigger picture when it comes to how data is the new oil, and the majority of technology startups are looking to profit from the creation, enrichment, and selling of data. I am hoping that it is the latter, but I also come across a lot of people who are actively in the know, and still police the front lines, and repeat the marketing message that startups are good.</p>
<p class="p1">This blind belief of startup storytelling and hype is why private equity firms buy beloved brands. This is why new waves of startups are founded, grown, and then harvest by industry leading firms. Because people blindly believe that the goodness that exists within the early days of a startup, and the goodwill they create will always be baked into the DNA of the startup&mdash;even once it is acquired. Instagram is still that amazing bootstrapped startup despite being part of Facebook, and Ben &amp; Jerry&rsquo;s is still owned by those two quirky founders despite being owned by Unilever. Now don&rsquo;t DM, email, or Tweet at people declaring I&rsquo;m anti-startup&mdash;that is a weak sauce argument. Or try to say I&rdquo;m saying we should do startups at all. I still believe we should do them. I still believe that startups can be a force for good. I still believe that venture capital can be necessary. What I am saying is we should always be skeptical and critical of the constant flow of feel good messaging out of startups, and we should always be mindful of what can happen in the future. We should all work hard to make sure there is strong policies in place at the state and federal levels protecting the rights of end-users, and not just the interests of corporations and their investors.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/12/14/believing-the-technology-startup-hype-and-refusing-see-anything-else/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/12/13/remember-that-an-application-is-not-just-about-someone-building-a-web-or-mobile-application-with-your-api/">Remember That An Application Is Not Just About Someone Building A Web Or Mobile Application With Your Api</a></h3>
        <span class="post-date">13 Dec 2019</span>
        ---
published: true
layout: post
title: 'Remember That An Application Is Not Just About Someone Building A Web or Mobile Application With Your API'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/la-muse-butterfly-purple-flower.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/la-muse-butterfly-purple-flower.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">I encounter regular waves of API providers who are discouraged with the traffic to their API portal as well as the number of developers who are actually building something on top of their API. Many suffer from the hangover of &ldquo;if you build it they will come&rdquo; syndrome. Believing that if they just publish their APIs that developers will just show up and build amazing things. While many of us evangelists and advocates have over-promised amazing outcomes when it comes to publishing APIs, many of us in the trenches have long been honest about the hard work it takes to make your APIs something developers will want to use.</p>
<p class="p1">Just publishing your APIs to a developer portal is not enough. Having a well designed and documented API is not enough. Making enough noise so that people find your API is a full time job, and ideally it is done by a whole team of people&mdash;study how Twilio has done it if you need a working example. Also, you have to regularly re-evaluate what the possibilities are when it comes to building or developing &ldquo;applications&rdquo;. This isn&rsquo;t the API ecosystem of a decade ago where we focused on building just widgets and mobile applications. There are many more ways in which people can put your APIs to work in 2019, and you should be making time to understand what those possibilities are. The chance that some new developer will randomly find your API and build the next killer mobile application is pretty slim, and the real world implementations are probably going be much more mundane and granular.</p>
<p class="p1">The important thing to remember about the word &ldquo;application&rdquo; is it does not necessary mean a web, mobile, or device application&mdash;it can simply mean &ldquo;applying&rdquo; your API.<span>&nbsp; </span>Which in a world of integration platform as a service (iPads), bots, voice, and other use cases, applying your API could mean many different things. Don&rsquo;t expect that all of your API portal visitors will be developers, and that they will have an application in mind. Most will just be looking for inspiration, kicking the tires, and understand what is possible. Many will just want the value you enable without having to write code or building an application, integrating and working with the services and tools they already are putting to use. Hoping that your API is ubiquitous across the integration pages of other API providers, and across the growing number of iPaaS providers who have emerged across the scene in the last couple of years.</p>
<p class="p1">Make sure you are regularly refreshing your view of the API landscape by frequenting the APIs of other providers. Visit their integration pages to see what complimentary APIs they have integrated with. Do you have an integrations page? Go play around with the different iPaaS players on the scene and see what types of integrations they offer, and what types of solutions they offer you to integrate your API. Of course, also make sure you have not just a reference Postman collection describing the entire surface area of your API, also make sure you have introduction, walk-through, and other on-boarding types of Postman collections for your APIs--making sure there is no friction for developers when it comes to learning about your API. The more you invest in reducing friction for your new API consumers, while also baking your API into other existing API platforms, the more your perspective of what exactly what an application is will shift, eventually landing somewhere that is more in sync with the API consumer you desire.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/12/13/remember-that-an-application-is-not-just-about-someone-building-a-web-or-mobile-application-with-your-api/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/12/12/the-postman-business-model-is-in-alignment-with-enterprise-objectives/">The Postman Business Model Is In Alignment With Enterprise Objectives</a></h3>
        <span class="post-date">12 Dec 2019</span>
        ---
published: true
layout: post
title: 'The Postman Business Model Is In Alignment With Enterprise Objectives'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/postman_plans_and_pricing.png
---
<p><a href="https://www.postman.com/pricing"><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/postman_plans_and_pricing.png" alt="" width="40%" align="right" /></a></p>
<p class="p1">One of the things that became very clear during my conversations with folks at AWS re:Invent last week is that Postman&rsquo;s revenue model is in alignment with what is needed within the enterprise. To help explain, let&rsquo;s answer the question I got over and over at re:Invent&mdash;how does Postman make money? Steady waves of folks would show up at our booth in the re:Invent expo hall, and usually after a couple minutes of talking about their FREE usage of Postman, and how ubiquitous the tool is at their organization, they would inquire about our pro and enterprise offerings&mdash;which is all about helping enterprise organizations get more organized when it comes to doing APIs.</p>
<p class="p1"><a href="https://www.postman.com/pricing">The Postman Pro and Enterprise offerings</a> are all about scaled usage of the platform, which includes the number of collections, users, teams, workspaces, and the collaboration, automation, and orchestration across them. All the core Postman features are free, and will remain free&mdash;developers love Postman because of its utility, and we do not intend to mess with that.<span>&nbsp; </span>Paying for Postman means you are getting more organized about how you manage users, collections, environments, teams, and workspaces, as well as using more monitors, runners, mocks, and documentation. While more usage doesn&rsquo;t always mean an organizations is doing things in a more logical fashion, but Postman enterprise features center around the organized governance of users, teams, workspaces, collections, and environments, steering enterprise customers towards optimizing how things get done.</p>
<p class="p1">Having observability into all of your teams delivering and consuming APIs is the most important thing you can be investing in as part of your enterprise operations&mdash;the Postman enterprise tier is centered around charging for collaboration, automation, and scaling your teams using a tool they already are using, which increases observability across your API operations. This is why I am working for Postman. I am regularly conflicted about how the companies I rely upon tier their pricing and scale the business side of what they do. The pricing usually doesn&rsquo;t reflect my business needs and priorities, and often just puts features out of my reach, or makes it so I cannot scale my consumption. Postman reflects what I need as an API provider and consumer, while also reflecting what enterprises in general are needing when it comes to their API journey.</p>
<p class="p1">If you know me, and have worked with me in the past you know I stress over the business ethics of APIs. The business of APIs is the foundation of the API Evangelist blog, and while I feel there is a huge opportunity for defining new products and services using APIs, I also feel there is a lot of examples of bad behavior when it comes to what APIs and API services cost. This is why the Postman monetization strategy makes me so happy. It isn&rsquo;t about cannibalizing all of the good will we&rsquo;ve established with developers, it is about continuing to build on this goodwill and helping companies, organizations, institutions, and government agencies be more successful in how they deliver and consume APIs. This is a business model I can get behind and passionately evangelize around, because I don&rsquo;t have to mute myself when it comes to the business of what I am doing&mdash;I can be proud of my work, and how I pay my bills.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/12/12/the-postman-business-model-is-in-alignment-with-enterprise-objectives/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/12/12/focusing-on-digital-api-capabilities-over-just-doing-apis/">Focusing On Digital Api Capabilities Over Just Doing Apis</a></h3>
        <span class="post-date">12 Dec 2019</span>
        ---
published: true
layout: post
title: 'Focusing On Digital API Capabilities Over Just Doing APIs'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/braceros-domingo-ulloa-satellite-dishes-pointing-up.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/braceros-domingo-ulloa-satellite-dishes-pointing-up.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">As I work on creating more useful Postman collections I am distilling my API definitions down to the small possible unit as I possibly can. While I have many robust reference Postman collections and OpenAPIs, I am enjoying creating Postman collections that accomplish just a single ting&mdash;representing each digital capability that I have. Currently my digital capabilities are spread across a number of servers, GitHub repositories, and Postman workspaces. If I use one of the APIs in my long list of API providers it is pretty common that I use less than 5% of the API paths from each individual providers. So, other than for sharing as part of my API Evangelist research, why do I need to wade through entire reference API collections to get at the one or two capabilities I need to actually use.</p>
<p class="p1">I&rsquo;m slowly working through the stack of APIs that I use, pulling out the different capabilities I put to work as part of my API Evangelist work, defining as single Postman collections that I list on my GitHub capabilities page. I have published two Twitter API capabilities I have defined, which I will be expanding on pretty quickly, helping document all of the essential API calls I make to the Twitter platform.</p>
<h2>Twitter</h2>
<table width="90%">
<tbody>
<tr>
<td><strong>Tweet Search</strong></td>
<td>A basic search for Tweets on Twitter by query.</td>
<td><a href="https://app.postman.com/run-collection/4e1e1215a622cee90d3a"><img src="https://camo.githubusercontent.com/271662c7525b6d3c5e9f88206b3dcc06bfa73a6d/68747470733a2f2f72756e2e7073746d6e2e696f2f627574746f6e2e737667" alt="Run in Postman" /></a></td>
</tr>
<tr>
<td><strong>Twitter Account Status</strong></td>
<td>Doing a lookup on users and returning only the fields that describe their status.</td>
<td><a href="https://app.postman.com/run-collection/0de9bb0fdacd6b8f1e74"><img src="https://camo.githubusercontent.com/271662c7525b6d3c5e9f88206b3dcc06bfa73a6d/68747470733a2f2f72756e2e7073746d6e2e696f2f627574746f6e2e737667" alt="Run in Postman" /></a></td>
</tr>
</tbody>
</table>
<p class="p1">I have probably another 50 individual Twitter platform capabilities I am putting to work across my platform. I am going to list them all out here, and then begin documenting how I put each of these capabilities to work. Then I&rsquo;m going to evaluate whether there is any opportunity for me to scale each capabilities using Postman monitors, helping me automate the orchestration of Twitter data across my operations. Next, I got to work defining a handful of GitHub capabilities I put to use on a regular basis.</p>
<h2>GitHub</h2>
<table width="90%">
<tbody>
<tr>
<td><strong>Search Code</strong></td>
<td>Searches GitHub for code, using a specific query.</td>
<td><a href="https://app.postman.com/run-collection/4f512e70fb83da7f081a"><img src="https://camo.githubusercontent.com/271662c7525b6d3c5e9f88206b3dcc06bfa73a6d/68747470733a2f2f72756e2e7073746d6e2e696f2f627574746f6e2e737667" alt="Run in Postman" /></a></td>
</tr>
<tr>
<td><strong>Search Issues</strong></td>
<td>Searches GitHub for issues, using a specific query.</td>
<td><a href="https://app.postman.com/run-collection/907bac453847f749671c"><img src="https://camo.githubusercontent.com/271662c7525b6d3c5e9f88206b3dcc06bfa73a6d/68747470733a2f2f72756e2e7073746d6e2e696f2f627574746f6e2e737667" alt="Run in Postman" /></a></td>
</tr>
<tr>
<td><strong>Search Repositories</strong></td>
<td>Searches GitHub for repositories, using a specific query.</td>
<td><a href="https://app.postman.com/run-collection/b0d83354ba4c8274d3f9"><img src="https://camo.githubusercontent.com/271662c7525b6d3c5e9f88206b3dcc06bfa73a6d/68747470733a2f2f72756e2e7073746d6e2e696f2f627574746f6e2e737667" alt="Run in Postman" /></a></td>
</tr>
<tr>
<td><strong>Search Users</strong></td>
<td>Searches GitHub for users, using a specific query.</td>
<td><a href="https://app.postman.com/run-collection/8672372adc904d3e8852"><img src="https://camo.githubusercontent.com/271662c7525b6d3c5e9f88206b3dcc06bfa73a6d/68747470733a2f2f72756e2e7073746d6e2e696f2f627574746f6e2e737667" alt="Run in Postman" /></a></td>
</tr>
<tr>
<td><strong>GitHub Public Events</strong></td>
<td>Lists public events for a GitHub user account.</td>
<td><a href="https://app.postman.com/run-collection/ab513b3f4b2b371549c5"><img src="https://camo.githubusercontent.com/271662c7525b6d3c5e9f88206b3dcc06bfa73a6d/68747470733a2f2f72756e2e7073746d6e2e696f2f627574746f6e2e737667" alt="Run in Postman" /></a></td>
</tr>
<tr>
<td><strong>GitHub Organization Events</strong></td>
<td>List public events for a GitHub organization.</td>
<td><a href="https://app.postman.com/run-collection/f84e4ce2bcd1e5bca235"><img src="https://camo.githubusercontent.com/271662c7525b6d3c5e9f88206b3dcc06bfa73a6d/68747470733a2f2f72756e2e7073746d6e2e696f2f627574746f6e2e737667" alt="Run in Postman" /></a></td>
</tr>
<tr>
<td><strong>GitHub List Organization Members</strong></td>
<td>List the members for a GitHub organization.</td>
<td><a href="https://app.postman.com/run-collection/0285c60b5c5ae16653f1"><img src="https://camo.githubusercontent.com/271662c7525b6d3c5e9f88206b3dcc06bfa73a6d/68747470733a2f2f72756e2e7073746d6e2e696f2f627574746f6e2e737667" alt="Run in Postman" /></a></td>
</tr>
</tbody>
</table>
<p class="p2">I have probably 50+ other GitHub capabilities I put to use on a regular basis. I am having to seriously reconsider how I use GitHub after the migration of my data API projects and websites off GitHub a couple of months, and migration of API management to the Postman platform. The process of distilling each individual GitHub API that I use down to a single Postman API capability collection is helping me think through how I use the platform, and get more organized when it comes to observing and regularly evaluate how I use GitHub.</p>
<p class="p1">Ultimately I am going to end up with a mess of individual Postman collections I am going to need to manage. This is fine, because I am building Postman collections to help me automate and govern all of my Postman collections. I&rsquo;m purposely looking to scale the number of APIs and derivative Postman collections I have to manage to push my skills when it comes to automating things with Postman. Focusing more on digital API capabilities over just simply doing APIs is helping me be more thoughtful and critical about how I put APIs to work, while being more precise in how I define API Evangelist capabilities.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/12/12/focusing-on-digital-api-capabilities-over-just-doing-apis/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/12/12/automatically-generate-openapi-for-your-apis-just-by-using-them/">Automatically Generate Openapi For Your Apis Just By Using Them</a></h3>
        <span class="post-date">12 Dec 2019</span>
        ---
published: true
layout: post
title: 'Automatically Generate OpenAPI For Your APIs Just By Using Them'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/optic_openapi_generation_diff.png
---
<p><a href="https://www.useoptic.com/"><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/optic_openapi_generation_diff.png" alt="" width="40%" align="right" /></a></p>
<p class="p1">I am a big fan of tools that just augment our normal existence then make our lives easier without having to do much additional work. One of the tools that fits into this category is <a href="https://www.useoptic.com/">Optic</a>, an open source tool that will generate OpenAPI definitions from your proxied traffic. <a href="https://apievangelist.com/2015/06/21/parsing-charles-proxy-exports-to-generate-swagger-definitions-while-also-linking-them-to-each-path/">A while back I developed my own script for doing this by processing Charles Proxy files synced with Dropbox</a>, but I never evolved it beyond Swagger when OpenAPI 3.0 was released. So I was pleased to talk with the Optic team at API World in San Jose a while back. Like many notes in my notebook, my thoughts on Optic got buried by the constant flow of conversations and ideas coming in on a daily basis, but a Tweet from them the other day reminded me that I wanted to showcase and talk a little more about what they are up to and why Optic is important to the API sector.</p>
<p class="p1">Optic will take your browser, CLI, and Postman API traffic and automatically generate an OpenAPI based upon your API calls that are routed through the Optic proxy. Helping us automate the generation of machine readable API contracts which can then be used across our API operations.<span>&nbsp; </span>The generation of OpenAPI from the exhaust of our existing work is valuable, but what also grabs my attention is that Optic helps handle the diffs between each OpenAPI generating, which can be used to help you detect changes in APIs that are already in use. As I said, I have had this capability for a while now, and it is something you can do within Postman&mdash;turning on a proxy and generating a Postman collection. But, having as a standalone open source open source component that produces OpenAPI contracts as a standalone service is pretty critical for helping us make sense of our API exhaust at scale.</p>
<p class="p1">Optic&rsquo;s core feature is generating OpenAPIs and managing the diff between each OpenAPI that comes in. Optic is also quickly sending signals about moving into other stops along the API life cycle like documentation and testing, which makes sense, but I recommend staying extremely focused on managing API definitions at scale across a large enterprise, and invest in these areas as next steps.</p>
<ul class="ul1">
<li class="li1"><strong>History</strong> - As an enterprise, I want to be able to pay for historic logging of all activity across groups who are delivering API infrastructure.</li>
<li class="li1">Playback - Allow for the playback of the evolution of a single version, or multiple version of each API definition being identified.</li>
<li class="li1"><strong>Notifications</strong> - I want robust premium notifications across teams helping ensure each stakeholder gets alerted when changes are detected.</li>
<li class="li1"><strong>Conversations</strong> - I would like to see a feedback loop baked into the evolution of API definitions, and the discovery of new APIs and changes to existing.<span>&nbsp;</span></li>
<li class="li1"><strong>Schema</strong> - Extraction of schema files from the OpenAPI, and allow for publishing of separate JSON Schema as well as the OpenAPI definition.</li>
<li class="li1"><strong>Versioning</strong> - Helping manage the versioning of APIs across operations, documenting which versions are still in use, or fading in overall usage.</li>
<li class="li1"><strong>Git Sync</strong> - Going beyond just the local .api folder of OpenAPIs, publishing to GitHub, GitLab or Bitbucket, and maintaining a catalog of APIs.</li>
<li class="li1"><strong>Cloud</strong> - I want to be able to proxy all of my cloud logs for AWS, Azure, and Google, and have OpenAPIs generated from across all traffic.</li>
<li class="li1"><strong>Logs</strong> - I want native NGINX / Apache log file connector for parsing my API traffic and publishing OpenAPI definitions in use across operations.</li>
</ul>
<p class="p1">I think there is probably a significant opportunity for Optic to move into documentation, testing, and other stops along the life cycle, but I think there is bigger opportunity for staying specialized on the auto-generation, diff, merge, fork, versioning, syncing, and evolution of machine readable artifacts (OpenAPI, JSON Schema, and Postman Collections. Staying focused on managing artifacts generated from the API exhaust we generate daily basis will help Optic remain competitive and highly useful to API providers. With OpenAPI as the heartbeat of Optic, every other API service provider can step up to deliver in their respective areas, and Optic can stay hyper focused on solving the growing API contract problem.</p>
<p class="p1">We will not convince every API provider of the value in creating OpenAPI definitions for all APIs being developed. Optic recognizes that the average developer is busy doing what they do each day, and if you can just proxy the exhaust from their world, you can automate the generation of API contracts that are already in use. Your organization may not fully see the benefits of going API design first, but you can&rsquo;t ignore the value of having machine readable contracts, and what they enable when it comes to deployment, management, testing, monitoring, performance, documentation, CLI, iPaaS, security, and many other stops along the API life cycle. Optic is a smart, simple, and straightforward solution to a real world problem every company faces, and I predict that if given a little more investment and resources Optic could be turned into an industrial grade API discovery and awareness tool that helps us automate the mapping of the fast growing API and micro service landscape that exists across every enterprise organization today.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/12/12/automatically-generate-openapi-for-your-apis-just-by-using-them/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/12/11/we-will-not-convince-everyone-to-go-api-design-first/">We Will Not Convince Everyone To Go Api Design First</a></h3>
        <span class="post-date">11 Dec 2019</span>
        ---
published: true
layout: post
title: 'We Will Not Convince Everyone To Go API Design First'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/gears-4882162452-fa3126b38d-b-blue-circuit.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/gears-4882162452-fa3126b38d-b-blue-circuit.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">I believe in going API first. I think it provides a positive step for development teams. I think it is one that makes sense for most enterprise organizations. But if I have learned anything in the last decade of working with APIs is that I rarely get what I want, and people don&rsquo;t always do what is right and what will make sense. I have gotten a lot of pushback from developers, API providers, and service providers regarding the notion that code first API delivery is bad, as well as the idea that API design first is good. For me, the real challenge here isn&rsquo;t about selling folks on one approach or the other, it is more about injecting more stakeholders and communication into the process earlier on in the evolution of APIs, rather than waiting until they are baked into production before iterating upon the design of the interface.</p>
<p class="p1">There are a lot of existing folks who are trained to deliver code across the enterprise landscape. I&rsquo;ve heard repeatedly from folks that they are a programmer, and not a templater, artifactor, or API designer. I get it. We have a lot of momentum occurring based upon the way things have been historically, and I don&rsquo;t doubt that it will be difficult to change our behavior. The challenge here lies around understanding how much of the pushback on API design first is purely about being resistant to change over there being multiple ways to tackle the deliver of an API. I feel pretty confident about there being multiple ways to actually deliver an API, and I don&rsquo;t care if you are mocking it, delivering via a gateway, with a framework, or hand pounding your artisan APIs on the forge in the workshop. I just care that there is as much light on the overall process, as many stakeholders as possible involved, and there is a feedback loop around what the design of the APIs should be. I don&rsquo;t care about it purely being about mock, gateway, or code as much as I care about there being thoughtful consideration of the design&mdash;first!</p>
<p class="p1">I&rsquo;m not convinced everyone will move from code first. If this is the reality, then we will need continued investment in services and tooling that will render OpenAPI and Postman collections in near real time from common frameworks and gateways, as well as there services and tooling that does the reverse and generate mocks, frameworks, and gateways from OpenAPI and Postman collections. Ultimately it shouldn&rsquo;t matter, as long as artifacts are available for required documention, establishing a contract for any API being delivered, providing machine and human readable artifacts that can keep all stakeholders informed. Providing the basis for the feedback loop that should exist between technical and business stakeholders who are invested in the successful API outcomes desired.</p>
<p class="p1">I have been in the business too long to think I&rsquo;m going to convince everyone of the merits of API design first. While I strongly believe the benefits of it far exceed those of a purely gateway or code first, I know that other people will undoubtedly see things differently. This is fine, and I will just work harder to emphasize the importance of introducing observability into the process, and the establishment of feedback loop for all stakeholders. I&rsquo;ll keep working to encourage companies to invest in open source tooling that helps reduce friction no matter which route you choose. While I wish everyone cared about the design of their APIs as much of us analysts, pundits, and architects do, I am not sure we will convince everyone of the merits of API design first, and we will need to accommodate multiple paths to get everyone there, while also keeping our eye out for other newer ways of getting APIs done that might come along in the future.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/12/11/we-will-not-convince-everyone-to-go-api-design-first/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/12/10/my-thoughts-on-amazon-eventbridge-schema-registry-and-discovery/">My Thoughts On Amazon Eventbridge Schema Registry And Discovery</a></h3>
        <span class="post-date">10 Dec 2019</span>
        ---
published: true
layout: post
title: 'My Thoughts ON Amazon EventBridge Schema Registry And Discovery'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/event_bridge_unite_video_thumbnail.64e8041d0d3c919aa503c8376b1fb9ae4dc11dcf.png
---
<p><a href="https://aws.amazon.com/blogs/compute/introducing-amazon-eventbridge-schema-registry-and-discovery-in-preview/"><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/event_bridge_unite_video_thumbnail.64e8041d0d3c919aa503c8376b1fb9ae4dc11dcf.png" alt="" width="40%" align="right" /></a></p>
<p class="p1">My friend Fran M&eacute;ndez (<a href="https://twitter.com/fmvilas">@fmvilas</a>) over at <a href="https://www.asyncapi.org/">AsyncAPI</a> asked me to share my opinions on <a href="https://aws.amazon.com/blogs/compute/introducing-amazon-eventbridge-schema-registry-and-discovery-in-preview/">Amazon&rsquo;s EventBridge schema registry and discovery</a>&nbsp;which is in preview. Something that is looking to be a pretty critical add-on to Amazon EventBridge, which provides a serverless event bus that connects application data from your own apps, SaaS, and AWS services. Event-driven approaches to APIs are growing in popularity for a number of reasons, and is something that is only increasing the need for us to get our schema house in order, resulting in solutions like the schema registry for EventBridge being pretty valuable to general API operations.</p>
<p class="p1">I haven&rsquo;t taken EventBridge for a test drive, so all of my thoughts are purely superficial, but at first glance it looks like something that can have a meaningful impact on how people are making sense of the schema we have floating around, but I think there will be some key elements that will make or break a solution like the schema registry, something Amazon is already thinking about with their code generation from the schema registry. Here are some of the initial thoughts I am having as I read through the announcements and documentation around EventBridge and the schema registry.</p>
<ul class="ul1">
<li class="li1"><strong>JSON Schema Generation</strong> - The auto publishing, diff&rsquo;ing, versioning, discovery, and evolving of JSON Schema representations for all schema in use will be pretty critical in making the registry tangible.</li>
<li class="li1"><strong>Protocol Buffers</strong> - There will need to be easy generation and conversion of Protocol Buffers as part of the process. I don&rsquo;t see that EventBridge supports gRPC or Protocol Buffers, but it was a thought I was having./</li>
<li class="li1"><strong>AsyncAPI Generation</strong> - The schema catalog should automatically generate and version AsyncAPI specifications for all the schema, and ultimately channels and topics being defined as part of EventBridge.</li>
<li class="li1"><strong>Tagging</strong> - Being able to tag schema, organize them, and discover based upon an evolving taxonomy that helps make sense of the expanding schema landscape will be critical when it comes to making it work/</li>
<li class="li1"><strong>HTTP 1.1&nbsp;- </strong>The schema registry shouldn&rsquo;t just be for the real-time and event-driven landscape, and should exist for the AWS API Gateway via CloudTrail, automatically generating JSON Schema and OpenAPI too!</li>
<li class="li1"><strong>Diff Superpowers</strong> - The schema catalog is going to need some serious diff superpowers for understanding and highlighting the difference between schema, allow humans and systems to understand the schema diff.</li>
<li class="li1"><strong>Code</strong> - I think the code binding is an interesting aspect of this and something that will attract developers to the schema registry, allowing them to be more agile and nimble when it comes to evolving the code needed for integrations.</li>
<li class="li1"><strong>Documentation</strong> - The schema registry should be able to easily generate documentation by publishing OpenAPI, AsyncAPI, and JSON Schema, allowing documentation to be automatically delivered as part of the pipeline.</li>
<li class="li1"><strong>Visualizations</strong> - Enterprise organization will need much more meaningful dashboards and visualizations on top of the schema registry, helping them map out the data landscape that is flowing and expanding across the enterprise.</li>
<li class="li1"><strong>Notifications</strong> - There will need to be the ability to be notified when schema changes occur, allowing for the governance of the messages being passed back and forth as part of all our integrations.</li>
<li class="li1"><strong>Testing</strong> - We will need to be able to generate tests from the JSON schema derived as pat of the schema registry, automating and providing quality control for the most critical channels being used across operations.</li>
<li class="li1"><strong>Traceability</strong> - There will need to be deep traceability eventually as part of the schema catalog, being able to understand where a message originated, and the many ways it might have been actually used across operations.</li>
<li class="li1"><strong>Audibility</strong> - The schema catalog should provide the ability to audit an entire organization, or specific teams and lines of business when it comes to their schema footprint, and the velocity at which they operate and evolve.</li>
<li class="li1"><strong>Governance</strong> - The schema catalog has the opportunity to provide a full snapshot of all the data being passed back and forth internal and amongst partners, allowing for companies to begin getting their schema house in order.</li>
<li class="li1"><strong>Regulatory</strong> - There is a huge opportunity for understanding what data is flowing around within enterprises from a regulatory vantage point, making it easier for regulators to have a full few of the schema landscape that exists.</li>
<li class="li1">Discovery - The search for the schema registry will need to be basic for 80% of what people are looking for, and then advanced for the other 20% allowing all stakeholders to paint the picture of the landscape they need.</li>
</ul>
<p class="p1">The EventBridge schema registry reflects my own design for an automated API discovery solution. I don&rsquo;t think we are going to get people to be API design first and thoughtfully craft all of their schema in use across API infrastructure. I think we are going to have to hoover it up from log files and other artifacts left around as part of regular operations. I think the EventBridge schema registry and approach to discovery should be default for all API Infrastructure, not just streaming, event-driven, and message bus solutions. Teams should be able to visit the schema registry and retrieve the artifacts like JSON Schema, OpenAPI, and Async API that they need. They should also be able to gather documentation, tests, and code bindings for all the messages already in motion. The schema registry should be the heartbeat of our operations, providing us with a complete view of the digital bits flowing around the enterprise.</p>
<p class="p1"><a href="https://aws.amazon.com/eventbridge/"><img src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/product_page_diagram_eventbridge_how_it_works.96da753d6591f93925f16716142f98d849c2ee0e.png" alt="" width="100%" /></a></p>
<p class="p1">I&rsquo;ll keep an eye on what is happening with EventBridge. I think it will take some serious tooling to make it something people will put to use. I think people want to get their schema house in order but don&rsquo;t always have the bandwidth and will to actually make something meaningful occur in this area&mdash;this is why API discovery has been so stalled for over a decade. However, with the right automation and tangible tooling like documentation, visualizations, notification, testing, code bindings, and traceability, we might see something like the EventBridge schema registry get more adoption. If you can pipe all your existing channels into the EventBridge and magically come out the other side with a usable registry of all our digital bits, you might see some folks finally begin to get a handle on the growing amount of data that is flowing around the enterprise on any given day.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/12/10/my-thoughts-on-amazon-eventbridge-schema-registry-and-discovery/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/12/10/abstracting-away-api-response-complexity-with-postman-visualizer/">Abstracting Away Api Response Complexity With Postman Visualizer</a></h3>
        <span class="post-date">10 Dec 2019</span>
        ---
published: true
layout: post
title: 'Abstracting Away API Response Complexity With Postman Visualizer'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/test_script.png
---
<p>I was creating <a href="http://apievangelist.com/2019/12/09/validating-twitter-users-using-the-twitter-api-without-writing-code/">a Postman collection for validating the status of Twitter users</a>, where I was looking to extract a subset of data from the very verbose Twitter API response for a Tweet Lookup. There is a lot of data contained within a single Tweet JSON response, and all I was looking for was just a handful of the fields. I thought this would be a great opportunity to show off the new Postman visualizer, where you can display the API response for each request however you want.</p>
<p>To get started I crafted an API request for the Twitter lookup API path, allowing me to pass in up to 100 Twitter user handles, and return a JSON response for all the Twitter users I want to check in on the status of&mdash;leveraging Postman to authorize and see the details of the API response.</p>
<p><img src="https://kinlane-productions2.s3.amazonaws.com/postman-stories/abstracting-away-response-complexity/see-response.png" alt="" width="100%" /></p>
<p>This res[omse has the data I need, but looking through the entire of the JSON response is a lot more than I can ask of many of the people I will be sharing the collection with. I&rsquo;m going to be sharing it with mostly non-developers, hoping to provide them them with a quick way to check the status of various Twitter users, and wading through the JSON is unacceptable, so I used the new Postman visualizer to render an HTML list of only the data I wanted.</p>
<p><img src="https://kinlane-productions2.s3.amazonaws.com/postman-stories/abstracting-away-response-complexity/see-visual-response.png" alt="" width="100%" /></p>
<p>The Postman visualizer allows me to pull only the fields I need and publish as HTML to the visualizer tab. Providing a more human readable view of the Twitter Lookup API response, making the Twitter API more accessible by developers and non-developers who are looking for a quick way to validate the status of one or many Twitter users.</p>
<p>To make this happen, all I did was add a test script to the API request, adding a little JavaScript which takes the JSON response, loop through each user being returned and retrieve only the fields I need, providing a quick snapshot of the status of each of the Twitter users I&rsquo;m question.</p>
<p><img src="https://kinlane-productions2.s3.amazonaws.com/postman-stories/abstracting-away-response-complexity/test-script.png" alt="" width="100%" /></p>
<p>The Postman visualizer tab combined with a little JavaScript provides a pretty sweet vehicle for making sense of API responses. Turning each API request into a little API-driven dashboard element. Allowing me to organize one or more individual API requests into a collection, providing simple HTML visuals that simplifies the data returned from any API. I can think of an endless number of interesting collections I could build on top of the Twitter API, or any other API I want to target with a Postman visualizer enabled collection.</p>
<p>This is a pattern I want to keep applying and evolving. It represents everything I love about APIs. Providing simple, useful API capabilities that anyone can run. Making APIs more accessible to developers, as well as non-developers. While there is still more authentication friction with some of these collections I&rsquo;m producing, I am still happy with the overall ability to package up an API call in this way. Providing shareable and executable machine and human readable units of digital value which makes APIs much more accessible and usable.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/12/10/abstracting-away-api-response-complexity-with-postman-visualizer/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/12/09/validating-twitter-users-using-the-twitter-api-without-writing-code/">Validating Twitter Users Using The Twitter Api Without Writing Code</a></h3>
        <span class="post-date">09 Dec 2019</span>
        ---
published: true
layout: post
title: 'Validating Twitter Users Using The Twitter API Without Writing Code'
image: https://kinlane-productions2.s3.amazonaws.com/postman-tutorials/twitter-status-lookup/see-visual-response.png
---
<p>I was asked on Twitter if I had any code for pulling the status of Twitter users. Since I am the API Evangelist, and the Chief Postman at Twitter I tend to prefer sharing of Postman collections rather than actual language specific code. It is easy for me to craft a single Postman request that accomplishes a specific purpose, then share as a template in the Postman API network, than it is to write code. Plus, any user can then execute on their own within their own local Postman client.  To satisfy this request, and demonstrate how Postman collections work, <a href="/admin/blog/&ldquo;https://documenter.postman.com/view/35240/SWE6aJ7a?version=latest&rdquo;">I created one for looking up the status of a list of any Twitter handle</a>, verifying the state of each individual Twitter user&mdash;providing only the basic information you need to validate one or many different Twitter accounts.</p>
<p>Before you can use this API collection you will have to download the Postman applications, then <a href="/admin/blog/&ldquo;https://developer.twitter.com/en/apps&rdquo;">setup your own Twitter application</a> so that you can make calls to the Twitter API--do not worry, it is painless, and something even a non-developer can do.</p>
<p><img src="https://kinlane-productions2.s3.amazonaws.com/postman-tutorials/twitter-status-lookup/twitter-application.png" alt="" width="100%" /></p>
<p>When filling out the form, all you need is to give your app a name, description, website URL, and tell them how it will be used. You can ignore the rest of the fields. Once the application is added you can obtain your access tokens by clicking on the keys and tokens tab.</p>
<p><img src="https://kinlane-productions2.s3.amazonaws.com/postman-tutorials/twitter-status-lookup/twitter-keys-and-tokens.jpg" alt="" width="100%" /></p>
<p>The first time you create your application you will have regenerate your access token and access token secret, and then you will need all four tokens to authenticate (Don't worry those aren't my real tokens). Once you have your own tokens, go back to your Postman application and click on the Twitter Lookup Postman collection, and edit its details.</p>
<p><img src="https://kinlane-productions2.s3.amazonaws.com/postman-tutorials/twitter-status-lookup/edit-collection.png" alt="" width="100%" /></p>
<p>Once the edit window pops up select the Authorization tab, then select to use OAuth 1.0 and add your auth data to request headers from the dropdown boxes, then add your own , , , and  from the application you setup.</p>
<p><img src="https://kinlane-productions2.s3.amazonaws.com/postman-tutorials/twitter-status-lookup/edit-collection-authorization.png" alt="" width="100%" /></p>
<p>Once you have entered all your tokens you should be able to make a Twitter lookup API request, passing in one or many Twitter handles for the users you'd like to validate the status for--then hitting the send button for the request in Postman.</p>
<p><img src="https://kinlane-productions2.s3.amazonaws.com/postman-tutorials/twitter-status-lookup/make-response.png" alt="" width="100%" /></p>
<p>Once you hit send on the request, with the proper authorization, you will see a full API response from the Twitter API in a JSON format, providing you with all the detail on each user included as part of the API request.</p>
<p><img src="https://kinlane-productions2.s3.amazonaws.com/postman-tutorials/twitter-status-lookup/see-response.png" alt="" width="100%" /></p>
<p>Each Twitter account response is pretty verbose, and requires you to wade through a lot of JSON to find what you are looking for. To help make more accessible to non-developers I made a visualizer response that only shows the relevant information to the status of each account. You can see this by clicking on the visualizer tab for the Postman response.</p>
<p><img src="https://kinlane-productions2.s3.amazonaws.com/postman-tutorials/twitter-status-lookup/see-visual-response.png" alt="" width="100%" /></p>
<p>This Postman collection should allow anyone (developer or non-developer) to work with the Twitter API and make lookups via the Twitter API to validate any Twitter user account. If you have any questions you an ping me on Twitter at [@apievangelist ](https://twitter.com/apievangelist), or via [info@apievangelist.com](mailto:info@apievangelist.com).</p>
<p><a href="/admin/blog/&ldquo;https://documenter.postman.com/view/35240/SWE6aJ7a?version=latest&rdquo;">You can view the basic documentation for this endpoint below, and run using the Run in Postman button in the top-right corner of this documentation</a>. You can also find code samples in a variety of programming languages using the dropdown just below the Run in Postman button, helping you quickly integrate this API capability into your application.</p>
<p>This Postman collection should allow anyone (developer or non-developer) to work with the Twitter API and make lookups via the Twitter API to validate any Twitter user account. If you have any questions on this Postman collection you can ping me on Twitter at&nbsp;@apievangelist&nbsp;, or via&nbsp;info@apievangelist.com.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/12/09/validating-twitter-users-using-the-twitter-api-without-writing-code/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/12/09/twitter-api-authorization-using-postman/">Twitter Api Authorization Using Postman</a></h3>
        <span class="post-date">09 Dec 2019</span>
        ---
published: true
layout: post
title: 'Twitter API Authorization Using Postman'
image: https://kinlane-productions2.s3.amazonaws.com/postman-tutorials/twitter-authorization/twitter-developer.png
---
<p><a href="http://apievangelist.com/2019/12/09/validating-twitter-users-using-the-twitter-api-without-writing-code/">I just created a new Postman collection for validating Twitter users via the Twitter API</a>.<span>&nbsp;</span>As part of the Postman collection documentation and tutorial I included the steps for authorizing with the Twitter API. This is something that can easily be a hurdle for developer, and will definitely run most non-developers off. In reality, setting up your own Twitter API application, then copying your API tokens and use them in a Postman collection is something anyone can accomplish. This is an authorization workflow that I will be referencing in many different Twitter API tutorials and stories on the blog, so I wanted to have as a standalone URL that I could easily share with anyone.</p>
<p>Before you can make any call to the Twitter API you will need to have four application tokens you can only obtain via your own Twitter developer account. The first step of this process is to setup a Twitter developer account which is different than your regular account, and can be done via <a href="https://developer.twitter.com">the Twitter developer portal</a>.</p>
<p><a href="https://developer.twitter.com"><img src="https://kinlane-productions2.s3.amazonaws.com/postman-tutorials/twitter-authorization/twitter-developer.png" alt="" width="100%" /></a></p>
<p>Once you have a Twitter developer account you can <a href="https://developer.twitter.com/en/apps">visit the application listing page</a>, and choose to create a new application in the top corner, and manage any existing application you have already added in the past. Allowing you to manage the details of your access to the Twitter API.</p>
<p><a href="https://developer.twitter.com/en/apps"><img src="https://kinlane-productions2.s3.amazonaws.com/postman-tutorials/twitter-authorization/twitter-application-list.png" alt="" width="100%" /></a></p>
<p>While creating an application there are a number of details you will need to consider, but to jumpstart your API Integration all you will need is the name, description, website URL, and tell Twitter how this app will be used. You can always edit these settings at any point in the future, so do not worry too much about them when getting started.</p>
<p><img src="https://kinlane-productions2.s3.amazonaws.com/postman-tutorials/twitter-authorization/twitter-application-add.png" alt="" width="100%" /></p>
<p>Once you have created your Twitter application you can visit the keys and tokens tab to obtain your consumer API keys as well as the access token and access token secret. Providing the four tokens you will need to actually authorize and make a successful call to the Twitter API using Postman.</p>
<p><img src="https://kinlane-productions2.s3.amazonaws.com/postman-tutorials/twitter-authorization/twitter-application-keys-and-tokens.jpg" alt="" width="100%" /></p>
<p>Now that you have the four tokens you will need to include them in the Postman collection being defined&mdash;for this exercise we will use a <a href="https://documenter.postman.com/view/35240/SWE6adN7?version=latest">basic Twitter Tweet search collection</a> we already have defined. Just click on Run in Postman button in the top right corner of the Twitter Tweet Search collection, and load the collection into your Postman client.</p>
<p><a href="https://documenter.postman.com/view/35240/SWE6adN7?version=latest"><img src="https://kinlane-productions2.s3.amazonaws.com/postman-tutorials/twitter-authorization/twitter-tweet-search.png" alt="" width="100%" /></a></p>
<p>Once the collection is loaded in your Postman application, you can click on the collection and choose to edit the settings for the entire collection, which is the first step in defining how you will authorize with the API.</p>
<p><img src="https://kinlane-productions2.s3.amazonaws.com/postman-tutorials/twitter-authorization/edit-postman-collection.png" alt="" width="100%" /></p>
<p>Once the edit collection window pops up you can select the Authorization tab to choose OAuth 1.0 as the type of authorization, and Add auth data to Request Headers from both available dropdown. Then you can add four separate variables for your <strong>Consumer Key</strong> , <strong>Consumer Secret </strong>, <strong>Access Token</strong> , and <strong>Token Secret </strong>.<span>&nbsp;</span></p>
<p><img src="https://kinlane-productions2.s3.amazonaws.com/postman-tutorials/twitter-authorization/edit-postman-collection-authorization.png" alt="" width="100%" /></p>
<p>These variables will be applied across every request within the collection, but we will need to add a new environment that define these variables for us, and abstract away our tokens from the Postman Tweet Search collection, allowing us to use the same tokens across many different collections.</p>
<p><img src="https://kinlane-productions2.s3.amazonaws.com/postman-tutorials/twitter-authorization/add-postman-environment.png" alt="" width="100%" /></p>
<p>While editing our new environment we can give it a name, and add four separate variables for each of our tokens we used as part of our authorization, including {consumer_key}}, , , and , adding the values from the Twitter applications we have already setup above.</p>
<p><img src="https://kinlane-productions2.s3.amazonaws.com/postman-tutorials/twitter-authorization/define-token-variables.png" alt="" width="100%" /></p>
<p>Now we just need to make sure each API request we have in our collection inherits authorization from the collection, which will apply our Twitter environment variables to the authorization for each requestr I add to this collection.</p>
<p><img src="https://kinlane-productions2.s3.amazonaws.com/postman-tutorials/twitter-authorization/request-inherit-authorization.png" alt="" width="100%" /></p>
<p>Then you can go ahead and make the API request, searching for Tweets via the Twitter API, changing the query parameter to contain the search term or phrase you wish to search the API, and see the JSON response in the Postman browser.</p>
<p><img src="https://kinlane-productions2.s3.amazonaws.com/postman-tutorials/twitter-authorization/make-request.png" alt="" width="100%" /></p>
<p>That should provide you with everything you need to authorize with the Twitter API using OAuth 1.0 within a Postman collection, while also properly abstracting away the Twitter authorization tokens using a Postman environment. Keeping your secrets centralized and then applied across each collection, and each of the individual requests you are making.</p>
<p>If you have any questions about this Postman collection you can Tweet at me via @apievangelist or email me for <a href="mailto:info@apievangelist.com"><span class="s1">info@apievangelist.com</span></a> to establish a more private channel to discuss the way this collection works.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/12/09/twitter-api-authorization-using-postman/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/12/09/a-postman-meetup-this-tuesday-in-seattle/">A Postman Meetup This Tuesday In Seattle</a></h3>
        <span class="post-date">09 Dec 2019</span>
        ---
published: true
layout: post
title: 'A Postman Meetup This Tuesday In Seattle'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/rain_princess_img_8374.jpg
---
<p><a href="https://www.eventbrite.com/e/postman-seattle-meetup-tickets-81807834435"><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/rain_princess_img_8374.jpg" alt="" width="40%" align="right" /></a></p>
<p>I am all recovered from being at AWS re:Invent all week in Las Vegas, and gearing up for <a href="https://www.eventbrite.com/e/postman-seattle-meetup-tickets-81807834435">a Postman meetup in Seattle this Tuesday</a>. I am stoked to be doing ane vent on my home turf, but I am aslo pretty happy with the lineup. I am going to be opening things off with a quick look at Postman collections, but then I have Tableau and NGINX giving some talks, and then a quick closing with a look at the Postman visualizer--here is the lineup for Tuesday nights goings on.</p>
<p class="p1" style="padding-left: 30px;"><strong>Postman API Collections</strong></p>
<p class="p1" style="padding-left: 30px;">Kin Lane (<a href="https://twitter.com/kinlane">@kinlane</a>), Chief Evangelist @ Postman</p>
<p class="p1" style="padding-left: 30px;">You save your Postman requests as collections each day, but have you learned about all the ways in which collections can be applied? Let&rsquo;s move beyond just reference collections for every endpoint in your API and making collections reflect the real world business use cases your APIs solve. Pushing your Postman collections to me more intuitive and useful for your developers, helping on-board them with the possibilities while also documenting what your APIs can do, providing portable, shareable, machine readable, and executable representations of what your APIs deliver.</p>
<p class="p1" style="padding-left: 30px;"><strong>How Tableau uses Postman to enable developers</strong></p>
<p class="p1" style="padding-left: 30px;">Geraldine Zanolli a.k.a Gigi (<a href="https://twitter.com/illonage">@illonage</a>) Developer Advocate @ Tableau</p>
<p class="p1" style="padding-left: 30px;">Tableau , well-known in the Business Intelligence industry for building great data visualizations, also offers a set of APIs and Developer Tools that allow developers to integrate, customize, automate, and extend Tableau to fit the specific needs of their organization. Learn how Tableau uses Postman to give developers an interface to do their first API request.</p>
<p class="p1" style="padding-left: 30px;"><strong>The NGINX API Gateway</strong></p>
<p class="p1" style="padding-left: 30px;">Liam Crilly (<a href="https://twitter.com/liamcrilly">@liamcrilly</a>),<span>&nbsp;</span>Director of Product Management @ NGINX</p>
<p class="p1" style="padding-left: 30px;">APIs are changing the way we build applications and changing the way we expose data, both inside and outside our organizations. But what is the most efficient and effective way to deliver these APIs? That&rsquo;s the job of the API gateway. In this session, we will look at different deployment patterns for API gateways, including:<span>&nbsp;</span></p>
<blockquote>
<p>- The centralized, edge gateway&nbsp;<br />- The multi-layer gateway&nbsp;<br />- Microgateways, sidecars and service mesh &nbsp;</p>
</blockquote>
<p class="p1" style="padding-left: 30px;">We discuss how software architecture, deployment practices, and security governance all influence the selection of the most appropriate API gateway pattern.</p>
<p class="p1" style="padding-left: 30px;"><strong>Postman Visualizations</strong></p>
<p class="p1" style="padding-left: 30px;">Kin Lane (<a href="https://twitter.com/kinlane">@kinlane</a>), Chief Evangelist @ Postman</p>
<p class="p1" style="padding-left: 30px;">Let&rsquo;s explore Postman&rsquo;s latest feature&mdash;visualizer. Don&rsquo;t just view API responses in JSON or XML, and use the visualizer tool to leverage any JavaScript visualization library to render your API responses as HTML tables, lists, bar charts, heat maps, tag clouds, or any other visualization you can imagine. Spend some more time with Kin Lane for an introduction into how you can begin to visualize data returned from APIs, making your Postman collections much more visually pleasing, while also making them accessible to business users who aren&rsquo;t afraid of getting downloading and putting Postman to work.</p>
<p class="p1">If you are in Seattle, come out and talk. I'll be sharing my first talk on Postman since joining the team. I'd love to hang out and talk APIs with you. I am hoping this is first of several API related events in Seattle. There is a lot of API related activity in the area, and I'm looking to get more in tune with where things are going. I look forward to seeing you all Tuesday evening--<a href="https://www.eventbrite.com/e/postman-seattle-meetup-tickets-81807834435">make sure and get registered, as we have limited space</a>, and things are already filling up.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/12/09/a-postman-meetup-this-tuesday-in-seattle/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/12/02/we-will-not-discuss-apis-without-a-postman-collection/">We Will Not Discuss Apis Without A Postman Collection</a></h3>
        <span class="post-date">02 Dec 2019</span>
        ---
published: true
layout: post
title: 'We Will Not Discuss APIs Without A Postman Collection'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/stalin-time-chess-in-the-park-with-pigeons.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/stalin-time-chess-in-the-park-with-pigeons.jpg" alt="" width="40%" align="right" /></p>
<p>I heard a story this morning while having breakfast with someone at the Venetian before I made my way to the re:Invent registration counter which reminded me of t<a href="https://apievangelist.com/2012/01/12/the-secret-to-amazons-success-internal-apis/">he now infamous secret to Amazon&rsquo;s API success myth story</a>. I can&rsquo;t mention the company involved because they are pretty confident they&rsquo;d never get approval to tell this story publicly, but as I so often do, I still feel it is worth telling even in an anonymous way. Internal groups at this company were having such a problem around coherently discussing the details of APIs between internal groups, that they made a rule that they will not talk with other teams about any API without there being a Postman collection present (ha, Postman mediator) to facilitate the conversation.</p>
<p>There has been several stories on this blog about the problems with emailing API responses between teams, and sending Microsoft Word documents with XML or JSON responses embedded in them. If you work within the enterprise you know that this is a common way to share API responses, and get guidance, ask questions, and generally discuss the details of each API being put to use. Imagine if all of this was banned, and if you had a question about the details of making an API request or parsing the response, it was mandatory to provide a Postman collection of each API request and response in question. Ensuring that ALL the details of the request with a real-life example of the response was present before any discussion would commence. Talk about a game changer when it comes to making sure people were on the same page when it came to discussing some very abstract concepts.</p>
<p>Ensuring team members are all on the same page when it comes to what an API is, let alone the endless number of details regarding query parameters, headers, authentication and other details takes a lot of work. Even if all stakeholders in a conversation are up to speed on the same API, understanding the different contexts in which each API can be executed takes a lot of communication. Why bother? Just bake every bit of that detail into a Postman collection, then share that collection to a workspace team members have access to, or directly provide them a link to the collection, and let the collection do all the talking. GET requests are easier to share, but once you get to the details involved within a POST, PUT, DELETE, or other request, you are going to need to make sure all the headers, body, and other details are present, otherwise the person you are speaking with will be lost&mdash;something that is extremely common in the API space, and is preventable using a Postman collection.</p>
<p>I like the concept of requiring all API stakeholders to communicate using a Postman collection. If you have a specific question about why this API request isn&rsquo;t working, share exactly the same request you are making with me before I will respond. If you are seeing something in the API response that shouldn&rsquo;t be there, then share the API request with me as a collection so I can see the response you are talking about. There is no reason why we should be going back and forth via email sharing XML and JSON responses&mdash;this isn&rsquo;t the best medium to get our point across. Require your technical and non-technical stakeholders to always provide a Postman collection when they are talking about a specific API and ensure everyone is on the same page before getting to work moving the conversation forward. I love that Postman collections provide this kind of foundation for how we communicate and collaborate around our digital capabilities, making all of our lives easier along the way.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/12/02/we-will-not-discuss-apis-without-a-postman-collection/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/12/02/mock-aws-services-using-postman-collections-with-examples/">Mock Aws Services Using Postman Collections With Examples</a></h3>
        <span class="post-date">02 Dec 2019</span>
        ---
published: true
layout: post
title: 'Mock AWS Services Using Postman Collections With Examples'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/mock_api_postman.jpeg
---
<p><a href="https://learning.postman.com/docs/postman/mock-servers/setting-up-mock/"><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/mock_api_postman.jpeg" alt="" width="40%" align="right" /></a></p>
<p class="p1"><a href="https://github.com/api-evangelist/aws">As I create each of the 50+ Postman collections for AWS services</a> I am always striving for establishing as complete of a collection I as possibly can&mdash;this includes having examples for each API request being defined. This is something that is easier said than done, as there are many different ways in which you can setup your AWS infrastructure, and work with your infrastructure using AWS APIs, but nonetheless, I still strive for ensuring there is an example saved as part of each Postman collection. While this helps me better define each request, there are numerous benefits from having API examples, and one of the most beneficial of these is being able to generate mock APIs from the AWS Postman collections I&rsquo;m publishing.</p>
<p class="p1">Taking a look at <a href="https://github.com/api-evangelist/aws/tree/master/dynamodb">the Postman collection I have published for Amazon DynamoDB</a>, I have managed to save examples for each of the API requests documented as part of the AWS reference Postman collection. This makes it so anyone can run the Postman collection within their own Postman platform account, and then generate a mock server for the Amazon DynamoDB API. Allowing developers to develop against the API without actually having to use a live AWS account, have the proper infrastructure and permissions setup, making it quicker and easier to jumpstart the development of desktop, web, and mobile applications. Allowing developers to publish their own mock servers for AWS services, and save time and money when it comes to your AWS budget.</p>
<p class="p1">I can envision developing AWS Postman collections that are complete with examples derived from specific AWS infrastructure deployments. Tailoring a specific setup and configuration, then making API requests to the AWS APIs needed for orchestrating against these existing infrastructure configurations, and saving the examples return from each API response. Essentially taking a snapshot of an existing AWS setup across multiple services, then making that snapshot available as a mocked set of AWS APIs that return the responses developers are needing when building specific application or integration. Using Postman to on-board developers with a specific architectural implementation, while also enabling development against the implementation via APIs without having to actually work with a live production environment, which impacts your overall project costs and AWS bill.</p>
<p class="p1">The notion of having mocks instances of the common AWS APIs I depend on is pretty valuable, but having mock instances as well as Postman collections for common ways that I setup infrastructure on AWS is even more interesting. This all begins to look a little like Ansible and Terraform for me, but for developers who just get API and don&rsquo;t understand these newer ways to deliver and manage infrastructure. Allowing developers to organize many different AWS units of compute they execute regularly, and reuse them across many different projects.<span>&nbsp;</span>I can see these types of Postman collections used to help developers manage their AWS infrastructure, but also be used to on-board new developers to existing ways of delivering infrastructure on AWS&mdash;providing a sort of templating approach to spinning up, managing, tearing down, and managing costs on AWS.</p>
<p class="p1">As part of my week at re:Invent I am going to be working on different AWS API implementations using the reference Postman collections I have crafted. I am working to define Postman collections that help deploy and manage APIs on AWS. I wanted to create reference Postman collections to highlight what you can do with AWS APIs using Postman, but I wanted to quickly be able to demonstrating other more interesting ways you can use these collections. Mocking AWS services using Postman collections represents a pretty compelling use case, especially if you pre-populate it with examples that are actually relevant to how you deliver AWS infrastructure, allowing system integrators and application developers more rapidly deliver their work, without incurring AWS charges, using mocked APIs deployed from AWS Postman collections. I will keep playing around and seeing what other useful examples of how you can use Postman to streamline and automate your AWS operations.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/12/02/mock-aws-services-using-postman-collections-with-examples/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/12/02/grpcs-potentially-fatal-weakness/">Grpcs Potentially Fatal Weakness</a></h3>
        <span class="post-date">02 Dec 2019</span>
        ---
published: true
layout: post
title: 'gRPCs Potentially Fatal Weakness'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/bf-skinner-old-broken-piano-street.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/bf-skinner-old-broken-piano-street.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">I was reading <a href="https://devblogs.microsoft.com/aspnet/grpc-vs-http-apis/">an article on Microsofts DevBlog about gRPC vs HTTP APIs</a>. It makes the usual arguments of how gRPC compares with HTTP APIs. While the arguments for gRPC are definitely compelling, I find the weaknesses of gRPC in this moment in time even more interesting, for two reasons, 1) they are something we can overcome with the right tooling and services, and 2) they reflect our challenge between the human and machine readablity of all of this, which many of us technologists really suck at, leaving me concerned whether or not we will be able to get this right&mdash;as I think we underestimated this characteristic of HTTP APIs, and have missed the full potential of this opportunity even as we are faced with this next step.</p>
<p class="p1">Here is what was said the blog post, highlighting two distinct weaknesses of gRPC, but which I view as more about systemic illnesses in the wider view of the API landscape, and our inability to understand the important role that humans play in all of this:</p>
<blockquote>
<p class="p1"><strong>Limited browser support</strong></p>
<p class="p1">gRPC has excellent cross-platform support! gRPC implementations are available for every programming language in common usage today. However one place you can&rsquo;t call a gRPC service from is a browser. gRPC heavily uses HTTP/2 features and no browser provides the level of control required over web requests to support a gRPC client. For example, browsers do not allow a caller to require that HTTP/2 be used, or provide access to underlying HTTP/2 frames.</p>
<p class="p2">gRPC-Web&nbsp;is an additional technology from the gRPC team that provides limited gRPC support in the browser. gRPC-Web consists of two parts: a JavaScript client that supports all modern browsers, and a gRPC-Web proxy on the server. The gRPC-Web client calls the proxy and the proxy will forward on the gRPC requests to the gRPC server.</p>
<p class="p1">Not all of gRPC&rsquo;s features are supported by gRPC-Web. Client and bidirectional streaming isn&rsquo;t supported, and there is limited support for server streaming.</p>
<p class="p1"><strong>Not human readable</strong></p>
<p class="p1">HTTP API requests using JSON are sent as text and can be read and created by humans.</p>
<p class="p1">gRPC messages are encoded with Protobuf by default. While Protobuf is efficient to send and receive, its binary format isn&rsquo;t human readable. Protobuf requires the message&rsquo;s interface description specified in the&nbsp;.proto&nbsp;file to properly deserialize. Additional tooling is required to analyze Protobuf payloads on the wire and to compose requests by hand.</p>
<p class="p1">Features such as&nbsp;server reflection&nbsp;and the&nbsp;gRPC command line tool&nbsp;exist to assist with binary Protobuf messages. Also, Protobuf messages support&nbsp;conversion to and from JSON. The built-in JSON conversion provides an efficient way to convert Protobuf messages to and from human readable form when debugging.</p>
</blockquote>
<p class="p2">Both of these weaknesses reflect the importance of humans still playing such a critical role in not just developing APIs, but also consuming them. We like to focus on the machine readability, automation, orchestration, and other ways in which APIs allow us to scale, but none of this happens without a human setting it into motion. If this activity is just limited to a small subset of technological wizards, it will only take us so far. Taking us back to my first point, we can get to work on providing client tooling for working with gRPC APIs&mdash;this will alleviate a lot of friction. However, we have to ask ourselves, with each additional step we take forward with APIs, or I guess even steps sideways, why aren&rsquo;t we investing more in the approaches being more human readable by default?</p>
<p class="p1">Like hypermedia, GraphQL, we will need to find ways to reduce the cognitive load with understanding what an API does, and minimize on-boarding friction with evolution in API tooling and services. However, this will still only get us part of the way there when it comes to on-boarding the masses of enterprise and startup developers who don&rsquo;t always care about learning all the technical details, and doing the heavy lifting to understand best practice when providing and consuming APIs. I know that somehow we think eventually we will be able to automate the human out of the equation. I mean c&rsquo;mon, gRPC does a whizz bang job of generating client libraries! But, in the end we are always going to need humans involved when providing and consuming APIs, and we need the APIs themselves to still be accessible to these human beings, even if everything is machine readable.</p>
<p class="p1">In my opinion there are two forces here: 1) business leaders and investors blind belief in technology and the faith that we will be able to automate out the human in this equation, which is the most costliest and problematic, and achieve some sort of capitalist nirvana, and 2) technologists lack of understanding of what it takes to operate business at scale, the human capital it takes, and our own lack of faith in human beings&mdash;both sides blindly believe the technology will get us out of the mess we find ourselves in. In the end, this allows us to overlook the importance of APIs being simple, human readable, and accessible to the widest possible developer and business audience as possible. Something that has been front and center with HTTP APIs, but with GraphQL, gRPC, and event-driven approaches we seem still overlook and underestimate&mdash;that humans are the essential ingredient in everything we do with APIs.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/12/02/grpcs-potentially-fatal-weakness/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/12/01/i-am-heading-to-vegas-for-aws-reinvent/">I Am Heading To Vegas For Aws Reinvent</a></h3>
        <span class="post-date">01 Dec 2019</span>
        ---
published: true
layout: post
title: 'I Am Heading To Vegas For AWS re:Invent'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/aws_reinvent_2019_las_vegas.png
---
<p><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/aws_reinvent_2019_las_vegas.png" alt="" width="40%" align="right" /></p>
<p class="p1">I&rsquo;m sitting in the Seattle airport waiting for my flight to Las Vegas. I&rsquo;m heading to AWS re:Invent, spending the entire week talking everything APIs with the masses at the flagship conference. It is my 3rd time in Vegas for re:Invent, but my first time exhibiting with such a strong brand&mdash;<a href="https://www.postman.com/">Postman</a>. Like years before, I will be there to talk to as many people as I can about how they are delivering APIs, and learning about the challenges they face when consuming APIs. However, this year I won&rsquo;t just be there as a representative for API Evangelist&mdash;this year I am there to help also talk about the role Postman plays in the delivery and consumption of APIs.</p>
<p class="p2">To get fired up for the conference I&rsquo;ve spent the last couple of weeks developing Postman collections for as many AWS APIs as I could&mdash;I had set 25 services as my target, <a href="https://github.com/api-evangelist/aws">and managed to a little more than 50 separate services defines as reference Postman collections</a>. I learned a lot throughout the process, assisting me in loading up a whole lot of details about common AWS API infrastructure into my brain, helping me prime my brain for conversations I will be having at re:Invent. Helping not just think deeply about AWS services, but also how Postman can be used to work with AWS APIs.</p>
<p class="p2">These Postman reference collections are just the foundation for my API understanding, API conversations, and other ways of considering how AWS APIs impact how we deliver applications in the cloud. While the AWS Postman collections help jumpstart anyones usage of AWS, I&rsquo;m also looking at how to use them to actually define, deploy, manage, and evolve APIs that operate on AWS. AWS APIs have long fascinated me, and have played a significant role in my evolution as the API Evangelist, In 2020 I&rsquo;m still keen on learning from AWS as an API pioneer, but I am more interested in learning how we can automate and orchestrate across the API life cycle using AWS APIs.</p>
<p class="p2">If you are at re:Invent this week come on by the Postman booth in the exhibit hall. I will be there for the next five days engaging with folks coming by the booth to talk about everything APIs. I&rsquo;d love to learn more about how you are using Postman, but I&rsquo;m also interested in your overall API journey, and how you provide and consume APIs. I&rsquo;d love to hear more about how you are using Postman and AWS as part of your API life cycle. I&rsquo;d also like to learn what you are hoping to learn more about at AWS, and what new things you are looking to invest in when it comes to API operations&mdash;anything from serverless to Kubernetes. I won&rsquo;t be speaking at AWS., or attending any sessions, so if you want to find me, the booth is where I&rsquo;ll be--come on by and share your story!</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/12/01/i-am-heading-to-vegas-for-aws-reinvent/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/11/27/i-am-happy-i-chose-the-term-evangelism/">I Am Happy I Chose The Term Evangelism</a></h3>
        <span class="post-date">27 Nov 2019</span>
        ---
published: true
layout: post
title: 'I Am Happy I Chose The Term Evangelism'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/aws-s3-stories-ellis-island-nazi-poster.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/aws-s3-stories-ellis-island-nazi-poster.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">There is always lot of discussion around the proper term to use for describing what it is we all do when it comes to getting the word out about our APIs. Some of use use the word evangelism, while others prefer to use advocacy, relations, or being an ambassador or champion. Sometimes it is focused on APIs, but other times it is focused on developers or other aspect of what we are looking to highlight. While there are many &ldquo;announced&rdquo; reasons why we evangelize, advocate, and champion, the real honest reason is always that we want to bring attention to our products and services. Sure, in some cases we are interested in educating and supporting developers, but really all of this is about bringing attention to whatever we are peddling&mdash;me included.</p>
<p class="p1">I didn&rsquo;t grow up religious&mdash;the opposite actually. I never went to a church ceremony until I was an adult. So the term evangelism doesn&rsquo;t carry a lot of baggage for me. However, I do fully understand that it does for many other people. Even though I didn&rsquo;t go to church, I did grow up around enough people who were very religious to understand the meaning evangelism can bring to the table. Early on in doing API Evangelism I felt somewhat bad for using this term, and felt like I was bringing a whole lot of unnecessary meaning and baggage to the table as I was trying to &ldquo;enlighten&rdquo; folks of the API potential. Now, after a decade of doing this, I&rsquo;m happy I chose the term evangelism, because I feel it best represents what it is I do in this technology obsessed world we have created for ourselves.<span>&nbsp;</span></p>
<p class="p1">Technology is the new religion for many people. You know what two of the fastest growing areas of APIs are? Blockchain and churches. When you have so many people blindly believing in technology, it begins to look and smell a lot like religion. When you embark on missions as a technology company to convert people to your ideology, it begins to look and smell a lot like religion. When you have people believing that you eventually there will be a higher consciousness to emerge from technology, and that we will be able to &ldquo;upload&rdquo; our own consciousness to the Internet&mdash;it is a religion. We are evangelists. I&rsquo;m not in denial of what I do. I am pretty confident that this isn&rsquo;t advocacy or championing, this is straight up religious evangelism&mdash;&ldquo;the spreading of the Christian Technological gospel by public preaching or personal witness&rdquo;.</p>
<p class="p1">So what now? IDK. Keep evangelizing. There is no stepping away now. We have opened Pandora&rsquo;s box. Technology is everywhere. My belief is that we keep working to educated the masses about technology, but make sure we are doing it in an ethical way? That word already seems so co-opted and abused, but ok. We keep pushing back on technology providers to be more observable, and respect the human beings that are putting these technology platforms to work. There is no stepping away at this point. I am totally complicit in this hustle, even though I can now see it for what it is. This is one of the reasons I&rsquo;m glad I&rsquo;m now branded with the term evangelism, because it perpetually reminds me of what I stand for, what I&rsquo;ve contributed to, and how much work I have in the future to redeem myself for my sins.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/11/27/i-am-happy-i-chose-the-term-evangelism/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/11/27/bulk-updating-my-postman-collections-using-the-postman-api/">Bulk Updating My Postman Collections Using The Postman Api</a></h3>
        <span class="post-date">27 Nov 2019</span>
        ---
published: true
layout: post
title: 'Bulk Updating My Postman Collections Using The Postman API'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/aws-s3-square-file-00-00-35-50-los-angeles-square.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/aws-s3-square-file-00-00-35-50-los-angeles-square.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">I had recently pulled all of the AWS Postman collections I have created and spread across Postman workspaces. <a href="https://github.com/api-evangelist/aws">After creating over 50 AWS Postman collections</a> I learned some things along the way, and realized I needed to update my variable for the baseURL of each API, but I had already created all my collections, and to update these variables manually would take me hours, if not days. So I got to work writing a script that would pull the latest JSON for each collection, conduct a find and replace on the  replacing it with a service specific base url that went something like this , then write back using the Postman API. This is something that would take me many hours to update across 50+ collections and nearly 1000 individual requests, but is something that I could accomplish in less than an hour with the Postman API.</p>
<p class="p1">Once again, when I can&rsquo;t get what I need to quickly in the Postman UI, I can quickly get things done using the Postman API. This is how it should be. I don&rsquo;t expect that the Postman UI keep pace with all of my needs. I like Postman as it is, and carefully plodding forward adding features that make sense to as wide of an audience as possible. I always know that I can get at what I need through the API, and automate the changes I need. In this case, I&rsquo;m able to rapidly make updates at scale across many different API collections, relying on Postman to help me manage API definitions manually through the interface and in many different automated ways via their API.</p>
<p class="p1">I am still getting my bearings when it comes to managing the variables I use across my many Postman collections. I am rapidly iterating upon how I name my variables for maximum flexibility within Postman environments, and where I apply them within my Postman collections. This is something that requires a lot of tweaking and changing of variables and how they are applied, which would not be possible through the Postman interface. This is fine. I don&rsquo;t fully understand the nature of changes I am goin to have to make at every turn, and there is no way I can expect Postman to accommodate this type of development. Making the Postman an indispensable tool for helping me better define and execute my many different Postman collections.</p>
<p class="p1">APIs are designed to act as a pressure relief valve for the feature road map of the applications they power. We can&rsquo;t expect every application to meet each of our needs, but we can expect every application to have an API. They are essential to how we put software to work, and represent the full potential of any digital resource or capability that we are putting to work as part of our operations. For me, the Postman API is what makes Postman such a powerful tool. I spend a significant portion of my in the Postman UI, but increasing it is the Postman collections, and the Postman API that are dominating most of my time. Allowing me to make bulk updates across my API infrastructure, increasing the power and flexibility of the APIs I am leveraging as part of my work.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/11/27/bulk-updating-my-postman-collections-using-the-postman-api/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/11/26/so-you-wanna-build-an-ipaas-solution/">So You Wanna Build An Ipaas Solution</a></h3>
        <span class="post-date">26 Nov 2019</span>
        ---
published: true
layout: post
title: 'So You Wanna Build An iPaaS Solution'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/docks-docks-copper-circuit.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/docks-docks-copper-circuit.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">I&rsquo;m getting more emails and DMs from startups doing what I&rsquo;d consider to be <a href="http://ipaas.apievangelist.com/">integration platform as a service (iPaaS) solutions</a>. These are services that help developers or business users integrate using multiple APIs. Think IFTTT or Zapier. I&rsquo;ve seen many waves of them come, and I&rsquo;ve seen many waves of them go away. I&rsquo;m always optimistic that someone will come along and make one that reflects my open API philosophy and still can make revenue to support itself. So far, Zapier is the closest one we have, and I&rdquo;m sure there are others, but honestly I&rsquo;ve grown weary of test driving new ones, and I am not as up to speed as I should be on what&rsquo;s out there.<span>&nbsp;</span></p>
<p class="p1">When it comes to iPaaS providers the bar is pretty high to convince me that I should be test driving your solution, and why I should support you in the long run. This is partly from just having supported so many services over the years, only to have them eventually go away. It is also because of new problems for consumers being introduced into the mix because of the abstracting away of the complexities of APIs, rather than joining forces to educate and fixes these complexities amongst API providers. I&rsquo;m always willing to talk with new iPaaS providers that come along, but I have a few requirements I like to put out there which usually filters the people who end up reaching out and engage from those who do not.</p>
<ul>
<li><strong>Due Diligence -</strong> Make sure you are testing driving and reviewing as many existing iPaaS platforms as you possibly can, because there are a lot of them, and the more you kick the tires on, the more robust and valuable your solution will be.</li>
<li><strong>API Definitions -</strong> Your solution needs to be API definition driven, adopting OpenAPI, Postman collections, and existing formats for defining each of the APIs you are integrating with, as well as mapping between multiple services.</li>
<li><strong>API Extensions </strong>- If the existing API definitions do not deliver what you need to sufficiently map your integrations then learn how to extend them, augment them, and work to evolve the existing specifications to meet your needs.</li>
<li><strong>Visualized Experience</strong> - Most of the new iPaaS providers I am talking with are focused on providing slick new visual tooling for defining integration&mdash;which I fully support but do not unnecessarily abstract away what really happens behind.</li>
<li><strong>Quick Code View </strong>- iPaaS tools should work for business users and developers, allowing both to easily click &ldquo;view source&rdquo; and see what is happening behind the scenes, being able to view either the code or artifacts behind each integration.</li>
<li><strong>Work With API Providers </strong>- Reach out and build relationships with the API providers you are build on top of. You won&rsquo;t be able to in all cases but you should try to reach out to them and establish some sort of relationship with your supply chain.</li>
<li><strong>Have An API -</strong> Do not build your business on top of APIs and not publish your own API. This is an unforgivable sin in my book, and will mean that you never quite see eye to eye with your API providers or your API consumers.</li>
<li><strong>Licensing</strong> - Don't be locking up workflows in some restrictive licensing, keeping everything open, sharable, and reusable across the API economy.</li>
</ul>
<p class="p1">That is my shortlist when it comes to what I need to see when you are building your iPaaS platform. I have plenty of other requirements, but this should let folks pre-filter before reaching out to me. So far, the ones I spoke with are meeting these requirements. However after talking with <a href="https://www.linkedin.com/in/trentmccann/?originalSubdomain=ca">my co-worker Trent McCann, the Engineering Manager for Quality at here at Postman</a>, and he had some opinions. For the record Trent<span>&nbsp; </span>has <em>&ldquo;lots of thoughts (opinions), not always valid but I tend to share them none the less&rdquo;</em>&mdash;regardless, I fee like they needed stating:</p>
<ol>
<li>Back in the day when WYSIWYG editors rolled onto the scene, they would put in all kinds of garbage code, even though it was never needed. So messy to look at and do anything with manually. Hate to see something like this happen again, just in another form.</li>
<li>You end up in ecosystems where you are totally at the mercy of the vendor. There is no code or little code to work in and even if there is, you may not have people with the skill sets to do much with it.</li>
</ol>
<p class="p1">I agree 100%. I&rsquo;d say the abstracting away of the API experience can begin to have a negative impact just like the WYSIWYG world as Trent points out. We need more web literacy. We need more API literacy. We need cleaner APIs from API providers. We DO NOT need garbage abstracted away, or as Trent says generated as part of new integrations with APIs&mdash;there is too much garbage out there already. Trent is spot on when it comes to his concerns. We need more investment in API providers delivering high quality easy to use APIs, and we need more investment in API consumers who are aware of common practices, while still also providing high quality visual / UI based services and tooling for integrating and daisy chaining APIs together.</p>
<p class="p1">If you are building a new iPaaS solution feel free to reach out&mdash;if you want to hear my thoughts that is. If you don&rsquo;t, I understand, feel free to email or tweet your solution at me and I&rdquo;ll add to my queue of services to test drive at some point. I wish you the best o luck in your work. Also, I recommend also taking a look at <a href="https://www.postman.com/collection">Postman collections</a>, as well as Postman <a href="https://learning.postman.com/docs/postman/collection-runs/starting-a-collection-run/">runners</a> and <a href="https://learning.postman.com/docs/postman/monitors/intro-monitors/">monitors</a>, and think about how you can incorporate these existing mechanisms into your work. Partly it is my job to recommend you do this, but mostly it is because we have 8M+ developers you can tap when it comes to delivering your integration solution. If your solution is already Postman collection defined, using the machine readable definition as a unit of compute in your API integration workflow, you are going to immediately be useful to our developers right out of the gate, which will help with that adoption curve of yours, which is always one of my biggest concerns with new iPaaS providers.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/11/26/so-you-wanna-build-an-ipaas-solution/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/11/26/pulling-all-my-postman-collections-using-the-postman-api/">Pulling All My Postman Collections Using The Postman Api</a></h3>
        <span class="post-date">26 Nov 2019</span>
        ---
published: true
layout: post
title: 'Pulling All My Postman Collections Using The Postman API'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/postman_api_all_collections_docs.png
---
<p><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/postman_api_all_collections_docs.png" alt="" width="40%" align="right" /></p>
<p class="p1">I needed access to <a href="https://github.com/api-evangelist/aws">all of the AWS Postman collections</a> I am building. The problem is they are distributed across multiple different workspaces. I had organized over 50 AWS Postman collections based upon the resource they were making available. Now I just wanted a list of all of them, and report on what I have done. It sounded like a good idea to group them by resource at first, but now that I needed to work with all of them in a single list, I&rsquo;m thinking maybe not. So I got to work pulling all of my collections from <a href="https://docs.api.postman.com/?version=latest#intro">the Postman API</a> and filtering out any collection that wasn&rsquo;t from AWS.</p>
<p class="p1">I find it easy to get caught up in what features are available to me via the interface of the services and tooling I use, letting the UI define what is possible. This is why I only use services and tooling that have APIs if I can help it&mdash;as the API is always the relief valve for allowing me to get done what I need. In this case, while very robust, I couldn&rsquo;t get everything I needed done with the Postman UI in the time period required, so I switched to the API, and was able to programmatically get at the data I needed. Allowing me to pull all of my collections from across workspaces, then organize and generate exactly the list of collections I needed for a specific report I&rsquo;m working on.</p>
<p class="p1">While talking with folks about Postman I regularly encounter individuals who speak about the limitations in the product, stating they couldn&rsquo;t use it to accomplish something because it didn&rsquo;t do this or that. Without ever considering that they could accomplish it via the API. Personally, I am impressed at how thoughtful Postman has been about adding new features, helping minimize the complexity and bloat of the platform. This is why I expect platforms to have APIs, so that I can get at what I need without feeling like I am blocked by their road map, or vision of the platform. I&rsquo;m used to having alternative visions of how to apply tools and services, so the API is where I get my work done.</p>
<p class="p1">I am doing a lot of work around syncing my legacy API catalog with my Postman workspaces, making sure there are Postman collections available for each API I am keeping an eye on. Postman is definitely not fully ready for managing hundreds of APIs, let alone thousands of APIs without some bottlenecks. This is fine. It will get there. I&rsquo;m still able to do what I need to accomplish, and I will also be able to benefit from the mocking, testing, documentation, runners, and monitoring, while also potentially influencing the road map with my feedback around streamlining collection, team, and workspace management with thousands of separate APIs.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/11/26/pulling-all-my-postman-collections-using-the-postman-api/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/11/26/is-it-an-amazon-or-aws-branded-service/">Is It An Amazon Or Aws Branded Service</a></h3>
        <span class="post-date">26 Nov 2019</span>
        ---
published: true
layout: post
title: 'Is it an Amazon or AWS Branded Service'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/copper_circuit_img_7072.jpg
---
<p><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/copper_circuit_img_7072.jpg" alt="" width="40%" align="right" /></p>
<p class="p1"><a href="https://github.com/api-evangelist/aws">I&rsquo;m working on 50+ AWS Postman collections at the moment</a>, as well as <a href="https://github.com/api-evangelist/aws/blob/master/environments.md">crafting Postman environments for use across them</a>. I&rsquo;ve encountered some namespace challenges in this work, and I was needing to establish a naming convention for the key / value pairs I&rsquo;m using within my Postman environments. To help establish the namespaces I am just taking the display name for each of the APIs I am profiling, but one thing I&rsquo;m noticing is that there are two different names in use across APIs, being either AWS or Amazon&mdash;with no rhyme or reason why a service is labeled one way or the other.<span>&nbsp;</span></p>
<p class="p1"><a href="https://docs.aws.amazon.com">Looking down the list of all the services they have</a>, I would say that <strong>AWS</strong> is more prominent than <strong>Amazon</strong> as the beginning namespace for each service. I&rsquo;m just curious if there is any guidance or rhyme or reason to the naming of services launched under AWS. At first it feels like I&rsquo;m being too pedantic, but from a branding, and even programmatically across services, it seems like having a common naming convention for services would make sense. <a href="http://apievangelist.com/2019/11/25/api-design-consistency-across-amazon-web-services/">Like my thoughts on the API design consistency across AWS APIs</a>, I&rsquo;m not trying to shame AWS, I am just trying to learn from what is happening, and share what I find with other API providers. I regularly use Amazon as an example to learn from in my API storytelling, which unfortunately sets them up for constructive criticism as well--I am sure they can handle. ;-)</p>
<p class="p1">For my environment variable challenge I am simply going to prefix my variables with aws as the service namespace. I&rsquo;m just standardizing for shortness, ease of use, and distinguishing AWS APIs from the other API providers I&rsquo;m profiling. I was more interested in just pausing and thinking about why this occurs, and work to think more deeply about how we name our APIs. For me, the lessons around naming our APIs is more about pushing us to put ourselves in our consumers shoes, and see our platform from the outside in. Something like naming of our services might seem trivial when you are inside of the firewall, but when it comes to working externally with the rest of the world these things matter a lot.</p>
<p class="p1">When you <a href="https://docs.aws.amazon.com">look down the list of services on their primary documentation page</a>&nbsp;it is interesting to see whether a service is prefixed with AWS or Amazon, and I also notice there are a handful like Service Quotas, Tag Editor, and Elastic Load Balancing that have no prefix at all. Interesting. I love working with Amazon APIs because there are always a lot of lessons present. Amazon has been doing APIs for a long time, and they have a lot of different services available. Like every other API provider they have to make a lot of decisions along the way across many different teams, and sometimes these little things can fall through the cracks if we aren&rsquo;t talking about, and telling stories about what is happening. The naming of our APIs is one of the most important steps you can take early on in an APIs life cycle, and having a well branded approach that is communicated consistently across teams can make a big impact down the road.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/11/26/is-it-an-amazon-or-aws-branded-service/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/11/25/where-o-where-is-my-api-key/">Where O Where Is My Api Key</a></h3>
        <span class="post-date">25 Nov 2019</span>
        ---
published: true
layout: post
title: 'Where O Where Is My API Key'
image: http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/udnie_img_2410.jpg
---
<p><img style="padding: 15px;" src="http://kinlane-productions2.s3.amazonaws.com/api_evangelist_site/blog/udnie_img_2410.jpg" alt="" width="40%" align="right" /></p>
<p class="p1">Finding your API key for an API provider can be a real pain in the ass. Depending on the account it can be buried deep within your settings, or possibly out in the back 40 in another separate developer account. I&rsquo;m not even talking about OAuth here, I am just talking about obtaining one or more API keys to access the valuable API resources you desire from a free service, or even from a service you are paying for. There is no standard for how to create, define, storage, and access API keys. It has been something that API providers have helped standardize somewhat (I guess?), but ultimately there is no unified way for me to access all the API keys I use across the thousands of API I use &mdash; yes, I do use thousands of APIs, because I am the API Evangelist.</p>
<p class="p1">Why can&rsquo;t API keys be easier to find, and exist as a default part of our platform accounts. They shouldn&rsquo;t be this hard to generate, find, and put to use. I keep coming back to my CloudFlare DNS application experience on this subject. Next to some of the actions I can take in the CloudFlare UI is a link to the API call to make the same action, complete with my API keys to make the calls. I don&rsquo;t have to do anything else other than use the application to find the keys. Can you imagine if every UI element in every application had the underlying API call available right next to it with API keys? Can you imagine if every API call came back with a link in the response to where I can take the same action in the UI? Maybe I have a different view of the world than others, but this seems like it should be common place in the tech sector. I&rsquo;m afraid many folks have seen APIs as some technical thing over there for too long, and wrongly feel that the average person shouldn&rsquo;t worry their head about these things.</p>
<p class="p1">The reasons why APIs are often so hidden, and API keys hidden even further is that most applications really don&rsquo;t want you snooping around under the hood. Most do not want you to understand what is happening or have access to the data behind an application, let alone to all of the actions being taken. When some applications genuinely do want people to use the API, the interfaces and APIs are both are often designed and developed by folks who haven&rsquo;t put much thought into the bigger picture when it comes to blending the world of web apps and APIs, as well as how to actually incentivize API usage&mdash;they are just tasked with a job of building a UI or delivering API, nothing much more than that. It is fascinating to me that we will publish APIs for our applications, intentionally providing an external interface for others to use, but then not put much thought into what it will be like for those people to actually learn about and put our APIs to use.</p>
<p class="p1">If you have an API, find a fresh email account and sign up for your service with it. See how long it takes you to go from new signup to finding your key. Now close the account, return to your developer portal, log in and see ho long it takes you to find your key again. See if you can reduce friction in either of these processes, making it dead simple for your API consumers to get the keys they need. Additionally, make sure all the information is present with the key to help them be successful with authentication using their keys. Also consider bundling authentication along with the API call for each UI element, preventing consumers from having to dig around in some far away account to make the API magic happen. Let&rsquo;s work a little hard to make our APIs the default thought behind every UI action we are taking within our applications, and I&rsquo;m guessing we&rsquo;d see our API adoption number shift pretty dramatically in response.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/11/25/where-o-where-is-my-api-key/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/11/25/api-design-consistency-across-amazon-web-services/">Api Design Consistency Across Amazon Web Services</a></h3>
        <span class="post-date">25 Nov 2019</span>
        ---
published: true
layout: post
title: 'API Design Consistency Across Amazon Web Services'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/scream-IMG_8494.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/scream-IMG_8494.jpg" alt="" width="40%" align="right" /></p>
<p class="p1"><a href="https://github.com/api-evangelist/aws">I have been crafting Postman collections for as many AWS APIs as I can before re:Invent</a>. As I work my way through the different APIs I&rdquo;m reminded of the difficulties involved in API consistency and governance at large enterprise organizations. While most AWS APIs employ a pretty formulaic XML RPC design, there are variations within how these RPC APIs work, but there are also several outliers of other more RESTful and even full blown hypermedia APIs present. Making for a pretty wild mix of API resources to put to work, something that has been abstracted away as part of their SDKs, but is painfully present when directly integrating with APIs across multiple services.</p>
<p class="p1">From the lay of the land I&rsquo;m guessing AWS had instituted their primary XML RPC approach, and baked that into governance law across the organization in early days. Over the years, after significant growth, some groups were able to publish APIs outside of this pattern, resulting in the patchwork quilt of services that are present. The most notable and ironic deviation from this pattern is the API for the AWS API Gateway, which employs a RESTful approach using the HAL media type. Which personally, I would prefer as the dominate pattern across all the service, but sadly it is the more legacy XML RPC pattern that dominates. I get it, you can&rsquo;t go changing the AWS S3 or EC2 APIs now, they are known for their stability, but I still think there are some important API design and governance lessons present in the valuable cloud API stack.</p>
<p class="p2">The first lesson in all of this I&rsquo;d say is that we need to make sure and establish your API design governance early on and socialize across all teams&mdash;even new ones. The second lesson I&rsquo;d say is to make sure and review your API design governance regularly to make sure you aren&rsquo;t missing any healthier patterns that may have come along. You don&rsquo;t want to get stuck with the one pattern that will introduce friction into the API integration process. Thirdly, I&rsquo;d say you can really smooth out bumps in your API design with some decent SDKs, as Amazon has. I&rsquo;ve used both their Node.js and PHP SDKs, and have found them to be pretty straightforward, and that they go a long way to smooth out the rough design that exists across different services. I don&rsquo;t think you should be always relying on your SDKs as.a crutch here, but it is good to know that you have options once you&rsquo;ve baked something into your production APIs.</p>
<p class="p1">I think course correcting the API design governance ship at AWS will be very hard, and take over decade. I&rsquo;m more using this as a lesson for other API providers. I&rsquo;m not saying Amazon shouldn&rsquo;t change, on the contrary, they should take the lead in publishing an API design guide like Microsoft and Google have, setting the tone for how future teams will delver their APIs. If done well, the guides can also provide a blueprint for AWS customers to follow when publishing their own APIs to the AWS API Gateway. Ideally, API design governance should be baked into the AWS API Gateway workflow, and if AWS believes in their own services, they&rsquo;d be using AWS API Gateway and their own prescribed API design workflow for all future APIs being delivered on the cloud platform. Some day, I will better document the geological layers of API design that have been played down over the entire history of AWS--I just need more time in my schedule. ;-)</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/11/25/api-design-consistency-across-amazon-web-services/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  
	 	
    
			
        <h3><a href="https://apievangelist.com/2019/11/25/api-copyright-directories/">Api Copyright Directories</a></h3>
        <span class="post-date">25 Nov 2019</span>
        ---
published: true
layout: post
title: 'API Copyright: Directories'
image: https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/aws-s3-stories-containership-dali-three.jpg
---
<p><img style="padding: 15px;" src="https://s3.amazonaws.com/kinlane-productions2/algorotoscope-master/aws-s3-stories-containership-dali-three.jpg" alt="" width="40%" align="right" /></p>
<p class="p1"><span class="s1"><a href="http://apievangelist.com/2019/11/17/api-copyright-heading-to-the-supreme-court/">I am gearing up for API copyright heading to the Supreme Court</a></span>, having another look at whether or not the naming and ordering of your API interface is copyrightable, as well as whether or not reimplementation of it can be considered fair use. To help strengthen my arguments that API should not be copyrightable I wanted to work through my thoughts about how APIs are similar to other existing concepts that are not copyrightable. One of the newer concepts I&rdquo;m working with to help strengthen my argument that copyright does not apply to APIs involves the directory, and shining a light on the fact that APIs are just a directory of our digital resources.</p>
<p class="p1">As with all of my API storytelling, I am focused exclusively on web API. Occasionally you&rsquo;l hear me talking about language and platform SDK APIs, browser APIs, and other variations, but the majority of what I mean when I say API is done via public DNS over HTTP, HTTP/2, and sometimes TCP. All of these APIs are just a directory of <a href="https://en.wikipedia.org/wiki/Uniform_Resource_Identifier">Uniform Resource Identifiers (URIs)</a>&nbsp;of corporate and institutional digital assets. Modern APIs most often leverage DNS, providing a machine readable listing of resources that are available within a specific domain. The domain and the resulting API directory are not creative expressions, they are an address that points to a directory of digital assets, allowing them to be found by developers for use in other applications and systems. APIs are not a form of creative expression, they are just helping companies, organizations, institutions, and government agencies make their digital resources and capabilities discoverable.</p>
<p class="p1">I can easily make the argument that APIs are simply a directory or menu of organizational resources and capabilities. Due to the diverse nature of what an API can be, I can also easily apply the analogy that APIs are also recipes. All the above is true. As with my restaurant menu and recipe stories, people have trouble believing that APIs are copyrightable because they struggle with separating the API from the data, content, media, algorithms, and processes being delivered using APIs. It is unlikely that your data is copyrightable, but the content and media might be. Your algorithms and processes behind the APIs might also be protected using patents. However, your directory for finding this intellectual property is not something that falls under copyright. Your API is just how you and your partners will discover, access, and put the valuable intellectual property for your organization to work wherever it is needed online.</p>
<p class="p1">APIs will continue to play an important role in defining copyrighted and patented intellectual property, but they should not be considered part of the portfolio. They simply are about access to the business IP portfolio, providing an authenticated, rate limited, logged, audible, and monetizable directory that governs how digital assets are used across desktop, web, mobile, device, and network applications. If the Supreme Court properly scrutinizes the layers of modern API infrastructure that is behind almost all applications in use online today, they will understand the nuances of how APIs do what they do, and begin to see how it important it is to keep this directory layer of the online economy well greased and open for business. If we allow an IP thicket to emerge at the integration layer of the web it will only work in favor of large tech companies, and lock out the smaller startups who are responsible for much of the innovation we have seen over the last twenty years.</p>

        <ul class="actions" style="text-align: center;">
          <li><a href="https://apievangelist.com/2019/11/25/api-copyright-directories/" class="button big">Details</a></li>
        </ul>
      	<center><hr style="width: 75%;" /></center>
				
    
  

<p align="center"><a href="http://apievangelist.com/archive/"><strong>View Previous Posts Via Archives</strong></a></p>

  </div>
</section>

              <footer>
	<hr>
	<div class="features">
		<article>
			<div class="content">
				<p align="center"><a href="https://www.postman.com" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/partners/postman-logo.png" width="75%" style="padding: 15px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
		<article>
			<div class="content">
				<p align="center"><a href="https://github.com/postmanlabs/newman" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/postman/newman-logo.png" width="75%" style="padding: 15px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
	</div>
	<hr>
	<p align="center">
		relevant work:
		<a href="http://apievangelist.com">apievangelist.com</a> |
		<a href="http://adopta.agency">adopta.agency</a>
	</p>
</footer>


            </div>
          </div>

          <div id="sidebar">
            <div class="inner">

              <nav id="menu">
  <header class="major">
    <h2>Menu</h2>
  </header>
  <ul>
    <li><a href="/">Homepage</a></li>
    <li><a href="/blog/">Blog</a></li>
    <li><a href="/about/">About</a></li>
  </ul>
</nav>

              <section>
	<div class="mini-posts">
		<header>
			<h2 style="text-align: center;"><i>API Evangelist Sponsors</i></h2>
		</header>
		<article>
			<div class="content">
				<p align="center"><a href="https://www.postman.com" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/partners/postman-logo.png" width="75%" style="padding: 5px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
		<article>
			<div class="content">
				<p align="center"><a href="https://tyk.io/" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/tyk/tyk-logo.png" width="75%" style="padding: 5px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
		<article>
			<div class="content">
				<p align="center"><a href="https://www.openapis.org/" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/specifications/openapi.png" width="75%" style="padding: 5px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
		<article>
			<div class="content">
				<p align="center"><a href="https://www.asyncapi.com/" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/asyncapi/asyncapi-horiozontal.png" width="75%" style="padding: 5px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
		<article>
			<div class="content">
				<p align="center"><a href="https://json-schema.org/" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/specifications/json-schema.png" width="75%" style="padding: 5px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
		<article>
			<div class="content">
				<p align="center"><a href="https://github.com/postmanlabs/newman" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/postman/newman-logo.png" width="75%" style="padding: 5px; border: 1px solid #000;" /></a></p>
			</div>
		</article>
	</div>
</section>


            </div>
          </div>

      </div>

<script src="/assets/js/skel.min.js"></script>
<script src="/assets/js/util.js"></script>
<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
<script src="/assets/js/main.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-1119465-51"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-1119465-51');
</script>


</body>
</html>
